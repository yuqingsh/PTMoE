
EnvironmentNameNotFound: Could not find conda environment: moe3d
You can list all discoverable environments with `conda info --envs`.


[2025-05-11 13:09:37,910 INFO train.py line 136 288342] => Loading config ...
[2025-05-11 13:09:37,911 INFO train.py line 138 288342] Save path: exp/ptv3/nuscenes_norm-semseg-pt-v3m1-0-nxnynzr_168597
[2025-05-11 13:09:38,461 INFO train.py line 139 288342] Config:
weight = None
resume = False
evaluate = True
test_only = False
seed = 24801787
save_path = 'exp/ptv3/nuscenes_norm-semseg-pt-v3m1-0-nxnynzr_168597'
num_worker = 16
batch_size = 12
batch_size_val = None
batch_size_test = None
epoch = 50
eval_epoch = 50
clip_grad = None
sync_bn = False
enable_amp = True
amp_dtype = 'float16'
empty_cache = False
empty_cache_per_epoch = False
find_unused_parameters = False
enable_wandb = True
wandb_project = 'pointcept'
wandb_key = None
mix_prob = 0.8
param_dicts = [dict(keyword='block', lr=0.0002)]
hooks = [
    dict(type='CheckpointLoader'),
    dict(type='ModelHook'),
    dict(type='IterationTimer', warmup_iter=2),
    dict(type='InformationWriter'),
    dict(type='SemSegEvaluator'),
    dict(type='CheckpointSaver', save_freq=None),
    dict(type='PreciseEvaluator', test_last=False)
]
train = dict(type='DefaultTrainer')
test = dict(type='SemSegTester', verbose=True)
model = dict(
    type='DefaultSegmentorV2',
    num_classes=16,
    backbone_out_channels=64,
    backbone=dict(
        type='PT-v3m1',
        in_channels=4,
        order=['z', 'z-trans', 'hilbert', 'hilbert-trans'],
        stride=(2, 2, 2, 2),
        enc_depths=(2, 2, 2, 6, 2),
        enc_channels=(32, 64, 128, 256, 512),
        enc_num_head=(2, 4, 8, 16, 32),
        enc_patch_size=(1024, 1024, 1024, 1024, 1024),
        dec_depths=(2, 2, 2, 2),
        dec_channels=(64, 64, 128, 256),
        dec_num_head=(4, 4, 8, 16),
        dec_patch_size=(1024, 1024, 1024, 1024),
        mlp_ratio=4,
        qkv_bias=True,
        qk_scale=None,
        attn_drop=0.0,
        proj_drop=0.0,
        drop_path=0.3,
        shuffle_orders=True,
        pre_norm=True,
        enable_rpe=False,
        enable_flash=True,
        upcast_attention=False,
        upcast_softmax=False,
        cls_mode=False,
        pdnorm_bn=False,
        pdnorm_ln=False,
        pdnorm_decouple=True,
        pdnorm_adaptive=False,
        pdnorm_affine=True,
        pdnorm_conditions=('nuScenes', 'SemanticKITTI', 'Waymo')),
    criteria=[
        dict(type='CrossEntropyLoss', loss_weight=1.0, ignore_index=-1),
        dict(
            type='LovaszLoss',
            mode='multiclass',
            loss_weight=1.0,
            ignore_index=-1)
    ])
optimizer = dict(type='AdamW', lr=0.002, weight_decay=0.005)
scheduler = dict(
    type='OneCycleLR',
    max_lr=[0.002, 0.0002],
    pct_start=0.04,
    anneal_strategy='cos',
    div_factor=10.0,
    final_div_factor=100.0)
dataset_type = 'NuScenesNormDataset'
data_root = 'data/nuscenes'
ignore_index = -1
names = [
    'barrier', 'bicycle', 'bus', 'car', 'construction_vehicle', 'motorcycle',
    'pedestrian', 'traffic_cone', 'trailer', 'truck', 'driveable_surface',
    'other_flat', 'sidewalk', 'terrain', 'manmade', 'vegetation'
]
data = dict(
    num_classes=16,
    ignore_index=-1,
    names=[
        'barrier', 'bicycle', 'bus', 'car', 'construction_vehicle',
        'motorcycle', 'pedestrian', 'traffic_cone', 'trailer', 'truck',
        'driveable_surface', 'other_flat', 'sidewalk', 'terrain', 'manmade',
        'vegetation'
    ],
    train=dict(
        type='NuScenesNormDataset',
        split='train',
        data_root='data/nuscenes',
        transform=[
            dict(
                type='RandomRotate',
                angle=[-1, 1],
                axis='z',
                center=[0, 0, 0],
                p=0.5),
            dict(type='RandomScale', scale=[0.9, 1.1]),
            dict(type='RandomFlip', p=0.5),
            dict(type='RandomJitter', sigma=0.005, clip=0.02),
            dict(
                type='GridSample',
                grid_size=0.05,
                hash_type='fnv',
                mode='train',
                return_grid_coord=True),
            dict(type='ToTensor'),
            dict(
                type='Collect',
                keys=('coord', 'grid_coord', 'segment'),
                feat_keys=('view_direction', 'strength'))
        ],
        test_mode=False,
        ignore_index=-1,
        loop=1),
    val=dict(
        type='NuScenesNormDataset',
        split='val',
        data_root='data/nuscenes',
        transform=[
            dict(
                type='GridSample',
                grid_size=0.05,
                hash_type='fnv',
                mode='train',
                return_grid_coord=True),
            dict(type='ToTensor'),
            dict(
                type='Collect',
                keys=('coord', 'grid_coord', 'segment'),
                feat_keys=('view_direction', 'strength'))
        ],
        test_mode=False,
        ignore_index=-1),
    test=dict(
        type='NuScenesNormDataset',
        split='val',
        data_root='data/nuscenes',
        transform=[
            dict(type='Copy', keys_dict=dict(segment='origin_segment')),
            dict(
                type='GridSample',
                grid_size=0.025,
                hash_type='fnv',
                mode='train',
                return_inverse=True)
        ],
        test_mode=True,
        test_cfg=dict(
            voxelize=dict(
                type='GridSample',
                grid_size=0.05,
                hash_type='fnv',
                mode='test',
                return_grid_coord=True),
            crop=None,
            post_transform=[
                dict(type='ToTensor'),
                dict(
                    type='Collect',
                    keys=('coord', 'grid_coord', 'index'),
                    feat_keys=('view_direction', 'strength'))
            ],
            aug_transform=[[{
                'type': 'RandomScale',
                'scale': [0.9, 0.9]
            }], [{
                'type': 'RandomScale',
                'scale': [0.95, 0.95]
            }], [{
                'type': 'RandomScale',
                'scale': [1, 1]
            }], [{
                'type': 'RandomScale',
                'scale': [1.05, 1.05]
            }], [{
                'type': 'RandomScale',
                'scale': [1.1, 1.1]
            }],
                           [{
                               'type': 'RandomScale',
                               'scale': [0.9, 0.9]
                           }, {
                               'type': 'RandomFlip',
                               'p': 1
                           }],
                           [{
                               'type': 'RandomScale',
                               'scale': [0.95, 0.95]
                           }, {
                               'type': 'RandomFlip',
                               'p': 1
                           }],
                           [{
                               'type': 'RandomScale',
                               'scale': [1, 1]
                           }, {
                               'type': 'RandomFlip',
                               'p': 1
                           }],
                           [{
                               'type': 'RandomScale',
                               'scale': [1.05, 1.05]
                           }, {
                               'type': 'RandomFlip',
                               'p': 1
                           }],
                           [{
                               'type': 'RandomScale',
                               'scale': [1.1, 1.1]
                           }, {
                               'type': 'RandomFlip',
                               'p': 1
                           }]]),
        ignore_index=-1))
num_worker_per_gpu = 4
batch_size_per_gpu = 3
batch_size_val_per_gpu = 1
batch_size_test_per_gpu = 1

[2025-05-11 13:09:38,461 INFO train.py line 140 288342] => Building model ...
[2025-05-11 13:09:39,206 INFO train.py line 241 288342] Num params: 46159312
[2025-05-11 13:09:39,392 INFO train.py line 142 288342] => Building writer ...
[2025-05-11 13:09:39,415 INFO train.py line 251 288342] Tensorboard writer logging dir: exp/ptv3/nuscenes_norm-semseg-pt-v3m1-0-nxnynzr_168597
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: yuqingsh (yuqingsh-tongji-university) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: creating run
wandb: Tracking run with wandb version 0.19.9
wandb: Run data is saved locally in exp/ptv3/nuscenes_norm-semseg-pt-v3m1-0-nxnynzr_168597/wandb/run-20250511_130941-w2ow55z3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ptv3/nuscenes_norm-semseg-pt-v3m1-0-nxnynzr_168597
wandb: â­ï¸ View project at https://wandb.ai/yuqingsh-tongji-university/pointcept
wandb: ðŸš€ View run at https://wandb.ai/yuqingsh-tongji-university/pointcept/runs/w2ow55z3
[2025-05-11 13:09:46,714 INFO train.py line 144 288342] => Building train dataset & dataloader ...
[2025-05-11 13:09:50,344 INFO defaults.py line 70 288342] Totally 28130 x 1 samples in nuscenes train set.
[2025-05-11 13:09:50,347 INFO train.py line 146 288342] => Building val dataset & dataloader ...
[2025-05-11 13:09:50,859 INFO defaults.py line 70 288342] Totally 6019 x 1 samples in nuscenes val set.
[2025-05-11 13:09:50,859 INFO train.py line 148 288342] => Building optimize, scheduler, scaler(amp) ...
[2025-05-11 13:09:50,862 INFO optimizer.py line 54 288342] Params Group 1 - lr: 0.002; Params: ['module.seg_head.weight', 'module.seg_head.bias', 'module.backbone.embedding.stem.conv.weight', 'module.backbone.embedding.stem.norm.weight', 'module.backbone.embedding.stem.norm.bias', 'module.backbone.enc.enc1.down.proj.weight', 'module.backbone.enc.enc1.down.proj.bias', 'module.backbone.enc.enc1.down.norm.0.weight', 'module.backbone.enc.enc1.down.norm.0.bias', 'module.backbone.enc.enc2.down.proj.weight', 'module.backbone.enc.enc2.down.proj.bias', 'module.backbone.enc.enc2.down.norm.0.weight', 'module.backbone.enc.enc2.down.norm.0.bias', 'module.backbone.enc.enc3.down.proj.weight', 'module.backbone.enc.enc3.down.proj.bias', 'module.backbone.enc.enc3.down.norm.0.weight', 'module.backbone.enc.enc3.down.norm.0.bias', 'module.backbone.enc.enc4.down.proj.weight', 'module.backbone.enc.enc4.down.proj.bias', 'module.backbone.enc.enc4.down.norm.0.weight', 'module.backbone.enc.enc4.down.norm.0.bias', 'module.backbone.dec.dec3.up.proj.0.weight', 'module.backbone.dec.dec3.up.proj.0.bias', 'module.backbone.dec.dec3.up.proj.1.weight', 'module.backbone.dec.dec3.up.proj.1.bias', 'module.backbone.dec.dec3.up.proj_skip.0.weight', 'module.backbone.dec.dec3.up.proj_skip.0.bias', 'module.backbone.dec.dec3.up.proj_skip.1.weight', 'module.backbone.dec.dec3.up.proj_skip.1.bias', 'module.backbone.dec.dec2.up.proj.0.weight', 'module.backbone.dec.dec2.up.proj.0.bias', 'module.backbone.dec.dec2.up.proj.1.weight', 'module.backbone.dec.dec2.up.proj.1.bias', 'module.backbone.dec.dec2.up.proj_skip.0.weight', 'module.backbone.dec.dec2.up.proj_skip.0.bias', 'module.backbone.dec.dec2.up.proj_skip.1.weight', 'module.backbone.dec.dec2.up.proj_skip.1.bias', 'module.backbone.dec.dec1.up.proj.0.weight', 'module.backbone.dec.dec1.up.proj.0.bias', 'module.backbone.dec.dec1.up.proj.1.weight', 'module.backbone.dec.dec1.up.proj.1.bias', 'module.backbone.dec.dec1.up.proj_skip.0.weight', 'module.backbone.dec.dec1.up.proj_skip.0.bias', 'module.backbone.dec.dec1.up.proj_skip.1.weight', 'module.backbone.dec.dec1.up.proj_skip.1.bias', 'module.backbone.dec.dec0.up.proj.0.weight', 'module.backbone.dec.dec0.up.proj.0.bias', 'module.backbone.dec.dec0.up.proj.1.weight', 'module.backbone.dec.dec0.up.proj.1.bias', 'module.backbone.dec.dec0.up.proj_skip.0.weight', 'module.backbone.dec.dec0.up.proj_skip.0.bias', 'module.backbone.dec.dec0.up.proj_skip.1.weight', 'module.backbone.dec.dec0.up.proj_skip.1.bias'].
[2025-05-11 13:09:50,862 INFO optimizer.py line 54 288342] Params Group 2 - lr: 0.0002; Params: ['module.backbone.enc.enc0.block0.cpe.0.weight', 'module.backbone.enc.enc0.block0.cpe.0.bias', 'module.backbone.enc.enc0.block0.cpe.1.weight', 'module.backbone.enc.enc0.block0.cpe.1.bias', 'module.backbone.enc.enc0.block0.cpe.2.weight', 'module.backbone.enc.enc0.block0.cpe.2.bias', 'module.backbone.enc.enc0.block0.norm1.0.weight', 'module.backbone.enc.enc0.block0.norm1.0.bias', 'module.backbone.enc.enc0.block0.attn.qkv.weight', 'module.backbone.enc.enc0.block0.attn.qkv.bias', 'module.backbone.enc.enc0.block0.attn.proj.weight', 'module.backbone.enc.enc0.block0.attn.proj.bias', 'module.backbone.enc.enc0.block0.norm2.0.weight', 'module.backbone.enc.enc0.block0.norm2.0.bias', 'module.backbone.enc.enc0.block0.mlp.0.fc1.weight', 'module.backbone.enc.enc0.block0.mlp.0.fc1.bias', 'module.backbone.enc.enc0.block0.mlp.0.fc2.weight', 'module.backbone.enc.enc0.block0.mlp.0.fc2.bias', 'module.backbone.enc.enc0.block1.cpe.0.weight', 'module.backbone.enc.enc0.block1.cpe.0.bias', 'module.backbone.enc.enc0.block1.cpe.1.weight', 'module.backbone.enc.enc0.block1.cpe.1.bias', 'module.backbone.enc.enc0.block1.cpe.2.weight', 'module.backbone.enc.enc0.block1.cpe.2.bias', 'module.backbone.enc.enc0.block1.norm1.0.weight', 'module.backbone.enc.enc0.block1.norm1.0.bias', 'module.backbone.enc.enc0.block1.attn.qkv.weight', 'module.backbone.enc.enc0.block1.attn.qkv.bias', 'module.backbone.enc.enc0.block1.attn.proj.weight', 'module.backbone.enc.enc0.block1.attn.proj.bias', 'module.backbone.enc.enc0.block1.norm2.0.weight', 'module.backbone.enc.enc0.block1.norm2.0.bias', 'module.backbone.enc.enc0.block1.mlp.0.fc1.weight', 'module.backbone.enc.enc0.block1.mlp.0.fc1.bias', 'module.backbone.enc.enc0.block1.mlp.0.fc2.weight', 'module.backbone.enc.enc0.block1.mlp.0.fc2.bias', 'module.backbone.enc.enc1.block0.cpe.0.weight', 'module.backbone.enc.enc1.block0.cpe.0.bias', 'module.backbone.enc.enc1.block0.cpe.1.weight', 'module.backbone.enc.enc1.block0.cpe.1.bias', 'module.backbone.enc.enc1.block0.cpe.2.weight', 'module.backbone.enc.enc1.block0.cpe.2.bias', 'module.backbone.enc.enc1.block0.norm1.0.weight', 'module.backbone.enc.enc1.block0.norm1.0.bias', 'module.backbone.enc.enc1.block0.attn.qkv.weight', 'module.backbone.enc.enc1.block0.attn.qkv.bias', 'module.backbone.enc.enc1.block0.attn.proj.weight', 'module.backbone.enc.enc1.block0.attn.proj.bias', 'module.backbone.enc.enc1.block0.norm2.0.weight', 'module.backbone.enc.enc1.block0.norm2.0.bias', 'module.backbone.enc.enc1.block0.mlp.0.fc1.weight', 'module.backbone.enc.enc1.block0.mlp.0.fc1.bias', 'module.backbone.enc.enc1.block0.mlp.0.fc2.weight', 'module.backbone.enc.enc1.block0.mlp.0.fc2.bias', 'module.backbone.enc.enc1.block1.cpe.0.weight', 'module.backbone.enc.enc1.block1.cpe.0.bias', 'module.backbone.enc.enc1.block1.cpe.1.weight', 'module.backbone.enc.enc1.block1.cpe.1.bias', 'module.backbone.enc.enc1.block1.cpe.2.weight', 'module.backbone.enc.enc1.block1.cpe.2.bias', 'module.backbone.enc.enc1.block1.norm1.0.weight', 'module.backbone.enc.enc1.block1.norm1.0.bias', 'module.backbone.enc.enc1.block1.attn.qkv.weight', 'module.backbone.enc.enc1.block1.attn.qkv.bias', 'module.backbone.enc.enc1.block1.attn.proj.weight', 'module.backbone.enc.enc1.block1.attn.proj.bias', 'module.backbone.enc.enc1.block1.norm2.0.weight', 'module.backbone.enc.enc1.block1.norm2.0.bias', 'module.backbone.enc.enc1.block1.mlp.0.fc1.weight', 'module.backbone.enc.enc1.block1.mlp.0.fc1.bias', 'module.backbone.enc.enc1.block1.mlp.0.fc2.weight', 'module.backbone.enc.enc1.block1.mlp.0.fc2.bias', 'module.backbone.enc.enc2.block0.cpe.0.weight', 'module.backbone.enc.enc2.block0.cpe.0.bias', 'module.backbone.enc.enc2.block0.cpe.1.weight', 'module.backbone.enc.enc2.block0.cpe.1.bias', 'module.backbone.enc.enc2.block0.cpe.2.weight', 'module.backbone.enc.enc2.block0.cpe.2.bias', 'module.backbone.enc.enc2.block0.norm1.0.weight', 'module.backbone.enc.enc2.block0.norm1.0.bias', 'module.backbone.enc.enc2.block0.attn.qkv.weight', 'module.backbone.enc.enc2.block0.attn.qkv.bias', 'module.backbone.enc.enc2.block0.attn.proj.weight', 'module.backbone.enc.enc2.block0.attn.proj.bias', 'module.backbone.enc.enc2.block0.norm2.0.weight', 'module.backbone.enc.enc2.block0.norm2.0.bias', 'module.backbone.enc.enc2.block0.mlp.0.fc1.weight', 'module.backbone.enc.enc2.block0.mlp.0.fc1.bias', 'module.backbone.enc.enc2.block0.mlp.0.fc2.weight', 'module.backbone.enc.enc2.block0.mlp.0.fc2.bias', 'module.backbone.enc.enc2.block1.cpe.0.weight', 'module.backbone.enc.enc2.block1.cpe.0.bias', 'module.backbone.enc.enc2.block1.cpe.1.weight', 'module.backbone.enc.enc2.block1.cpe.1.bias', 'module.backbone.enc.enc2.block1.cpe.2.weight', 'module.backbone.enc.enc2.block1.cpe.2.bias', 'module.backbone.enc.enc2.block1.norm1.0.weight', 'module.backbone.enc.enc2.block1.norm1.0.bias', 'module.backbone.enc.enc2.block1.attn.qkv.weight', 'module.backbone.enc.enc2.block1.attn.qkv.bias', 'module.backbone.enc.enc2.block1.attn.proj.weight', 'module.backbone.enc.enc2.block1.attn.proj.bias', 'module.backbone.enc.enc2.block1.norm2.0.weight', 'module.backbone.enc.enc2.block1.norm2.0.bias', 'module.backbone.enc.enc2.block1.mlp.0.fc1.weight', 'module.backbone.enc.enc2.block1.mlp.0.fc1.bias', 'module.backbone.enc.enc2.block1.mlp.0.fc2.weight', 'module.backbone.enc.enc2.block1.mlp.0.fc2.bias', 'module.backbone.enc.enc3.block0.cpe.0.weight', 'module.backbone.enc.enc3.block0.cpe.0.bias', 'module.backbone.enc.enc3.block0.cpe.1.weight', 'module.backbone.enc.enc3.block0.cpe.1.bias', 'module.backbone.enc.enc3.block0.cpe.2.weight', 'module.backbone.enc.enc3.block0.cpe.2.bias', 'module.backbone.enc.enc3.block0.norm1.0.weight', 'module.backbone.enc.enc3.block0.norm1.0.bias', 'module.backbone.enc.enc3.block0.attn.qkv.weight', 'module.backbone.enc.enc3.block0.attn.qkv.bias', 'module.backbone.enc.enc3.block0.attn.proj.weight', 'module.backbone.enc.enc3.block0.attn.proj.bias', 'module.backbone.enc.enc3.block0.norm2.0.weight', 'module.backbone.enc.enc3.block0.norm2.0.bias', 'module.backbone.enc.enc3.block0.mlp.0.fc1.weight', 'module.backbone.enc.enc3.block0.mlp.0.fc1.bias', 'module.backbone.enc.enc3.block0.mlp.0.fc2.weight', 'module.backbone.enc.enc3.block0.mlp.0.fc2.bias', 'module.backbone.enc.enc3.block1.cpe.0.weight', 'module.backbone.enc.enc3.block1.cpe.0.bias', 'module.backbone.enc.enc3.block1.cpe.1.weight', 'module.backbone.enc.enc3.block1.cpe.1.bias', 'module.backbone.enc.enc3.block1.cpe.2.weight', 'module.backbone.enc.enc3.block1.cpe.2.bias', 'module.backbone.enc.enc3.block1.norm1.0.weight', 'module.backbone.enc.enc3.block1.norm1.0.bias', 'module.backbone.enc.enc3.block1.attn.qkv.weight', 'module.backbone.enc.enc3.block1.attn.qkv.bias', 'module.backbone.enc.enc3.block1.attn.proj.weight', 'module.backbone.enc.enc3.block1.attn.proj.bias', 'module.backbone.enc.enc3.block1.norm2.0.weight', 'module.backbone.enc.enc3.block1.norm2.0.bias', 'module.backbone.enc.enc3.block1.mlp.0.fc1.weight', 'module.backbone.enc.enc3.block1.mlp.0.fc1.bias', 'module.backbone.enc.enc3.block1.mlp.0.fc2.weight', 'module.backbone.enc.enc3.block1.mlp.0.fc2.bias', 'module.backbone.enc.enc3.block2.cpe.0.weight', 'module.backbone.enc.enc3.block2.cpe.0.bias', 'module.backbone.enc.enc3.block2.cpe.1.weight', 'module.backbone.enc.enc3.block2.cpe.1.bias', 'module.backbone.enc.enc3.block2.cpe.2.weight', 'module.backbone.enc.enc3.block2.cpe.2.bias', 'module.backbone.enc.enc3.block2.norm1.0.weight', 'module.backbone.enc.enc3.block2.norm1.0.bias', 'module.backbone.enc.enc3.block2.attn.qkv.weight', 'module.backbone.enc.enc3.block2.attn.qkv.bias', 'module.backbone.enc.enc3.block2.attn.proj.weight', 'module.backbone.enc.enc3.block2.attn.proj.bias', 'module.backbone.enc.enc3.block2.norm2.0.weight', 'module.backbone.enc.enc3.block2.norm2.0.bias', 'module.backbone.enc.enc3.block2.mlp.0.fc1.weight', 'module.backbone.enc.enc3.block2.mlp.0.fc1.bias', 'module.backbone.enc.enc3.block2.mlp.0.fc2.weight', 'module.backbone.enc.enc3.block2.mlp.0.fc2.bias', 'module.backbone.enc.enc3.block3.cpe.0.weight', 'module.backbone.enc.enc3.block3.cpe.0.bias', 'module.backbone.enc.enc3.block3.cpe.1.weight', 'module.backbone.enc.enc3.block3.cpe.1.bias', 'module.backbone.enc.enc3.block3.cpe.2.weight', 'module.backbone.enc.enc3.block3.cpe.2.bias', 'module.backbone.enc.enc3.block3.norm1.0.weight', 'module.backbone.enc.enc3.block3.norm1.0.bias', 'module.backbone.enc.enc3.block3.attn.qkv.weight', 'module.backbone.enc.enc3.block3.attn.qkv.bias', 'module.backbone.enc.enc3.block3.attn.proj.weight', 'module.backbone.enc.enc3.block3.attn.proj.bias', 'module.backbone.enc.enc3.block3.norm2.0.weight', 'module.backbone.enc.enc3.block3.norm2.0.bias', 'module.backbone.enc.enc3.block3.mlp.0.fc1.weight', 'module.backbone.enc.enc3.block3.mlp.0.fc1.bias', 'module.backbone.enc.enc3.block3.mlp.0.fc2.weight', 'module.backbone.enc.enc3.block3.mlp.0.fc2.bias', 'module.backbone.enc.enc3.block4.cpe.0.weight', 'module.backbone.enc.enc3.block4.cpe.0.bias', 'module.backbone.enc.enc3.block4.cpe.1.weight', 'module.backbone.enc.enc3.block4.cpe.1.bias', 'module.backbone.enc.enc3.block4.cpe.2.weight', 'module.backbone.enc.enc3.block4.cpe.2.bias', 'module.backbone.enc.enc3.block4.norm1.0.weight', 'module.backbone.enc.enc3.block4.norm1.0.bias', 'module.backbone.enc.enc3.block4.attn.qkv.weight', 'module.backbone.enc.enc3.block4.attn.qkv.bias', 'module.backbone.enc.enc3.block4.attn.proj.weight', 'module.backbone.enc.enc3.block4.attn.proj.bias', 'module.backbone.enc.enc3.block4.norm2.0.weight', 'module.backbone.enc.enc3.block4.norm2.0.bias', 'module.backbone.enc.enc3.block4.mlp.0.fc1.weight', 'module.backbone.enc.enc3.block4.mlp.0.fc1.bias', 'module.backbone.enc.enc3.block4.mlp.0.fc2.weight', 'module.backbone.enc.enc3.block4.mlp.0.fc2.bias', 'module.backbone.enc.enc3.block5.cpe.0.weight', 'module.backbone.enc.enc3.block5.cpe.0.bias', 'module.backbone.enc.enc3.block5.cpe.1.weight', 'module.backbone.enc.enc3.block5.cpe.1.bias', 'module.backbone.enc.enc3.block5.cpe.2.weight', 'module.backbone.enc.enc3.block5.cpe.2.bias', 'module.backbone.enc.enc3.block5.norm1.0.weight', 'module.backbone.enc.enc3.block5.norm1.0.bias', 'module.backbone.enc.enc3.block5.attn.qkv.weight', 'module.backbone.enc.enc3.block5.attn.qkv.bias', 'module.backbone.enc.enc3.block5.attn.proj.weight', 'module.backbone.enc.enc3.block5.attn.proj.bias', 'module.backbone.enc.enc3.block5.norm2.0.weight', 'module.backbone.enc.enc3.block5.norm2.0.bias', 'module.backbone.enc.enc3.block5.mlp.0.fc1.weight', 'module.backbone.enc.enc3.block5.mlp.0.fc1.bias', 'module.backbone.enc.enc3.block5.mlp.0.fc2.weight', 'module.backbone.enc.enc3.block5.mlp.0.fc2.bias', 'module.backbone.enc.enc4.block0.cpe.0.weight', 'module.backbone.enc.enc4.block0.cpe.0.bias', 'module.backbone.enc.enc4.block0.cpe.1.weight', 'module.backbone.enc.enc4.block0.cpe.1.bias', 'module.backbone.enc.enc4.block0.cpe.2.weight', 'module.backbone.enc.enc4.block0.cpe.2.bias', 'module.backbone.enc.enc4.block0.norm1.0.weight', 'module.backbone.enc.enc4.block0.norm1.0.bias', 'module.backbone.enc.enc4.block0.attn.qkv.weight', 'module.backbone.enc.enc4.block0.attn.qkv.bias', 'module.backbone.enc.enc4.block0.attn.proj.weight', 'module.backbone.enc.enc4.block0.attn.proj.bias', 'module.backbone.enc.enc4.block0.norm2.0.weight', 'module.backbone.enc.enc4.block0.norm2.0.bias', 'module.backbone.enc.enc4.block0.mlp.0.fc1.weight', 'module.backbone.enc.enc4.block0.mlp.0.fc1.bias', 'module.backbone.enc.enc4.block0.mlp.0.fc2.weight', 'module.backbone.enc.enc4.block0.mlp.0.fc2.bias', 'module.backbone.enc.enc4.block1.cpe.0.weight', 'module.backbone.enc.enc4.block1.cpe.0.bias', 'module.backbone.enc.enc4.block1.cpe.1.weight', 'module.backbone.enc.enc4.block1.cpe.1.bias', 'module.backbone.enc.enc4.block1.cpe.2.weight', 'module.backbone.enc.enc4.block1.cpe.2.bias', 'module.backbone.enc.enc4.block1.norm1.0.weight', 'module.backbone.enc.enc4.block1.norm1.0.bias', 'module.backbone.enc.enc4.block1.attn.qkv.weight', 'module.backbone.enc.enc4.block1.attn.qkv.bias', 'module.backbone.enc.enc4.block1.attn.proj.weight', 'module.backbone.enc.enc4.block1.attn.proj.bias', 'module.backbone.enc.enc4.block1.norm2.0.weight', 'module.backbone.enc.enc4.block1.norm2.0.bias', 'module.backbone.enc.enc4.block1.mlp.0.fc1.weight', 'module.backbone.enc.enc4.block1.mlp.0.fc1.bias', 'module.backbone.enc.enc4.block1.mlp.0.fc2.weight', 'module.backbone.enc.enc4.block1.mlp.0.fc2.bias', 'module.backbone.dec.dec3.block0.cpe.0.weight', 'module.backbone.dec.dec3.block0.cpe.0.bias', 'module.backbone.dec.dec3.block0.cpe.1.weight', 'module.backbone.dec.dec3.block0.cpe.1.bias', 'module.backbone.dec.dec3.block0.cpe.2.weight', 'module.backbone.dec.dec3.block0.cpe.2.bias', 'module.backbone.dec.dec3.block0.norm1.0.weight', 'module.backbone.dec.dec3.block0.norm1.0.bias', 'module.backbone.dec.dec3.block0.attn.qkv.weight', 'module.backbone.dec.dec3.block0.attn.qkv.bias', 'module.backbone.dec.dec3.block0.attn.proj.weight', 'module.backbone.dec.dec3.block0.attn.proj.bias', 'module.backbone.dec.dec3.block0.norm2.0.weight', 'module.backbone.dec.dec3.block0.norm2.0.bias', 'module.backbone.dec.dec3.block0.mlp.0.fc1.weight', 'module.backbone.dec.dec3.block0.mlp.0.fc1.bias', 'module.backbone.dec.dec3.block0.mlp.0.fc2.weight', 'module.backbone.dec.dec3.block0.mlp.0.fc2.bias', 'module.backbone.dec.dec3.block1.cpe.0.weight', 'module.backbone.dec.dec3.block1.cpe.0.bias', 'module.backbone.dec.dec3.block1.cpe.1.weight', 'module.backbone.dec.dec3.block1.cpe.1.bias', 'module.backbone.dec.dec3.block1.cpe.2.weight', 'module.backbone.dec.dec3.block1.cpe.2.bias', 'module.backbone.dec.dec3.block1.norm1.0.weight', 'module.backbone.dec.dec3.block1.norm1.0.bias', 'module.backbone.dec.dec3.block1.attn.qkv.weight', 'module.backbone.dec.dec3.block1.attn.qkv.bias', 'module.backbone.dec.dec3.block1.attn.proj.weight', 'module.backbone.dec.dec3.block1.attn.proj.bias', 'module.backbone.dec.dec3.block1.norm2.0.weight', 'module.backbone.dec.dec3.block1.norm2.0.bias', 'module.backbone.dec.dec3.block1.mlp.0.fc1.weight', 'module.backbone.dec.dec3.block1.mlp.0.fc1.bias', 'module.backbone.dec.dec3.block1.mlp.0.fc2.weight', 'module.backbone.dec.dec3.block1.mlp.0.fc2.bias', 'module.backbone.dec.dec2.block0.cpe.0.weight', 'module.backbone.dec.dec2.block0.cpe.0.bias', 'module.backbone.dec.dec2.block0.cpe.1.weight', 'module.backbone.dec.dec2.block0.cpe.1.bias', 'module.backbone.dec.dec2.block0.cpe.2.weight', 'module.backbone.dec.dec2.block0.cpe.2.bias', 'module.backbone.dec.dec2.block0.norm1.0.weight', 'module.backbone.dec.dec2.block0.norm1.0.bias', 'module.backbone.dec.dec2.block0.attn.qkv.weight', 'module.backbone.dec.dec2.block0.attn.qkv.bias', 'module.backbone.dec.dec2.block0.attn.proj.weight', 'module.backbone.dec.dec2.block0.attn.proj.bias', 'module.backbone.dec.dec2.block0.norm2.0.weight', 'module.backbone.dec.dec2.block0.norm2.0.bias', 'module.backbone.dec.dec2.block0.mlp.0.fc1.weight', 'module.backbone.dec.dec2.block0.mlp.0.fc1.bias', 'module.backbone.dec.dec2.block0.mlp.0.fc2.weight', 'module.backbone.dec.dec2.block0.mlp.0.fc2.bias', 'module.backbone.dec.dec2.block1.cpe.0.weight', 'module.backbone.dec.dec2.block1.cpe.0.bias', 'module.backbone.dec.dec2.block1.cpe.1.weight', 'module.backbone.dec.dec2.block1.cpe.1.bias', 'module.backbone.dec.dec2.block1.cpe.2.weight', 'module.backbone.dec.dec2.block1.cpe.2.bias', 'module.backbone.dec.dec2.block1.norm1.0.weight', 'module.backbone.dec.dec2.block1.norm1.0.bias', 'module.backbone.dec.dec2.block1.attn.qkv.weight', 'module.backbone.dec.dec2.block1.attn.qkv.bias', 'module.backbone.dec.dec2.block1.attn.proj.weight', 'module.backbone.dec.dec2.block1.attn.proj.bias', 'module.backbone.dec.dec2.block1.norm2.0.weight', 'module.backbone.dec.dec2.block1.norm2.0.bias', 'module.backbone.dec.dec2.block1.mlp.0.fc1.weight', 'module.backbone.dec.dec2.block1.mlp.0.fc1.bias', 'module.backbone.dec.dec2.block1.mlp.0.fc2.weight', 'module.backbone.dec.dec2.block1.mlp.0.fc2.bias', 'module.backbone.dec.dec1.block0.cpe.0.weight', 'module.backbone.dec.dec1.block0.cpe.0.bias', 'module.backbone.dec.dec1.block0.cpe.1.weight', 'module.backbone.dec.dec1.block0.cpe.1.bias', 'module.backbone.dec.dec1.block0.cpe.2.weight', 'module.backbone.dec.dec1.block0.cpe.2.bias', 'module.backbone.dec.dec1.block0.norm1.0.weight', 'module.backbone.dec.dec1.block0.norm1.0.bias', 'module.backbone.dec.dec1.block0.attn.qkv.weight', 'module.backbone.dec.dec1.block0.attn.qkv.bias', 'module.backbone.dec.dec1.block0.attn.proj.weight', 'module.backbone.dec.dec1.block0.attn.proj.bias', 'module.backbone.dec.dec1.block0.norm2.0.weight', 'module.backbone.dec.dec1.block0.norm2.0.bias', 'module.backbone.dec.dec1.block0.mlp.0.fc1.weight', 'module.backbone.dec.dec1.block0.mlp.0.fc1.bias', 'module.backbone.dec.dec1.block0.mlp.0.fc2.weight', 'module.backbone.dec.dec1.block0.mlp.0.fc2.bias', 'module.backbone.dec.dec1.block1.cpe.0.weight', 'module.backbone.dec.dec1.block1.cpe.0.bias', 'module.backbone.dec.dec1.block1.cpe.1.weight', 'module.backbone.dec.dec1.block1.cpe.1.bias', 'module.backbone.dec.dec1.block1.cpe.2.weight', 'module.backbone.dec.dec1.block1.cpe.2.bias', 'module.backbone.dec.dec1.block1.norm1.0.weight', 'module.backbone.dec.dec1.block1.norm1.0.bias', 'module.backbone.dec.dec1.block1.attn.qkv.weight', 'module.backbone.dec.dec1.block1.attn.qkv.bias', 'module.backbone.dec.dec1.block1.attn.proj.weight', 'module.backbone.dec.dec1.block1.attn.proj.bias', 'module.backbone.dec.dec1.block1.norm2.0.weight', 'module.backbone.dec.dec1.block1.norm2.0.bias', 'module.backbone.dec.dec1.block1.mlp.0.fc1.weight', 'module.backbone.dec.dec1.block1.mlp.0.fc1.bias', 'module.backbone.dec.dec1.block1.mlp.0.fc2.weight', 'module.backbone.dec.dec1.block1.mlp.0.fc2.bias', 'module.backbone.dec.dec0.block0.cpe.0.weight', 'module.backbone.dec.dec0.block0.cpe.0.bias', 'module.backbone.dec.dec0.block0.cpe.1.weight', 'module.backbone.dec.dec0.block0.cpe.1.bias', 'module.backbone.dec.dec0.block0.cpe.2.weight', 'module.backbone.dec.dec0.block0.cpe.2.bias', 'module.backbone.dec.dec0.block0.norm1.0.weight', 'module.backbone.dec.dec0.block0.norm1.0.bias', 'module.backbone.dec.dec0.block0.attn.qkv.weight', 'module.backbone.dec.dec0.block0.attn.qkv.bias', 'module.backbone.dec.dec0.block0.attn.proj.weight', 'module.backbone.dec.dec0.block0.attn.proj.bias', 'module.backbone.dec.dec0.block0.norm2.0.weight', 'module.backbone.dec.dec0.block0.norm2.0.bias', 'module.backbone.dec.dec0.block0.mlp.0.fc1.weight', 'module.backbone.dec.dec0.block0.mlp.0.fc1.bias', 'module.backbone.dec.dec0.block0.mlp.0.fc2.weight', 'module.backbone.dec.dec0.block0.mlp.0.fc2.bias', 'module.backbone.dec.dec0.block1.cpe.0.weight', 'module.backbone.dec.dec0.block1.cpe.0.bias', 'module.backbone.dec.dec0.block1.cpe.1.weight', 'module.backbone.dec.dec0.block1.cpe.1.bias', 'module.backbone.dec.dec0.block1.cpe.2.weight', 'module.backbone.dec.dec0.block1.cpe.2.bias', 'module.backbone.dec.dec0.block1.norm1.0.weight', 'module.backbone.dec.dec0.block1.norm1.0.bias', 'module.backbone.dec.dec0.block1.attn.qkv.weight', 'module.backbone.dec.dec0.block1.attn.qkv.bias', 'module.backbone.dec.dec0.block1.attn.proj.weight', 'module.backbone.dec.dec0.block1.attn.proj.bias', 'module.backbone.dec.dec0.block1.norm2.0.weight', 'module.backbone.dec.dec0.block1.norm2.0.bias', 'module.backbone.dec.dec0.block1.mlp.0.fc1.weight', 'module.backbone.dec.dec0.block1.mlp.0.fc1.bias', 'module.backbone.dec.dec0.block1.mlp.0.fc2.weight', 'module.backbone.dec.dec0.block1.mlp.0.fc2.bias'].
[2025-05-11 13:09:50,863 INFO train.py line 152 288342] => Building hooks ...
[2025-05-11 13:09:50,864 INFO misc.py line 237 288342] => Loading checkpoint & weight ...
[2025-05-11 13:09:50,864 INFO misc.py line 274 288342] No weight found at: None
[2025-05-11 13:09:50,864 INFO train.py line 159 288342] >>>>>>>>>>>>>>>> Start Training >>>>>>>>>>>>>>>>
[2025-05-11 13:11:18,358 INFO misc.py line 117 288342] Train: [1/50][1/2344] Data 1.823 (1.823) Batch 6.500 (6.500) Remain 211:36:25 loss: 3.7256 Lr: 0.00020
[2025-05-11 13:11:18,895 INFO misc.py line 117 288342] Train: [1/50][2/2344] Data 0.003 (0.003) Batch 0.536 (0.536) Remain 17:27:26 loss: 3.3719 Lr: 0.00020
[2025-05-11 13:11:19,354 INFO misc.py line 117 288342] Train: [1/50][3/2344] Data 0.003 (0.003) Batch 0.459 (0.459) Remain 14:57:06 loss: 3.7716 Lr: 0.00020
[2025-05-11 13:11:20,065 INFO misc.py line 117 288342] Train: [1/50][4/2344] Data 0.002 (0.002) Batch 0.710 (0.710) Remain 23:07:01 loss: 3.5409 Lr: 0.00020
[2025-05-11 13:11:20,674 INFO misc.py line 117 288342] Train: [1/50][5/2344] Data 0.003 (0.003) Batch 0.610 (0.660) Remain 21:28:51 loss: 3.5516 Lr: 0.00020
[2025-05-11 13:11:21,323 INFO misc.py line 117 288342] Train: [1/50][6/2344] Data 0.002 (0.003) Batch 0.649 (0.656) Remain 21:21:37 loss: 3.1847 Lr: 0.00020
[2025-05-11 13:11:21,930 INFO misc.py line 117 288342] Train: [1/50][7/2344] Data 0.003 (0.003) Batch 0.608 (0.644) Remain 20:57:53 loss: 3.4348 Lr: 0.00020
[2025-05-11 13:11:22,487 INFO misc.py line 117 288342] Train: [1/50][8/2344] Data 0.003 (0.003) Batch 0.557 (0.627) Remain 20:23:45 loss: 3.1532 Lr: 0.00020
[2025-05-11 13:11:23,110 INFO misc.py line 117 288342] Train: [1/50][9/2344] Data 0.003 (0.003) Batch 0.623 (0.626) Remain 20:22:29 loss: 3.1604 Lr: 0.00020
[2025-05-11 13:11:23,674 INFO misc.py line 117 288342] Train: [1/50][10/2344] Data 0.003 (0.003) Batch 0.564 (0.617) Remain 20:05:12 loss: 2.9220 Lr: 0.00020
[2025-05-11 13:11:24,373 INFO misc.py line 117 288342] Train: [1/50][11/2344] Data 0.003 (0.003) Batch 0.699 (0.627) Remain 20:25:10 loss: 3.2279 Lr: 0.00020
[2025-05-11 13:11:25,050 INFO misc.py line 117 288342] Train: [1/50][12/2344] Data 0.004 (0.003) Batch 0.677 (0.633) Remain 20:36:00 loss: 2.8482 Lr: 0.00020
[2025-05-11 13:11:25,799 INFO misc.py line 117 288342] Train: [1/50][13/2344] Data 0.003 (0.003) Batch 0.749 (0.644) Remain 20:58:44 loss: 2.7995 Lr: 0.00020
[2025-05-11 13:11:26,556 INFO misc.py line 117 288342] Train: [1/50][14/2344] Data 0.003 (0.003) Batch 0.757 (0.655) Remain 21:18:40 loss: 2.7593 Lr: 0.00020
[2025-05-11 13:11:27,145 INFO misc.py line 117 288342] Train: [1/50][15/2344] Data 0.003 (0.003) Batch 0.589 (0.649) Remain 21:08:03 loss: 2.7594 Lr: 0.00020
[2025-05-11 13:11:27,658 INFO misc.py line 117 288342] Train: [1/50][16/2344] Data 0.002 (0.003) Batch 0.513 (0.639) Remain 20:47:31 loss: 2.7270 Lr: 0.00020
[2025-05-11 13:11:28,221 INFO misc.py line 117 288342] Train: [1/50][17/2344] Data 0.003 (0.003) Batch 0.563 (0.633) Remain 20:36:53 loss: 2.8371 Lr: 0.00020
[2025-05-11 13:11:28,851 INFO misc.py line 117 288342] Train: [1/50][18/2344] Data 0.003 (0.003) Batch 0.631 (0.633) Remain 20:36:32 loss: 2.5832 Lr: 0.00020
[2025-05-11 13:11:29,575 INFO misc.py line 117 288342] Train: [1/50][19/2344] Data 0.003 (0.003) Batch 0.724 (0.639) Remain 20:47:36 loss: 2.7387 Lr: 0.00020
[2025-05-11 13:11:30,083 INFO misc.py line 117 288342] Train: [1/50][20/2344] Data 0.003 (0.003) Batch 0.508 (0.631) Remain 20:32:35 loss: 2.7707 Lr: 0.00020
[2025-05-11 13:11:30,578 INFO misc.py line 117 288342] Train: [1/50][21/2344] Data 0.003 (0.003) Batch 0.495 (0.624) Remain 20:17:47 loss: 2.8800 Lr: 0.00020
[2025-05-11 13:11:31,073 INFO misc.py line 117 288342] Train: [1/50][22/2344] Data 0.003 (0.003) Batch 0.494 (0.617) Remain 20:04:29 loss: 2.6885 Lr: 0.00020
[2025-05-11 13:11:31,682 INFO misc.py line 117 288342] Train: [1/50][23/2344] Data 0.003 (0.003) Batch 0.609 (0.616) Remain 20:03:45 loss: 2.4961 Lr: 0.00020
[2025-05-11 13:11:32,196 INFO misc.py line 117 288342] Train: [1/50][24/2344] Data 0.003 (0.003) Batch 0.514 (0.612) Remain 19:54:15 loss: 2.6025 Lr: 0.00020
[2025-05-11 13:11:32,906 INFO misc.py line 117 288342] Train: [1/50][25/2344] Data 0.003 (0.003) Batch 0.709 (0.616) Remain 20:02:56 loss: 2.1091 Lr: 0.00020
[2025-05-11 13:11:33,491 INFO misc.py line 117 288342] Train: [1/50][26/2344] Data 0.003 (0.003) Batch 0.585 (0.615) Remain 20:00:17 loss: 2.4858 Lr: 0.00020
[2025-05-11 13:11:34,184 INFO misc.py line 117 288342] Train: [1/50][27/2344] Data 0.003 (0.003) Batch 0.693 (0.618) Remain 20:06:40 loss: 2.9056 Lr: 0.00020
[2025-05-11 13:11:34,696 INFO misc.py line 117 288342] Train: [1/50][28/2344] Data 0.003 (0.003) Batch 0.512 (0.614) Remain 19:58:25 loss: 2.2641 Lr: 0.00020
[2025-05-11 13:11:35,311 INFO misc.py line 117 288342] Train: [1/50][29/2344] Data 0.003 (0.003) Batch 0.615 (0.614) Remain 19:58:30 loss: 2.2093 Lr: 0.00020
[2025-05-11 13:11:36,028 INFO misc.py line 117 288342] Train: [1/50][30/2344] Data 0.002 (0.003) Batch 0.717 (0.618) Remain 20:05:59 loss: 2.0879 Lr: 0.00020
[2025-05-11 13:11:36,694 INFO misc.py line 117 288342] Train: [1/50][31/2344] Data 0.003 (0.003) Batch 0.665 (0.619) Remain 20:09:18 loss: 2.5139 Lr: 0.00020
[2025-05-11 13:11:37,349 INFO misc.py line 117 288342] Train: [1/50][32/2344] Data 0.003 (0.003) Batch 0.655 (0.621) Remain 20:11:44 loss: 2.4865 Lr: 0.00020
[2025-05-11 13:11:37,959 INFO misc.py line 117 288342] Train: [1/50][33/2344] Data 0.003 (0.003) Batch 0.609 (0.620) Remain 20:11:00 loss: 2.2838 Lr: 0.00020
[2025-05-11 13:11:38,574 INFO misc.py line 117 288342] Train: [1/50][34/2344] Data 0.003 (0.003) Batch 0.616 (0.620) Remain 20:10:42 loss: 2.4780 Lr: 0.00020
[2025-05-11 13:11:39,116 INFO misc.py line 117 288342] Train: [1/50][35/2344] Data 0.002 (0.003) Batch 0.542 (0.618) Remain 20:05:55 loss: 2.1868 Lr: 0.00020
[2025-05-11 13:11:39,649 INFO misc.py line 117 288342] Train: [1/50][36/2344] Data 0.003 (0.003) Batch 0.533 (0.615) Remain 20:00:55 loss: 2.3717 Lr: 0.00020
[2025-05-11 13:11:40,206 INFO misc.py line 117 288342] Train: [1/50][37/2344] Data 0.003 (0.003) Batch 0.557 (0.613) Remain 19:57:34 loss: 2.5486 Lr: 0.00020
[2025-05-11 13:11:40,783 INFO misc.py line 117 288342] Train: [1/50][38/2344] Data 0.003 (0.003) Batch 0.577 (0.612) Remain 19:55:33 loss: 1.9317 Lr: 0.00020
[2025-05-11 13:11:41,503 INFO misc.py line 117 288342] Train: [1/50][39/2344] Data 0.003 (0.003) Batch 0.720 (0.615) Remain 20:01:23 loss: 2.3709 Lr: 0.00020
[2025-05-11 13:11:42,172 INFO misc.py line 117 288342] Train: [1/50][40/2344] Data 0.003 (0.003) Batch 0.669 (0.617) Remain 20:04:13 loss: 1.8310 Lr: 0.00020
[2025-05-11 13:11:42,809 INFO misc.py line 117 288342] Train: [1/50][41/2344] Data 0.003 (0.003) Batch 0.636 (0.617) Remain 20:05:13 loss: 2.5170 Lr: 0.00020
[2025-05-11 13:11:43,390 INFO misc.py line 117 288342] Train: [1/50][42/2344] Data 0.003 (0.003) Batch 0.582 (0.616) Remain 20:03:25 loss: 2.3500 Lr: 0.00020
[2025-05-11 13:11:43,997 INFO misc.py line 117 288342] Train: [1/50][43/2344] Data 0.003 (0.003) Batch 0.607 (0.616) Remain 20:02:57 loss: 2.2952 Lr: 0.00020
[2025-05-11 13:11:44,670 INFO misc.py line 117 288342] Train: [1/50][44/2344] Data 0.003 (0.003) Batch 0.673 (0.617) Remain 20:05:39 loss: 1.8525 Lr: 0.00020
[2025-05-11 13:11:45,189 INFO misc.py line 117 288342] Train: [1/50][45/2344] Data 0.003 (0.003) Batch 0.518 (0.615) Remain 20:01:01 loss: 2.0299 Lr: 0.00020
[2025-05-11 13:11:45,725 INFO misc.py line 117 288342] Train: [1/50][46/2344] Data 0.003 (0.003) Batch 0.537 (0.613) Remain 19:57:28 loss: 2.3529 Lr: 0.00020
[2025-05-11 13:11:46,251 INFO misc.py line 117 288342] Train: [1/50][47/2344] Data 0.003 (0.003) Batch 0.526 (0.611) Remain 19:53:35 loss: 2.0084 Lr: 0.00020
[2025-05-11 13:11:46,888 INFO misc.py line 117 288342] Train: [1/50][48/2344] Data 0.003 (0.003) Batch 0.637 (0.612) Remain 19:54:40 loss: 1.7749 Lr: 0.00020
[2025-05-11 13:11:47,465 INFO misc.py line 117 288342] Train: [1/50][49/2344] Data 0.002 (0.003) Batch 0.577 (0.611) Remain 19:53:10 loss: 2.2158 Lr: 0.00020
[2025-05-11 13:11:48,017 INFO misc.py line 117 288342] Train: [1/50][50/2344] Data 0.003 (0.003) Batch 0.552 (0.610) Remain 19:50:41 loss: 1.9945 Lr: 0.00020
[2025-05-11 13:11:48,530 INFO misc.py line 117 288342] Train: [1/50][51/2344] Data 0.004 (0.003) Batch 0.513 (0.608) Remain 19:46:45 loss: 2.1139 Lr: 0.00020
[2025-05-11 13:11:49,038 INFO misc.py line 117 288342] Train: [1/50][52/2344] Data 0.003 (0.003) Batch 0.508 (0.606) Remain 19:42:46 loss: 1.9494 Lr: 0.00020
[2025-05-11 13:11:49,613 INFO misc.py line 117 288342] Train: [1/50][53/2344] Data 0.003 (0.003) Batch 0.575 (0.605) Remain 19:41:33 loss: 2.3106 Lr: 0.00020
[2025-05-11 13:11:50,165 INFO misc.py line 117 288342] Train: [1/50][54/2344] Data 0.003 (0.003) Batch 0.552 (0.604) Remain 19:39:31 loss: 2.2880 Lr: 0.00020
[2025-05-11 13:11:50,662 INFO misc.py line 117 288342] Train: [1/50][55/2344] Data 0.003 (0.003) Batch 0.497 (0.602) Remain 19:35:29 loss: 2.0607 Lr: 0.00020
[2025-05-11 13:11:51,301 INFO misc.py line 117 288342] Train: [1/50][56/2344] Data 0.003 (0.003) Batch 0.639 (0.603) Remain 19:36:51 loss: 2.1537 Lr: 0.00020
[2025-05-11 13:11:51,974 INFO misc.py line 117 288342] Train: [1/50][57/2344] Data 0.003 (0.003) Batch 0.672 (0.604) Remain 19:39:21 loss: 1.8065 Lr: 0.00020
[2025-05-11 13:11:52,639 INFO misc.py line 117 288342] Train: [1/50][58/2344] Data 0.003 (0.003) Batch 0.665 (0.605) Remain 19:41:30 loss: 1.9658 Lr: 0.00020
[2025-05-11 13:11:53,320 INFO misc.py line 117 288342] Train: [1/50][59/2344] Data 0.003 (0.003) Batch 0.682 (0.607) Remain 19:44:10 loss: 2.1135 Lr: 0.00020
[2025-05-11 13:11:53,774 INFO misc.py line 117 288342] Train: [1/50][60/2344] Data 0.003 (0.003) Batch 0.454 (0.604) Remain 19:38:55 loss: 2.1747 Lr: 0.00020
[2025-05-11 13:11:54,381 INFO misc.py line 117 288342] Train: [1/50][61/2344] Data 0.003 (0.003) Batch 0.607 (0.604) Remain 19:39:01 loss: 2.1608 Lr: 0.00020
[2025-05-11 13:11:55,069 INFO misc.py line 117 288342] Train: [1/50][62/2344] Data 0.003 (0.003) Batch 0.687 (0.605) Remain 19:41:46 loss: 1.9618 Lr: 0.00020
[2025-05-11 13:11:55,703 INFO misc.py line 117 288342] Train: [1/50][63/2344] Data 0.003 (0.003) Batch 0.634 (0.606) Remain 19:42:42 loss: 1.9189 Lr: 0.00020
[2025-05-11 13:11:56,407 INFO misc.py line 117 288342] Train: [1/50][64/2344] Data 0.003 (0.003) Batch 0.704 (0.607) Remain 19:45:51 loss: 2.0539 Lr: 0.00020
[2025-05-11 13:11:57,023 INFO misc.py line 117 288342] Train: [1/50][65/2344] Data 0.003 (0.003) Batch 0.616 (0.608) Remain 19:46:07 loss: 1.9321 Lr: 0.00020
[2025-05-11 13:11:57,630 INFO misc.py line 117 288342] Train: [1/50][66/2344] Data 0.003 (0.003) Batch 0.606 (0.608) Remain 19:46:04 loss: 1.9263 Lr: 0.00020
[2025-05-11 13:11:58,265 INFO misc.py line 117 288342] Train: [1/50][67/2344] Data 0.002 (0.003) Batch 0.636 (0.608) Remain 19:46:55 loss: 2.0779 Lr: 0.00020
[2025-05-11 13:11:58,876 INFO misc.py line 117 288342] Train: [1/50][68/2344] Data 0.003 (0.003) Batch 0.611 (0.608) Remain 19:46:59 loss: 1.8177 Lr: 0.00020
[2025-05-11 13:11:59,609 INFO misc.py line 117 288342] Train: [1/50][69/2344] Data 0.002 (0.003) Batch 0.733 (0.610) Remain 19:50:40 loss: 1.8376 Lr: 0.00020
[2025-05-11 13:12:00,216 INFO misc.py line 117 288342] Train: [1/50][70/2344] Data 0.003 (0.003) Batch 0.607 (0.610) Remain 19:50:34 loss: 1.7716 Lr: 0.00020
[2025-05-11 13:12:00,855 INFO misc.py line 117 288342] Train: [1/50][71/2344] Data 0.003 (0.003) Batch 0.639 (0.610) Remain 19:51:25 loss: 1.9610 Lr: 0.00020
[2025-05-11 13:12:01,420 INFO misc.py line 117 288342] Train: [1/50][72/2344] Data 0.002 (0.003) Batch 0.565 (0.610) Remain 19:50:06 loss: 2.0033 Lr: 0.00020
[2025-05-11 13:12:02,030 INFO misc.py line 117 288342] Train: [1/50][73/2344] Data 0.003 (0.003) Batch 0.610 (0.610) Remain 19:50:06 loss: 2.0580 Lr: 0.00020
[2025-05-11 13:12:02,740 INFO misc.py line 117 288342] Train: [1/50][74/2344] Data 0.003 (0.003) Batch 0.710 (0.611) Remain 19:52:51 loss: 2.1696 Lr: 0.00020
[2025-05-11 13:12:03,287 INFO misc.py line 117 288342] Train: [1/50][75/2344] Data 0.003 (0.003) Batch 0.547 (0.610) Remain 19:51:06 loss: 2.1611 Lr: 0.00020
[2025-05-11 13:12:03,844 INFO misc.py line 117 288342] Train: [1/50][76/2344] Data 0.003 (0.003) Batch 0.557 (0.609) Remain 19:49:41 loss: 1.7856 Lr: 0.00020
[2025-05-11 13:12:04,439 INFO misc.py line 117 288342] Train: [1/50][77/2344] Data 0.003 (0.003) Batch 0.594 (0.609) Remain 19:49:17 loss: 1.8974 Lr: 0.00020
[2025-05-11 13:12:04,964 INFO misc.py line 117 288342] Train: [1/50][78/2344] Data 0.003 (0.003) Batch 0.525 (0.608) Remain 19:47:05 loss: 1.6825 Lr: 0.00020
[2025-05-11 13:12:05,590 INFO misc.py line 117 288342] Train: [1/50][79/2344] Data 0.003 (0.003) Batch 0.626 (0.608) Remain 19:47:32 loss: 1.7922 Lr: 0.00020
[2025-05-11 13:12:06,245 INFO misc.py line 117 288342] Train: [1/50][80/2344] Data 0.003 (0.003) Batch 0.655 (0.609) Remain 19:48:42 loss: 1.7156 Lr: 0.00020
[2025-05-11 13:12:06,773 INFO misc.py line 117 288342] Train: [1/50][81/2344] Data 0.003 (0.003) Batch 0.528 (0.608) Remain 19:46:40 loss: 1.9989 Lr: 0.00020
[2025-05-11 13:12:07,376 INFO misc.py line 117 288342] Train: [1/50][82/2344] Data 0.003 (0.003) Batch 0.603 (0.608) Remain 19:46:32 loss: 1.6390 Lr: 0.00020
[2025-05-11 13:12:08,067 INFO misc.py line 117 288342] Train: [1/50][83/2344] Data 0.002 (0.003) Batch 0.690 (0.609) Remain 19:48:32 loss: 1.5933 Lr: 0.00020
[2025-05-11 13:12:08,578 INFO misc.py line 117 288342] Train: [1/50][84/2344] Data 0.002 (0.003) Batch 0.511 (0.608) Remain 19:46:10 loss: 1.6879 Lr: 0.00020
[2025-05-11 13:12:09,190 INFO misc.py line 117 288342] Train: [1/50][85/2344] Data 0.002 (0.003) Batch 0.613 (0.608) Remain 19:46:17 loss: 1.5708 Lr: 0.00020
[2025-05-11 13:12:09,782 INFO misc.py line 117 288342] Train: [1/50][86/2344] Data 0.002 (0.003) Batch 0.592 (0.608) Remain 19:45:54 loss: 1.6124 Lr: 0.00020
[2025-05-11 13:12:10,440 INFO misc.py line 117 288342] Train: [1/50][87/2344] Data 0.003 (0.003) Batch 0.657 (0.608) Remain 19:47:03 loss: 1.7183 Lr: 0.00020
[2025-05-11 13:12:11,000 INFO misc.py line 117 288342] Train: [1/50][88/2344] Data 0.003 (0.003) Batch 0.561 (0.608) Remain 19:45:57 loss: 1.8249 Lr: 0.00020
[2025-05-11 13:12:11,588 INFO misc.py line 117 288342] Train: [1/50][89/2344] Data 0.003 (0.003) Batch 0.588 (0.607) Remain 19:45:29 loss: 2.0618 Lr: 0.00020
[2025-05-11 13:12:12,173 INFO misc.py line 117 288342] Train: [1/50][90/2344] Data 0.003 (0.003) Batch 0.584 (0.607) Remain 19:44:57 loss: 1.6047 Lr: 0.00020
[2025-05-11 13:12:12,713 INFO misc.py line 117 288342] Train: [1/50][91/2344] Data 0.003 (0.003) Batch 0.540 (0.606) Remain 19:43:28 loss: 1.7188 Lr: 0.00020
[2025-05-11 13:12:13,314 INFO misc.py line 117 288342] Train: [1/50][92/2344] Data 0.003 (0.003) Batch 0.601 (0.606) Remain 19:43:21 loss: 1.4579 Lr: 0.00020
[2025-05-11 13:12:13,878 INFO misc.py line 117 288342] Train: [1/50][93/2344] Data 0.003 (0.003) Batch 0.564 (0.606) Remain 19:42:25 loss: 1.6330 Lr: 0.00020
[2025-05-11 13:12:14,454 INFO misc.py line 117 288342] Train: [1/50][94/2344] Data 0.002 (0.003) Batch 0.576 (0.605) Remain 19:41:46 loss: 2.0748 Lr: 0.00020
[2025-05-11 13:12:15,229 INFO misc.py line 117 288342] Train: [1/50][95/2344] Data 0.002 (0.003) Batch 0.775 (0.607) Remain 19:45:21 loss: 1.5747 Lr: 0.00020
[2025-05-11 13:12:15,731 INFO misc.py line 117 288342] Train: [1/50][96/2344] Data 0.002 (0.003) Batch 0.502 (0.606) Remain 19:43:08 loss: 1.8627 Lr: 0.00020
[2025-05-11 13:12:16,254 INFO misc.py line 117 288342] Train: [1/50][97/2344] Data 0.002 (0.003) Batch 0.523 (0.605) Remain 19:41:24 loss: 2.0086 Lr: 0.00020
[2025-05-11 13:12:16,817 INFO misc.py line 117 288342] Train: [1/50][98/2344] Data 0.003 (0.003) Batch 0.563 (0.605) Remain 19:40:31 loss: 1.2655 Lr: 0.00020
[2025-05-11 13:12:17,286 INFO misc.py line 117 288342] Train: [1/50][99/2344] Data 0.003 (0.003) Batch 0.469 (0.603) Remain 19:37:44 loss: 1.6640 Lr: 0.00020
[2025-05-11 13:12:17,883 INFO misc.py line 117 288342] Train: [1/50][100/2344] Data 0.003 (0.003) Batch 0.597 (0.603) Remain 19:37:36 loss: 1.7578 Lr: 0.00020
[2025-05-11 13:12:18,461 INFO misc.py line 117 288342] Train: [1/50][101/2344] Data 0.003 (0.003) Batch 0.578 (0.603) Remain 19:37:05 loss: 1.6383 Lr: 0.00020
[2025-05-11 13:12:19,115 INFO misc.py line 117 288342] Train: [1/50][102/2344] Data 0.003 (0.003) Batch 0.654 (0.604) Remain 19:38:05 loss: 1.6983 Lr: 0.00020
[2025-05-11 13:12:19,851 INFO misc.py line 117 288342] Train: [1/50][103/2344] Data 0.003 (0.003) Batch 0.736 (0.605) Remain 19:40:39 loss: 1.6602 Lr: 0.00020
[2025-05-11 13:12:20,456 INFO misc.py line 117 288342] Train: [1/50][104/2344] Data 0.003 (0.003) Batch 0.605 (0.605) Remain 19:40:38 loss: 1.6234 Lr: 0.00020
[2025-05-11 13:12:20,996 INFO misc.py line 117 288342] Train: [1/50][105/2344] Data 0.002 (0.003) Batch 0.540 (0.604) Remain 19:39:23 loss: 1.7012 Lr: 0.00020
[2025-05-11 13:12:21,480 INFO misc.py line 117 288342] Train: [1/50][106/2344] Data 0.002 (0.003) Batch 0.484 (0.603) Remain 19:37:06 loss: 2.0753 Lr: 0.00020
[2025-05-11 13:12:22,119 INFO misc.py line 117 288342] Train: [1/50][107/2344] Data 0.003 (0.003) Batch 0.639 (0.604) Remain 19:37:45 loss: 1.7759 Lr: 0.00020
[2025-05-11 13:12:22,602 INFO misc.py line 117 288342] Train: [1/50][108/2344] Data 0.003 (0.003) Batch 0.484 (0.602) Remain 19:35:31 loss: 1.5718 Lr: 0.00020
[2025-05-11 13:12:23,056 INFO misc.py line 117 288342] Train: [1/50][109/2344] Data 0.003 (0.003) Batch 0.454 (0.601) Remain 19:32:47 loss: 1.6191 Lr: 0.00020
[2025-05-11 13:12:23,745 INFO misc.py line 117 288342] Train: [1/50][110/2344] Data 0.003 (0.003) Batch 0.688 (0.602) Remain 19:34:22 loss: 1.6915 Lr: 0.00020
[2025-05-11 13:12:24,335 INFO misc.py line 117 288342] Train: [1/50][111/2344] Data 0.003 (0.003) Batch 0.590 (0.602) Remain 19:34:09 loss: 1.5290 Lr: 0.00020
[2025-05-11 13:12:24,853 INFO misc.py line 117 288342] Train: [1/50][112/2344] Data 0.002 (0.003) Batch 0.518 (0.601) Remain 19:32:39 loss: 1.6980 Lr: 0.00020
[2025-05-11 13:12:25,607 INFO misc.py line 117 288342] Train: [1/50][113/2344] Data 0.003 (0.003) Batch 0.754 (0.602) Remain 19:35:21 loss: 1.6289 Lr: 0.00020
[2025-05-11 13:12:26,339 INFO misc.py line 117 288342] Train: [1/50][114/2344] Data 0.002 (0.003) Batch 0.732 (0.603) Remain 19:37:37 loss: 1.4751 Lr: 0.00020
[2025-05-11 13:12:26,838 INFO misc.py line 117 288342] Train: [1/50][115/2344] Data 0.003 (0.003) Batch 0.499 (0.603) Remain 19:35:47 loss: 1.4954 Lr: 0.00020
[2025-05-11 13:12:27,473 INFO misc.py line 117 288342] Train: [1/50][116/2344] Data 0.003 (0.003) Batch 0.635 (0.603) Remain 19:36:21 loss: 1.6305 Lr: 0.00020
[2025-05-11 13:12:28,058 INFO misc.py line 117 288342] Train: [1/50][117/2344] Data 0.003 (0.003) Batch 0.584 (0.603) Remain 19:36:01 loss: 1.8066 Lr: 0.00020
[2025-05-11 13:12:28,744 INFO misc.py line 117 288342] Train: [1/50][118/2344] Data 0.003 (0.003) Batch 0.687 (0.603) Remain 19:37:26 loss: 1.5511 Lr: 0.00020
[2025-05-11 13:12:29,299 INFO misc.py line 117 288342] Train: [1/50][119/2344] Data 0.003 (0.003) Batch 0.555 (0.603) Remain 19:36:36 loss: 1.6284 Lr: 0.00020
[2025-05-11 13:12:30,031 INFO misc.py line 117 288342] Train: [1/50][120/2344] Data 0.003 (0.003) Batch 0.732 (0.604) Remain 19:38:45 loss: 1.6142 Lr: 0.00020
[2025-05-11 13:12:30,578 INFO misc.py line 117 288342] Train: [1/50][121/2344] Data 0.003 (0.003) Batch 0.546 (0.604) Remain 19:37:47 loss: 1.3791 Lr: 0.00020
[2025-05-11 13:12:31,195 INFO misc.py line 117 288342] Train: [1/50][122/2344] Data 0.003 (0.003) Batch 0.617 (0.604) Remain 19:38:00 loss: 1.4394 Lr: 0.00020
[2025-05-11 13:12:31,781 INFO misc.py line 117 288342] Train: [1/50][123/2344] Data 0.003 (0.003) Batch 0.586 (0.604) Remain 19:37:42 loss: 1.4502 Lr: 0.00020
[2025-05-11 13:12:32,342 INFO misc.py line 117 288342] Train: [1/50][124/2344] Data 0.003 (0.003) Batch 0.562 (0.603) Remain 19:37:01 loss: 1.7218 Lr: 0.00020
[2025-05-11 13:12:32,905 INFO misc.py line 117 288342] Train: [1/50][125/2344] Data 0.002 (0.003) Batch 0.563 (0.603) Remain 19:36:21 loss: 1.4246 Lr: 0.00020
[2025-05-11 13:12:33,503 INFO misc.py line 117 288342] Train: [1/50][126/2344] Data 0.003 (0.003) Batch 0.598 (0.603) Remain 19:36:15 loss: 1.6473 Lr: 0.00020
[2025-05-11 13:12:34,207 INFO misc.py line 117 288342] Train: [1/50][127/2344] Data 0.003 (0.003) Batch 0.705 (0.604) Remain 19:37:51 loss: 1.3573 Lr: 0.00020
[2025-05-11 13:12:34,857 INFO misc.py line 117 288342] Train: [1/50][128/2344] Data 0.003 (0.003) Batch 0.650 (0.604) Remain 19:38:34 loss: 1.4582 Lr: 0.00020
[2025-05-11 13:12:35,594 INFO misc.py line 117 288342] Train: [1/50][129/2344] Data 0.003 (0.003) Batch 0.737 (0.605) Remain 19:40:37 loss: 1.5345 Lr: 0.00020
[2025-05-11 13:12:36,302 INFO misc.py line 117 288342] Train: [1/50][130/2344] Data 0.003 (0.003) Batch 0.707 (0.606) Remain 19:42:10 loss: 1.4434 Lr: 0.00020
[2025-05-11 13:12:36,922 INFO misc.py line 117 288342] Train: [1/50][131/2344] Data 0.002 (0.003) Batch 0.620 (0.606) Remain 19:42:23 loss: 1.5890 Lr: 0.00020
[2025-05-11 13:12:37,630 INFO misc.py line 117 288342] Train: [1/50][132/2344] Data 0.003 (0.003) Batch 0.708 (0.607) Remain 19:43:55 loss: 1.3283 Lr: 0.00020
[2025-05-11 13:12:38,248 INFO misc.py line 117 288342] Train: [1/50][133/2344] Data 0.003 (0.003) Batch 0.618 (0.607) Remain 19:44:04 loss: 1.5054 Lr: 0.00020
[2025-05-11 13:12:38,881 INFO misc.py line 117 288342] Train: [1/50][134/2344] Data 0.003 (0.003) Batch 0.633 (0.607) Remain 19:44:27 loss: 1.2973 Lr: 0.00020
[2025-05-11 13:12:39,558 INFO misc.py line 117 288342] Train: [1/50][135/2344] Data 0.003 (0.003) Batch 0.677 (0.608) Remain 19:45:29 loss: 1.8486 Lr: 0.00020
[2025-05-11 13:12:40,172 INFO misc.py line 117 288342] Train: [1/50][136/2344] Data 0.003 (0.003) Batch 0.614 (0.608) Remain 19:45:33 loss: 1.5851 Lr: 0.00020
[2025-05-11 13:12:40,887 INFO misc.py line 117 288342] Train: [1/50][137/2344] Data 0.003 (0.003) Batch 0.714 (0.608) Remain 19:47:06 loss: 1.7596 Lr: 0.00020
[2025-05-11 13:12:41,432 INFO misc.py line 117 288342] Train: [1/50][138/2344] Data 0.003 (0.003) Batch 0.546 (0.608) Remain 19:46:11 loss: 1.5172 Lr: 0.00020
[2025-05-11 13:12:41,977 INFO misc.py line 117 288342] Train: [1/50][139/2344] Data 0.003 (0.003) Batch 0.545 (0.608) Remain 19:45:16 loss: 1.4530 Lr: 0.00020
[2025-05-11 13:12:42,688 INFO misc.py line 117 288342] Train: [1/50][140/2344] Data 0.003 (0.003) Batch 0.711 (0.608) Remain 19:46:44 loss: 1.3262 Lr: 0.00020
[2025-05-11 13:12:43,251 INFO misc.py line 117 288342] Train: [1/50][141/2344] Data 0.002 (0.003) Batch 0.563 (0.608) Remain 19:46:06 loss: 1.6624 Lr: 0.00020
[2025-05-11 13:12:43,838 INFO misc.py line 117 288342] Train: [1/50][142/2344] Data 0.002 (0.003) Batch 0.586 (0.608) Remain 19:45:47 loss: 1.4781 Lr: 0.00020
[2025-05-11 13:12:44,350 INFO misc.py line 117 288342] Train: [1/50][143/2344] Data 0.003 (0.003) Batch 0.512 (0.607) Remain 19:44:26 loss: 2.0879 Lr: 0.00020
[2025-05-11 13:12:45,082 INFO misc.py line 117 288342] Train: [1/50][144/2344] Data 0.003 (0.003) Batch 0.732 (0.608) Remain 19:46:09 loss: 1.6206 Lr: 0.00020
[2025-05-11 13:12:45,756 INFO misc.py line 117 288342] Train: [1/50][145/2344] Data 0.003 (0.003) Batch 0.675 (0.608) Remain 19:47:03 loss: 1.4831 Lr: 0.00020
[2025-05-11 13:12:46,308 INFO misc.py line 117 288342] Train: [1/50][146/2344] Data 0.003 (0.003) Batch 0.552 (0.608) Remain 19:46:16 loss: 1.8836 Lr: 0.00020
[2025-05-11 13:12:46,872 INFO misc.py line 117 288342] Train: [1/50][147/2344] Data 0.004 (0.003) Batch 0.563 (0.608) Remain 19:45:39 loss: 1.3387 Lr: 0.00020
[2025-05-11 13:12:47,544 INFO misc.py line 117 288342] Train: [1/50][148/2344] Data 0.003 (0.003) Batch 0.672 (0.608) Remain 19:46:31 loss: 1.5286 Lr: 0.00020
[2025-05-11 13:12:48,157 INFO misc.py line 117 288342] Train: [1/50][149/2344] Data 0.003 (0.003) Batch 0.613 (0.608) Remain 19:46:34 loss: 1.5655 Lr: 0.00020
[2025-05-11 13:12:48,866 INFO misc.py line 117 288342] Train: [1/50][150/2344] Data 0.003 (0.003) Batch 0.709 (0.609) Remain 19:47:54 loss: 1.6705 Lr: 0.00020
[2025-05-11 13:12:49,553 INFO misc.py line 117 288342] Train: [1/50][151/2344] Data 0.003 (0.003) Batch 0.687 (0.609) Remain 19:48:55 loss: 1.4661 Lr: 0.00020
[2025-05-11 13:12:50,104 INFO misc.py line 117 288342] Train: [1/50][152/2344] Data 0.003 (0.003) Batch 0.551 (0.609) Remain 19:48:08 loss: 1.5596 Lr: 0.00020
[2025-05-11 13:12:50,613 INFO misc.py line 117 288342] Train: [1/50][153/2344] Data 0.003 (0.003) Batch 0.509 (0.608) Remain 19:46:50 loss: 1.4947 Lr: 0.00020
[2025-05-11 13:12:51,256 INFO misc.py line 117 288342] Train: [1/50][154/2344] Data 0.003 (0.003) Batch 0.644 (0.609) Remain 19:47:16 loss: 1.4055 Lr: 0.00020
[2025-05-11 13:12:51,806 INFO misc.py line 117 288342] Train: [1/50][155/2344] Data 0.003 (0.003) Batch 0.550 (0.608) Remain 19:46:30 loss: 1.6341 Lr: 0.00020
[2025-05-11 13:12:52,476 INFO misc.py line 117 288342] Train: [1/50][156/2344] Data 0.002 (0.003) Batch 0.671 (0.609) Remain 19:47:17 loss: 1.3269 Lr: 0.00020
[2025-05-11 13:12:53,247 INFO misc.py line 117 288342] Train: [1/50][157/2344] Data 0.003 (0.003) Batch 0.771 (0.610) Remain 19:49:20 loss: 1.4612 Lr: 0.00020
[2025-05-11 13:12:53,934 INFO misc.py line 117 288342] Train: [1/50][158/2344] Data 0.002 (0.003) Batch 0.687 (0.610) Remain 19:50:17 loss: 1.5014 Lr: 0.00020
[2025-05-11 13:12:54,606 INFO misc.py line 117 288342] Train: [1/50][159/2344] Data 0.003 (0.003) Batch 0.672 (0.611) Remain 19:51:03 loss: 1.3646 Lr: 0.00021
[2025-05-11 13:12:55,281 INFO misc.py line 117 288342] Train: [1/50][160/2344] Data 0.003 (0.003) Batch 0.675 (0.611) Remain 19:51:51 loss: 1.2056 Lr: 0.00021
[2025-05-11 13:12:55,880 INFO misc.py line 117 288342] Train: [1/50][161/2344] Data 0.002 (0.003) Batch 0.598 (0.611) Remain 19:51:41 loss: 1.5628 Lr: 0.00021
[2025-05-11 13:12:56,521 INFO misc.py line 117 288342] Train: [1/50][162/2344] Data 0.003 (0.003) Batch 0.641 (0.611) Remain 19:52:03 loss: 1.3994 Lr: 0.00021
[2025-05-11 13:12:56,989 INFO misc.py line 117 288342] Train: [1/50][163/2344] Data 0.003 (0.003) Batch 0.467 (0.610) Remain 19:50:17 loss: 1.6144 Lr: 0.00021
[2025-05-11 13:12:57,642 INFO misc.py line 117 288342] Train: [1/50][164/2344] Data 0.003 (0.003) Batch 0.654 (0.610) Remain 19:50:48 loss: 1.4283 Lr: 0.00021
[2025-05-11 13:12:58,210 INFO misc.py line 117 288342] Train: [1/50][165/2344] Data 0.003 (0.003) Batch 0.568 (0.610) Remain 19:50:17 loss: 1.9127 Lr: 0.00021
[2025-05-11 13:12:58,965 INFO misc.py line 117 288342] Train: [1/50][166/2344] Data 0.003 (0.003) Batch 0.755 (0.611) Remain 19:52:00 loss: 1.4510 Lr: 0.00021
[2025-05-11 13:12:59,466 INFO misc.py line 117 288342] Train: [1/50][167/2344] Data 0.003 (0.003) Batch 0.500 (0.610) Remain 19:50:40 loss: 1.6487 Lr: 0.00021
[2025-05-11 13:13:00,001 INFO misc.py line 117 288342] Train: [1/50][168/2344] Data 0.003 (0.003) Batch 0.535 (0.610) Remain 19:49:46 loss: 1.5920 Lr: 0.00021
[2025-05-11 13:13:00,579 INFO misc.py line 117 288342] Train: [1/50][169/2344] Data 0.003 (0.003) Batch 0.578 (0.610) Remain 19:49:23 loss: 1.2901 Lr: 0.00021
[2025-05-11 13:13:01,236 INFO misc.py line 117 288342] Train: [1/50][170/2344] Data 0.003 (0.003) Batch 0.657 (0.610) Remain 19:49:56 loss: 1.4324 Lr: 0.00021
[2025-05-11 13:13:01,784 INFO misc.py line 117 288342] Train: [1/50][171/2344] Data 0.003 (0.003) Batch 0.548 (0.610) Remain 19:49:12 loss: 1.4026 Lr: 0.00021
[2025-05-11 13:13:02,364 INFO misc.py line 117 288342] Train: [1/50][172/2344] Data 0.003 (0.003) Batch 0.580 (0.610) Remain 19:48:51 loss: 1.4291 Lr: 0.00021
[2025-05-11 13:13:02,964 INFO misc.py line 117 288342] Train: [1/50][173/2344] Data 0.003 (0.003) Batch 0.600 (0.609) Remain 19:48:43 loss: 1.3587 Lr: 0.00021
[2025-05-11 13:13:03,598 INFO misc.py line 117 288342] Train: [1/50][174/2344] Data 0.003 (0.003) Batch 0.635 (0.610) Remain 19:49:00 loss: 1.4870 Lr: 0.00021
[2025-05-11 13:13:04,238 INFO misc.py line 117 288342] Train: [1/50][175/2344] Data 0.003 (0.003) Batch 0.640 (0.610) Remain 19:49:20 loss: 1.4080 Lr: 0.00021
[2025-05-11 13:13:04,754 INFO misc.py line 117 288342] Train: [1/50][176/2344] Data 0.003 (0.003) Batch 0.515 (0.609) Remain 19:48:16 loss: 1.3855 Lr: 0.00021
[2025-05-11 13:13:05,432 INFO misc.py line 117 288342] Train: [1/50][177/2344] Data 0.003 (0.003) Batch 0.678 (0.610) Remain 19:49:02 loss: 1.5627 Lr: 0.00021
[2025-05-11 13:13:06,001 INFO misc.py line 117 288342] Train: [1/50][178/2344] Data 0.003 (0.003) Batch 0.569 (0.609) Remain 19:48:33 loss: 1.4289 Lr: 0.00021
[2025-05-11 13:13:06,629 INFO misc.py line 117 288342] Train: [1/50][179/2344] Data 0.003 (0.003) Batch 0.628 (0.610) Remain 19:48:45 loss: 1.4534 Lr: 0.00021
[2025-05-11 13:13:07,291 INFO misc.py line 117 288342] Train: [1/50][180/2344] Data 0.003 (0.003) Batch 0.662 (0.610) Remain 19:49:19 loss: 1.3445 Lr: 0.00021
[2025-05-11 13:13:08,048 INFO misc.py line 117 288342] Train: [1/50][181/2344] Data 0.003 (0.003) Batch 0.757 (0.611) Remain 19:50:56 loss: 1.6184 Lr: 0.00021
[2025-05-11 13:13:08,629 INFO misc.py line 117 288342] Train: [1/50][182/2344] Data 0.003 (0.003) Batch 0.581 (0.610) Remain 19:50:36 loss: 1.4246 Lr: 0.00021
[2025-05-11 13:13:09,169 INFO misc.py line 117 288342] Train: [1/50][183/2344] Data 0.003 (0.003) Batch 0.540 (0.610) Remain 19:49:50 loss: 1.4986 Lr: 0.00021
[2025-05-11 13:13:09,895 INFO misc.py line 117 288342] Train: [1/50][184/2344] Data 0.003 (0.003) Batch 0.726 (0.611) Remain 19:51:04 loss: 1.5509 Lr: 0.00021
[2025-05-11 13:13:10,455 INFO misc.py line 117 288342] Train: [1/50][185/2344] Data 0.003 (0.003) Batch 0.560 (0.610) Remain 19:50:30 loss: 1.7821 Lr: 0.00021
[2025-05-11 13:13:11,217 INFO misc.py line 117 288342] Train: [1/50][186/2344] Data 0.003 (0.003) Batch 0.762 (0.611) Remain 19:52:07 loss: 1.6816 Lr: 0.00021
[2025-05-11 13:13:11,880 INFO misc.py line 117 288342] Train: [1/50][187/2344] Data 0.003 (0.003) Batch 0.663 (0.612) Remain 19:52:39 loss: 1.7744 Lr: 0.00021
[2025-05-11 13:13:12,481 INFO misc.py line 117 288342] Train: [1/50][188/2344] Data 0.003 (0.003) Batch 0.601 (0.611) Remain 19:52:32 loss: 1.3757 Lr: 0.00021
[2025-05-11 13:13:13,192 INFO misc.py line 117 288342] Train: [1/50][189/2344] Data 0.003 (0.003) Batch 0.712 (0.612) Remain 19:53:34 loss: 1.5229 Lr: 0.00021
[2025-05-11 13:13:13,758 INFO misc.py line 117 288342] Train: [1/50][190/2344] Data 0.002 (0.003) Batch 0.565 (0.612) Remain 19:53:04 loss: 1.3528 Lr: 0.00021
[2025-05-11 13:13:14,294 INFO misc.py line 117 288342] Train: [1/50][191/2344] Data 0.003 (0.003) Batch 0.536 (0.611) Remain 19:52:16 loss: 1.4544 Lr: 0.00021
[2025-05-11 13:13:14,899 INFO misc.py line 117 288342] Train: [1/50][192/2344] Data 0.003 (0.003) Batch 0.606 (0.611) Remain 19:52:12 loss: 1.1241 Lr: 0.00021
[2025-05-11 13:13:15,384 INFO misc.py line 117 288342] Train: [1/50][193/2344] Data 0.003 (0.003) Batch 0.485 (0.611) Remain 19:50:54 loss: 1.3538 Lr: 0.00021
[2025-05-11 13:13:15,905 INFO misc.py line 117 288342] Train: [1/50][194/2344] Data 0.002 (0.003) Batch 0.520 (0.610) Remain 19:49:58 loss: 1.3892 Lr: 0.00021
[2025-05-11 13:13:16,552 INFO misc.py line 117 288342] Train: [1/50][195/2344] Data 0.003 (0.003) Batch 0.647 (0.610) Remain 19:50:20 loss: 1.4648 Lr: 0.00021
[2025-05-11 13:13:17,186 INFO misc.py line 117 288342] Train: [1/50][196/2344] Data 0.003 (0.003) Batch 0.634 (0.611) Remain 19:50:34 loss: 1.3217 Lr: 0.00021
[2025-05-11 13:13:17,775 INFO misc.py line 117 288342] Train: [1/50][197/2344] Data 0.003 (0.003) Batch 0.589 (0.610) Remain 19:50:20 loss: 1.6207 Lr: 0.00021
[2025-05-11 13:13:18,259 INFO misc.py line 117 288342] Train: [1/50][198/2344] Data 0.003 (0.003) Batch 0.484 (0.610) Remain 19:49:03 loss: 1.3647 Lr: 0.00021
[2025-05-11 13:13:18,865 INFO misc.py line 117 288342] Train: [1/50][199/2344] Data 0.003 (0.003) Batch 0.606 (0.610) Remain 19:49:01 loss: 1.3818 Lr: 0.00021
[2025-05-11 13:13:19,636 INFO misc.py line 117 288342] Train: [1/50][200/2344] Data 0.002 (0.003) Batch 0.771 (0.611) Remain 19:50:36 loss: 1.4109 Lr: 0.00021
[2025-05-11 13:13:20,122 INFO misc.py line 117 288342] Train: [1/50][201/2344] Data 0.003 (0.003) Batch 0.487 (0.610) Remain 19:49:22 loss: 1.7506 Lr: 0.00021
[2025-05-11 13:13:20,944 INFO misc.py line 117 288342] Train: [1/50][202/2344] Data 0.003 (0.003) Batch 0.822 (0.611) Remain 19:51:26 loss: 1.3013 Lr: 0.00021
[2025-05-11 13:13:21,453 INFO misc.py line 117 288342] Train: [1/50][203/2344] Data 0.003 (0.003) Batch 0.509 (0.610) Remain 19:50:26 loss: 1.5691 Lr: 0.00021
[2025-05-11 13:13:22,028 INFO misc.py line 117 288342] Train: [1/50][204/2344] Data 0.003 (0.003) Batch 0.575 (0.610) Remain 19:50:04 loss: 1.4868 Lr: 0.00021
[2025-05-11 13:13:22,597 INFO misc.py line 117 288342] Train: [1/50][205/2344] Data 0.002 (0.003) Batch 0.569 (0.610) Remain 19:49:40 loss: 1.3941 Lr: 0.00021
[2025-05-11 13:13:23,290 INFO misc.py line 117 288342] Train: [1/50][206/2344] Data 0.003 (0.003) Batch 0.693 (0.611) Remain 19:50:27 loss: 1.4096 Lr: 0.00021
[2025-05-11 13:13:23,912 INFO misc.py line 117 288342] Train: [1/50][207/2344] Data 0.003 (0.003) Batch 0.622 (0.611) Remain 19:50:33 loss: 1.4996 Lr: 0.00021
[2025-05-11 13:13:24,525 INFO misc.py line 117 288342] Train: [1/50][208/2344] Data 0.002 (0.003) Batch 0.613 (0.611) Remain 19:50:33 loss: 1.5141 Lr: 0.00021
[2025-05-11 13:13:25,126 INFO misc.py line 117 288342] Train: [1/50][209/2344] Data 0.003 (0.003) Batch 0.601 (0.611) Remain 19:50:27 loss: 1.5990 Lr: 0.00021
[2025-05-11 13:13:25,707 INFO misc.py line 117 288342] Train: [1/50][210/2344] Data 0.002 (0.003) Batch 0.581 (0.610) Remain 19:50:10 loss: 1.1668 Lr: 0.00021
[2025-05-11 13:13:26,299 INFO misc.py line 117 288342] Train: [1/50][211/2344] Data 0.003 (0.003) Batch 0.592 (0.610) Remain 19:49:59 loss: 1.6253 Lr: 0.00021
[2025-05-11 13:13:27,028 INFO misc.py line 117 288342] Train: [1/50][212/2344] Data 0.003 (0.003) Batch 0.729 (0.611) Remain 19:51:05 loss: 1.3160 Lr: 0.00021
[2025-05-11 13:13:27,694 INFO misc.py line 117 288342] Train: [1/50][213/2344] Data 0.003 (0.003) Batch 0.666 (0.611) Remain 19:51:35 loss: 1.3424 Lr: 0.00021
[2025-05-11 13:13:28,391 INFO misc.py line 117 288342] Train: [1/50][214/2344] Data 0.003 (0.003) Batch 0.697 (0.612) Remain 19:52:22 loss: 1.5485 Lr: 0.00021
[2025-05-11 13:13:28,986 INFO misc.py line 117 288342] Train: [1/50][215/2344] Data 0.003 (0.003) Batch 0.596 (0.611) Remain 19:52:12 loss: 1.4270 Lr: 0.00021
[2025-05-11 13:13:29,653 INFO misc.py line 117 288342] Train: [1/50][216/2344] Data 0.003 (0.003) Batch 0.666 (0.612) Remain 19:52:42 loss: 1.6145 Lr: 0.00021
[2025-05-11 13:13:30,313 INFO misc.py line 117 288342] Train: [1/50][217/2344] Data 0.003 (0.003) Batch 0.660 (0.612) Remain 19:53:08 loss: 1.2695 Lr: 0.00021
[2025-05-11 13:13:31,072 INFO misc.py line 117 288342] Train: [1/50][218/2344] Data 0.003 (0.003) Batch 0.758 (0.613) Remain 19:54:27 loss: 1.6104 Lr: 0.00021
[2025-05-11 13:13:31,609 INFO misc.py line 117 288342] Train: [1/50][219/2344] Data 0.003 (0.003) Batch 0.537 (0.612) Remain 19:53:46 loss: 1.2840 Lr: 0.00021
[2025-05-11 13:13:32,256 INFO misc.py line 117 288342] Train: [1/50][220/2344] Data 0.003 (0.003) Batch 0.647 (0.612) Remain 19:54:04 loss: 1.5542 Lr: 0.00021
[2025-05-11 13:13:32,809 INFO misc.py line 117 288342] Train: [1/50][221/2344] Data 0.003 (0.003) Batch 0.552 (0.612) Remain 19:53:31 loss: 1.6113 Lr: 0.00021
[2025-05-11 13:13:33,570 INFO misc.py line 117 288342] Train: [1/50][222/2344] Data 0.003 (0.003) Batch 0.761 (0.613) Remain 19:54:50 loss: 1.6178 Lr: 0.00021
[2025-05-11 13:13:34,092 INFO misc.py line 117 288342] Train: [1/50][223/2344] Data 0.003 (0.003) Batch 0.522 (0.612) Remain 19:54:01 loss: 1.3359 Lr: 0.00021
[2025-05-11 13:13:34,665 INFO misc.py line 117 288342] Train: [1/50][224/2344] Data 0.003 (0.003) Batch 0.572 (0.612) Remain 19:53:40 loss: 1.5007 Lr: 0.00021
[2025-05-11 13:13:35,345 INFO misc.py line 117 288342] Train: [1/50][225/2344] Data 0.003 (0.003) Batch 0.681 (0.613) Remain 19:54:15 loss: 1.1890 Lr: 0.00021
[2025-05-11 13:13:36,042 INFO misc.py line 117 288342] Train: [1/50][226/2344] Data 0.002 (0.003) Batch 0.696 (0.613) Remain 19:54:58 loss: 1.2195 Lr: 0.00021
[2025-05-11 13:13:36,608 INFO misc.py line 117 288342] Train: [1/50][227/2344] Data 0.003 (0.003) Batch 0.566 (0.613) Remain 19:54:33 loss: 1.1749 Lr: 0.00021
[2025-05-11 13:13:37,142 INFO misc.py line 117 288342] Train: [1/50][228/2344] Data 0.002 (0.003) Batch 0.534 (0.612) Remain 19:53:52 loss: 1.5396 Lr: 0.00021
[2025-05-11 13:13:37,687 INFO misc.py line 117 288342] Train: [1/50][229/2344] Data 0.002 (0.003) Batch 0.545 (0.612) Remain 19:53:16 loss: 1.4672 Lr: 0.00021
[2025-05-11 13:13:38,355 INFO misc.py line 117 288342] Train: [1/50][230/2344] Data 0.003 (0.003) Batch 0.668 (0.612) Remain 19:53:44 loss: 1.4458 Lr: 0.00021
[2025-05-11 13:13:38,993 INFO misc.py line 117 288342] Train: [1/50][231/2344] Data 0.003 (0.003) Batch 0.639 (0.612) Remain 19:53:57 loss: 1.4499 Lr: 0.00021
[2025-05-11 13:13:39,621 INFO misc.py line 117 288342] Train: [1/50][232/2344] Data 0.003 (0.003) Batch 0.627 (0.613) Remain 19:54:04 loss: 1.4826 Lr: 0.00021
[2025-05-11 13:13:40,389 INFO misc.py line 117 288342] Train: [1/50][233/2344] Data 0.002 (0.003) Batch 0.768 (0.613) Remain 19:55:23 loss: 1.5727 Lr: 0.00021
[2025-05-11 13:13:41,116 INFO misc.py line 117 288342] Train: [1/50][234/2344] Data 0.002 (0.003) Batch 0.727 (0.614) Remain 19:56:20 loss: 1.5291 Lr: 0.00021
[2025-05-11 13:13:41,681 INFO misc.py line 117 288342] Train: [1/50][235/2344] Data 0.003 (0.003) Batch 0.566 (0.613) Remain 19:55:55 loss: 1.9686 Lr: 0.00021
[2025-05-11 13:13:42,349 INFO misc.py line 117 288342] Train: [1/50][236/2344] Data 0.002 (0.003) Batch 0.667 (0.614) Remain 19:56:21 loss: 1.4195 Lr: 0.00021
[2025-05-11 13:13:43,028 INFO misc.py line 117 288342] Train: [1/50][237/2344] Data 0.002 (0.003) Batch 0.679 (0.614) Remain 19:56:53 loss: 1.2966 Lr: 0.00021
[2025-05-11 13:13:43,559 INFO misc.py line 117 288342] Train: [1/50][238/2344] Data 0.003 (0.003) Batch 0.531 (0.614) Remain 19:56:11 loss: 1.3714 Lr: 0.00021
[2025-05-11 13:13:44,313 INFO misc.py line 117 288342] Train: [1/50][239/2344] Data 0.003 (0.003) Batch 0.754 (0.614) Remain 19:57:21 loss: 1.0767 Lr: 0.00021
[2025-05-11 13:13:45,015 INFO misc.py line 117 288342] Train: [1/50][240/2344] Data 0.003 (0.003) Batch 0.702 (0.615) Remain 19:58:04 loss: 1.4172 Lr: 0.00021
[2025-05-11 13:13:45,670 INFO misc.py line 117 288342] Train: [1/50][241/2344] Data 0.003 (0.003) Batch 0.655 (0.615) Remain 19:58:23 loss: 1.2088 Lr: 0.00021
[2025-05-11 13:13:46,278 INFO misc.py line 117 288342] Train: [1/50][242/2344] Data 0.003 (0.003) Batch 0.608 (0.615) Remain 19:58:19 loss: 1.4727 Lr: 0.00021
[2025-05-11 13:13:46,999 INFO misc.py line 117 288342] Train: [1/50][243/2344] Data 0.002 (0.003) Batch 0.721 (0.615) Remain 19:59:10 loss: 1.1362 Lr: 0.00021
[2025-05-11 13:13:47,666 INFO misc.py line 117 288342] Train: [1/50][244/2344] Data 0.002 (0.003) Batch 0.667 (0.615) Remain 19:59:34 loss: 1.4288 Lr: 0.00021
[2025-05-11 13:13:48,248 INFO misc.py line 117 288342] Train: [1/50][245/2344] Data 0.003 (0.003) Batch 0.582 (0.615) Remain 19:59:17 loss: 1.4335 Lr: 0.00021
[2025-05-11 13:13:48,772 INFO misc.py line 117 288342] Train: [1/50][246/2344] Data 0.002 (0.003) Batch 0.524 (0.615) Remain 19:58:33 loss: 1.7428 Lr: 0.00021
[2025-05-11 13:13:49,300 INFO misc.py line 117 288342] Train: [1/50][247/2344] Data 0.003 (0.003) Batch 0.529 (0.615) Remain 19:57:51 loss: 1.5645 Lr: 0.00021
[2025-05-11 13:13:49,771 INFO misc.py line 117 288342] Train: [1/50][248/2344] Data 0.003 (0.003) Batch 0.471 (0.614) Remain 19:56:42 loss: 1.4323 Lr: 0.00021
[2025-05-11 13:13:50,475 INFO misc.py line 117 288342] Train: [1/50][249/2344] Data 0.003 (0.003) Batch 0.704 (0.614) Remain 19:57:24 loss: 1.3148 Lr: 0.00021
[2025-05-11 13:13:51,179 INFO misc.py line 117 288342] Train: [1/50][250/2344] Data 0.003 (0.003) Batch 0.704 (0.615) Remain 19:58:06 loss: 1.3288 Lr: 0.00021
[2025-05-11 13:13:51,787 INFO misc.py line 117 288342] Train: [1/50][251/2344] Data 0.003 (0.003) Batch 0.608 (0.615) Remain 19:58:02 loss: 1.4544 Lr: 0.00021
[2025-05-11 13:13:52,334 INFO misc.py line 117 288342] Train: [1/50][252/2344] Data 0.003 (0.003) Batch 0.547 (0.614) Remain 19:57:29 loss: 1.2625 Lr: 0.00021
[2025-05-11 13:13:52,898 INFO misc.py line 117 288342] Train: [1/50][253/2344] Data 0.002 (0.003) Batch 0.564 (0.614) Remain 19:57:05 loss: 1.5098 Lr: 0.00021
[2025-05-11 13:13:53,546 INFO misc.py line 117 288342] Train: [1/50][254/2344] Data 0.002 (0.003) Batch 0.649 (0.614) Remain 19:57:21 loss: 1.4963 Lr: 0.00021
[2025-05-11 13:13:54,128 INFO misc.py line 117 288342] Train: [1/50][255/2344] Data 0.003 (0.003) Batch 0.582 (0.614) Remain 19:57:05 loss: 1.2267 Lr: 0.00021
[2025-05-11 13:13:54,748 INFO misc.py line 117 288342] Train: [1/50][256/2344] Data 0.002 (0.003) Batch 0.619 (0.614) Remain 19:57:07 loss: 1.4670 Lr: 0.00021
[2025-05-11 13:13:55,193 INFO misc.py line 117 288342] Train: [1/50][257/2344] Data 0.003 (0.003) Batch 0.445 (0.614) Remain 19:55:48 loss: 1.4923 Lr: 0.00021
[2025-05-11 13:13:55,712 INFO misc.py line 117 288342] Train: [1/50][258/2344] Data 0.003 (0.003) Batch 0.519 (0.613) Remain 19:55:04 loss: 1.4260 Lr: 0.00021
[2025-05-11 13:13:56,324 INFO misc.py line 117 288342] Train: [1/50][259/2344] Data 0.003 (0.003) Batch 0.612 (0.613) Remain 19:55:03 loss: 1.3210 Lr: 0.00021
[2025-05-11 13:13:57,066 INFO misc.py line 117 288342] Train: [1/50][260/2344] Data 0.002 (0.003) Batch 0.742 (0.614) Remain 19:56:01 loss: 1.2891 Lr: 0.00021
[2025-05-11 13:13:57,537 INFO misc.py line 117 288342] Train: [1/50][261/2344] Data 0.003 (0.003) Batch 0.471 (0.613) Remain 19:54:56 loss: 1.2620 Lr: 0.00021
[2025-05-11 13:13:58,232 INFO misc.py line 117 288342] Train: [1/50][262/2344] Data 0.003 (0.003) Batch 0.694 (0.613) Remain 19:55:32 loss: 1.2408 Lr: 0.00021
[2025-05-11 13:13:58,802 INFO misc.py line 117 288342] Train: [1/50][263/2344] Data 0.002 (0.003) Batch 0.571 (0.613) Remain 19:55:12 loss: 1.4002 Lr: 0.00021
[2025-05-11 13:13:59,411 INFO misc.py line 117 288342] Train: [1/50][264/2344] Data 0.003 (0.003) Batch 0.609 (0.613) Remain 19:55:10 loss: 1.3469 Lr: 0.00021
[2025-05-11 13:14:00,042 INFO misc.py line 117 288342] Train: [1/50][265/2344] Data 0.002 (0.003) Batch 0.630 (0.613) Remain 19:55:17 loss: 1.6859 Lr: 0.00021
[2025-05-11 13:14:00,591 INFO misc.py line 117 288342] Train: [1/50][266/2344] Data 0.002 (0.003) Batch 0.549 (0.613) Remain 19:54:48 loss: 1.3420 Lr: 0.00021
[2025-05-11 13:14:01,208 INFO misc.py line 117 288342] Train: [1/50][267/2344] Data 0.003 (0.003) Batch 0.617 (0.613) Remain 19:54:49 loss: 1.1482 Lr: 0.00021
[2025-05-11 13:14:01,767 INFO misc.py line 117 288342] Train: [1/50][268/2344] Data 0.003 (0.003) Batch 0.559 (0.613) Remain 19:54:24 loss: 1.6289 Lr: 0.00021
[2025-05-11 13:14:02,315 INFO misc.py line 117 288342] Train: [1/50][269/2344] Data 0.003 (0.003) Batch 0.548 (0.613) Remain 19:53:55 loss: 1.4042 Lr: 0.00021
[2025-05-11 13:14:02,941 INFO misc.py line 117 288342] Train: [1/50][270/2344] Data 0.003 (0.003) Batch 0.626 (0.613) Remain 19:54:00 loss: 1.1894 Lr: 0.00021
[2025-05-11 13:14:03,358 INFO misc.py line 117 288342] Train: [1/50][271/2344] Data 0.003 (0.003) Batch 0.418 (0.612) Remain 19:52:35 loss: 1.3813 Lr: 0.00021
[2025-05-11 13:14:04,012 INFO misc.py line 117 288342] Train: [1/50][272/2344] Data 0.003 (0.003) Batch 0.653 (0.612) Remain 19:52:52 loss: 1.1948 Lr: 0.00021
[2025-05-11 13:14:04,604 INFO misc.py line 117 288342] Train: [1/50][273/2344] Data 0.003 (0.003) Batch 0.592 (0.612) Remain 19:52:43 loss: 1.3779 Lr: 0.00021
[2025-05-11 13:14:05,149 INFO misc.py line 117 288342] Train: [1/50][274/2344] Data 0.002 (0.003) Batch 0.545 (0.612) Remain 19:52:13 loss: 1.2976 Lr: 0.00022
[2025-05-11 13:14:05,733 INFO misc.py line 117 288342] Train: [1/50][275/2344] Data 0.003 (0.003) Batch 0.584 (0.612) Remain 19:52:01 loss: 1.2196 Lr: 0.00022
[2025-05-11 13:14:06,379 INFO misc.py line 117 288342] Train: [1/50][276/2344] Data 0.003 (0.003) Batch 0.646 (0.612) Remain 19:52:15 loss: 1.1630 Lr: 0.00022
[2025-05-11 13:14:07,173 INFO misc.py line 117 288342] Train: [1/50][277/2344] Data 0.003 (0.003) Batch 0.795 (0.612) Remain 19:53:32 loss: 1.2473 Lr: 0.00022
[2025-05-11 13:14:07,749 INFO misc.py line 117 288342] Train: [1/50][278/2344] Data 0.003 (0.003) Batch 0.576 (0.612) Remain 19:53:16 loss: 1.0106 Lr: 0.00022
[2025-05-11 13:14:08,228 INFO misc.py line 117 288342] Train: [1/50][279/2344] Data 0.003 (0.003) Batch 0.478 (0.612) Remain 19:52:19 loss: 1.5769 Lr: 0.00022
[2025-05-11 13:14:08,745 INFO misc.py line 117 288342] Train: [1/50][280/2344] Data 0.003 (0.003) Batch 0.517 (0.612) Remain 19:51:38 loss: 1.4154 Lr: 0.00022
[2025-05-11 13:14:09,188 INFO misc.py line 117 288342] Train: [1/50][281/2344] Data 0.002 (0.003) Batch 0.443 (0.611) Remain 19:50:27 loss: 1.4180 Lr: 0.00022
[2025-05-11 13:14:09,941 INFO misc.py line 117 288342] Train: [1/50][282/2344] Data 0.003 (0.003) Batch 0.752 (0.611) Remain 19:51:25 loss: 1.4920 Lr: 0.00022
[2025-05-11 13:14:10,541 INFO misc.py line 117 288342] Train: [1/50][283/2344] Data 0.003 (0.003) Batch 0.600 (0.611) Remain 19:51:20 loss: 1.5106 Lr: 0.00022
[2025-05-11 13:14:11,105 INFO misc.py line 117 288342] Train: [1/50][284/2344] Data 0.002 (0.003) Batch 0.564 (0.611) Remain 19:51:00 loss: 1.2953 Lr: 0.00022
[2025-05-11 13:14:11,705 INFO misc.py line 117 288342] Train: [1/50][285/2344] Data 0.003 (0.003) Batch 0.600 (0.611) Remain 19:50:55 loss: 1.6956 Lr: 0.00022
[2025-05-11 13:14:12,247 INFO misc.py line 117 288342] Train: [1/50][286/2344] Data 0.003 (0.003) Batch 0.542 (0.611) Remain 19:50:25 loss: 1.2703 Lr: 0.00022
[2025-05-11 13:14:12,781 INFO misc.py line 117 288342] Train: [1/50][287/2344] Data 0.003 (0.003) Batch 0.534 (0.611) Remain 19:49:53 loss: 1.4148 Lr: 0.00022
[2025-05-11 13:14:13,319 INFO misc.py line 117 288342] Train: [1/50][288/2344] Data 0.003 (0.003) Batch 0.539 (0.610) Remain 19:49:23 loss: 1.0558 Lr: 0.00022
[2025-05-11 13:14:13,862 INFO misc.py line 117 288342] Train: [1/50][289/2344] Data 0.003 (0.003) Batch 0.542 (0.610) Remain 19:48:54 loss: 1.3911 Lr: 0.00022
[2025-05-11 13:14:14,463 INFO misc.py line 117 288342] Train: [1/50][290/2344] Data 0.002 (0.003) Batch 0.602 (0.610) Remain 19:48:50 loss: 1.7405 Lr: 0.00022
[2025-05-11 13:14:15,057 INFO misc.py line 117 288342] Train: [1/50][291/2344] Data 0.002 (0.003) Batch 0.594 (0.610) Remain 19:48:43 loss: 1.2798 Lr: 0.00022
[2025-05-11 13:14:15,701 INFO misc.py line 117 288342] Train: [1/50][292/2344] Data 0.003 (0.003) Batch 0.644 (0.610) Remain 19:48:56 loss: 1.4143 Lr: 0.00022
[2025-05-11 13:14:16,471 INFO misc.py line 117 288342] Train: [1/50][293/2344] Data 0.003 (0.003) Batch 0.770 (0.611) Remain 19:50:00 loss: 1.3316 Lr: 0.00022
[2025-05-11 13:14:17,058 INFO misc.py line 117 288342] Train: [1/50][294/2344] Data 0.002 (0.003) Batch 0.587 (0.611) Remain 19:49:50 loss: 1.4607 Lr: 0.00022
[2025-05-11 13:14:17,699 INFO misc.py line 117 288342] Train: [1/50][295/2344] Data 0.003 (0.003) Batch 0.641 (0.611) Remain 19:50:01 loss: 1.2818 Lr: 0.00022
[2025-05-11 13:14:18,252 INFO misc.py line 117 288342] Train: [1/50][296/2344] Data 0.002 (0.003) Batch 0.553 (0.611) Remain 19:49:38 loss: 1.4017 Lr: 0.00022
[2025-05-11 13:14:18,897 INFO misc.py line 117 288342] Train: [1/50][297/2344] Data 0.003 (0.003) Batch 0.645 (0.611) Remain 19:49:51 loss: 1.3006 Lr: 0.00022
[2025-05-11 13:14:19,469 INFO misc.py line 117 288342] Train: [1/50][298/2344] Data 0.003 (0.003) Batch 0.572 (0.611) Remain 19:49:35 loss: 1.1483 Lr: 0.00022
[2025-05-11 13:14:20,079 INFO misc.py line 117 288342] Train: [1/50][299/2344] Data 0.003 (0.003) Batch 0.611 (0.611) Remain 19:49:34 loss: 1.4386 Lr: 0.00022
[2025-05-11 13:14:20,625 INFO misc.py line 117 288342] Train: [1/50][300/2344] Data 0.003 (0.003) Batch 0.545 (0.610) Remain 19:49:08 loss: 1.4844 Lr: 0.00022
[2025-05-11 13:14:21,216 INFO misc.py line 117 288342] Train: [1/50][301/2344] Data 0.003 (0.003) Batch 0.591 (0.610) Remain 19:49:00 loss: 1.3406 Lr: 0.00022
[2025-05-11 13:14:21,755 INFO misc.py line 117 288342] Train: [1/50][302/2344] Data 0.002 (0.003) Batch 0.539 (0.610) Remain 19:48:31 loss: 1.4782 Lr: 0.00022
[2025-05-11 13:14:22,394 INFO misc.py line 117 288342] Train: [1/50][303/2344] Data 0.003 (0.003) Batch 0.639 (0.610) Remain 19:48:42 loss: 1.3861 Lr: 0.00022
[2025-05-11 13:14:22,898 INFO misc.py line 117 288342] Train: [1/50][304/2344] Data 0.002 (0.003) Batch 0.504 (0.610) Remain 19:48:00 loss: 1.3873 Lr: 0.00022
[2025-05-11 13:14:23,539 INFO misc.py line 117 288342] Train: [1/50][305/2344] Data 0.003 (0.003) Batch 0.640 (0.610) Remain 19:48:11 loss: 1.4166 Lr: 0.00022
[2025-05-11 13:14:24,106 INFO misc.py line 117 288342] Train: [1/50][306/2344] Data 0.003 (0.003) Batch 0.567 (0.610) Remain 19:47:54 loss: 1.2938 Lr: 0.00022
[2025-05-11 13:14:24,739 INFO misc.py line 117 288342] Train: [1/50][307/2344] Data 0.003 (0.003) Batch 0.633 (0.610) Remain 19:48:03 loss: 1.2464 Lr: 0.00022
[2025-05-11 13:14:25,340 INFO misc.py line 117 288342] Train: [1/50][308/2344] Data 0.003 (0.003) Batch 0.601 (0.610) Remain 19:47:59 loss: 1.1103 Lr: 0.00022
[2025-05-11 13:14:26,008 INFO misc.py line 117 288342] Train: [1/50][309/2344] Data 0.003 (0.003) Batch 0.668 (0.610) Remain 19:48:20 loss: 1.2034 Lr: 0.00022
[2025-05-11 13:14:26,659 INFO misc.py line 117 288342] Train: [1/50][310/2344] Data 0.003 (0.003) Batch 0.651 (0.610) Remain 19:48:35 loss: 1.4337 Lr: 0.00022
[2025-05-11 13:14:27,325 INFO misc.py line 117 288342] Train: [1/50][311/2344] Data 0.003 (0.003) Batch 0.666 (0.610) Remain 19:48:56 loss: 1.0880 Lr: 0.00022
[2025-05-11 13:14:28,019 INFO misc.py line 117 288342] Train: [1/50][312/2344] Data 0.003 (0.003) Batch 0.694 (0.611) Remain 19:49:27 loss: 1.4232 Lr: 0.00022
[2025-05-11 13:14:28,560 INFO misc.py line 117 288342] Train: [1/50][313/2344] Data 0.003 (0.003) Batch 0.541 (0.610) Remain 19:49:00 loss: 1.1907 Lr: 0.00022
[2025-05-11 13:14:29,204 INFO misc.py line 117 288342] Train: [1/50][314/2344] Data 0.003 (0.003) Batch 0.644 (0.610) Remain 19:49:12 loss: 1.4288 Lr: 0.00022
[2025-05-11 13:14:29,699 INFO misc.py line 117 288342] Train: [1/50][315/2344] Data 0.002 (0.003) Batch 0.494 (0.610) Remain 19:48:28 loss: 1.3716 Lr: 0.00022
[2025-05-11 13:14:30,345 INFO misc.py line 117 288342] Train: [1/50][316/2344] Data 0.003 (0.003) Batch 0.646 (0.610) Remain 19:48:41 loss: 1.6942 Lr: 0.00022
[2025-05-11 13:14:30,945 INFO misc.py line 117 288342] Train: [1/50][317/2344] Data 0.003 (0.003) Batch 0.600 (0.610) Remain 19:48:37 loss: 1.6017 Lr: 0.00022
[2025-05-11 13:14:31,614 INFO misc.py line 117 288342] Train: [1/50][318/2344] Data 0.002 (0.003) Batch 0.669 (0.610) Remain 19:48:58 loss: 1.2321 Lr: 0.00022
[2025-05-11 13:14:32,459 INFO misc.py line 117 288342] Train: [1/50][319/2344] Data 0.003 (0.003) Batch 0.845 (0.611) Remain 19:50:24 loss: 1.2956 Lr: 0.00022
[2025-05-11 13:14:33,007 INFO misc.py line 117 288342] Train: [1/50][320/2344] Data 0.002 (0.003) Batch 0.548 (0.611) Remain 19:50:00 loss: 1.3265 Lr: 0.00022
[2025-05-11 13:14:33,602 INFO misc.py line 117 288342] Train: [1/50][321/2344] Data 0.002 (0.003) Batch 0.595 (0.611) Remain 19:49:54 loss: 1.3323 Lr: 0.00022
[2025-05-11 13:14:34,272 INFO misc.py line 117 288342] Train: [1/50][322/2344] Data 0.003 (0.003) Batch 0.670 (0.611) Remain 19:50:15 loss: 1.1388 Lr: 0.00022
[2025-05-11 13:14:34,939 INFO misc.py line 117 288342] Train: [1/50][323/2344] Data 0.003 (0.003) Batch 0.666 (0.611) Remain 19:50:35 loss: 1.3671 Lr: 0.00022
[2025-05-11 13:14:35,608 INFO misc.py line 117 288342] Train: [1/50][324/2344] Data 0.003 (0.003) Batch 0.669 (0.611) Remain 19:50:55 loss: 1.5704 Lr: 0.00022
[2025-05-11 13:14:36,348 INFO misc.py line 117 288342] Train: [1/50][325/2344] Data 0.003 (0.003) Batch 0.740 (0.612) Remain 19:51:41 loss: 1.3075 Lr: 0.00022
[2025-05-11 13:14:36,984 INFO misc.py line 117 288342] Train: [1/50][326/2344] Data 0.002 (0.003) Batch 0.636 (0.612) Remain 19:51:49 loss: 1.5611 Lr: 0.00022
[2025-05-11 13:14:37,706 INFO misc.py line 117 288342] Train: [1/50][327/2344] Data 0.003 (0.003) Batch 0.722 (0.612) Remain 19:52:29 loss: 1.3310 Lr: 0.00022
[2025-05-11 13:14:38,262 INFO misc.py line 117 288342] Train: [1/50][328/2344] Data 0.003 (0.003) Batch 0.556 (0.612) Remain 19:52:08 loss: 1.7622 Lr: 0.00022
[2025-05-11 13:14:38,903 INFO misc.py line 117 288342] Train: [1/50][329/2344] Data 0.003 (0.003) Batch 0.641 (0.612) Remain 19:52:17 loss: 1.2769 Lr: 0.00022
[2025-05-11 13:14:39,668 INFO misc.py line 117 288342] Train: [1/50][330/2344] Data 0.003 (0.003) Batch 0.765 (0.613) Remain 19:53:11 loss: 1.4595 Lr: 0.00022
[2025-05-11 13:14:40,133 INFO misc.py line 117 288342] Train: [1/50][331/2344] Data 0.003 (0.003) Batch 0.466 (0.612) Remain 19:52:18 loss: 1.2038 Lr: 0.00022
[2025-05-11 13:14:40,754 INFO misc.py line 117 288342] Train: [1/50][332/2344] Data 0.003 (0.003) Batch 0.620 (0.612) Remain 19:52:21 loss: 1.3308 Lr: 0.00022
[2025-05-11 13:14:41,283 INFO misc.py line 117 288342] Train: [1/50][333/2344] Data 0.002 (0.003) Batch 0.529 (0.612) Remain 19:51:51 loss: 1.2836 Lr: 0.00022
[2025-05-11 13:14:41,922 INFO misc.py line 117 288342] Train: [1/50][334/2344] Data 0.003 (0.003) Batch 0.639 (0.612) Remain 19:52:00 loss: 1.4328 Lr: 0.00022
[2025-05-11 13:14:42,498 INFO misc.py line 117 288342] Train: [1/50][335/2344] Data 0.003 (0.003) Batch 0.575 (0.612) Remain 19:51:46 loss: 1.1164 Lr: 0.00022
[2025-05-11 13:14:43,151 INFO misc.py line 117 288342] Train: [1/50][336/2344] Data 0.003 (0.003) Batch 0.653 (0.612) Remain 19:52:00 loss: 1.3163 Lr: 0.00022
[2025-05-11 13:14:43,729 INFO misc.py line 117 288342] Train: [1/50][337/2344] Data 0.003 (0.003) Batch 0.579 (0.612) Remain 19:51:48 loss: 1.1293 Lr: 0.00022
[2025-05-11 13:14:44,396 INFO misc.py line 117 288342] Train: [1/50][338/2344] Data 0.003 (0.003) Batch 0.667 (0.612) Remain 19:52:07 loss: 1.3559 Lr: 0.00022
[2025-05-11 13:14:44,872 INFO misc.py line 117 288342] Train: [1/50][339/2344] Data 0.003 (0.003) Batch 0.476 (0.612) Remain 19:51:19 loss: 1.2220 Lr: 0.00022
[2025-05-11 13:14:45,554 INFO misc.py line 117 288342] Train: [1/50][340/2344] Data 0.002 (0.003) Batch 0.682 (0.612) Remain 19:51:42 loss: 0.9486 Lr: 0.00022
[2025-05-11 13:14:46,126 INFO misc.py line 117 288342] Train: [1/50][341/2344] Data 0.002 (0.003) Batch 0.572 (0.612) Remain 19:51:28 loss: 1.3250 Lr: 0.00022
[2025-05-11 13:14:46,697 INFO misc.py line 117 288342] Train: [1/50][342/2344] Data 0.003 (0.003) Batch 0.571 (0.612) Remain 19:51:13 loss: 1.3594 Lr: 0.00022
[2025-05-11 13:14:47,249 INFO misc.py line 117 288342] Train: [1/50][343/2344] Data 0.002 (0.003) Batch 0.552 (0.611) Remain 19:50:52 loss: 1.3875 Lr: 0.00022
[2025-05-11 13:14:47,880 INFO misc.py line 117 288342] Train: [1/50][344/2344] Data 0.003 (0.003) Batch 0.631 (0.612) Remain 19:50:58 loss: 1.2569 Lr: 0.00022
[2025-05-11 13:14:48,579 INFO misc.py line 117 288342] Train: [1/50][345/2344] Data 0.003 (0.003) Batch 0.699 (0.612) Remain 19:51:27 loss: 1.2654 Lr: 0.00022
[2025-05-11 13:14:49,237 INFO misc.py line 117 288342] Train: [1/50][346/2344] Data 0.003 (0.003) Batch 0.658 (0.612) Remain 19:51:43 loss: 1.0771 Lr: 0.00022
[2025-05-11 13:14:49,968 INFO misc.py line 117 288342] Train: [1/50][347/2344] Data 0.002 (0.003) Batch 0.731 (0.612) Remain 19:52:23 loss: 1.5358 Lr: 0.00022
[2025-05-11 13:14:50,480 INFO misc.py line 117 288342] Train: [1/50][348/2344] Data 0.003 (0.003) Batch 0.512 (0.612) Remain 19:51:48 loss: 1.4328 Lr: 0.00022
[2025-05-11 13:14:51,196 INFO misc.py line 117 288342] Train: [1/50][349/2344] Data 0.003 (0.003) Batch 0.715 (0.612) Remain 19:52:22 loss: 1.2097 Lr: 0.00022
[2025-05-11 13:14:51,872 INFO misc.py line 117 288342] Train: [1/50][350/2344] Data 0.003 (0.003) Batch 0.676 (0.612) Remain 19:52:43 loss: 1.2079 Lr: 0.00022
[2025-05-11 13:14:52,543 INFO misc.py line 117 288342] Train: [1/50][351/2344] Data 0.003 (0.003) Batch 0.671 (0.613) Remain 19:53:02 loss: 1.1697 Lr: 0.00022
[2025-05-11 13:14:53,189 INFO misc.py line 117 288342] Train: [1/50][352/2344] Data 0.003 (0.003) Batch 0.646 (0.613) Remain 19:53:13 loss: 1.2578 Lr: 0.00022
[2025-05-11 13:14:53,757 INFO misc.py line 117 288342] Train: [1/50][353/2344] Data 0.003 (0.003) Batch 0.568 (0.613) Remain 19:52:57 loss: 1.3185 Lr: 0.00022
[2025-05-11 13:14:54,432 INFO misc.py line 117 288342] Train: [1/50][354/2344] Data 0.003 (0.003) Batch 0.674 (0.613) Remain 19:53:17 loss: 1.3166 Lr: 0.00023
[2025-05-11 13:14:55,050 INFO misc.py line 117 288342] Train: [1/50][355/2344] Data 0.003 (0.003) Batch 0.618 (0.613) Remain 19:53:19 loss: 1.2291 Lr: 0.00023
[2025-05-11 13:14:55,653 INFO misc.py line 117 288342] Train: [1/50][356/2344] Data 0.003 (0.003) Batch 0.603 (0.613) Remain 19:53:15 loss: 1.3071 Lr: 0.00023
[2025-05-11 13:14:56,347 INFO misc.py line 117 288342] Train: [1/50][357/2344] Data 0.003 (0.003) Batch 0.694 (0.613) Remain 19:53:41 loss: 1.3472 Lr: 0.00023
[2025-05-11 13:14:56,945 INFO misc.py line 117 288342] Train: [1/50][358/2344] Data 0.003 (0.003) Batch 0.598 (0.613) Remain 19:53:35 loss: 1.2097 Lr: 0.00023
[2025-05-11 13:14:57,523 INFO misc.py line 117 288342] Train: [1/50][359/2344] Data 0.003 (0.003) Batch 0.578 (0.613) Remain 19:53:23 loss: 1.2503 Lr: 0.00023
[2025-05-11 13:14:58,333 INFO misc.py line 117 288342] Train: [1/50][360/2344] Data 0.003 (0.003) Batch 0.811 (0.613) Remain 19:54:27 loss: 1.3228 Lr: 0.00023
[2025-05-11 13:14:58,942 INFO misc.py line 117 288342] Train: [1/50][361/2344] Data 0.003 (0.003) Batch 0.609 (0.613) Remain 19:54:25 loss: 1.2152 Lr: 0.00023
[2025-05-11 13:14:59,625 INFO misc.py line 117 288342] Train: [1/50][362/2344] Data 0.003 (0.003) Batch 0.683 (0.614) Remain 19:54:47 loss: 1.3303 Lr: 0.00023
[2025-05-11 13:15:00,191 INFO misc.py line 117 288342] Train: [1/50][363/2344] Data 0.003 (0.003) Batch 0.566 (0.613) Remain 19:54:31 loss: 1.5931 Lr: 0.00023
[2025-05-11 13:15:00,768 INFO misc.py line 117 288342] Train: [1/50][364/2344] Data 0.003 (0.003) Batch 0.577 (0.613) Remain 19:54:19 loss: 1.1161 Lr: 0.00023
[2025-05-11 13:15:01,335 INFO misc.py line 117 288342] Train: [1/50][365/2344] Data 0.003 (0.003) Batch 0.568 (0.613) Remain 19:54:03 loss: 1.2408 Lr: 0.00023
[2025-05-11 13:15:02,056 INFO misc.py line 117 288342] Train: [1/50][366/2344] Data 0.003 (0.003) Batch 0.721 (0.614) Remain 19:54:37 loss: 1.6736 Lr: 0.00023
[2025-05-11 13:15:02,724 INFO misc.py line 117 288342] Train: [1/50][367/2344] Data 0.003 (0.003) Batch 0.668 (0.614) Remain 19:54:54 loss: 0.9690 Lr: 0.00023
[2025-05-11 13:15:03,310 INFO misc.py line 117 288342] Train: [1/50][368/2344] Data 0.003 (0.003) Batch 0.586 (0.614) Remain 19:54:45 loss: 1.1569 Lr: 0.00023
[2025-05-11 13:15:03,797 INFO misc.py line 117 288342] Train: [1/50][369/2344] Data 0.002 (0.003) Batch 0.487 (0.613) Remain 19:54:04 loss: 1.1485 Lr: 0.00023
[2025-05-11 13:15:04,363 INFO misc.py line 117 288342] Train: [1/50][370/2344] Data 0.003 (0.003) Batch 0.567 (0.613) Remain 19:53:48 loss: 1.1858 Lr: 0.00023
[2025-05-11 13:15:05,001 INFO misc.py line 117 288342] Train: [1/50][371/2344] Data 0.003 (0.003) Batch 0.638 (0.613) Remain 19:53:56 loss: 1.3780 Lr: 0.00023
[2025-05-11 13:15:05,532 INFO misc.py line 117 288342] Train: [1/50][372/2344] Data 0.003 (0.003) Batch 0.531 (0.613) Remain 19:53:29 loss: 1.4140 Lr: 0.00023
[2025-05-11 13:15:06,092 INFO misc.py line 117 288342] Train: [1/50][373/2344] Data 0.003 (0.003) Batch 0.560 (0.613) Remain 19:53:11 loss: 1.0177 Lr: 0.00023
[2025-05-11 13:15:07,493 INFO misc.py line 117 288342] Train: [1/50][374/2344] Data 0.003 (0.003) Batch 1.401 (0.615) Remain 19:57:19 loss: 1.2268 Lr: 0.00023
[2025-05-11 13:15:07,887 INFO misc.py line 117 288342] Train: [1/50][375/2344] Data 0.003 (0.003) Batch 0.395 (0.614) Remain 19:56:09 loss: 1.1925 Lr: 0.00023
[2025-05-11 13:15:08,405 INFO misc.py line 117 288342] Train: [1/50][376/2344] Data 0.002 (0.003) Batch 0.517 (0.614) Remain 19:55:38 loss: 1.3313 Lr: 0.00023
[2025-05-11 13:15:09,061 INFO misc.py line 117 288342] Train: [1/50][377/2344] Data 0.002 (0.003) Batch 0.657 (0.614) Remain 19:55:51 loss: 1.4187 Lr: 0.00023
[2025-05-11 13:15:09,654 INFO misc.py line 117 288342] Train: [1/50][378/2344] Data 0.002 (0.003) Batch 0.592 (0.614) Remain 19:55:43 loss: 1.2545 Lr: 0.00023
[2025-05-11 13:15:10,150 INFO misc.py line 117 288342] Train: [1/50][379/2344] Data 0.002 (0.003) Batch 0.496 (0.614) Remain 19:55:06 loss: 1.3064 Lr: 0.00023
[2025-05-11 13:15:10,718 INFO misc.py line 117 288342] Train: [1/50][380/2344] Data 0.003 (0.003) Batch 0.568 (0.614) Remain 19:54:51 loss: 1.5904 Lr: 0.00023
[2025-05-11 13:15:11,338 INFO misc.py line 117 288342] Train: [1/50][381/2344] Data 0.003 (0.003) Batch 0.619 (0.614) Remain 19:54:53 loss: 1.6893 Lr: 0.00023
[2025-05-11 13:15:11,913 INFO misc.py line 117 288342] Train: [1/50][382/2344] Data 0.003 (0.003) Batch 0.576 (0.614) Remain 19:54:40 loss: 1.4419 Lr: 0.00023
[2025-05-11 13:15:12,496 INFO misc.py line 117 288342] Train: [1/50][383/2344] Data 0.003 (0.003) Batch 0.583 (0.614) Remain 19:54:30 loss: 1.0572 Lr: 0.00023
[2025-05-11 13:15:13,224 INFO misc.py line 117 288342] Train: [1/50][384/2344] Data 0.002 (0.003) Batch 0.728 (0.614) Remain 19:55:05 loss: 1.5648 Lr: 0.00023
[2025-05-11 13:15:13,884 INFO misc.py line 117 288342] Train: [1/50][385/2344] Data 0.003 (0.003) Batch 0.660 (0.614) Remain 19:55:18 loss: 1.3393 Lr: 0.00023
[2025-05-11 13:15:14,517 INFO misc.py line 117 288342] Train: [1/50][386/2344] Data 0.002 (0.003) Batch 0.634 (0.614) Remain 19:55:23 loss: 1.1873 Lr: 0.00023
[2025-05-11 13:15:15,103 INFO misc.py line 117 288342] Train: [1/50][387/2344] Data 0.002 (0.003) Batch 0.585 (0.614) Remain 19:55:14 loss: 1.1205 Lr: 0.00023
[2025-05-11 13:15:15,802 INFO misc.py line 117 288342] Train: [1/50][388/2344] Data 0.002 (0.003) Batch 0.700 (0.614) Remain 19:55:39 loss: 1.3642 Lr: 0.00023
[2025-05-11 13:15:16,379 INFO misc.py line 117 288342] Train: [1/50][389/2344] Data 0.002 (0.003) Batch 0.577 (0.614) Remain 19:55:28 loss: 1.1227 Lr: 0.00023
[2025-05-11 13:15:16,985 INFO misc.py line 117 288342] Train: [1/50][390/2344] Data 0.003 (0.003) Batch 0.606 (0.614) Remain 19:55:25 loss: 1.2907 Lr: 0.00023
[2025-05-11 13:15:17,531 INFO misc.py line 117 288342] Train: [1/50][391/2344] Data 0.002 (0.003) Batch 0.546 (0.614) Remain 19:55:03 loss: 1.3859 Lr: 0.00023
[2025-05-11 13:15:18,043 INFO misc.py line 117 288342] Train: [1/50][392/2344] Data 0.003 (0.003) Batch 0.513 (0.614) Remain 19:54:32 loss: 1.4018 Lr: 0.00023
[2025-05-11 13:15:18,628 INFO misc.py line 117 288342] Train: [1/50][393/2344] Data 0.003 (0.003) Batch 0.585 (0.614) Remain 19:54:23 loss: 1.3426 Lr: 0.00023
[2025-05-11 13:15:19,278 INFO misc.py line 117 288342] Train: [1/50][394/2344] Data 0.003 (0.003) Batch 0.649 (0.614) Remain 19:54:33 loss: 1.7125 Lr: 0.00023
[2025-05-11 13:15:20,021 INFO misc.py line 117 288342] Train: [1/50][395/2344] Data 0.003 (0.003) Batch 0.743 (0.614) Remain 19:55:11 loss: 1.0290 Lr: 0.00023
[2025-05-11 13:15:20,622 INFO misc.py line 117 288342] Train: [1/50][396/2344] Data 0.003 (0.003) Batch 0.601 (0.614) Remain 19:55:07 loss: 1.3571 Lr: 0.00023
[2025-05-11 13:15:21,345 INFO misc.py line 117 288342] Train: [1/50][397/2344] Data 0.003 (0.003) Batch 0.723 (0.614) Remain 19:55:39 loss: 1.0417 Lr: 0.00023
[2025-05-11 13:15:22,076 INFO misc.py line 117 288342] Train: [1/50][398/2344] Data 0.003 (0.003) Batch 0.731 (0.614) Remain 19:56:12 loss: 1.3431 Lr: 0.00023
[2025-05-11 13:15:22,532 INFO misc.py line 117 288342] Train: [1/50][399/2344] Data 0.003 (0.003) Batch 0.456 (0.614) Remain 19:55:25 loss: 1.3282 Lr: 0.00023
[2025-05-11 13:15:23,230 INFO misc.py line 117 288342] Train: [1/50][400/2344] Data 0.003 (0.003) Batch 0.698 (0.614) Remain 19:55:49 loss: 1.2078 Lr: 0.00023
[2025-05-11 13:15:23,835 INFO misc.py line 117 288342] Train: [1/50][401/2344] Data 0.003 (0.003) Batch 0.605 (0.614) Remain 19:55:46 loss: 1.0893 Lr: 0.00023
[2025-05-11 13:15:24,362 INFO misc.py line 117 288342] Train: [1/50][402/2344] Data 0.003 (0.003) Batch 0.527 (0.614) Remain 19:55:20 loss: 0.9691 Lr: 0.00023
[2025-05-11 13:15:25,087 INFO misc.py line 117 288342] Train: [1/50][403/2344] Data 0.003 (0.003) Batch 0.725 (0.614) Remain 19:55:51 loss: 1.4720 Lr: 0.00023
[2025-05-11 13:15:25,805 INFO misc.py line 117 288342] Train: [1/50][404/2344] Data 0.003 (0.003) Batch 0.718 (0.615) Remain 19:56:21 loss: 1.2935 Lr: 0.00023
[2025-05-11 13:15:26,427 INFO misc.py line 117 288342] Train: [1/50][405/2344] Data 0.003 (0.003) Batch 0.622 (0.615) Remain 19:56:23 loss: 1.2366 Lr: 0.00023
[2025-05-11 13:15:27,034 INFO misc.py line 117 288342] Train: [1/50][406/2344] Data 0.003 (0.003) Batch 0.606 (0.615) Remain 19:56:20 loss: 1.4455 Lr: 0.00023
[2025-05-11 13:15:27,613 INFO misc.py line 117 288342] Train: [1/50][407/2344] Data 0.003 (0.003) Batch 0.579 (0.615) Remain 19:56:09 loss: 1.5962 Lr: 0.00023
[2025-05-11 13:15:28,267 INFO misc.py line 117 288342] Train: [1/50][408/2344] Data 0.002 (0.003) Batch 0.654 (0.615) Remain 19:56:20 loss: 1.5547 Lr: 0.00023
[2025-05-11 13:15:28,838 INFO misc.py line 117 288342] Train: [1/50][409/2344] Data 0.002 (0.003) Batch 0.571 (0.614) Remain 19:56:06 loss: 1.4987 Lr: 0.00023
[2025-05-11 13:15:29,483 INFO misc.py line 117 288342] Train: [1/50][410/2344] Data 0.003 (0.003) Batch 0.645 (0.615) Remain 19:56:15 loss: 1.1933 Lr: 0.00023
[2025-05-11 13:15:29,931 INFO misc.py line 117 288342] Train: [1/50][411/2344] Data 0.002 (0.003) Batch 0.448 (0.614) Remain 19:55:26 loss: 1.1926 Lr: 0.00023
[2025-05-11 13:15:30,532 INFO misc.py line 117 288342] Train: [1/50][412/2344] Data 0.003 (0.003) Batch 0.601 (0.614) Remain 19:55:22 loss: 1.2748 Lr: 0.00023
[2025-05-11 13:15:31,230 INFO misc.py line 117 288342] Train: [1/50][413/2344] Data 0.003 (0.003) Batch 0.697 (0.614) Remain 19:55:45 loss: 1.1141 Lr: 0.00023
[2025-05-11 13:15:31,856 INFO misc.py line 117 288342] Train: [1/50][414/2344] Data 0.003 (0.003) Batch 0.626 (0.614) Remain 19:55:48 loss: 1.1420 Lr: 0.00023
[2025-05-11 13:15:32,466 INFO misc.py line 117 288342] Train: [1/50][415/2344] Data 0.003 (0.003) Batch 0.610 (0.614) Remain 19:55:46 loss: 1.2070 Lr: 0.00023
[2025-05-11 13:15:33,076 INFO misc.py line 117 288342] Train: [1/50][416/2344] Data 0.002 (0.003) Batch 0.610 (0.614) Remain 19:55:44 loss: 1.4495 Lr: 0.00023
[2025-05-11 13:15:33,691 INFO misc.py line 117 288342] Train: [1/50][417/2344] Data 0.002 (0.003) Batch 0.615 (0.614) Remain 19:55:44 loss: 1.1158 Lr: 0.00023
[2025-05-11 13:15:34,258 INFO misc.py line 117 288342] Train: [1/50][418/2344] Data 0.003 (0.003) Batch 0.566 (0.614) Remain 19:55:30 loss: 1.0755 Lr: 0.00023
[2025-05-11 13:15:34,756 INFO misc.py line 117 288342] Train: [1/50][419/2344] Data 0.003 (0.003) Batch 0.498 (0.614) Remain 19:54:56 loss: 1.4574 Lr: 0.00024
[2025-05-11 13:15:35,345 INFO misc.py line 117 288342] Train: [1/50][420/2344] Data 0.003 (0.003) Batch 0.590 (0.614) Remain 19:54:49 loss: 0.9301 Lr: 0.00024
[2025-05-11 13:15:36,159 INFO misc.py line 117 288342] Train: [1/50][421/2344] Data 0.003 (0.003) Batch 0.814 (0.614) Remain 19:55:44 loss: 1.2569 Lr: 0.00024
[2025-05-11 13:15:36,852 INFO misc.py line 117 288342] Train: [1/50][422/2344] Data 0.002 (0.003) Batch 0.693 (0.615) Remain 19:56:06 loss: 1.3247 Lr: 0.00024
[2025-05-11 13:15:37,483 INFO misc.py line 117 288342] Train: [1/50][423/2344] Data 0.003 (0.003) Batch 0.631 (0.615) Remain 19:56:10 loss: 1.3359 Lr: 0.00024
[2025-05-11 13:15:38,095 INFO misc.py line 117 288342] Train: [1/50][424/2344] Data 0.002 (0.003) Batch 0.612 (0.615) Remain 19:56:08 loss: 1.1711 Lr: 0.00024
[2025-05-11 13:15:38,627 INFO misc.py line 117 288342] Train: [1/50][425/2344] Data 0.003 (0.003) Batch 0.532 (0.614) Remain 19:55:45 loss: 1.5005 Lr: 0.00024
[2025-05-11 13:15:39,259 INFO misc.py line 117 288342] Train: [1/50][426/2344] Data 0.003 (0.003) Batch 0.632 (0.614) Remain 19:55:49 loss: 1.2296 Lr: 0.00024
[2025-05-11 13:15:39,948 INFO misc.py line 117 288342] Train: [1/50][427/2344] Data 0.003 (0.003) Batch 0.689 (0.615) Remain 19:56:09 loss: 1.1345 Lr: 0.00024
[2025-05-11 13:15:40,510 INFO misc.py line 117 288342] Train: [1/50][428/2344] Data 0.003 (0.003) Batch 0.563 (0.614) Remain 19:55:54 loss: 1.3017 Lr: 0.00024
[2025-05-11 13:15:41,145 INFO misc.py line 117 288342] Train: [1/50][429/2344] Data 0.004 (0.003) Batch 0.635 (0.615) Remain 19:55:59 loss: 1.1171 Lr: 0.00024
[2025-05-11 13:15:41,785 INFO misc.py line 117 288342] Train: [1/50][430/2344] Data 0.003 (0.003) Batch 0.639 (0.615) Remain 19:56:05 loss: 1.2260 Lr: 0.00024
[2025-05-11 13:15:42,414 INFO misc.py line 117 288342] Train: [1/50][431/2344] Data 0.003 (0.003) Batch 0.629 (0.615) Remain 19:56:09 loss: 1.0562 Lr: 0.00024
[2025-05-11 13:15:43,103 INFO misc.py line 117 288342] Train: [1/50][432/2344] Data 0.003 (0.003) Batch 0.689 (0.615) Remain 19:56:28 loss: 1.1406 Lr: 0.00024
[2025-05-11 13:15:43,709 INFO misc.py line 117 288342] Train: [1/50][433/2344] Data 0.003 (0.003) Batch 0.606 (0.615) Remain 19:56:25 loss: 1.4317 Lr: 0.00024
[2025-05-11 13:15:44,345 INFO misc.py line 117 288342] Train: [1/50][434/2344] Data 0.003 (0.003) Batch 0.636 (0.615) Remain 19:56:30 loss: 1.3707 Lr: 0.00024
[2025-05-11 13:15:44,987 INFO misc.py line 117 288342] Train: [1/50][435/2344] Data 0.003 (0.003) Batch 0.642 (0.615) Remain 19:56:37 loss: 1.0977 Lr: 0.00024
[2025-05-11 13:15:45,537 INFO misc.py line 117 288342] Train: [1/50][436/2344] Data 0.003 (0.003) Batch 0.551 (0.615) Remain 19:56:19 loss: 1.2062 Lr: 0.00024
[2025-05-11 13:15:46,150 INFO misc.py line 117 288342] Train: [1/50][437/2344] Data 0.002 (0.003) Batch 0.613 (0.615) Remain 19:56:18 loss: 1.0721 Lr: 0.00024
[2025-05-11 13:15:46,635 INFO misc.py line 117 288342] Train: [1/50][438/2344] Data 0.002 (0.003) Batch 0.484 (0.614) Remain 19:55:42 loss: 1.1739 Lr: 0.00024
[2025-05-11 13:15:47,270 INFO misc.py line 117 288342] Train: [1/50][439/2344] Data 0.003 (0.003) Batch 0.635 (0.614) Remain 19:55:47 loss: 1.0969 Lr: 0.00024
[2025-05-11 13:15:47,818 INFO misc.py line 117 288342] Train: [1/50][440/2344] Data 0.002 (0.003) Batch 0.548 (0.614) Remain 19:55:29 loss: 1.1500 Lr: 0.00024
[2025-05-11 13:15:48,412 INFO misc.py line 117 288342] Train: [1/50][441/2344] Data 0.003 (0.003) Batch 0.594 (0.614) Remain 19:55:23 loss: 1.4467 Lr: 0.00024
[2025-05-11 13:15:49,077 INFO misc.py line 117 288342] Train: [1/50][442/2344] Data 0.003 (0.003) Batch 0.665 (0.614) Remain 19:55:36 loss: 1.0978 Lr: 0.00024
[2025-05-11 13:15:49,643 INFO misc.py line 117 288342] Train: [1/50][443/2344] Data 0.002 (0.003) Batch 0.566 (0.614) Remain 19:55:22 loss: 1.2710 Lr: 0.00024
[2025-05-11 13:15:50,274 INFO misc.py line 117 288342] Train: [1/50][444/2344] Data 0.003 (0.003) Batch 0.631 (0.614) Remain 19:55:26 loss: 1.4299 Lr: 0.00024
[2025-05-11 13:15:50,786 INFO misc.py line 117 288342] Train: [1/50][445/2344] Data 0.003 (0.003) Batch 0.512 (0.614) Remain 19:54:58 loss: 1.1257 Lr: 0.00024
[2025-05-11 13:15:51,351 INFO misc.py line 117 288342] Train: [1/50][446/2344] Data 0.002 (0.003) Batch 0.564 (0.614) Remain 19:54:45 loss: 1.1064 Lr: 0.00024
[2025-05-11 13:15:51,868 INFO misc.py line 117 288342] Train: [1/50][447/2344] Data 0.003 (0.003) Batch 0.518 (0.614) Remain 19:54:19 loss: 1.2781 Lr: 0.00024
[2025-05-11 13:15:52,352 INFO misc.py line 117 288342] Train: [1/50][448/2344] Data 0.003 (0.003) Batch 0.484 (0.613) Remain 19:53:44 loss: 1.6432 Lr: 0.00024
[2025-05-11 13:15:53,033 INFO misc.py line 117 288342] Train: [1/50][449/2344] Data 0.003 (0.003) Batch 0.680 (0.614) Remain 19:54:01 loss: 1.0492 Lr: 0.00024
[2025-05-11 13:15:53,655 INFO misc.py line 117 288342] Train: [1/50][450/2344] Data 0.003 (0.003) Batch 0.623 (0.614) Remain 19:54:03 loss: 1.3427 Lr: 0.00024
[2025-05-11 13:15:54,389 INFO misc.py line 117 288342] Train: [1/50][451/2344] Data 0.003 (0.003) Batch 0.734 (0.614) Remain 19:54:34 loss: 1.4726 Lr: 0.00024
[2025-05-11 13:15:54,953 INFO misc.py line 117 288342] Train: [1/50][452/2344] Data 0.003 (0.003) Batch 0.564 (0.614) Remain 19:54:20 loss: 1.2211 Lr: 0.00024
[2025-05-11 13:15:55,471 INFO misc.py line 117 288342] Train: [1/50][453/2344] Data 0.003 (0.003) Batch 0.518 (0.614) Remain 19:53:54 loss: 1.3133 Lr: 0.00024
[2025-05-11 13:15:56,145 INFO misc.py line 117 288342] Train: [1/50][454/2344] Data 0.003 (0.003) Batch 0.675 (0.614) Remain 19:54:10 loss: 1.3131 Lr: 0.00024
[2025-05-11 13:15:56,872 INFO misc.py line 117 288342] Train: [1/50][455/2344] Data 0.003 (0.003) Batch 0.726 (0.614) Remain 19:54:38 loss: 1.2448 Lr: 0.00024
[2025-05-11 13:15:57,540 INFO misc.py line 117 288342] Train: [1/50][456/2344] Data 0.003 (0.003) Batch 0.668 (0.614) Remain 19:54:51 loss: 1.1333 Lr: 0.00024
[2025-05-11 13:15:58,288 INFO misc.py line 117 288342] Train: [1/50][457/2344] Data 0.003 (0.003) Batch 0.749 (0.614) Remain 19:55:25 loss: 1.0925 Lr: 0.00024
[2025-05-11 13:15:58,903 INFO misc.py line 117 288342] Train: [1/50][458/2344] Data 0.003 (0.003) Batch 0.615 (0.614) Remain 19:55:25 loss: 1.2315 Lr: 0.00024
[2025-05-11 13:15:59,467 INFO misc.py line 117 288342] Train: [1/50][459/2344] Data 0.003 (0.003) Batch 0.564 (0.614) Remain 19:55:11 loss: 1.1591 Lr: 0.00024
[2025-05-11 13:16:00,002 INFO misc.py line 117 288342] Train: [1/50][460/2344] Data 0.003 (0.003) Batch 0.535 (0.614) Remain 19:54:50 loss: 1.0515 Lr: 0.00024
[2025-05-11 13:16:01,365 INFO misc.py line 117 288342] Train: [1/50][461/2344] Data 0.003 (0.003) Batch 1.362 (0.616) Remain 19:58:01 loss: 1.0006 Lr: 0.00024
[2025-05-11 13:16:02,125 INFO misc.py line 117 288342] Train: [1/50][462/2344] Data 0.003 (0.003) Batch 0.760 (0.616) Remain 19:58:37 loss: 1.1081 Lr: 0.00024
[2025-05-11 13:16:02,788 INFO misc.py line 117 288342] Train: [1/50][463/2344] Data 0.002 (0.003) Batch 0.663 (0.616) Remain 19:58:48 loss: 1.4275 Lr: 0.00024
[2025-05-11 13:16:03,430 INFO misc.py line 117 288342] Train: [1/50][464/2344] Data 0.003 (0.003) Batch 0.642 (0.616) Remain 19:58:54 loss: 1.5112 Lr: 0.00024
[2025-05-11 13:16:03,981 INFO misc.py line 117 288342] Train: [1/50][465/2344] Data 0.003 (0.003) Batch 0.551 (0.616) Remain 19:58:37 loss: 1.1814 Lr: 0.00024
[2025-05-11 13:16:04,471 INFO misc.py line 117 288342] Train: [1/50][466/2344] Data 0.003 (0.003) Batch 0.490 (0.616) Remain 19:58:04 loss: 1.2504 Lr: 0.00024
[2025-05-11 13:16:05,206 INFO misc.py line 117 288342] Train: [1/50][467/2344] Data 0.003 (0.003) Batch 0.735 (0.616) Remain 19:58:34 loss: 1.1748 Lr: 0.00024
[2025-05-11 13:16:05,953 INFO misc.py line 117 288342] Train: [1/50][468/2344] Data 0.003 (0.003) Batch 0.747 (0.616) Remain 19:59:06 loss: 1.0881 Lr: 0.00024
[2025-05-11 13:16:06,541 INFO misc.py line 117 288342] Train: [1/50][469/2344] Data 0.002 (0.003) Batch 0.588 (0.616) Remain 19:58:58 loss: 1.0531 Lr: 0.00024
[2025-05-11 13:16:07,164 INFO misc.py line 117 288342] Train: [1/50][470/2344] Data 0.003 (0.003) Batch 0.623 (0.616) Remain 19:58:59 loss: 1.4220 Lr: 0.00024
[2025-05-11 13:16:07,794 INFO misc.py line 117 288342] Train: [1/50][471/2344] Data 0.002 (0.003) Batch 0.630 (0.616) Remain 19:59:02 loss: 1.3903 Lr: 0.00024
[2025-05-11 13:16:08,335 INFO misc.py line 117 288342] Train: [1/50][472/2344] Data 0.002 (0.003) Batch 0.541 (0.616) Remain 19:58:43 loss: 1.1214 Lr: 0.00024
[2025-05-11 13:16:09,067 INFO misc.py line 117 288342] Train: [1/50][473/2344] Data 0.003 (0.003) Batch 0.732 (0.616) Remain 19:59:11 loss: 1.1218 Lr: 0.00024
[2025-05-11 13:16:09,658 INFO misc.py line 117 288342] Train: [1/50][474/2344] Data 0.003 (0.003) Batch 0.591 (0.616) Remain 19:59:04 loss: 1.3302 Lr: 0.00024
[2025-05-11 13:16:10,350 INFO misc.py line 117 288342] Train: [1/50][475/2344] Data 0.003 (0.003) Batch 0.692 (0.617) Remain 19:59:22 loss: 1.1820 Lr: 0.00025
[2025-05-11 13:16:10,826 INFO misc.py line 117 288342] Train: [1/50][476/2344] Data 0.002 (0.003) Batch 0.476 (0.616) Remain 19:58:47 loss: 1.4051 Lr: 0.00025
[2025-05-11 13:16:11,428 INFO misc.py line 117 288342] Train: [1/50][477/2344] Data 0.003 (0.003) Batch 0.602 (0.616) Remain 19:58:43 loss: 1.3633 Lr: 0.00025
[2025-05-11 13:16:12,046 INFO misc.py line 117 288342] Train: [1/50][478/2344] Data 0.003 (0.003) Batch 0.617 (0.616) Remain 19:58:43 loss: 1.1550 Lr: 0.00025
[2025-05-11 13:16:13,534 INFO misc.py line 117 288342] Train: [1/50][479/2344] Data 0.003 (0.003) Batch 1.488 (0.618) Remain 20:02:16 loss: 1.1963 Lr: 0.00025
[2025-05-11 13:16:14,202 INFO misc.py line 117 288342] Train: [1/50][480/2344] Data 0.003 (0.003) Batch 0.669 (0.618) Remain 20:02:27 loss: 1.2173 Lr: 0.00025
[2025-05-11 13:16:14,851 INFO misc.py line 117 288342] Train: [1/50][481/2344] Data 0.003 (0.003) Batch 0.649 (0.618) Remain 20:02:34 loss: 1.2292 Lr: 0.00025
[2025-05-11 13:16:15,530 INFO misc.py line 117 288342] Train: [1/50][482/2344] Data 0.003 (0.003) Batch 0.678 (0.618) Remain 20:02:48 loss: 1.1985 Lr: 0.00025
[2025-05-11 13:16:16,166 INFO misc.py line 117 288342] Train: [1/50][483/2344] Data 0.003 (0.003) Batch 0.637 (0.618) Remain 20:02:52 loss: 1.1938 Lr: 0.00025
[2025-05-11 13:16:16,789 INFO misc.py line 117 288342] Train: [1/50][484/2344] Data 0.003 (0.003) Batch 0.623 (0.618) Remain 20:02:53 loss: 1.3059 Lr: 0.00025
[2025-05-11 13:16:17,386 INFO misc.py line 117 288342] Train: [1/50][485/2344] Data 0.003 (0.003) Batch 0.596 (0.618) Remain 20:02:47 loss: 1.2830 Lr: 0.00025
[2025-05-11 13:16:17,990 INFO misc.py line 117 288342] Train: [1/50][486/2344] Data 0.003 (0.003) Batch 0.605 (0.618) Remain 20:02:43 loss: 1.0121 Lr: 0.00025
[2025-05-11 13:16:18,646 INFO misc.py line 117 288342] Train: [1/50][487/2344] Data 0.003 (0.003) Batch 0.655 (0.618) Remain 20:02:51 loss: 1.2012 Lr: 0.00025
[2025-05-11 13:16:19,111 INFO misc.py line 117 288342] Train: [1/50][488/2344] Data 0.003 (0.003) Batch 0.465 (0.618) Remain 20:02:14 loss: 1.3320 Lr: 0.00025
[2025-05-11 13:16:19,840 INFO misc.py line 117 288342] Train: [1/50][489/2344] Data 0.003 (0.003) Batch 0.728 (0.618) Remain 20:02:40 loss: 1.2277 Lr: 0.00025
[2025-05-11 13:16:20,442 INFO misc.py line 117 288342] Train: [1/50][490/2344] Data 0.003 (0.003) Batch 0.603 (0.618) Remain 20:02:35 loss: 1.1267 Lr: 0.00025
[2025-05-11 13:16:20,996 INFO misc.py line 117 288342] Train: [1/50][491/2344] Data 0.003 (0.003) Batch 0.554 (0.618) Remain 20:02:19 loss: 1.2061 Lr: 0.00025
[2025-05-11 13:16:21,620 INFO misc.py line 117 288342] Train: [1/50][492/2344] Data 0.002 (0.003) Batch 0.623 (0.618) Remain 20:02:20 loss: 1.0487 Lr: 0.00025
[2025-05-11 13:16:22,132 INFO misc.py line 117 288342] Train: [1/50][493/2344] Data 0.003 (0.003) Batch 0.513 (0.618) Remain 20:01:54 loss: 1.0642 Lr: 0.00025
[2025-05-11 13:16:22,749 INFO misc.py line 117 288342] Train: [1/50][494/2344] Data 0.003 (0.003) Batch 0.617 (0.618) Remain 20:01:53 loss: 1.0057 Lr: 0.00025
[2025-05-11 13:16:23,359 INFO misc.py line 117 288342] Train: [1/50][495/2344] Data 0.003 (0.003) Batch 0.610 (0.618) Remain 20:01:51 loss: 1.0446 Lr: 0.00025
[2025-05-11 13:16:23,908 INFO misc.py line 117 288342] Train: [1/50][496/2344] Data 0.003 (0.003) Batch 0.550 (0.618) Remain 20:01:34 loss: 1.0897 Lr: 0.00025
[2025-05-11 13:16:24,640 INFO misc.py line 117 288342] Train: [1/50][497/2344] Data 0.003 (0.003) Batch 0.732 (0.618) Remain 20:02:00 loss: 1.2345 Lr: 0.00025
[2025-05-11 13:16:25,301 INFO misc.py line 117 288342] Train: [1/50][498/2344] Data 0.003 (0.003) Batch 0.661 (0.618) Remain 20:02:10 loss: 1.4014 Lr: 0.00025
[2025-05-11 13:16:25,854 INFO misc.py line 117 288342] Train: [1/50][499/2344] Data 0.003 (0.003) Batch 0.553 (0.618) Remain 20:01:54 loss: 1.0166 Lr: 0.00025
[2025-05-11 13:16:26,450 INFO misc.py line 117 288342] Train: [1/50][500/2344] Data 0.003 (0.003) Batch 0.596 (0.618) Remain 20:01:48 loss: 1.2645 Lr: 0.00025
[2025-05-11 13:16:27,075 INFO misc.py line 117 288342] Train: [1/50][501/2344] Data 0.003 (0.003) Batch 0.625 (0.618) Remain 20:01:49 loss: 1.3682 Lr: 0.00025
[2025-05-11 13:16:27,680 INFO misc.py line 117 288342] Train: [1/50][502/2344] Data 0.003 (0.003) Batch 0.605 (0.618) Remain 20:01:46 loss: 1.1525 Lr: 0.00025
[2025-05-11 13:16:28,124 INFO misc.py line 117 288342] Train: [1/50][503/2344] Data 0.003 (0.003) Batch 0.444 (0.618) Remain 20:01:04 loss: 1.7955 Lr: 0.00025
[2025-05-11 13:16:28,681 INFO misc.py line 117 288342] Train: [1/50][504/2344] Data 0.003 (0.003) Batch 0.557 (0.617) Remain 20:00:50 loss: 1.4602 Lr: 0.00025
[2025-05-11 13:16:29,299 INFO misc.py line 117 288342] Train: [1/50][505/2344] Data 0.003 (0.003) Batch 0.618 (0.617) Remain 20:00:49 loss: 1.4020 Lr: 0.00025
[2025-05-11 13:16:29,815 INFO misc.py line 117 288342] Train: [1/50][506/2344] Data 0.003 (0.003) Batch 0.516 (0.617) Remain 20:00:25 loss: 1.1128 Lr: 0.00025
[2025-05-11 13:16:30,412 INFO misc.py line 117 288342] Train: [1/50][507/2344] Data 0.003 (0.003) Batch 0.597 (0.617) Remain 20:00:20 loss: 1.1704 Lr: 0.00025
[2025-05-11 13:16:31,003 INFO misc.py line 117 288342] Train: [1/50][508/2344] Data 0.003 (0.003) Batch 0.592 (0.617) Remain 20:00:13 loss: 1.0142 Lr: 0.00025
[2025-05-11 13:16:31,566 INFO misc.py line 117 288342] Train: [1/50][509/2344] Data 0.003 (0.003) Batch 0.562 (0.617) Remain 20:00:00 loss: 0.9920 Lr: 0.00025
[2025-05-11 13:16:32,119 INFO misc.py line 117 288342] Train: [1/50][510/2344] Data 0.003 (0.003) Batch 0.553 (0.617) Remain 19:59:45 loss: 1.1437 Lr: 0.00025
[2025-05-11 13:16:32,745 INFO misc.py line 117 288342] Train: [1/50][511/2344] Data 0.003 (0.003) Batch 0.627 (0.617) Remain 19:59:46 loss: 1.2215 Lr: 0.00025
[2025-05-11 13:16:33,365 INFO misc.py line 117 288342] Train: [1/50][512/2344] Data 0.002 (0.003) Batch 0.620 (0.617) Remain 19:59:46 loss: 1.2610 Lr: 0.00025
[2025-05-11 13:16:33,953 INFO misc.py line 117 288342] Train: [1/50][513/2344] Data 0.002 (0.003) Batch 0.588 (0.617) Remain 19:59:39 loss: 1.0661 Lr: 0.00025
[2025-05-11 13:16:34,531 INFO misc.py line 117 288342] Train: [1/50][514/2344] Data 0.027 (0.003) Batch 0.578 (0.617) Remain 19:59:29 loss: 1.2746 Lr: 0.00025
[2025-05-11 13:16:35,197 INFO misc.py line 117 288342] Train: [1/50][515/2344] Data 0.003 (0.003) Batch 0.666 (0.617) Remain 19:59:40 loss: 1.1060 Lr: 0.00025
[2025-05-11 13:16:35,812 INFO misc.py line 117 288342] Train: [1/50][516/2344] Data 0.003 (0.003) Batch 0.615 (0.617) Remain 19:59:39 loss: 1.1043 Lr: 0.00025
[2025-05-11 13:16:36,287 INFO misc.py line 117 288342] Train: [1/50][517/2344] Data 0.003 (0.003) Batch 0.475 (0.617) Remain 19:59:06 loss: 0.9911 Lr: 0.00025
[2025-05-11 13:16:36,754 INFO misc.py line 117 288342] Train: [1/50][518/2344] Data 0.003 (0.003) Batch 0.467 (0.616) Remain 19:58:32 loss: 1.3909 Lr: 0.00025
[2025-05-11 13:16:37,434 INFO misc.py line 117 288342] Train: [1/50][519/2344] Data 0.003 (0.003) Batch 0.680 (0.616) Remain 19:58:45 loss: 1.0956 Lr: 0.00025
[2025-05-11 13:16:37,892 INFO misc.py line 117 288342] Train: [1/50][520/2344] Data 0.003 (0.003) Batch 0.458 (0.616) Remain 19:58:09 loss: 0.9902 Lr: 0.00025
[2025-05-11 13:16:38,398 INFO misc.py line 117 288342] Train: [1/50][521/2344] Data 0.003 (0.003) Batch 0.506 (0.616) Remain 19:57:44 loss: 1.0947 Lr: 0.00025
[2025-05-11 13:16:38,985 INFO misc.py line 117 288342] Train: [1/50][522/2344] Data 0.003 (0.003) Batch 0.588 (0.616) Remain 19:57:37 loss: 1.3746 Lr: 0.00025
[2025-05-11 13:16:39,605 INFO misc.py line 117 288342] Train: [1/50][523/2344] Data 0.003 (0.003) Batch 0.619 (0.616) Remain 19:57:37 loss: 1.0996 Lr: 0.00025
[2025-05-11 13:16:40,126 INFO misc.py line 117 288342] Train: [1/50][524/2344] Data 0.003 (0.003) Batch 0.522 (0.616) Remain 19:57:15 loss: 1.2651 Lr: 0.00025
[2025-05-11 13:16:40,683 INFO misc.py line 117 288342] Train: [1/50][525/2344] Data 0.002 (0.003) Batch 0.556 (0.616) Remain 19:57:01 loss: 1.2536 Lr: 0.00025
[2025-05-11 13:16:41,425 INFO misc.py line 117 288342] Train: [1/50][526/2344] Data 0.003 (0.003) Batch 0.743 (0.616) Remain 19:57:29 loss: 1.2922 Lr: 0.00025
[2025-05-11 13:16:42,014 INFO misc.py line 117 288342] Train: [1/50][527/2344] Data 0.003 (0.003) Batch 0.588 (0.616) Remain 19:57:22 loss: 1.2723 Lr: 0.00026
[2025-05-11 13:16:42,721 INFO misc.py line 117 288342] Train: [1/50][528/2344] Data 0.002 (0.003) Batch 0.708 (0.616) Remain 19:57:42 loss: 1.2092 Lr: 0.00026
[2025-05-11 13:16:43,309 INFO misc.py line 117 288342] Train: [1/50][529/2344] Data 0.002 (0.003) Batch 0.588 (0.616) Remain 19:57:35 loss: 1.2403 Lr: 0.00026
[2025-05-11 13:16:43,894 INFO misc.py line 117 288342] Train: [1/50][530/2344] Data 0.002 (0.003) Batch 0.585 (0.616) Remain 19:57:28 loss: 1.2238 Lr: 0.00026
[2025-05-11 13:16:44,538 INFO misc.py line 117 288342] Train: [1/50][531/2344] Data 0.002 (0.003) Batch 0.644 (0.616) Remain 19:57:33 loss: 1.2127 Lr: 0.00026
[2025-05-11 13:16:45,191 INFO misc.py line 117 288342] Train: [1/50][532/2344] Data 0.002 (0.003) Batch 0.653 (0.616) Remain 19:57:41 loss: 1.3916 Lr: 0.00026
[2025-05-11 13:16:45,800 INFO misc.py line 117 288342] Train: [1/50][533/2344] Data 0.030 (0.003) Batch 0.609 (0.616) Remain 19:57:39 loss: 1.1122 Lr: 0.00026
[2025-05-11 13:16:46,467 INFO misc.py line 117 288342] Train: [1/50][534/2344] Data 0.003 (0.003) Batch 0.668 (0.616) Remain 19:57:49 loss: 1.1465 Lr: 0.00026
[2025-05-11 13:16:47,127 INFO misc.py line 117 288342] Train: [1/50][535/2344] Data 0.003 (0.003) Batch 0.659 (0.616) Remain 19:57:58 loss: 0.9934 Lr: 0.00026
[2025-05-11 13:16:47,693 INFO misc.py line 117 288342] Train: [1/50][536/2344] Data 0.003 (0.003) Batch 0.567 (0.616) Remain 19:57:47 loss: 1.2317 Lr: 0.00026
[2025-05-11 13:16:48,285 INFO misc.py line 117 288342] Train: [1/50][537/2344] Data 0.003 (0.003) Batch 0.591 (0.616) Remain 19:57:41 loss: 1.2216 Lr: 0.00026
[2025-05-11 13:16:48,773 INFO misc.py line 117 288342] Train: [1/50][538/2344] Data 0.003 (0.003) Batch 0.488 (0.616) Remain 19:57:12 loss: 1.3456 Lr: 0.00026
[2025-05-11 13:16:49,298 INFO misc.py line 117 288342] Train: [1/50][539/2344] Data 0.003 (0.003) Batch 0.525 (0.616) Remain 19:56:52 loss: 1.4182 Lr: 0.00026
[2025-05-11 13:16:49,938 INFO misc.py line 117 288342] Train: [1/50][540/2344] Data 0.003 (0.003) Batch 0.640 (0.616) Remain 19:56:57 loss: 1.0170 Lr: 0.00026
[2025-05-11 13:16:50,657 INFO misc.py line 117 288342] Train: [1/50][541/2344] Data 0.003 (0.003) Batch 0.719 (0.616) Remain 19:57:18 loss: 1.0657 Lr: 0.00026
[2025-05-11 13:16:51,272 INFO misc.py line 117 288342] Train: [1/50][542/2344] Data 0.002 (0.003) Batch 0.615 (0.616) Remain 19:57:18 loss: 1.0792 Lr: 0.00026
[2025-05-11 13:16:51,723 INFO misc.py line 117 288342] Train: [1/50][543/2344] Data 0.002 (0.003) Batch 0.451 (0.615) Remain 19:56:41 loss: 1.2402 Lr: 0.00026
[2025-05-11 13:16:52,221 INFO misc.py line 117 288342] Train: [1/50][544/2344] Data 0.003 (0.003) Batch 0.497 (0.615) Remain 19:56:15 loss: 1.1463 Lr: 0.00026
[2025-05-11 13:16:52,737 INFO misc.py line 117 288342] Train: [1/50][545/2344] Data 0.003 (0.003) Batch 0.517 (0.615) Remain 19:55:54 loss: 1.2570 Lr: 0.00026
[2025-05-11 13:16:53,243 INFO misc.py line 117 288342] Train: [1/50][546/2344] Data 0.003 (0.003) Batch 0.506 (0.615) Remain 19:55:30 loss: 1.0743 Lr: 0.00026
[2025-05-11 13:16:53,734 INFO misc.py line 117 288342] Train: [1/50][547/2344] Data 0.003 (0.003) Batch 0.491 (0.615) Remain 19:55:02 loss: 1.2061 Lr: 0.00026
[2025-05-11 13:16:54,232 INFO misc.py line 117 288342] Train: [1/50][548/2344] Data 0.003 (0.003) Batch 0.498 (0.614) Remain 19:54:37 loss: 1.3237 Lr: 0.00026
[2025-05-11 13:16:54,825 INFO misc.py line 117 288342] Train: [1/50][549/2344] Data 0.003 (0.003) Batch 0.593 (0.614) Remain 19:54:32 loss: 1.1253 Lr: 0.00026
[2025-05-11 13:16:55,578 INFO misc.py line 117 288342] Train: [1/50][550/2344] Data 0.003 (0.003) Batch 0.752 (0.615) Remain 19:55:00 loss: 1.1252 Lr: 0.00026
[2025-05-11 13:16:56,303 INFO misc.py line 117 288342] Train: [1/50][551/2344] Data 0.003 (0.003) Batch 0.725 (0.615) Remain 19:55:23 loss: 1.3912 Lr: 0.00026
[2025-05-11 13:16:56,963 INFO misc.py line 117 288342] Train: [1/50][552/2344] Data 0.003 (0.003) Batch 0.661 (0.615) Remain 19:55:32 loss: 1.3903 Lr: 0.00026
[2025-05-11 13:16:57,541 INFO misc.py line 117 288342] Train: [1/50][553/2344] Data 0.003 (0.003) Batch 0.578 (0.615) Remain 19:55:24 loss: 1.7538 Lr: 0.00026
[2025-05-11 13:16:58,062 INFO misc.py line 117 288342] Train: [1/50][554/2344] Data 0.003 (0.003) Batch 0.522 (0.615) Remain 19:55:03 loss: 1.2521 Lr: 0.00026
[2025-05-11 13:16:58,621 INFO misc.py line 117 288342] Train: [1/50][555/2344] Data 0.003 (0.003) Batch 0.559 (0.615) Remain 19:54:51 loss: 1.2837 Lr: 0.00026
[2025-05-11 13:16:59,311 INFO misc.py line 117 288342] Train: [1/50][556/2344] Data 0.003 (0.003) Batch 0.690 (0.615) Remain 19:55:06 loss: 1.0500 Lr: 0.00026
[2025-05-11 13:16:59,975 INFO misc.py line 117 288342] Train: [1/50][557/2344] Data 0.003 (0.003) Batch 0.664 (0.615) Remain 19:55:16 loss: 1.0528 Lr: 0.00026
[2025-05-11 13:17:00,658 INFO misc.py line 117 288342] Train: [1/50][558/2344] Data 0.003 (0.003) Batch 0.683 (0.615) Remain 19:55:30 loss: 1.0495 Lr: 0.00026
[2025-05-11 13:17:01,393 INFO misc.py line 117 288342] Train: [1/50][559/2344] Data 0.003 (0.003) Batch 0.735 (0.615) Remain 19:55:54 loss: 1.1686 Lr: 0.00026
[2025-05-11 13:17:01,976 INFO misc.py line 117 288342] Train: [1/50][560/2344] Data 0.003 (0.003) Batch 0.583 (0.615) Remain 19:55:47 loss: 1.2847 Lr: 0.00026
[2025-05-11 13:17:02,636 INFO misc.py line 117 288342] Train: [1/50][561/2344] Data 0.003 (0.003) Batch 0.660 (0.615) Remain 19:55:56 loss: 0.9072 Lr: 0.00026
[2025-05-11 13:17:03,361 INFO misc.py line 117 288342] Train: [1/50][562/2344] Data 0.003 (0.003) Batch 0.725 (0.615) Remain 19:56:18 loss: 1.2480 Lr: 0.00026
[2025-05-11 13:17:04,081 INFO misc.py line 117 288342] Train: [1/50][563/2344] Data 0.003 (0.003) Batch 0.720 (0.616) Remain 19:56:39 loss: 0.8378 Lr: 0.00026
[2025-05-11 13:17:04,703 INFO misc.py line 117 288342] Train: [1/50][564/2344] Data 0.003 (0.003) Batch 0.623 (0.616) Remain 19:56:40 loss: 1.3939 Lr: 0.00026
[2025-05-11 13:17:05,305 INFO misc.py line 117 288342] Train: [1/50][565/2344] Data 0.003 (0.003) Batch 0.602 (0.616) Remain 19:56:36 loss: 1.1389 Lr: 0.00026
[2025-05-11 13:17:05,931 INFO misc.py line 117 288342] Train: [1/50][566/2344] Data 0.003 (0.003) Batch 0.626 (0.616) Remain 19:56:38 loss: 1.4481 Lr: 0.00026
[2025-05-11 13:17:06,636 INFO misc.py line 117 288342] Train: [1/50][567/2344] Data 0.003 (0.003) Batch 0.705 (0.616) Remain 19:56:56 loss: 1.1781 Lr: 0.00026
[2025-05-11 13:17:07,321 INFO misc.py line 117 288342] Train: [1/50][568/2344] Data 0.003 (0.003) Batch 0.685 (0.616) Remain 19:57:10 loss: 0.9842 Lr: 0.00026
[2025-05-11 13:17:07,971 INFO misc.py line 117 288342] Train: [1/50][569/2344] Data 0.003 (0.003) Batch 0.650 (0.616) Remain 19:57:16 loss: 1.0414 Lr: 0.00026
[2025-05-11 13:17:08,811 INFO misc.py line 117 288342] Train: [1/50][570/2344] Data 0.003 (0.003) Batch 0.840 (0.616) Remain 19:58:01 loss: 1.3307 Lr: 0.00026
[2025-05-11 13:17:09,238 INFO misc.py line 117 288342] Train: [1/50][571/2344] Data 0.002 (0.003) Batch 0.427 (0.616) Remain 19:57:22 loss: 1.1839 Lr: 0.00026
[2025-05-11 13:17:09,836 INFO misc.py line 117 288342] Train: [1/50][572/2344] Data 0.003 (0.003) Batch 0.598 (0.616) Remain 19:57:18 loss: 1.1055 Lr: 0.00026
[2025-05-11 13:17:10,478 INFO misc.py line 117 288342] Train: [1/50][573/2344] Data 0.003 (0.003) Batch 0.642 (0.616) Remain 19:57:22 loss: 1.1589 Lr: 0.00027
[2025-05-11 13:17:11,050 INFO misc.py line 117 288342] Train: [1/50][574/2344] Data 0.003 (0.003) Batch 0.572 (0.616) Remain 19:57:13 loss: 0.9839 Lr: 0.00027
[2025-05-11 13:17:11,679 INFO misc.py line 117 288342] Train: [1/50][575/2344] Data 0.003 (0.003) Batch 0.629 (0.616) Remain 19:57:15 loss: 1.3053 Lr: 0.00027
[2025-05-11 13:17:12,329 INFO misc.py line 117 288342] Train: [1/50][576/2344] Data 0.002 (0.003) Batch 0.650 (0.616) Remain 19:57:21 loss: 1.1526 Lr: 0.00027
[2025-05-11 13:17:12,941 INFO misc.py line 117 288342] Train: [1/50][577/2344] Data 0.002 (0.003) Batch 0.612 (0.616) Remain 19:57:20 loss: 1.0433 Lr: 0.00027
[2025-05-11 13:17:13,616 INFO misc.py line 117 288342] Train: [1/50][578/2344] Data 0.002 (0.003) Batch 0.675 (0.616) Remain 19:57:31 loss: 1.2369 Lr: 0.00027
[2025-05-11 13:17:14,373 INFO misc.py line 117 288342] Train: [1/50][579/2344] Data 0.002 (0.003) Batch 0.757 (0.616) Remain 19:57:59 loss: 1.1017 Lr: 0.00027
[2025-05-11 13:17:15,063 INFO misc.py line 117 288342] Train: [1/50][580/2344] Data 0.003 (0.003) Batch 0.689 (0.616) Remain 19:58:13 loss: 1.1281 Lr: 0.00027
[2025-05-11 13:17:15,633 INFO misc.py line 117 288342] Train: [1/50][581/2344] Data 0.003 (0.003) Batch 0.570 (0.616) Remain 19:58:03 loss: 1.1424 Lr: 0.00027
[2025-05-11 13:17:16,202 INFO misc.py line 117 288342] Train: [1/50][582/2344] Data 0.002 (0.003) Batch 0.569 (0.616) Remain 19:57:53 loss: 1.4294 Lr: 0.00027
[2025-05-11 13:17:16,659 INFO misc.py line 117 288342] Train: [1/50][583/2344] Data 0.003 (0.003) Batch 0.456 (0.616) Remain 19:57:20 loss: 1.2746 Lr: 0.00027
[2025-05-11 13:17:17,268 INFO misc.py line 117 288342] Train: [1/50][584/2344] Data 0.003 (0.003) Batch 0.609 (0.616) Remain 19:57:18 loss: 1.1848 Lr: 0.00027
[2025-05-11 13:17:17,877 INFO misc.py line 117 288342] Train: [1/50][585/2344] Data 0.003 (0.003) Batch 0.610 (0.616) Remain 19:57:16 loss: 1.4151 Lr: 0.00027
[2025-05-11 13:17:18,420 INFO misc.py line 117 288342] Train: [1/50][586/2344] Data 0.003 (0.003) Batch 0.542 (0.616) Remain 19:57:01 loss: 1.3561 Lr: 0.00027
[2025-05-11 13:17:18,960 INFO misc.py line 117 288342] Train: [1/50][587/2344] Data 0.003 (0.003) Batch 0.541 (0.616) Remain 19:56:45 loss: 1.3379 Lr: 0.00027
[2025-05-11 13:17:19,587 INFO misc.py line 117 288342] Train: [1/50][588/2344] Data 0.003 (0.003) Batch 0.627 (0.616) Remain 19:56:47 loss: 1.3546 Lr: 0.00027
[2025-05-11 13:17:20,249 INFO misc.py line 117 288342] Train: [1/50][589/2344] Data 0.002 (0.003) Batch 0.662 (0.616) Remain 19:56:56 loss: 1.2112 Lr: 0.00027
[2025-05-11 13:17:20,852 INFO misc.py line 117 288342] Train: [1/50][590/2344] Data 0.003 (0.003) Batch 0.602 (0.616) Remain 19:56:52 loss: 0.9988 Lr: 0.00027
[2025-05-11 13:17:21,420 INFO misc.py line 117 288342] Train: [1/50][591/2344] Data 0.002 (0.003) Batch 0.568 (0.616) Remain 19:56:42 loss: 1.2883 Lr: 0.00027
[2025-05-11 13:17:22,014 INFO misc.py line 117 288342] Train: [1/50][592/2344] Data 0.003 (0.003) Batch 0.594 (0.616) Remain 19:56:37 loss: 1.2379 Lr: 0.00027
[2025-05-11 13:17:22,668 INFO misc.py line 117 288342] Train: [1/50][593/2344] Data 0.002 (0.003) Batch 0.654 (0.616) Remain 19:56:44 loss: 1.4575 Lr: 0.00027
[2025-05-11 13:17:23,334 INFO misc.py line 117 288342] Train: [1/50][594/2344] Data 0.003 (0.003) Batch 0.666 (0.616) Remain 19:56:54 loss: 1.0893 Lr: 0.00027
[2025-05-11 13:17:23,941 INFO misc.py line 117 288342] Train: [1/50][595/2344] Data 0.002 (0.003) Batch 0.607 (0.616) Remain 19:56:51 loss: 1.4442 Lr: 0.00027
[2025-05-11 13:17:24,556 INFO misc.py line 117 288342] Train: [1/50][596/2344] Data 0.003 (0.003) Batch 0.615 (0.616) Remain 19:56:50 loss: 1.4132 Lr: 0.00027
[2025-05-11 13:17:25,233 INFO misc.py line 117 288342] Train: [1/50][597/2344] Data 0.003 (0.003) Batch 0.677 (0.616) Remain 19:57:02 loss: 1.1620 Lr: 0.00027
[2025-05-11 13:17:25,852 INFO misc.py line 117 288342] Train: [1/50][598/2344] Data 0.003 (0.003) Batch 0.619 (0.616) Remain 19:57:02 loss: 1.1657 Lr: 0.00027
[2025-05-11 13:17:26,483 INFO misc.py line 117 288342] Train: [1/50][599/2344] Data 0.003 (0.003) Batch 0.631 (0.616) Remain 19:57:04 loss: 1.1611 Lr: 0.00027
[2025-05-11 13:17:27,114 INFO misc.py line 117 288342] Train: [1/50][600/2344] Data 0.003 (0.003) Batch 0.631 (0.616) Remain 19:57:06 loss: 1.1245 Lr: 0.00027
[2025-05-11 13:17:27,722 INFO misc.py line 117 288342] Train: [1/50][601/2344] Data 0.003 (0.003) Batch 0.608 (0.616) Remain 19:57:04 loss: 1.2190 Lr: 0.00027
[2025-05-11 13:17:28,352 INFO misc.py line 117 288342] Train: [1/50][602/2344] Data 0.003 (0.003) Batch 0.630 (0.616) Remain 19:57:06 loss: 1.0876 Lr: 0.00027
[2025-05-11 13:17:28,872 INFO misc.py line 117 288342] Train: [1/50][603/2344] Data 0.003 (0.003) Batch 0.520 (0.616) Remain 19:56:47 loss: 1.0756 Lr: 0.00027
[2025-05-11 13:17:29,371 INFO misc.py line 117 288342] Train: [1/50][604/2344] Data 0.003 (0.003) Batch 0.499 (0.616) Remain 19:56:24 loss: 1.5900 Lr: 0.00027
[2025-05-11 13:17:30,079 INFO misc.py line 117 288342] Train: [1/50][605/2344] Data 0.003 (0.003) Batch 0.708 (0.616) Remain 19:56:41 loss: 1.1042 Lr: 0.00027
[2025-05-11 13:17:30,690 INFO misc.py line 117 288342] Train: [1/50][606/2344] Data 0.003 (0.003) Batch 0.611 (0.616) Remain 19:56:40 loss: 1.1401 Lr: 0.00027
[2025-05-11 13:17:31,262 INFO misc.py line 117 288342] Train: [1/50][607/2344] Data 0.002 (0.003) Batch 0.572 (0.616) Remain 19:56:30 loss: 1.2075 Lr: 0.00027
[2025-05-11 13:17:31,712 INFO misc.py line 117 288342] Train: [1/50][608/2344] Data 0.002 (0.003) Batch 0.450 (0.615) Remain 19:55:58 loss: 1.0037 Lr: 0.00027
[2025-05-11 13:17:32,345 INFO misc.py line 117 288342] Train: [1/50][609/2344] Data 0.003 (0.003) Batch 0.633 (0.615) Remain 19:56:01 loss: 1.2164 Lr: 0.00027
[2025-05-11 13:17:32,951 INFO misc.py line 117 288342] Train: [1/50][610/2344] Data 0.003 (0.003) Batch 0.606 (0.615) Remain 19:55:58 loss: 1.2170 Lr: 0.00027
[2025-05-11 13:17:33,560 INFO misc.py line 117 288342] Train: [1/50][611/2344] Data 0.002 (0.003) Batch 0.608 (0.615) Remain 19:55:56 loss: 1.0836 Lr: 0.00027
[2025-05-11 13:17:34,116 INFO misc.py line 117 288342] Train: [1/50][612/2344] Data 0.003 (0.003) Batch 0.556 (0.615) Remain 19:55:44 loss: 1.4199 Lr: 0.00027
[2025-05-11 13:17:34,709 INFO misc.py line 117 288342] Train: [1/50][613/2344] Data 0.003 (0.003) Batch 0.593 (0.615) Remain 19:55:39 loss: 0.9337 Lr: 0.00027
[2025-05-11 13:17:35,307 INFO misc.py line 117 288342] Train: [1/50][614/2344] Data 0.003 (0.003) Batch 0.598 (0.615) Remain 19:55:35 loss: 1.2476 Lr: 0.00027
[2025-05-11 13:17:35,828 INFO misc.py line 117 288342] Train: [1/50][615/2344] Data 0.003 (0.003) Batch 0.521 (0.615) Remain 19:55:17 loss: 1.2026 Lr: 0.00027
[2025-05-11 13:17:36,477 INFO misc.py line 117 288342] Train: [1/50][616/2344] Data 0.003 (0.003) Batch 0.650 (0.615) Remain 19:55:23 loss: 1.1896 Lr: 0.00028
[2025-05-11 13:17:37,055 INFO misc.py line 117 288342] Train: [1/50][617/2344] Data 0.002 (0.003) Batch 0.578 (0.615) Remain 19:55:15 loss: 1.0375 Lr: 0.00028
[2025-05-11 13:17:37,753 INFO misc.py line 117 288342] Train: [1/50][618/2344] Data 0.003 (0.003) Batch 0.698 (0.615) Remain 19:55:30 loss: 1.1035 Lr: 0.00028
[2025-05-11 13:17:38,198 INFO misc.py line 117 288342] Train: [1/50][619/2344] Data 0.003 (0.003) Batch 0.445 (0.615) Remain 19:54:57 loss: 1.2344 Lr: 0.00028
[2025-05-11 13:17:38,914 INFO misc.py line 117 288342] Train: [1/50][620/2344] Data 0.003 (0.003) Batch 0.716 (0.615) Remain 19:55:16 loss: 1.0049 Lr: 0.00028
[2025-05-11 13:17:39,690 INFO misc.py line 117 288342] Train: [1/50][621/2344] Data 0.002 (0.003) Batch 0.776 (0.615) Remain 19:55:46 loss: 1.0764 Lr: 0.00028
[2025-05-11 13:17:40,269 INFO misc.py line 117 288342] Train: [1/50][622/2344] Data 0.002 (0.003) Batch 0.579 (0.615) Remain 19:55:38 loss: 1.0011 Lr: 0.00028
[2025-05-11 13:17:40,788 INFO misc.py line 117 288342] Train: [1/50][623/2344] Data 0.003 (0.003) Batch 0.519 (0.615) Remain 19:55:19 loss: 1.1164 Lr: 0.00028
[2025-05-11 13:17:41,290 INFO misc.py line 117 288342] Train: [1/50][624/2344] Data 0.003 (0.003) Batch 0.502 (0.615) Remain 19:54:58 loss: 1.0087 Lr: 0.00028
[2025-05-11 13:17:41,835 INFO misc.py line 117 288342] Train: [1/50][625/2344] Data 0.003 (0.003) Batch 0.545 (0.615) Remain 19:54:44 loss: 0.9816 Lr: 0.00028
[2025-05-11 13:17:42,366 INFO misc.py line 117 288342] Train: [1/50][626/2344] Data 0.002 (0.003) Batch 0.530 (0.615) Remain 19:54:27 loss: 1.0076 Lr: 0.00028
[2025-05-11 13:17:42,941 INFO misc.py line 117 288342] Train: [1/50][627/2344] Data 0.003 (0.003) Batch 0.575 (0.615) Remain 19:54:19 loss: 1.0951 Lr: 0.00028
[2025-05-11 13:17:43,431 INFO misc.py line 117 288342] Train: [1/50][628/2344] Data 0.003 (0.003) Batch 0.490 (0.615) Remain 19:53:55 loss: 1.1859 Lr: 0.00028
[2025-05-11 13:17:44,081 INFO misc.py line 117 288342] Train: [1/50][629/2344] Data 0.003 (0.003) Batch 0.651 (0.615) Remain 19:54:02 loss: 0.9993 Lr: 0.00028
[2025-05-11 13:17:44,878 INFO misc.py line 117 288342] Train: [1/50][630/2344] Data 0.003 (0.003) Batch 0.797 (0.615) Remain 19:54:35 loss: 1.2762 Lr: 0.00028
[2025-05-11 13:17:45,538 INFO misc.py line 117 288342] Train: [1/50][631/2344] Data 0.005 (0.003) Batch 0.660 (0.615) Remain 19:54:43 loss: 1.1622 Lr: 0.00028
[2025-05-11 13:17:46,185 INFO misc.py line 117 288342] Train: [1/50][632/2344] Data 0.003 (0.003) Batch 0.647 (0.615) Remain 19:54:48 loss: 1.1343 Lr: 0.00028
[2025-05-11 13:17:46,845 INFO misc.py line 117 288342] Train: [1/50][633/2344] Data 0.003 (0.003) Batch 0.660 (0.615) Remain 19:54:56 loss: 1.2570 Lr: 0.00028
[2025-05-11 13:17:47,533 INFO misc.py line 117 288342] Train: [1/50][634/2344] Data 0.003 (0.003) Batch 0.688 (0.615) Remain 19:55:08 loss: 1.1560 Lr: 0.00028
[2025-05-11 13:17:48,181 INFO misc.py line 117 288342] Train: [1/50][635/2344] Data 0.003 (0.003) Batch 0.648 (0.615) Remain 19:55:14 loss: 1.1764 Lr: 0.00028
[2025-05-11 13:17:48,799 INFO misc.py line 117 288342] Train: [1/50][636/2344] Data 0.003 (0.003) Batch 0.618 (0.615) Remain 19:55:14 loss: 1.0754 Lr: 0.00028
[2025-05-11 13:17:49,569 INFO misc.py line 117 288342] Train: [1/50][637/2344] Data 0.003 (0.003) Batch 0.770 (0.615) Remain 19:55:42 loss: 1.3013 Lr: 0.00028
[2025-05-11 13:17:50,202 INFO misc.py line 117 288342] Train: [1/50][638/2344] Data 0.002 (0.003) Batch 0.633 (0.616) Remain 19:55:44 loss: 1.4494 Lr: 0.00028
[2025-05-11 13:17:50,810 INFO misc.py line 117 288342] Train: [1/50][639/2344] Data 0.003 (0.003) Batch 0.608 (0.615) Remain 19:55:42 loss: 1.1443 Lr: 0.00028
[2025-05-11 13:17:51,286 INFO misc.py line 117 288342] Train: [1/50][640/2344] Data 0.003 (0.003) Batch 0.476 (0.615) Remain 19:55:16 loss: 1.2811 Lr: 0.00028
[2025-05-11 13:17:51,964 INFO misc.py line 117 288342] Train: [1/50][641/2344] Data 0.002 (0.003) Batch 0.678 (0.615) Remain 19:55:27 loss: 1.2500 Lr: 0.00028
[2025-05-11 13:17:52,436 INFO misc.py line 117 288342] Train: [1/50][642/2344] Data 0.003 (0.003) Batch 0.472 (0.615) Remain 19:55:00 loss: 1.1750 Lr: 0.00028
[2025-05-11 13:17:53,106 INFO misc.py line 117 288342] Train: [1/50][643/2344] Data 0.002 (0.003) Batch 0.670 (0.615) Remain 19:55:10 loss: 1.1820 Lr: 0.00028
[2025-05-11 13:17:53,817 INFO misc.py line 117 288342] Train: [1/50][644/2344] Data 0.003 (0.003) Batch 0.711 (0.615) Remain 19:55:26 loss: 1.2875 Lr: 0.00028
[2025-05-11 13:17:54,472 INFO misc.py line 117 288342] Train: [1/50][645/2344] Data 0.002 (0.003) Batch 0.655 (0.615) Remain 19:55:33 loss: 1.0589 Lr: 0.00028
[2025-05-11 13:17:55,001 INFO misc.py line 117 288342] Train: [1/50][646/2344] Data 0.002 (0.003) Batch 0.529 (0.615) Remain 19:55:17 loss: 0.9422 Lr: 0.00028
[2025-05-11 13:17:55,570 INFO misc.py line 117 288342] Train: [1/50][647/2344] Data 0.003 (0.003) Batch 0.569 (0.615) Remain 19:55:08 loss: 1.1755 Lr: 0.00028
[2025-05-11 13:17:56,192 INFO misc.py line 117 288342] Train: [1/50][648/2344] Data 0.002 (0.003) Batch 0.622 (0.615) Remain 19:55:08 loss: 1.1921 Lr: 0.00028
[2025-05-11 13:17:56,837 INFO misc.py line 117 288342] Train: [1/50][649/2344] Data 0.002 (0.003) Batch 0.645 (0.615) Remain 19:55:13 loss: 1.0224 Lr: 0.00028
[2025-05-11 13:17:57,434 INFO misc.py line 117 288342] Train: [1/50][650/2344] Data 0.002 (0.003) Batch 0.596 (0.615) Remain 19:55:09 loss: 0.9783 Lr: 0.00028
[2025-05-11 13:17:58,084 INFO misc.py line 117 288342] Train: [1/50][651/2344] Data 0.003 (0.003) Batch 0.650 (0.615) Remain 19:55:15 loss: 1.0821 Lr: 0.00028
[2025-05-11 13:17:58,697 INFO misc.py line 117 288342] Train: [1/50][652/2344] Data 0.002 (0.003) Batch 0.613 (0.615) Remain 19:55:14 loss: 1.1546 Lr: 0.00028
[2025-05-11 13:17:59,191 INFO misc.py line 117 288342] Train: [1/50][653/2344] Data 0.003 (0.003) Batch 0.494 (0.615) Remain 19:54:51 loss: 1.0014 Lr: 0.00028
[2025-05-11 13:17:59,982 INFO misc.py line 117 288342] Train: [1/50][654/2344] Data 0.003 (0.003) Batch 0.791 (0.615) Remain 19:55:22 loss: 1.2266 Lr: 0.00028
[2025-05-11 13:18:00,529 INFO misc.py line 117 288342] Train: [1/50][655/2344] Data 0.003 (0.003) Batch 0.547 (0.615) Remain 19:55:09 loss: 1.2467 Lr: 0.00028
[2025-05-11 13:18:01,162 INFO misc.py line 117 288342] Train: [1/50][656/2344] Data 0.003 (0.003) Batch 0.633 (0.615) Remain 19:55:12 loss: 1.0740 Lr: 0.00029
[2025-05-11 13:18:01,761 INFO misc.py line 117 288342] Train: [1/50][657/2344] Data 0.003 (0.003) Batch 0.599 (0.615) Remain 19:55:08 loss: 1.1972 Lr: 0.00029
[2025-05-11 13:18:02,409 INFO misc.py line 117 288342] Train: [1/50][658/2344] Data 0.002 (0.003) Batch 0.649 (0.615) Remain 19:55:14 loss: 1.0199 Lr: 0.00029
[2025-05-11 13:18:02,996 INFO misc.py line 117 288342] Train: [1/50][659/2344] Data 0.002 (0.003) Batch 0.587 (0.615) Remain 19:55:08 loss: 0.9857 Lr: 0.00029
[2025-05-11 13:18:03,637 INFO misc.py line 117 288342] Train: [1/50][660/2344] Data 0.003 (0.003) Batch 0.641 (0.615) Remain 19:55:12 loss: 0.9344 Lr: 0.00029
[2025-05-11 13:18:04,155 INFO misc.py line 117 288342] Train: [1/50][661/2344] Data 0.003 (0.003) Batch 0.518 (0.615) Remain 19:54:54 loss: 1.1234 Lr: 0.00029
[2025-05-11 13:18:04,651 INFO misc.py line 117 288342] Train: [1/50][662/2344] Data 0.003 (0.003) Batch 0.496 (0.615) Remain 19:54:32 loss: 1.2889 Lr: 0.00029
[2025-05-11 13:18:05,127 INFO misc.py line 117 288342] Train: [1/50][663/2344] Data 0.003 (0.003) Batch 0.476 (0.615) Remain 19:54:07 loss: 1.2159 Lr: 0.00029
[2025-05-11 13:18:05,599 INFO misc.py line 117 288342] Train: [1/50][664/2344] Data 0.003 (0.003) Batch 0.473 (0.615) Remain 19:53:41 loss: 1.1905 Lr: 0.00029
[2025-05-11 13:18:06,257 INFO misc.py line 117 288342] Train: [1/50][665/2344] Data 0.003 (0.003) Batch 0.658 (0.615) Remain 19:53:48 loss: 1.0398 Lr: 0.00029
[2025-05-11 13:18:06,964 INFO misc.py line 117 288342] Train: [1/50][666/2344] Data 0.002 (0.003) Batch 0.707 (0.615) Remain 19:54:04 loss: 0.9500 Lr: 0.00029
[2025-05-11 13:18:07,559 INFO misc.py line 117 288342] Train: [1/50][667/2344] Data 0.002 (0.003) Batch 0.594 (0.615) Remain 19:54:00 loss: 1.2224 Lr: 0.00029
[2025-05-11 13:18:08,279 INFO misc.py line 117 288342] Train: [1/50][668/2344] Data 0.003 (0.003) Batch 0.720 (0.615) Remain 19:54:18 loss: 1.1721 Lr: 0.00029
[2025-05-11 13:18:08,944 INFO misc.py line 117 288342] Train: [1/50][669/2344] Data 0.003 (0.003) Batch 0.665 (0.615) Remain 19:54:26 loss: 1.2222 Lr: 0.00029
[2025-05-11 13:18:09,644 INFO misc.py line 117 288342] Train: [1/50][670/2344] Data 0.003 (0.003) Batch 0.700 (0.615) Remain 19:54:40 loss: 1.0750 Lr: 0.00029
[2025-05-11 13:18:10,399 INFO misc.py line 117 288342] Train: [1/50][671/2344] Data 0.003 (0.003) Batch 0.755 (0.615) Remain 19:55:04 loss: 1.2859 Lr: 0.00029
[2025-05-11 13:18:10,903 INFO misc.py line 117 288342] Train: [1/50][672/2344] Data 0.003 (0.003) Batch 0.504 (0.615) Remain 19:54:44 loss: 0.8251 Lr: 0.00029
[2025-05-11 13:18:11,489 INFO misc.py line 117 288342] Train: [1/50][673/2344] Data 0.003 (0.003) Batch 0.587 (0.615) Remain 19:54:38 loss: 1.2262 Lr: 0.00029
[2025-05-11 13:18:12,065 INFO misc.py line 117 288342] Train: [1/50][674/2344] Data 0.002 (0.003) Batch 0.576 (0.615) Remain 19:54:31 loss: 1.1211 Lr: 0.00029
[2025-05-11 13:18:12,636 INFO misc.py line 117 288342] Train: [1/50][675/2344] Data 0.002 (0.003) Batch 0.571 (0.615) Remain 19:54:23 loss: 0.9514 Lr: 0.00029
[2025-05-11 13:18:13,204 INFO misc.py line 117 288342] Train: [1/50][676/2344] Data 0.002 (0.003) Batch 0.568 (0.615) Remain 19:54:14 loss: 0.9981 Lr: 0.00029
[2025-05-11 13:18:13,839 INFO misc.py line 117 288342] Train: [1/50][677/2344] Data 0.003 (0.003) Batch 0.635 (0.615) Remain 19:54:17 loss: 1.0276 Lr: 0.00029
[2025-05-11 13:18:14,494 INFO misc.py line 117 288342] Train: [1/50][678/2344] Data 0.003 (0.003) Batch 0.655 (0.615) Remain 19:54:23 loss: 1.2139 Lr: 0.00029
[2025-05-11 13:18:15,080 INFO misc.py line 117 288342] Train: [1/50][679/2344] Data 0.002 (0.003) Batch 0.586 (0.615) Remain 19:54:17 loss: 1.1910 Lr: 0.00029
[2025-05-11 13:18:15,700 INFO misc.py line 117 288342] Train: [1/50][680/2344] Data 0.003 (0.003) Batch 0.620 (0.615) Remain 19:54:18 loss: 1.0900 Lr: 0.00029
[2025-05-11 13:18:16,477 INFO misc.py line 117 288342] Train: [1/50][681/2344] Data 0.002 (0.003) Batch 0.776 (0.615) Remain 19:54:45 loss: 0.9937 Lr: 0.00029
[2025-05-11 13:18:16,895 INFO misc.py line 117 288342] Train: [1/50][682/2344] Data 0.003 (0.003) Batch 0.419 (0.615) Remain 19:54:10 loss: 1.1803 Lr: 0.00029
[2025-05-11 13:18:17,484 INFO misc.py line 117 288342] Train: [1/50][683/2344] Data 0.003 (0.003) Batch 0.589 (0.615) Remain 19:54:05 loss: 1.0582 Lr: 0.00029
[2025-05-11 13:18:18,144 INFO misc.py line 117 288342] Train: [1/50][684/2344] Data 0.003 (0.003) Batch 0.659 (0.615) Remain 19:54:12 loss: 1.3547 Lr: 0.00029
[2025-05-11 13:18:18,690 INFO misc.py line 117 288342] Train: [1/50][685/2344] Data 0.003 (0.003) Batch 0.546 (0.615) Remain 19:54:00 loss: 0.9044 Lr: 0.00029
[2025-05-11 13:18:19,264 INFO misc.py line 117 288342] Train: [1/50][686/2344] Data 0.003 (0.003) Batch 0.574 (0.615) Remain 19:53:52 loss: 1.1305 Lr: 0.00029
[2025-05-11 13:18:20,020 INFO misc.py line 117 288342] Train: [1/50][687/2344] Data 0.003 (0.003) Batch 0.755 (0.615) Remain 19:54:16 loss: 1.1352 Lr: 0.00029
[2025-05-11 13:18:20,758 INFO misc.py line 117 288342] Train: [1/50][688/2344] Data 0.004 (0.003) Batch 0.740 (0.615) Remain 19:54:36 loss: 1.2474 Lr: 0.00029
[2025-05-11 13:18:21,421 INFO misc.py line 117 288342] Train: [1/50][689/2344] Data 0.003 (0.003) Batch 0.663 (0.615) Remain 19:54:44 loss: 0.9205 Lr: 0.00029
[2025-05-11 13:18:21,961 INFO misc.py line 117 288342] Train: [1/50][690/2344] Data 0.003 (0.003) Batch 0.540 (0.615) Remain 19:54:30 loss: 0.9832 Lr: 0.00029
[2025-05-11 13:18:22,533 INFO misc.py line 117 288342] Train: [1/50][691/2344] Data 0.003 (0.003) Batch 0.572 (0.615) Remain 19:54:22 loss: 0.9947 Lr: 0.00029
[2025-05-11 13:18:23,085 INFO misc.py line 117 288342] Train: [1/50][692/2344] Data 0.002 (0.003) Batch 0.552 (0.615) Remain 19:54:11 loss: 1.1690 Lr: 0.00029
[2025-05-11 13:18:23,692 INFO misc.py line 117 288342] Train: [1/50][693/2344] Data 0.003 (0.003) Batch 0.607 (0.615) Remain 19:54:09 loss: 1.2537 Lr: 0.00029
[2025-05-11 13:18:24,394 INFO misc.py line 117 288342] Train: [1/50][694/2344] Data 0.003 (0.003) Batch 0.702 (0.615) Remain 19:54:23 loss: 1.0545 Lr: 0.00030
[2025-05-11 13:18:25,042 INFO misc.py line 117 288342] Train: [1/50][695/2344] Data 0.003 (0.003) Batch 0.647 (0.615) Remain 19:54:28 loss: 1.3516 Lr: 0.00030
[2025-05-11 13:18:25,834 INFO misc.py line 117 288342] Train: [1/50][696/2344] Data 0.003 (0.003) Batch 0.792 (0.615) Remain 19:54:57 loss: 0.9455 Lr: 0.00030
[2025-05-11 13:18:26,521 INFO misc.py line 117 288342] Train: [1/50][697/2344] Data 0.002 (0.003) Batch 0.687 (0.616) Remain 19:55:09 loss: 1.3134 Lr: 0.00030
[2025-05-11 13:18:27,048 INFO misc.py line 117 288342] Train: [1/50][698/2344] Data 0.003 (0.003) Batch 0.527 (0.615) Remain 19:54:53 loss: 1.0770 Lr: 0.00030
[2025-05-11 13:18:27,657 INFO misc.py line 117 288342] Train: [1/50][699/2344] Data 0.002 (0.003) Batch 0.609 (0.615) Remain 19:54:51 loss: 1.3246 Lr: 0.00030
[2025-05-11 13:18:28,272 INFO misc.py line 117 288342] Train: [1/50][700/2344] Data 0.002 (0.003) Batch 0.615 (0.615) Remain 19:54:51 loss: 0.7047 Lr: 0.00030
[2025-05-11 13:18:28,925 INFO misc.py line 117 288342] Train: [1/50][701/2344] Data 0.003 (0.003) Batch 0.653 (0.615) Remain 19:54:56 loss: 1.1326 Lr: 0.00030
[2025-05-11 13:18:29,596 INFO misc.py line 117 288342] Train: [1/50][702/2344] Data 0.002 (0.003) Batch 0.671 (0.616) Remain 19:55:05 loss: 1.5220 Lr: 0.00030
[2025-05-11 13:18:30,210 INFO misc.py line 117 288342] Train: [1/50][703/2344] Data 0.002 (0.003) Batch 0.614 (0.616) Remain 19:55:04 loss: 1.3745 Lr: 0.00030
[2025-05-11 13:18:30,772 INFO misc.py line 117 288342] Train: [1/50][704/2344] Data 0.003 (0.003) Batch 0.562 (0.615) Remain 19:54:55 loss: 1.2254 Lr: 0.00030
[2025-05-11 13:18:31,411 INFO misc.py line 117 288342] Train: [1/50][705/2344] Data 0.003 (0.003) Batch 0.639 (0.615) Remain 19:54:58 loss: 1.0387 Lr: 0.00030
[2025-05-11 13:18:31,896 INFO misc.py line 117 288342] Train: [1/50][706/2344] Data 0.003 (0.003) Batch 0.485 (0.615) Remain 19:54:36 loss: 1.0859 Lr: 0.00030
[2025-05-11 13:18:32,393 INFO misc.py line 117 288342] Train: [1/50][707/2344] Data 0.003 (0.003) Batch 0.497 (0.615) Remain 19:54:16 loss: 1.2202 Lr: 0.00030
[2025-05-11 13:18:32,904 INFO misc.py line 117 288342] Train: [1/50][708/2344] Data 0.003 (0.003) Batch 0.511 (0.615) Remain 19:53:58 loss: 1.1977 Lr: 0.00030
[2025-05-11 13:18:33,388 INFO misc.py line 117 288342] Train: [1/50][709/2344] Data 0.003 (0.003) Batch 0.484 (0.615) Remain 19:53:36 loss: 1.1348 Lr: 0.00030
[2025-05-11 13:18:34,161 INFO misc.py line 117 288342] Train: [1/50][710/2344] Data 0.003 (0.003) Batch 0.772 (0.615) Remain 19:54:01 loss: 1.0270 Lr: 0.00030
[2025-05-11 13:18:34,830 INFO misc.py line 117 288342] Train: [1/50][711/2344] Data 0.003 (0.003) Batch 0.670 (0.615) Remain 19:54:09 loss: 1.2051 Lr: 0.00030
[2025-05-11 13:18:35,537 INFO misc.py line 117 288342] Train: [1/50][712/2344] Data 0.003 (0.003) Batch 0.707 (0.615) Remain 19:54:24 loss: 1.2886 Lr: 0.00030
[2025-05-11 13:18:36,221 INFO misc.py line 117 288342] Train: [1/50][713/2344] Data 0.003 (0.003) Batch 0.684 (0.615) Remain 19:54:34 loss: 1.1367 Lr: 0.00030
[2025-05-11 13:18:36,787 INFO misc.py line 117 288342] Train: [1/50][714/2344] Data 0.003 (0.003) Batch 0.565 (0.615) Remain 19:54:26 loss: 1.2279 Lr: 0.00030
[2025-05-11 13:18:37,461 INFO misc.py line 117 288342] Train: [1/50][715/2344] Data 0.003 (0.003) Batch 0.674 (0.615) Remain 19:54:35 loss: 0.9297 Lr: 0.00030
[2025-05-11 13:18:38,006 INFO misc.py line 117 288342] Train: [1/50][716/2344] Data 0.003 (0.003) Batch 0.546 (0.615) Remain 19:54:23 loss: 0.8653 Lr: 0.00030
[2025-05-11 13:18:38,618 INFO misc.py line 117 288342] Train: [1/50][717/2344] Data 0.003 (0.003) Batch 0.611 (0.615) Remain 19:54:21 loss: 1.0229 Lr: 0.00030
[2025-05-11 13:18:39,190 INFO misc.py line 117 288342] Train: [1/50][718/2344] Data 0.003 (0.003) Batch 0.572 (0.615) Remain 19:54:14 loss: 1.2350 Lr: 0.00030
[2025-05-11 13:18:39,734 INFO misc.py line 117 288342] Train: [1/50][719/2344] Data 0.003 (0.003) Batch 0.544 (0.615) Remain 19:54:02 loss: 1.1761 Lr: 0.00030
[2025-05-11 13:18:40,345 INFO misc.py line 117 288342] Train: [1/50][720/2344] Data 0.002 (0.003) Batch 0.611 (0.615) Remain 19:54:00 loss: 1.0968 Lr: 0.00030
[2025-05-11 13:18:41,041 INFO misc.py line 117 288342] Train: [1/50][721/2344] Data 0.003 (0.003) Batch 0.696 (0.615) Remain 19:54:13 loss: 1.2856 Lr: 0.00030
[2025-05-11 13:18:41,786 INFO misc.py line 117 288342] Train: [1/50][722/2344] Data 0.002 (0.003) Batch 0.746 (0.615) Remain 19:54:33 loss: 1.2386 Lr: 0.00030
[2025-05-11 13:18:42,434 INFO misc.py line 117 288342] Train: [1/50][723/2344] Data 0.003 (0.003) Batch 0.647 (0.615) Remain 19:54:38 loss: 0.9523 Lr: 0.00030
[2025-05-11 13:18:43,125 INFO misc.py line 117 288342] Train: [1/50][724/2344] Data 0.003 (0.003) Batch 0.692 (0.615) Remain 19:54:50 loss: 1.0581 Lr: 0.00030
[2025-05-11 13:18:43,741 INFO misc.py line 117 288342] Train: [1/50][725/2344] Data 0.003 (0.003) Batch 0.615 (0.615) Remain 19:54:49 loss: 1.2124 Lr: 0.00030
[2025-05-11 13:18:44,238 INFO misc.py line 117 288342] Train: [1/50][726/2344] Data 0.003 (0.003) Batch 0.497 (0.615) Remain 19:54:29 loss: 1.0517 Lr: 0.00030
[2025-05-11 13:18:44,822 INFO misc.py line 117 288342] Train: [1/50][727/2344] Data 0.003 (0.003) Batch 0.584 (0.615) Remain 19:54:24 loss: 1.1616 Lr: 0.00030
[2025-05-11 13:18:45,475 INFO misc.py line 117 288342] Train: [1/50][728/2344] Data 0.003 (0.003) Batch 0.653 (0.615) Remain 19:54:29 loss: 1.0065 Lr: 0.00030
[2025-05-11 13:18:46,169 INFO misc.py line 117 288342] Train: [1/50][729/2344] Data 0.003 (0.003) Batch 0.694 (0.615) Remain 19:54:41 loss: 1.2332 Lr: 0.00030
[2025-05-11 13:18:46,765 INFO misc.py line 117 288342] Train: [1/50][730/2344] Data 0.003 (0.003) Batch 0.597 (0.615) Remain 19:54:37 loss: 1.0977 Lr: 0.00031
[2025-05-11 13:18:47,343 INFO misc.py line 117 288342] Train: [1/50][731/2344] Data 0.002 (0.003) Batch 0.578 (0.615) Remain 19:54:31 loss: 1.3034 Lr: 0.00031
[2025-05-11 13:18:48,069 INFO misc.py line 117 288342] Train: [1/50][732/2344] Data 0.002 (0.003) Batch 0.726 (0.616) Remain 19:54:48 loss: 1.1212 Lr: 0.00031
[2025-05-11 13:18:48,738 INFO misc.py line 117 288342] Train: [1/50][733/2344] Data 0.002 (0.003) Batch 0.669 (0.616) Remain 19:54:56 loss: 1.1498 Lr: 0.00031
[2025-05-11 13:18:49,423 INFO misc.py line 117 288342] Train: [1/50][734/2344] Data 0.002 (0.003) Batch 0.684 (0.616) Remain 19:55:06 loss: 1.0212 Lr: 0.00031
[2025-05-11 13:18:50,080 INFO misc.py line 117 288342] Train: [1/50][735/2344] Data 0.003 (0.003) Batch 0.658 (0.616) Remain 19:55:12 loss: 1.1709 Lr: 0.00031
[2025-05-11 13:18:50,777 INFO misc.py line 117 288342] Train: [1/50][736/2344] Data 0.003 (0.003) Batch 0.697 (0.616) Remain 19:55:24 loss: 1.1963 Lr: 0.00031
[2025-05-11 13:18:51,496 INFO misc.py line 117 288342] Train: [1/50][737/2344] Data 0.003 (0.003) Batch 0.719 (0.616) Remain 19:55:40 loss: 1.1595 Lr: 0.00031
[2025-05-11 13:18:52,100 INFO misc.py line 117 288342] Train: [1/50][738/2344] Data 0.002 (0.003) Batch 0.604 (0.616) Remain 19:55:38 loss: 1.1300 Lr: 0.00031
[2025-05-11 13:18:52,744 INFO misc.py line 117 288342] Train: [1/50][739/2344] Data 0.003 (0.003) Batch 0.644 (0.616) Remain 19:55:42 loss: 1.1048 Lr: 0.00031
[2025-05-11 13:18:53,342 INFO misc.py line 117 288342] Train: [1/50][740/2344] Data 0.003 (0.003) Batch 0.598 (0.616) Remain 19:55:38 loss: 1.1837 Lr: 0.00031
[2025-05-11 13:18:53,830 INFO misc.py line 117 288342] Train: [1/50][741/2344] Data 0.003 (0.003) Batch 0.488 (0.616) Remain 19:55:17 loss: 1.2547 Lr: 0.00031
[2025-05-11 13:18:54,450 INFO misc.py line 117 288342] Train: [1/50][742/2344] Data 0.003 (0.003) Batch 0.620 (0.616) Remain 19:55:17 loss: 1.1010 Lr: 0.00031
[2025-05-11 13:18:55,115 INFO misc.py line 117 288342] Train: [1/50][743/2344] Data 0.003 (0.003) Batch 0.666 (0.616) Remain 19:55:24 loss: 0.6972 Lr: 0.00031
[2025-05-11 13:18:55,673 INFO misc.py line 117 288342] Train: [1/50][744/2344] Data 0.002 (0.003) Batch 0.558 (0.616) Remain 19:55:15 loss: 0.9492 Lr: 0.00031
[2025-05-11 13:18:56,272 INFO misc.py line 117 288342] Train: [1/50][745/2344] Data 0.003 (0.003) Batch 0.599 (0.616) Remain 19:55:11 loss: 1.2919 Lr: 0.00031
[2025-05-11 13:18:56,949 INFO misc.py line 117 288342] Train: [1/50][746/2344] Data 0.003 (0.003) Batch 0.677 (0.616) Remain 19:55:20 loss: 1.1291 Lr: 0.00031
[2025-05-11 13:18:57,525 INFO misc.py line 117 288342] Train: [1/50][747/2344] Data 0.003 (0.003) Batch 0.576 (0.616) Remain 19:55:14 loss: 1.2101 Lr: 0.00031
[2025-05-11 13:18:58,138 INFO misc.py line 117 288342] Train: [1/50][748/2344] Data 0.003 (0.003) Batch 0.613 (0.616) Remain 19:55:12 loss: 1.0107 Lr: 0.00031
[2025-05-11 13:18:58,698 INFO misc.py line 117 288342] Train: [1/50][749/2344] Data 0.003 (0.003) Batch 0.561 (0.616) Remain 19:55:03 loss: 0.9123 Lr: 0.00031
[2025-05-11 13:18:59,309 INFO misc.py line 117 288342] Train: [1/50][750/2344] Data 0.002 (0.003) Batch 0.610 (0.616) Remain 19:55:02 loss: 1.3136 Lr: 0.00031
[2025-05-11 13:18:59,939 INFO misc.py line 117 288342] Train: [1/50][751/2344] Data 0.003 (0.003) Batch 0.630 (0.616) Remain 19:55:03 loss: 0.9547 Lr: 0.00031
[2025-05-11 13:19:00,760 INFO misc.py line 117 288342] Train: [1/50][752/2344] Data 0.002 (0.003) Batch 0.821 (0.616) Remain 19:55:35 loss: 1.1882 Lr: 0.00031
[2025-05-11 13:19:01,430 INFO misc.py line 117 288342] Train: [1/50][753/2344] Data 0.003 (0.003) Batch 0.670 (0.616) Remain 19:55:42 loss: 0.9053 Lr: 0.00031
[2025-05-11 13:19:02,071 INFO misc.py line 117 288342] Train: [1/50][754/2344] Data 0.003 (0.003) Batch 0.641 (0.616) Remain 19:55:46 loss: 0.9503 Lr: 0.00031
[2025-05-11 13:19:02,792 INFO misc.py line 117 288342] Train: [1/50][755/2344] Data 0.002 (0.003) Batch 0.721 (0.616) Remain 19:56:01 loss: 0.9875 Lr: 0.00031
[2025-05-11 13:19:03,450 INFO misc.py line 117 288342] Train: [1/50][756/2344] Data 0.003 (0.003) Batch 0.658 (0.616) Remain 19:56:07 loss: 0.8951 Lr: 0.00031
[2025-05-11 13:19:04,145 INFO misc.py line 117 288342] Train: [1/50][757/2344] Data 0.003 (0.003) Batch 0.695 (0.616) Remain 19:56:19 loss: 1.0016 Lr: 0.00031
[2025-05-11 13:19:04,801 INFO misc.py line 117 288342] Train: [1/50][758/2344] Data 0.003 (0.003) Batch 0.656 (0.616) Remain 19:56:24 loss: 1.0981 Lr: 0.00031
[2025-05-11 13:19:05,213 INFO misc.py line 117 288342] Train: [1/50][759/2344] Data 0.003 (0.003) Batch 0.411 (0.616) Remain 19:55:52 loss: 0.9674 Lr: 0.00031
[2025-05-11 13:19:05,737 INFO misc.py line 117 288342] Train: [1/50][760/2344] Data 0.003 (0.003) Batch 0.525 (0.616) Remain 19:55:37 loss: 1.0205 Lr: 0.00031
[2025-05-11 13:19:06,412 INFO misc.py line 117 288342] Train: [1/50][761/2344] Data 0.002 (0.003) Batch 0.674 (0.616) Remain 19:55:46 loss: 1.0545 Lr: 0.00031
[2025-05-11 13:19:07,093 INFO misc.py line 117 288342] Train: [1/50][762/2344] Data 0.003 (0.003) Batch 0.681 (0.616) Remain 19:55:55 loss: 1.2657 Lr: 0.00031
[2025-05-11 13:19:07,666 INFO misc.py line 117 288342] Train: [1/50][763/2344] Data 0.002 (0.003) Batch 0.574 (0.616) Remain 19:55:48 loss: 0.9927 Lr: 0.00031
[2025-05-11 13:19:08,281 INFO misc.py line 117 288342] Train: [1/50][764/2344] Data 0.003 (0.003) Batch 0.615 (0.616) Remain 19:55:47 loss: 1.2440 Lr: 0.00031
[2025-05-11 13:19:08,845 INFO misc.py line 117 288342] Train: [1/50][765/2344] Data 0.002 (0.003) Batch 0.563 (0.616) Remain 19:55:38 loss: 0.9200 Lr: 0.00032
[2025-05-11 13:19:09,505 INFO misc.py line 117 288342] Train: [1/50][766/2344] Data 0.003 (0.003) Batch 0.660 (0.616) Remain 19:55:44 loss: 1.0232 Lr: 0.00032
[2025-05-11 13:19:10,225 INFO misc.py line 117 288342] Train: [1/50][767/2344] Data 0.003 (0.003) Batch 0.720 (0.616) Remain 19:56:00 loss: 1.1182 Lr: 0.00032
[2025-05-11 13:19:10,787 INFO misc.py line 117 288342] Train: [1/50][768/2344] Data 0.003 (0.003) Batch 0.562 (0.616) Remain 19:55:51 loss: 1.1528 Lr: 0.00032
[2025-05-11 13:19:11,348 INFO misc.py line 117 288342] Train: [1/50][769/2344] Data 0.003 (0.003) Batch 0.561 (0.616) Remain 19:55:42 loss: 1.0774 Lr: 0.00032
[2025-05-11 13:19:12,067 INFO misc.py line 117 288342] Train: [1/50][770/2344] Data 0.003 (0.003) Batch 0.719 (0.616) Remain 19:55:57 loss: 0.9455 Lr: 0.00032
[2025-05-11 13:19:12,666 INFO misc.py line 117 288342] Train: [1/50][771/2344] Data 0.003 (0.003) Batch 0.599 (0.616) Remain 19:55:54 loss: 1.1400 Lr: 0.00032
[2025-05-11 13:19:13,401 INFO misc.py line 117 288342] Train: [1/50][772/2344] Data 0.003 (0.003) Batch 0.735 (0.616) Remain 19:56:11 loss: 1.0698 Lr: 0.00032
[2025-05-11 13:19:13,978 INFO misc.py line 117 288342] Train: [1/50][773/2344] Data 0.003 (0.003) Batch 0.578 (0.616) Remain 19:56:04 loss: 1.2021 Lr: 0.00032
[2025-05-11 13:19:14,558 INFO misc.py line 117 288342] Train: [1/50][774/2344] Data 0.003 (0.003) Batch 0.580 (0.616) Remain 19:55:58 loss: 1.1688 Lr: 0.00032
[2025-05-11 13:19:15,217 INFO misc.py line 117 288342] Train: [1/50][775/2344] Data 0.003 (0.003) Batch 0.659 (0.616) Remain 19:56:04 loss: 0.9955 Lr: 0.00032
[2025-05-11 13:19:15,818 INFO misc.py line 117 288342] Train: [1/50][776/2344] Data 0.003 (0.003) Batch 0.600 (0.616) Remain 19:56:01 loss: 1.0989 Lr: 0.00032
[2025-05-11 13:19:16,434 INFO misc.py line 117 288342] Train: [1/50][777/2344] Data 0.003 (0.003) Batch 0.616 (0.616) Remain 19:56:00 loss: 1.0276 Lr: 0.00032
[2025-05-11 13:19:17,053 INFO misc.py line 117 288342] Train: [1/50][778/2344] Data 0.003 (0.003) Batch 0.619 (0.616) Remain 19:56:00 loss: 1.2247 Lr: 0.00032
[2025-05-11 13:19:17,704 INFO misc.py line 117 288342] Train: [1/50][779/2344] Data 0.002 (0.003) Batch 0.651 (0.616) Remain 19:56:05 loss: 1.1421 Lr: 0.00032
[2025-05-11 13:19:18,314 INFO misc.py line 117 288342] Train: [1/50][780/2344] Data 0.002 (0.003) Batch 0.610 (0.616) Remain 19:56:03 loss: 1.2520 Lr: 0.00032
[2025-05-11 13:19:18,972 INFO misc.py line 117 288342] Train: [1/50][781/2344] Data 0.003 (0.003) Batch 0.658 (0.616) Remain 19:56:09 loss: 0.9970 Lr: 0.00032
[2025-05-11 13:19:19,562 INFO misc.py line 117 288342] Train: [1/50][782/2344] Data 0.002 (0.003) Batch 0.590 (0.616) Remain 19:56:04 loss: 0.9256 Lr: 0.00032
[2025-05-11 13:19:20,195 INFO misc.py line 117 288342] Train: [1/50][783/2344] Data 0.002 (0.003) Batch 0.633 (0.616) Remain 19:56:06 loss: 1.0089 Lr: 0.00032
[2025-05-11 13:19:20,736 INFO misc.py line 117 288342] Train: [1/50][784/2344] Data 0.003 (0.003) Batch 0.541 (0.616) Remain 19:55:54 loss: 0.9862 Lr: 0.00032
[2025-05-11 13:19:21,359 INFO misc.py line 117 288342] Train: [1/50][785/2344] Data 0.002 (0.003) Batch 0.623 (0.616) Remain 19:55:55 loss: 1.2545 Lr: 0.00032
[2025-05-11 13:19:22,197 INFO misc.py line 117 288342] Train: [1/50][786/2344] Data 0.003 (0.003) Batch 0.838 (0.617) Remain 19:56:27 loss: 1.1077 Lr: 0.00032
[2025-05-11 13:19:22,876 INFO misc.py line 117 288342] Train: [1/50][787/2344] Data 0.003 (0.003) Batch 0.679 (0.617) Remain 19:56:35 loss: 1.0212 Lr: 0.00032
[2025-05-11 13:19:23,385 INFO misc.py line 117 288342] Train: [1/50][788/2344] Data 0.002 (0.003) Batch 0.510 (0.617) Remain 19:56:19 loss: 1.1604 Lr: 0.00032
[2025-05-11 13:19:23,820 INFO misc.py line 117 288342] Train: [1/50][789/2344] Data 0.003 (0.003) Batch 0.435 (0.616) Remain 19:55:51 loss: 1.5528 Lr: 0.00032
[2025-05-11 13:19:24,361 INFO misc.py line 117 288342] Train: [1/50][790/2344] Data 0.003 (0.003) Batch 0.541 (0.616) Remain 19:55:40 loss: 0.9414 Lr: 0.00032
[2025-05-11 13:19:24,959 INFO misc.py line 117 288342] Train: [1/50][791/2344] Data 0.003 (0.003) Batch 0.598 (0.616) Remain 19:55:36 loss: 1.0679 Lr: 0.00032
[2025-05-11 13:19:25,563 INFO misc.py line 117 288342] Train: [1/50][792/2344] Data 0.003 (0.003) Batch 0.604 (0.616) Remain 19:55:34 loss: 1.0617 Lr: 0.00032
[2025-05-11 13:19:26,123 INFO misc.py line 117 288342] Train: [1/50][793/2344] Data 0.003 (0.003) Batch 0.561 (0.616) Remain 19:55:25 loss: 1.0567 Lr: 0.00032
[2025-05-11 13:19:26,800 INFO misc.py line 117 288342] Train: [1/50][794/2344] Data 0.002 (0.003) Batch 0.677 (0.616) Remain 19:55:33 loss: 0.9173 Lr: 0.00032
[2025-05-11 13:19:27,504 INFO misc.py line 117 288342] Train: [1/50][795/2344] Data 0.002 (0.003) Batch 0.703 (0.616) Remain 19:55:46 loss: 1.3820 Lr: 0.00032
[2025-05-11 13:19:28,069 INFO misc.py line 117 288342] Train: [1/50][796/2344] Data 0.003 (0.003) Batch 0.565 (0.616) Remain 19:55:37 loss: 1.3433 Lr: 0.00032
[2025-05-11 13:19:28,688 INFO misc.py line 117 288342] Train: [1/50][797/2344] Data 0.003 (0.003) Batch 0.619 (0.616) Remain 19:55:37 loss: 1.0592 Lr: 0.00032
[2025-05-11 13:19:29,464 INFO misc.py line 117 288342] Train: [1/50][798/2344] Data 0.002 (0.003) Batch 0.776 (0.616) Remain 19:56:00 loss: 1.1009 Lr: 0.00033
[2025-05-11 13:19:30,023 INFO misc.py line 117 288342] Train: [1/50][799/2344] Data 0.003 (0.003) Batch 0.559 (0.616) Remain 19:55:51 loss: 1.2126 Lr: 0.00033
[2025-05-11 13:19:30,628 INFO misc.py line 117 288342] Train: [1/50][800/2344] Data 0.003 (0.003) Batch 0.605 (0.616) Remain 19:55:49 loss: 1.0748 Lr: 0.00033
[2025-05-11 13:19:31,276 INFO misc.py line 117 288342] Train: [1/50][801/2344] Data 0.002 (0.003) Batch 0.649 (0.616) Remain 19:55:53 loss: 1.1836 Lr: 0.00033
[2025-05-11 13:19:31,794 INFO misc.py line 117 288342] Train: [1/50][802/2344] Data 0.002 (0.003) Batch 0.517 (0.616) Remain 19:55:38 loss: 1.2286 Lr: 0.00033
[2025-05-11 13:19:32,253 INFO misc.py line 117 288342] Train: [1/50][803/2344] Data 0.003 (0.003) Batch 0.459 (0.616) Remain 19:55:14 loss: 0.9915 Lr: 0.00033
[2025-05-11 13:19:32,810 INFO misc.py line 117 288342] Train: [1/50][804/2344] Data 0.003 (0.003) Batch 0.557 (0.616) Remain 19:55:05 loss: 1.1419 Lr: 0.00033
[2025-05-11 13:19:33,415 INFO misc.py line 117 288342] Train: [1/50][805/2344] Data 0.003 (0.003) Batch 0.606 (0.616) Remain 19:55:03 loss: 1.1381 Lr: 0.00033
[2025-05-11 13:19:34,038 INFO misc.py line 117 288342] Train: [1/50][806/2344] Data 0.002 (0.003) Batch 0.623 (0.616) Remain 19:55:03 loss: 0.9712 Lr: 0.00033
[2025-05-11 13:19:34,545 INFO misc.py line 117 288342] Train: [1/50][807/2344] Data 0.002 (0.003) Batch 0.507 (0.616) Remain 19:54:47 loss: 1.2672 Lr: 0.00033
[2025-05-11 13:19:35,096 INFO misc.py line 117 288342] Train: [1/50][808/2344] Data 0.002 (0.003) Batch 0.551 (0.616) Remain 19:54:37 loss: 1.3237 Lr: 0.00033
[2025-05-11 13:19:35,660 INFO misc.py line 117 288342] Train: [1/50][809/2344] Data 0.003 (0.003) Batch 0.564 (0.616) Remain 19:54:29 loss: 1.2378 Lr: 0.00033
[2025-05-11 13:19:36,268 INFO misc.py line 117 288342] Train: [1/50][810/2344] Data 0.003 (0.003) Batch 0.608 (0.616) Remain 19:54:27 loss: 1.0263 Lr: 0.00033
[2025-05-11 13:19:36,954 INFO misc.py line 117 288342] Train: [1/50][811/2344] Data 0.003 (0.003) Batch 0.686 (0.616) Remain 19:54:36 loss: 1.0570 Lr: 0.00033
[2025-05-11 13:19:37,505 INFO misc.py line 117 288342] Train: [1/50][812/2344] Data 0.003 (0.003) Batch 0.551 (0.616) Remain 19:54:27 loss: 1.1140 Lr: 0.00033
[2025-05-11 13:19:38,044 INFO misc.py line 117 288342] Train: [1/50][813/2344] Data 0.003 (0.003) Batch 0.539 (0.616) Remain 19:54:15 loss: 0.7657 Lr: 0.00033
[2025-05-11 13:19:38,590 INFO misc.py line 117 288342] Train: [1/50][814/2344] Data 0.002 (0.003) Batch 0.546 (0.616) Remain 19:54:04 loss: 0.9784 Lr: 0.00033
[2025-05-11 13:19:39,240 INFO misc.py line 117 288342] Train: [1/50][815/2344] Data 0.003 (0.003) Batch 0.650 (0.616) Remain 19:54:09 loss: 1.1427 Lr: 0.00033
[2025-05-11 13:19:39,794 INFO misc.py line 117 288342] Train: [1/50][816/2344] Data 0.003 (0.003) Batch 0.553 (0.616) Remain 19:53:59 loss: 1.0818 Lr: 0.00033
[2025-05-11 13:19:40,420 INFO misc.py line 117 288342] Train: [1/50][817/2344] Data 0.002 (0.003) Batch 0.626 (0.616) Remain 19:54:00 loss: 1.0539 Lr: 0.00033
[2025-05-11 13:19:41,096 INFO misc.py line 117 288342] Train: [1/50][818/2344] Data 0.003 (0.003) Batch 0.676 (0.616) Remain 19:54:08 loss: 1.1399 Lr: 0.00033
[2025-05-11 13:19:41,794 INFO misc.py line 117 288342] Train: [1/50][819/2344] Data 0.003 (0.003) Batch 0.699 (0.616) Remain 19:54:19 loss: 1.0829 Lr: 0.00033
[2025-05-11 13:19:42,637 INFO misc.py line 117 288342] Train: [1/50][820/2344] Data 0.003 (0.003) Batch 0.843 (0.616) Remain 19:54:51 loss: 1.0086 Lr: 0.00033
[2025-05-11 13:19:43,219 INFO misc.py line 117 288342] Train: [1/50][821/2344] Data 0.003 (0.003) Batch 0.582 (0.616) Remain 19:54:46 loss: 0.9160 Lr: 0.00033
[2025-05-11 13:19:43,956 INFO misc.py line 117 288342] Train: [1/50][822/2344] Data 0.003 (0.003) Batch 0.737 (0.616) Remain 19:55:02 loss: 1.2031 Lr: 0.00033
[2025-05-11 13:19:44,634 INFO misc.py line 117 288342] Train: [1/50][823/2344] Data 0.003 (0.003) Batch 0.678 (0.616) Remain 19:55:10 loss: 0.9857 Lr: 0.00033
[2025-05-11 13:19:45,241 INFO misc.py line 117 288342] Train: [1/50][824/2344] Data 0.002 (0.003) Batch 0.606 (0.616) Remain 19:55:08 loss: 0.9666 Lr: 0.00033
[2025-05-11 13:19:45,714 INFO misc.py line 117 288342] Train: [1/50][825/2344] Data 0.003 (0.003) Batch 0.473 (0.616) Remain 19:54:47 loss: 1.0199 Lr: 0.00033
[2025-05-11 13:19:46,275 INFO misc.py line 117 288342] Train: [1/50][826/2344] Data 0.003 (0.003) Batch 0.561 (0.616) Remain 19:54:39 loss: 0.9492 Lr: 0.00033
[2025-05-11 13:19:46,891 INFO misc.py line 117 288342] Train: [1/50][827/2344] Data 0.003 (0.003) Batch 0.616 (0.616) Remain 19:54:38 loss: 1.0398 Lr: 0.00033
[2025-05-11 13:19:47,519 INFO misc.py line 117 288342] Train: [1/50][828/2344] Data 0.003 (0.003) Batch 0.628 (0.616) Remain 19:54:39 loss: 1.0007 Lr: 0.00033
[2025-05-11 13:19:48,012 INFO misc.py line 117 288342] Train: [1/50][829/2344] Data 0.002 (0.003) Batch 0.494 (0.616) Remain 19:54:22 loss: 1.1253 Lr: 0.00033
[2025-05-11 13:19:48,510 INFO misc.py line 117 288342] Train: [1/50][830/2344] Data 0.003 (0.003) Batch 0.497 (0.616) Remain 19:54:04 loss: 0.8011 Lr: 0.00034
[2025-05-11 13:19:49,120 INFO misc.py line 117 288342] Train: [1/50][831/2344] Data 0.003 (0.003) Batch 0.610 (0.616) Remain 19:54:03 loss: 1.0651 Lr: 0.00034
[2025-05-11 13:19:49,740 INFO misc.py line 117 288342] Train: [1/50][832/2344] Data 0.002 (0.003) Batch 0.621 (0.616) Remain 19:54:03 loss: 1.2963 Lr: 0.00034
[2025-05-11 13:19:50,326 INFO misc.py line 117 288342] Train: [1/50][833/2344] Data 0.002 (0.003) Batch 0.586 (0.616) Remain 19:53:58 loss: 1.0268 Lr: 0.00034
[2025-05-11 13:19:50,903 INFO misc.py line 117 288342] Train: [1/50][834/2344] Data 0.003 (0.003) Batch 0.577 (0.616) Remain 19:53:52 loss: 1.0973 Lr: 0.00034
[2025-05-11 13:19:51,544 INFO misc.py line 117 288342] Train: [1/50][835/2344] Data 0.002 (0.003) Batch 0.641 (0.616) Remain 19:53:55 loss: 1.0196 Lr: 0.00034
[2025-05-11 13:19:52,179 INFO misc.py line 117 288342] Train: [1/50][836/2344] Data 0.002 (0.003) Batch 0.634 (0.616) Remain 19:53:57 loss: 1.1305 Lr: 0.00034
[2025-05-11 13:19:52,816 INFO misc.py line 117 288342] Train: [1/50][837/2344] Data 0.003 (0.003) Batch 0.637 (0.616) Remain 19:54:00 loss: 1.2383 Lr: 0.00034
[2025-05-11 13:19:53,460 INFO misc.py line 117 288342] Train: [1/50][838/2344] Data 0.002 (0.003) Batch 0.644 (0.616) Remain 19:54:03 loss: 1.1684 Lr: 0.00034
[2025-05-11 13:19:54,064 INFO misc.py line 117 288342] Train: [1/50][839/2344] Data 0.002 (0.003) Batch 0.604 (0.616) Remain 19:54:01 loss: 1.0200 Lr: 0.00034
[2025-05-11 13:19:54,738 INFO misc.py line 117 288342] Train: [1/50][840/2344] Data 0.003 (0.003) Batch 0.674 (0.616) Remain 19:54:08 loss: 1.0675 Lr: 0.00034
[2025-05-11 13:19:55,262 INFO misc.py line 117 288342] Train: [1/50][841/2344] Data 0.002 (0.003) Batch 0.524 (0.616) Remain 19:53:55 loss: 1.1842 Lr: 0.00034
[2025-05-11 13:19:55,817 INFO misc.py line 117 288342] Train: [1/50][842/2344] Data 0.003 (0.003) Batch 0.555 (0.616) Remain 19:53:46 loss: 1.0437 Lr: 0.00034
[2025-05-11 13:19:56,467 INFO misc.py line 117 288342] Train: [1/50][843/2344] Data 0.003 (0.003) Batch 0.650 (0.616) Remain 19:53:50 loss: 1.1411 Lr: 0.00034
[2025-05-11 13:19:57,084 INFO misc.py line 117 288342] Train: [1/50][844/2344] Data 0.003 (0.003) Batch 0.617 (0.616) Remain 19:53:50 loss: 1.0762 Lr: 0.00034
[2025-05-11 13:19:57,772 INFO misc.py line 117 288342] Train: [1/50][845/2344] Data 0.003 (0.003) Batch 0.688 (0.616) Remain 19:53:59 loss: 1.0467 Lr: 0.00034
[2025-05-11 13:19:58,386 INFO misc.py line 117 288342] Train: [1/50][846/2344] Data 0.003 (0.003) Batch 0.614 (0.616) Remain 19:53:58 loss: 0.9969 Lr: 0.00034
[2025-05-11 13:19:59,094 INFO misc.py line 117 288342] Train: [1/50][847/2344] Data 0.003 (0.003) Batch 0.708 (0.616) Remain 19:54:10 loss: 1.0414 Lr: 0.00034
[2025-05-11 13:19:59,624 INFO misc.py line 117 288342] Train: [1/50][848/2344] Data 0.003 (0.003) Batch 0.530 (0.616) Remain 19:53:58 loss: 1.0755 Lr: 0.00034
[2025-05-11 13:20:00,117 INFO misc.py line 117 288342] Train: [1/50][849/2344] Data 0.002 (0.003) Batch 0.493 (0.616) Remain 19:53:40 loss: 1.0781 Lr: 0.00034
[2025-05-11 13:20:00,663 INFO misc.py line 117 288342] Train: [1/50][850/2344] Data 0.003 (0.003) Batch 0.545 (0.615) Remain 19:53:30 loss: 1.0371 Lr: 0.00034
[2025-05-11 13:20:01,335 INFO misc.py line 117 288342] Train: [1/50][851/2344] Data 0.003 (0.003) Batch 0.673 (0.616) Remain 19:53:37 loss: 1.0342 Lr: 0.00034
[2025-05-11 13:20:01,980 INFO misc.py line 117 288342] Train: [1/50][852/2344] Data 0.002 (0.003) Batch 0.644 (0.616) Remain 19:53:41 loss: 1.1349 Lr: 0.00034
[2025-05-11 13:20:02,690 INFO misc.py line 117 288342] Train: [1/50][853/2344] Data 0.002 (0.003) Batch 0.710 (0.616) Remain 19:53:53 loss: 0.9149 Lr: 0.00034
[2025-05-11 13:20:03,238 INFO misc.py line 117 288342] Train: [1/50][854/2344] Data 0.003 (0.003) Batch 0.548 (0.616) Remain 19:53:43 loss: 1.3011 Lr: 0.00034
[2025-05-11 13:20:03,994 INFO misc.py line 117 288342] Train: [1/50][855/2344] Data 0.003 (0.003) Batch 0.756 (0.616) Remain 19:54:02 loss: 1.1330 Lr: 0.00034
[2025-05-11 13:20:04,478 INFO misc.py line 117 288342] Train: [1/50][856/2344] Data 0.003 (0.003) Batch 0.485 (0.616) Remain 19:53:43 loss: 1.2747 Lr: 0.00034
[2025-05-11 13:20:05,102 INFO misc.py line 117 288342] Train: [1/50][857/2344] Data 0.003 (0.003) Batch 0.623 (0.616) Remain 19:53:44 loss: 1.0456 Lr: 0.00034
[2025-05-11 13:20:05,643 INFO misc.py line 117 288342] Train: [1/50][858/2344] Data 0.003 (0.003) Batch 0.541 (0.616) Remain 19:53:33 loss: 1.0812 Lr: 0.00034
[2025-05-11 13:20:06,329 INFO misc.py line 117 288342] Train: [1/50][859/2344] Data 0.003 (0.003) Batch 0.686 (0.616) Remain 19:53:42 loss: 0.9629 Lr: 0.00034
[2025-05-11 13:20:07,007 INFO misc.py line 117 288342] Train: [1/50][860/2344] Data 0.003 (0.003) Batch 0.678 (0.616) Remain 19:53:50 loss: 1.1030 Lr: 0.00034
[2025-05-11 13:20:07,586 INFO misc.py line 117 288342] Train: [1/50][861/2344] Data 0.003 (0.003) Batch 0.579 (0.616) Remain 19:53:44 loss: 0.9333 Lr: 0.00035
[2025-05-11 13:20:08,217 INFO misc.py line 117 288342] Train: [1/50][862/2344] Data 0.002 (0.003) Batch 0.631 (0.616) Remain 19:53:45 loss: 1.0146 Lr: 0.00035
[2025-05-11 13:20:08,857 INFO misc.py line 117 288342] Train: [1/50][863/2344] Data 0.003 (0.003) Batch 0.640 (0.616) Remain 19:53:48 loss: 1.0601 Lr: 0.00035
[2025-05-11 13:20:09,500 INFO misc.py line 117 288342] Train: [1/50][864/2344] Data 0.003 (0.003) Batch 0.643 (0.616) Remain 19:53:51 loss: 1.0938 Lr: 0.00035
[2025-05-11 13:20:10,170 INFO misc.py line 117 288342] Train: [1/50][865/2344] Data 0.003 (0.003) Batch 0.671 (0.616) Remain 19:53:58 loss: 1.1889 Lr: 0.00035
[2025-05-11 13:20:10,863 INFO misc.py line 117 288342] Train: [1/50][866/2344] Data 0.003 (0.003) Batch 0.692 (0.616) Remain 19:54:08 loss: 1.1050 Lr: 0.00035
[2025-05-11 13:20:11,468 INFO misc.py line 117 288342] Train: [1/50][867/2344] Data 0.002 (0.003) Batch 0.605 (0.616) Remain 19:54:06 loss: 0.9864 Lr: 0.00035
[2025-05-11 13:20:11,926 INFO misc.py line 117 288342] Train: [1/50][868/2344] Data 0.003 (0.003) Batch 0.458 (0.616) Remain 19:53:44 loss: 1.5471 Lr: 0.00035
[2025-05-11 13:20:12,439 INFO misc.py line 117 288342] Train: [1/50][869/2344] Data 0.002 (0.003) Batch 0.513 (0.616) Remain 19:53:29 loss: 0.9752 Lr: 0.00035
[2025-05-11 13:20:13,016 INFO misc.py line 117 288342] Train: [1/50][870/2344] Data 0.002 (0.003) Batch 0.577 (0.616) Remain 19:53:24 loss: 1.1091 Lr: 0.00035
[2025-05-11 13:20:13,703 INFO misc.py line 117 288342] Train: [1/50][871/2344] Data 0.002 (0.003) Batch 0.687 (0.616) Remain 19:53:32 loss: 1.0792 Lr: 0.00035
[2025-05-11 13:20:14,219 INFO misc.py line 117 288342] Train: [1/50][872/2344] Data 0.002 (0.003) Batch 0.516 (0.615) Remain 19:53:19 loss: 1.1245 Lr: 0.00035
[2025-05-11 13:20:14,778 INFO misc.py line 117 288342] Train: [1/50][873/2344] Data 0.002 (0.003) Batch 0.559 (0.615) Remain 19:53:10 loss: 0.9057 Lr: 0.00035
[2025-05-11 13:20:15,277 INFO misc.py line 117 288342] Train: [1/50][874/2344] Data 0.003 (0.003) Batch 0.499 (0.615) Remain 19:52:54 loss: 1.0288 Lr: 0.00035
[2025-05-11 13:20:15,880 INFO misc.py line 117 288342] Train: [1/50][875/2344] Data 0.003 (0.003) Batch 0.603 (0.615) Remain 19:52:52 loss: 0.8595 Lr: 0.00035
[2025-05-11 13:20:16,423 INFO misc.py line 117 288342] Train: [1/50][876/2344] Data 0.003 (0.003) Batch 0.543 (0.615) Remain 19:52:42 loss: 1.0111 Lr: 0.00035
[2025-05-11 13:20:17,112 INFO misc.py line 117 288342] Train: [1/50][877/2344] Data 0.003 (0.003) Batch 0.689 (0.615) Remain 19:52:51 loss: 1.0164 Lr: 0.00035
[2025-05-11 13:20:17,608 INFO misc.py line 117 288342] Train: [1/50][878/2344] Data 0.002 (0.003) Batch 0.496 (0.615) Remain 19:52:35 loss: 1.0628 Lr: 0.00035
[2025-05-11 13:20:18,301 INFO misc.py line 117 288342] Train: [1/50][879/2344] Data 0.002 (0.003) Batch 0.693 (0.615) Remain 19:52:44 loss: 1.1551 Lr: 0.00035
[2025-05-11 13:20:18,845 INFO misc.py line 117 288342] Train: [1/50][880/2344] Data 0.002 (0.003) Batch 0.544 (0.615) Remain 19:52:34 loss: 1.6418 Lr: 0.00035
[2025-05-11 13:20:19,383 INFO misc.py line 117 288342] Train: [1/50][881/2344] Data 0.002 (0.003) Batch 0.538 (0.615) Remain 19:52:23 loss: 0.9942 Lr: 0.00035
[2025-05-11 13:20:19,910 INFO misc.py line 117 288342] Train: [1/50][882/2344] Data 0.003 (0.003) Batch 0.527 (0.615) Remain 19:52:11 loss: 1.0700 Lr: 0.00035
[2025-05-11 13:20:20,569 INFO misc.py line 117 288342] Train: [1/50][883/2344] Data 0.003 (0.003) Batch 0.659 (0.615) Remain 19:52:16 loss: 1.2931 Lr: 0.00035
[2025-05-11 13:20:21,161 INFO misc.py line 117 288342] Train: [1/50][884/2344] Data 0.003 (0.003) Batch 0.592 (0.615) Remain 19:52:13 loss: 1.0923 Lr: 0.00035
[2025-05-11 13:20:21,786 INFO misc.py line 117 288342] Train: [1/50][885/2344] Data 0.003 (0.003) Batch 0.625 (0.615) Remain 19:52:13 loss: 0.8822 Lr: 0.00035
[2025-05-11 13:20:22,404 INFO misc.py line 117 288342] Train: [1/50][886/2344] Data 0.002 (0.003) Batch 0.617 (0.615) Remain 19:52:13 loss: 1.0494 Lr: 0.00035
[2025-05-11 13:20:23,128 INFO misc.py line 117 288342] Train: [1/50][887/2344] Data 0.003 (0.003) Batch 0.725 (0.615) Remain 19:52:27 loss: 1.0843 Lr: 0.00035
[2025-05-11 13:20:23,810 INFO misc.py line 117 288342] Train: [1/50][888/2344] Data 0.003 (0.003) Batch 0.681 (0.615) Remain 19:52:35 loss: 0.9550 Lr: 0.00035
[2025-05-11 13:20:24,508 INFO misc.py line 117 288342] Train: [1/50][889/2344] Data 0.003 (0.003) Batch 0.699 (0.615) Remain 19:52:45 loss: 0.8883 Lr: 0.00035
[2025-05-11 13:20:25,040 INFO misc.py line 117 288342] Train: [1/50][890/2344] Data 0.003 (0.003) Batch 0.532 (0.615) Remain 19:52:34 loss: 1.1965 Lr: 0.00035
[2025-05-11 13:20:25,569 INFO misc.py line 117 288342] Train: [1/50][891/2344] Data 0.002 (0.003) Batch 0.529 (0.615) Remain 19:52:22 loss: 1.0174 Lr: 0.00036
[2025-05-11 13:20:26,087 INFO misc.py line 117 288342] Train: [1/50][892/2344] Data 0.003 (0.003) Batch 0.518 (0.615) Remain 19:52:09 loss: 1.1657 Lr: 0.00036
[2025-05-11 13:20:26,681 INFO misc.py line 117 288342] Train: [1/50][893/2344] Data 0.003 (0.003) Batch 0.594 (0.615) Remain 19:52:05 loss: 1.1684 Lr: 0.00036
[2025-05-11 13:20:27,232 INFO misc.py line 117 288342] Train: [1/50][894/2344] Data 0.002 (0.003) Batch 0.551 (0.615) Remain 19:51:56 loss: 1.0392 Lr: 0.00036
[2025-05-11 13:20:27,831 INFO misc.py line 117 288342] Train: [1/50][895/2344] Data 0.003 (0.003) Batch 0.598 (0.615) Remain 19:51:53 loss: 0.8854 Lr: 0.00036
[2025-05-11 13:20:28,437 INFO misc.py line 117 288342] Train: [1/50][896/2344] Data 0.003 (0.003) Batch 0.607 (0.615) Remain 19:51:52 loss: 1.1767 Lr: 0.00036
[2025-05-11 13:20:28,993 INFO misc.py line 117 288342] Train: [1/50][897/2344] Data 0.003 (0.003) Batch 0.556 (0.615) Remain 19:51:43 loss: 1.1013 Lr: 0.00036
[2025-05-11 13:20:29,567 INFO misc.py line 117 288342] Train: [1/50][898/2344] Data 0.003 (0.003) Batch 0.574 (0.615) Remain 19:51:38 loss: 0.8161 Lr: 0.00036
[2025-05-11 13:20:30,041 INFO misc.py line 117 288342] Train: [1/50][899/2344] Data 0.002 (0.003) Batch 0.474 (0.615) Remain 19:51:19 loss: 1.0520 Lr: 0.00036
[2025-05-11 13:20:30,653 INFO misc.py line 117 288342] Train: [1/50][900/2344] Data 0.003 (0.003) Batch 0.611 (0.615) Remain 19:51:18 loss: 0.8847 Lr: 0.00036
[2025-05-11 13:20:31,390 INFO misc.py line 117 288342] Train: [1/50][901/2344] Data 0.002 (0.003) Batch 0.738 (0.615) Remain 19:51:33 loss: 1.0226 Lr: 0.00036
[2025-05-11 13:20:32,014 INFO misc.py line 117 288342] Train: [1/50][902/2344] Data 0.002 (0.003) Batch 0.624 (0.615) Remain 19:51:33 loss: 1.1752 Lr: 0.00036
[2025-05-11 13:20:32,579 INFO misc.py line 117 288342] Train: [1/50][903/2344] Data 0.002 (0.003) Batch 0.565 (0.615) Remain 19:51:26 loss: 1.1475 Lr: 0.00036
[2025-05-11 13:20:33,221 INFO misc.py line 117 288342] Train: [1/50][904/2344] Data 0.002 (0.003) Batch 0.642 (0.615) Remain 19:51:29 loss: 1.0117 Lr: 0.00036
[2025-05-11 13:20:33,968 INFO misc.py line 117 288342] Train: [1/50][905/2344] Data 0.002 (0.003) Batch 0.746 (0.615) Remain 19:51:46 loss: 1.2113 Lr: 0.00036
[2025-05-11 13:20:34,563 INFO misc.py line 117 288342] Train: [1/50][906/2344] Data 0.003 (0.003) Batch 0.596 (0.615) Remain 19:51:43 loss: 0.9891 Lr: 0.00036
[2025-05-11 13:20:35,171 INFO misc.py line 117 288342] Train: [1/50][907/2344] Data 0.003 (0.003) Batch 0.607 (0.615) Remain 19:51:41 loss: 1.0054 Lr: 0.00036
[2025-05-11 13:20:35,731 INFO misc.py line 117 288342] Train: [1/50][908/2344] Data 0.003 (0.003) Batch 0.560 (0.615) Remain 19:51:33 loss: 0.9601 Lr: 0.00036
[2025-05-11 13:20:36,363 INFO misc.py line 117 288342] Train: [1/50][909/2344] Data 0.003 (0.003) Batch 0.633 (0.615) Remain 19:51:35 loss: 1.0257 Lr: 0.00036
[2025-05-11 13:20:37,031 INFO misc.py line 117 288342] Train: [1/50][910/2344] Data 0.003 (0.003) Batch 0.668 (0.615) Remain 19:51:41 loss: 1.1884 Lr: 0.00036
[2025-05-11 13:20:37,552 INFO misc.py line 117 288342] Train: [1/50][911/2344] Data 0.003 (0.003) Batch 0.521 (0.615) Remain 19:51:29 loss: 0.9545 Lr: 0.00036
[2025-05-11 13:20:37,998 INFO misc.py line 117 288342] Train: [1/50][912/2344] Data 0.003 (0.003) Batch 0.447 (0.615) Remain 19:51:06 loss: 1.0547 Lr: 0.00036
[2025-05-11 13:20:38,588 INFO misc.py line 117 288342] Train: [1/50][913/2344] Data 0.003 (0.003) Batch 0.589 (0.615) Remain 19:51:03 loss: 1.2126 Lr: 0.00036
[2025-05-11 13:20:39,307 INFO misc.py line 117 288342] Train: [1/50][914/2344] Data 0.003 (0.003) Batch 0.719 (0.615) Remain 19:51:15 loss: 1.0548 Lr: 0.00036
[2025-05-11 13:20:39,971 INFO misc.py line 117 288342] Train: [1/50][915/2344] Data 0.002 (0.003) Batch 0.664 (0.615) Remain 19:51:21 loss: 1.0437 Lr: 0.00036
[2025-05-11 13:20:40,511 INFO misc.py line 117 288342] Train: [1/50][916/2344] Data 0.002 (0.003) Batch 0.540 (0.615) Remain 19:51:11 loss: 1.2092 Lr: 0.00036
[2025-05-11 13:20:41,189 INFO misc.py line 117 288342] Train: [1/50][917/2344] Data 0.002 (0.003) Batch 0.678 (0.615) Remain 19:51:18 loss: 0.8362 Lr: 0.00036
[2025-05-11 13:20:41,767 INFO misc.py line 117 288342] Train: [1/50][918/2344] Data 0.003 (0.003) Batch 0.578 (0.615) Remain 19:51:13 loss: 0.8513 Lr: 0.00036
[2025-05-11 13:20:42,371 INFO misc.py line 117 288342] Train: [1/50][919/2344] Data 0.002 (0.003) Batch 0.604 (0.615) Remain 19:51:11 loss: 0.9377 Lr: 0.00036
[2025-05-11 13:20:42,909 INFO misc.py line 117 288342] Train: [1/50][920/2344] Data 0.002 (0.003) Batch 0.538 (0.615) Remain 19:51:01 loss: 1.0133 Lr: 0.00037
[2025-05-11 13:20:43,481 INFO misc.py line 117 288342] Train: [1/50][921/2344] Data 0.003 (0.003) Batch 0.572 (0.615) Remain 19:50:55 loss: 1.0685 Lr: 0.00037
[2025-05-11 13:20:44,147 INFO misc.py line 117 288342] Train: [1/50][922/2344] Data 0.003 (0.003) Batch 0.666 (0.615) Remain 19:51:01 loss: 1.1646 Lr: 0.00037
[2025-05-11 13:20:44,669 INFO misc.py line 117 288342] Train: [1/50][923/2344] Data 0.003 (0.003) Batch 0.522 (0.614) Remain 19:50:48 loss: 1.3476 Lr: 0.00037
[2025-05-11 13:20:45,301 INFO misc.py line 117 288342] Train: [1/50][924/2344] Data 0.003 (0.003) Batch 0.632 (0.614) Remain 19:50:50 loss: 0.9822 Lr: 0.00037
[2025-05-11 13:20:45,826 INFO misc.py line 117 288342] Train: [1/50][925/2344] Data 0.003 (0.003) Batch 0.526 (0.614) Remain 19:50:38 loss: 0.9377 Lr: 0.00037
[2025-05-11 13:20:46,396 INFO misc.py line 117 288342] Train: [1/50][926/2344] Data 0.002 (0.003) Batch 0.570 (0.614) Remain 19:50:32 loss: 1.0329 Lr: 0.00037
[2025-05-11 13:20:46,981 INFO misc.py line 117 288342] Train: [1/50][927/2344] Data 0.002 (0.003) Batch 0.585 (0.614) Remain 19:50:28 loss: 1.4918 Lr: 0.00037
[2025-05-11 13:20:47,569 INFO misc.py line 117 288342] Train: [1/50][928/2344] Data 0.002 (0.003) Batch 0.588 (0.614) Remain 19:50:24 loss: 1.0615 Lr: 0.00037
[2025-05-11 13:20:48,210 INFO misc.py line 117 288342] Train: [1/50][929/2344] Data 0.002 (0.003) Batch 0.641 (0.614) Remain 19:50:26 loss: 1.0991 Lr: 0.00037
[2025-05-11 13:20:48,993 INFO misc.py line 117 288342] Train: [1/50][930/2344] Data 0.002 (0.003) Batch 0.783 (0.614) Remain 19:50:47 loss: 1.1936 Lr: 0.00037
[2025-05-11 13:20:49,590 INFO misc.py line 117 288342] Train: [1/50][931/2344] Data 0.003 (0.003) Batch 0.597 (0.614) Remain 19:50:44 loss: 1.0299 Lr: 0.00037
[2025-05-11 13:20:50,221 INFO misc.py line 117 288342] Train: [1/50][932/2344] Data 0.002 (0.003) Batch 0.632 (0.614) Remain 19:50:46 loss: 0.9576 Lr: 0.00037
[2025-05-11 13:20:50,869 INFO misc.py line 117 288342] Train: [1/50][933/2344] Data 0.002 (0.003) Batch 0.648 (0.615) Remain 19:50:49 loss: 0.8944 Lr: 0.00037
[2025-05-11 13:20:51,466 INFO misc.py line 117 288342] Train: [1/50][934/2344] Data 0.002 (0.003) Batch 0.597 (0.615) Remain 19:50:46 loss: 1.0835 Lr: 0.00037
[2025-05-11 13:20:52,108 INFO misc.py line 117 288342] Train: [1/50][935/2344] Data 0.002 (0.003) Batch 0.642 (0.615) Remain 19:50:49 loss: 0.9253 Lr: 0.00037
[2025-05-11 13:20:52,848 INFO misc.py line 117 288342] Train: [1/50][936/2344] Data 0.002 (0.003) Batch 0.740 (0.615) Remain 19:51:04 loss: 1.1533 Lr: 0.00037
[2025-05-11 13:20:53,400 INFO misc.py line 117 288342] Train: [1/50][937/2344] Data 0.003 (0.003) Batch 0.552 (0.615) Remain 19:50:56 loss: 1.0651 Lr: 0.00037
[2025-05-11 13:20:54,062 INFO misc.py line 117 288342] Train: [1/50][938/2344] Data 0.003 (0.003) Batch 0.662 (0.615) Remain 19:51:01 loss: 1.0813 Lr: 0.00037
[2025-05-11 13:20:54,727 INFO misc.py line 117 288342] Train: [1/50][939/2344] Data 0.002 (0.003) Batch 0.665 (0.615) Remain 19:51:07 loss: 1.1864 Lr: 0.00037
[2025-05-11 13:20:55,268 INFO misc.py line 117 288342] Train: [1/50][940/2344] Data 0.002 (0.003) Batch 0.541 (0.615) Remain 19:50:57 loss: 1.1592 Lr: 0.00037
[2025-05-11 13:20:55,825 INFO misc.py line 117 288342] Train: [1/50][941/2344] Data 0.003 (0.003) Batch 0.558 (0.615) Remain 19:50:49 loss: 0.9975 Lr: 0.00037
[2025-05-11 13:20:56,364 INFO misc.py line 117 288342] Train: [1/50][942/2344] Data 0.003 (0.003) Batch 0.539 (0.614) Remain 19:50:39 loss: 1.1159 Lr: 0.00037
[2025-05-11 13:20:57,040 INFO misc.py line 117 288342] Train: [1/50][943/2344] Data 0.003 (0.003) Batch 0.676 (0.615) Remain 19:50:46 loss: 1.2121 Lr: 0.00037
[2025-05-11 13:20:57,818 INFO misc.py line 117 288342] Train: [1/50][944/2344] Data 0.003 (0.003) Batch 0.778 (0.615) Remain 19:51:06 loss: 1.2195 Lr: 0.00037
[2025-05-11 13:20:58,603 INFO misc.py line 117 288342] Train: [1/50][945/2344] Data 0.003 (0.003) Batch 0.785 (0.615) Remain 19:51:26 loss: 1.0237 Lr: 0.00037
[2025-05-11 13:20:59,117 INFO misc.py line 117 288342] Train: [1/50][946/2344] Data 0.003 (0.003) Batch 0.513 (0.615) Remain 19:51:13 loss: 1.3319 Lr: 0.00037
[2025-05-11 13:20:59,673 INFO misc.py line 117 288342] Train: [1/50][947/2344] Data 0.003 (0.003) Batch 0.556 (0.615) Remain 19:51:05 loss: 1.0509 Lr: 0.00037
[2025-05-11 13:21:00,295 INFO misc.py line 117 288342] Train: [1/50][948/2344] Data 0.005 (0.003) Batch 0.622 (0.615) Remain 19:51:05 loss: 1.1987 Lr: 0.00037
[2025-05-11 13:21:01,029 INFO misc.py line 117 288342] Train: [1/50][949/2344] Data 0.003 (0.003) Batch 0.734 (0.615) Remain 19:51:20 loss: 1.1715 Lr: 0.00038
[2025-05-11 13:21:01,467 INFO misc.py line 117 288342] Train: [1/50][950/2344] Data 0.003 (0.003) Batch 0.438 (0.615) Remain 19:50:57 loss: 0.9760 Lr: 0.00038
[2025-05-11 13:21:02,175 INFO misc.py line 117 288342] Train: [1/50][951/2344] Data 0.002 (0.003) Batch 0.708 (0.615) Remain 19:51:08 loss: 0.9617 Lr: 0.00038
[2025-05-11 13:21:02,730 INFO misc.py line 117 288342] Train: [1/50][952/2344] Data 0.003 (0.003) Batch 0.555 (0.615) Remain 19:51:00 loss: 1.0341 Lr: 0.00038
[2025-05-11 13:21:03,315 INFO misc.py line 117 288342] Train: [1/50][953/2344] Data 0.002 (0.003) Batch 0.585 (0.615) Remain 19:50:56 loss: 1.0012 Lr: 0.00038
[2025-05-11 13:21:03,937 INFO misc.py line 117 288342] Train: [1/50][954/2344] Data 0.003 (0.003) Batch 0.622 (0.615) Remain 19:50:56 loss: 1.0159 Lr: 0.00038
[2025-05-11 13:21:04,600 INFO misc.py line 117 288342] Train: [1/50][955/2344] Data 0.003 (0.003) Batch 0.663 (0.615) Remain 19:51:01 loss: 1.2272 Lr: 0.00038
[2025-05-11 13:21:05,264 INFO misc.py line 117 288342] Train: [1/50][956/2344] Data 0.003 (0.003) Batch 0.664 (0.615) Remain 19:51:07 loss: 1.0276 Lr: 0.00038
[2025-05-11 13:21:05,723 INFO misc.py line 117 288342] Train: [1/50][957/2344] Data 0.003 (0.003) Batch 0.459 (0.615) Remain 19:50:47 loss: 1.1403 Lr: 0.00038
[2025-05-11 13:21:06,331 INFO misc.py line 117 288342] Train: [1/50][958/2344] Data 0.003 (0.003) Batch 0.608 (0.615) Remain 19:50:46 loss: 1.1227 Lr: 0.00038
[2025-05-11 13:21:06,906 INFO misc.py line 117 288342] Train: [1/50][959/2344] Data 0.003 (0.003) Batch 0.575 (0.615) Remain 19:50:40 loss: 0.7177 Lr: 0.00038
[2025-05-11 13:21:07,540 INFO misc.py line 117 288342] Train: [1/50][960/2344] Data 0.003 (0.003) Batch 0.634 (0.615) Remain 19:50:42 loss: 0.8846 Lr: 0.00038
[2025-05-11 13:21:08,161 INFO misc.py line 117 288342] Train: [1/50][961/2344] Data 0.003 (0.003) Batch 0.621 (0.615) Remain 19:50:42 loss: 0.9235 Lr: 0.00038
[2025-05-11 13:21:08,840 INFO misc.py line 117 288342] Train: [1/50][962/2344] Data 0.003 (0.003) Batch 0.679 (0.615) Remain 19:50:49 loss: 0.8715 Lr: 0.00038
[2025-05-11 13:21:09,423 INFO misc.py line 117 288342] Train: [1/50][963/2344] Data 0.003 (0.003) Batch 0.584 (0.615) Remain 19:50:45 loss: 1.1571 Lr: 0.00038
[2025-05-11 13:21:10,013 INFO misc.py line 117 288342] Train: [1/50][964/2344] Data 0.003 (0.003) Batch 0.589 (0.615) Remain 19:50:41 loss: 0.9612 Lr: 0.00038
[2025-05-11 13:21:10,583 INFO misc.py line 117 288342] Train: [1/50][965/2344] Data 0.003 (0.003) Batch 0.571 (0.615) Remain 19:50:35 loss: 1.0951 Lr: 0.00038
[2025-05-11 13:21:11,214 INFO misc.py line 117 288342] Train: [1/50][966/2344] Data 0.003 (0.003) Batch 0.631 (0.615) Remain 19:50:37 loss: 1.0249 Lr: 0.00038
[2025-05-11 13:21:11,817 INFO misc.py line 117 288342] Train: [1/50][967/2344] Data 0.003 (0.003) Batch 0.603 (0.615) Remain 19:50:35 loss: 0.7878 Lr: 0.00038
[2025-05-11 13:21:12,569 INFO misc.py line 117 288342] Train: [1/50][968/2344] Data 0.002 (0.003) Batch 0.752 (0.615) Remain 19:50:51 loss: 0.9162 Lr: 0.00038
[2025-05-11 13:21:13,115 INFO misc.py line 117 288342] Train: [1/50][969/2344] Data 0.003 (0.003) Batch 0.546 (0.615) Remain 19:50:42 loss: 1.0222 Lr: 0.00038
[2025-05-11 13:21:13,754 INFO misc.py line 117 288342] Train: [1/50][970/2344] Data 0.002 (0.003) Batch 0.639 (0.615) Remain 19:50:44 loss: 0.8837 Lr: 0.00038
[2025-05-11 13:21:14,374 INFO misc.py line 117 288342] Train: [1/50][971/2344] Data 0.003 (0.003) Batch 0.620 (0.615) Remain 19:50:44 loss: 1.0705 Lr: 0.00038
[2025-05-11 13:21:14,941 INFO misc.py line 117 288342] Train: [1/50][972/2344] Data 0.002 (0.003) Batch 0.566 (0.615) Remain 19:50:38 loss: 0.8681 Lr: 0.00038
[2025-05-11 13:21:15,540 INFO misc.py line 117 288342] Train: [1/50][973/2344] Data 0.002 (0.003) Batch 0.599 (0.615) Remain 19:50:35 loss: 1.2206 Lr: 0.00038
[2025-05-11 13:21:16,188 INFO misc.py line 117 288342] Train: [1/50][974/2344] Data 0.002 (0.003) Batch 0.649 (0.615) Remain 19:50:39 loss: 1.2771 Lr: 0.00038
[2025-05-11 13:21:16,787 INFO misc.py line 117 288342] Train: [1/50][975/2344] Data 0.002 (0.003) Batch 0.599 (0.615) Remain 19:50:36 loss: 0.9493 Lr: 0.00038
[2025-05-11 13:21:17,490 INFO misc.py line 117 288342] Train: [1/50][976/2344] Data 0.002 (0.003) Batch 0.703 (0.615) Remain 19:50:46 loss: 0.9033 Lr: 0.00039
[2025-05-11 13:21:18,080 INFO misc.py line 117 288342] Train: [1/50][977/2344] Data 0.002 (0.003) Batch 0.590 (0.615) Remain 19:50:43 loss: 1.0844 Lr: 0.00039
[2025-05-11 13:21:18,872 INFO misc.py line 117 288342] Train: [1/50][978/2344] Data 0.003 (0.003) Batch 0.792 (0.615) Remain 19:51:03 loss: 1.1829 Lr: 0.00039
[2025-05-11 13:21:19,285 INFO misc.py line 117 288342] Train: [1/50][979/2344] Data 0.003 (0.003) Batch 0.413 (0.615) Remain 19:50:38 loss: 1.1447 Lr: 0.00039
[2025-05-11 13:21:19,844 INFO misc.py line 117 288342] Train: [1/50][980/2344] Data 0.003 (0.003) Batch 0.559 (0.615) Remain 19:50:31 loss: 0.9586 Lr: 0.00039
[2025-05-11 13:21:20,454 INFO misc.py line 117 288342] Train: [1/50][981/2344] Data 0.003 (0.003) Batch 0.611 (0.615) Remain 19:50:30 loss: 1.0537 Lr: 0.00039
[2025-05-11 13:21:20,942 INFO misc.py line 117 288342] Train: [1/50][982/2344] Data 0.003 (0.003) Batch 0.488 (0.614) Remain 19:50:14 loss: 1.0129 Lr: 0.00039
[2025-05-11 13:21:21,672 INFO misc.py line 117 288342] Train: [1/50][983/2344] Data 0.002 (0.003) Batch 0.729 (0.615) Remain 19:50:27 loss: 1.0675 Lr: 0.00039
[2025-05-11 13:21:22,195 INFO misc.py line 117 288342] Train: [1/50][984/2344] Data 0.003 (0.003) Batch 0.523 (0.615) Remain 19:50:16 loss: 0.9709 Lr: 0.00039
[2025-05-11 13:21:22,953 INFO misc.py line 117 288342] Train: [1/50][985/2344] Data 0.002 (0.003) Batch 0.758 (0.615) Remain 19:50:32 loss: 1.1194 Lr: 0.00039
[2025-05-11 13:21:23,485 INFO misc.py line 117 288342] Train: [1/50][986/2344] Data 0.003 (0.003) Batch 0.532 (0.615) Remain 19:50:22 loss: 0.8126 Lr: 0.00039
[2025-05-11 13:21:24,104 INFO misc.py line 117 288342] Train: [1/50][987/2344] Data 0.003 (0.003) Batch 0.620 (0.615) Remain 19:50:22 loss: 1.1717 Lr: 0.00039
[2025-05-11 13:21:24,936 INFO misc.py line 117 288342] Train: [1/50][988/2344] Data 0.003 (0.003) Batch 0.831 (0.615) Remain 19:50:47 loss: 1.0187 Lr: 0.00039
[2025-05-11 13:21:25,375 INFO misc.py line 117 288342] Train: [1/50][989/2344] Data 0.003 (0.003) Batch 0.439 (0.615) Remain 19:50:26 loss: 0.9778 Lr: 0.00039
[2025-05-11 13:21:25,955 INFO misc.py line 117 288342] Train: [1/50][990/2344] Data 0.003 (0.003) Batch 0.581 (0.615) Remain 19:50:21 loss: 1.1691 Lr: 0.00039
[2025-05-11 13:21:26,601 INFO misc.py line 117 288342] Train: [1/50][991/2344] Data 0.002 (0.003) Batch 0.645 (0.615) Remain 19:50:24 loss: 1.2013 Lr: 0.00039
[2025-05-11 13:21:27,296 INFO misc.py line 117 288342] Train: [1/50][992/2344] Data 0.028 (0.003) Batch 0.695 (0.615) Remain 19:50:33 loss: 0.9651 Lr: 0.00039
[2025-05-11 13:21:27,830 INFO misc.py line 117 288342] Train: [1/50][993/2344] Data 0.002 (0.003) Batch 0.534 (0.615) Remain 19:50:23 loss: 1.0312 Lr: 0.00039
[2025-05-11 13:21:28,475 INFO misc.py line 117 288342] Train: [1/50][994/2344] Data 0.002 (0.003) Batch 0.645 (0.615) Remain 19:50:26 loss: 1.0840 Lr: 0.00039
[2025-05-11 13:21:29,018 INFO misc.py line 117 288342] Train: [1/50][995/2344] Data 0.003 (0.003) Batch 0.543 (0.615) Remain 19:50:17 loss: 0.8777 Lr: 0.00039
[2025-05-11 13:21:29,630 INFO misc.py line 117 288342] Train: [1/50][996/2344] Data 0.003 (0.003) Batch 0.613 (0.615) Remain 19:50:16 loss: 0.7657 Lr: 0.00039
[2025-05-11 13:21:30,309 INFO misc.py line 117 288342] Train: [1/50][997/2344] Data 0.003 (0.003) Batch 0.679 (0.615) Remain 19:50:23 loss: 1.2608 Lr: 0.00039
[2025-05-11 13:21:31,032 INFO misc.py line 117 288342] Train: [1/50][998/2344] Data 0.003 (0.003) Batch 0.723 (0.615) Remain 19:50:35 loss: 0.9850 Lr: 0.00039
[2025-05-11 13:21:31,691 INFO misc.py line 117 288342] Train: [1/50][999/2344] Data 0.003 (0.003) Batch 0.658 (0.615) Remain 19:50:39 loss: 0.9483 Lr: 0.00039
[2025-05-11 13:21:32,351 INFO misc.py line 117 288342] Train: [1/50][1000/2344] Data 0.003 (0.003) Batch 0.660 (0.615) Remain 19:50:44 loss: 1.1262 Lr: 0.00039
[2025-05-11 13:21:33,095 INFO misc.py line 117 288342] Train: [1/50][1001/2344] Data 0.003 (0.003) Batch 0.744 (0.615) Remain 19:50:58 loss: 1.0176 Lr: 0.00039
[2025-05-11 13:21:33,832 INFO misc.py line 117 288342] Train: [1/50][1002/2344] Data 0.002 (0.003) Batch 0.737 (0.615) Remain 19:51:12 loss: 1.3296 Lr: 0.00039
[2025-05-11 13:21:34,399 INFO misc.py line 117 288342] Train: [1/50][1003/2344] Data 0.003 (0.003) Batch 0.568 (0.615) Remain 19:51:06 loss: 0.9190 Lr: 0.00040
[2025-05-11 13:21:34,964 INFO misc.py line 117 288342] Train: [1/50][1004/2344] Data 0.003 (0.003) Batch 0.565 (0.615) Remain 19:50:59 loss: 0.9465 Lr: 0.00040
[2025-05-11 13:21:35,398 INFO misc.py line 117 288342] Train: [1/50][1005/2344] Data 0.003 (0.003) Batch 0.433 (0.615) Remain 19:50:38 loss: 1.2172 Lr: 0.00040
[2025-05-11 13:21:35,976 INFO misc.py line 117 288342] Train: [1/50][1006/2344] Data 0.003 (0.003) Batch 0.578 (0.615) Remain 19:50:33 loss: 1.0113 Lr: 0.00040
[2025-05-11 13:21:36,460 INFO misc.py line 117 288342] Train: [1/50][1007/2344] Data 0.003 (0.003) Batch 0.484 (0.615) Remain 19:50:17 loss: 0.8516 Lr: 0.00040
[2025-05-11 13:21:37,151 INFO misc.py line 117 288342] Train: [1/50][1008/2344] Data 0.003 (0.003) Batch 0.691 (0.615) Remain 19:50:25 loss: 1.1591 Lr: 0.00040
[2025-05-11 13:21:37,794 INFO misc.py line 117 288342] Train: [1/50][1009/2344] Data 0.002 (0.003) Batch 0.643 (0.615) Remain 19:50:28 loss: 1.0539 Lr: 0.00040
[2025-05-11 13:21:38,419 INFO misc.py line 117 288342] Train: [1/50][1010/2344] Data 0.002 (0.003) Batch 0.626 (0.615) Remain 19:50:29 loss: 0.9625 Lr: 0.00040
[2025-05-11 13:21:38,891 INFO misc.py line 117 288342] Train: [1/50][1011/2344] Data 0.003 (0.003) Batch 0.471 (0.615) Remain 19:50:11 loss: 0.8193 Lr: 0.00040
[2025-05-11 13:21:39,440 INFO misc.py line 117 288342] Train: [1/50][1012/2344] Data 0.003 (0.003) Batch 0.549 (0.615) Remain 19:50:03 loss: 1.1953 Lr: 0.00040
[2025-05-11 13:21:40,029 INFO misc.py line 117 288342] Train: [1/50][1013/2344] Data 0.003 (0.003) Batch 0.588 (0.615) Remain 19:50:00 loss: 0.9733 Lr: 0.00040
[2025-05-11 13:21:40,658 INFO misc.py line 117 288342] Train: [1/50][1014/2344] Data 0.003 (0.003) Batch 0.629 (0.615) Remain 19:50:01 loss: 0.8537 Lr: 0.00040
[2025-05-11 13:21:41,396 INFO misc.py line 117 288342] Train: [1/50][1015/2344] Data 0.003 (0.003) Batch 0.738 (0.615) Remain 19:50:14 loss: 0.8868 Lr: 0.00040
[2025-05-11 13:21:42,080 INFO misc.py line 117 288342] Train: [1/50][1016/2344] Data 0.003 (0.003) Batch 0.684 (0.615) Remain 19:50:22 loss: 0.8983 Lr: 0.00040
[2025-05-11 13:21:42,594 INFO misc.py line 117 288342] Train: [1/50][1017/2344] Data 0.003 (0.003) Batch 0.514 (0.615) Remain 19:50:09 loss: 1.0521 Lr: 0.00040
[2025-05-11 13:21:43,197 INFO misc.py line 117 288342] Train: [1/50][1018/2344] Data 0.003 (0.003) Batch 0.603 (0.615) Remain 19:50:08 loss: 0.9667 Lr: 0.00040
[2025-05-11 13:21:43,757 INFO misc.py line 117 288342] Train: [1/50][1019/2344] Data 0.003 (0.003) Batch 0.560 (0.615) Remain 19:50:01 loss: 0.8140 Lr: 0.00040
[2025-05-11 13:21:44,421 INFO misc.py line 117 288342] Train: [1/50][1020/2344] Data 0.003 (0.003) Batch 0.664 (0.615) Remain 19:50:06 loss: 1.0754 Lr: 0.00040
[2025-05-11 13:21:45,051 INFO misc.py line 117 288342] Train: [1/50][1021/2344] Data 0.003 (0.003) Batch 0.630 (0.615) Remain 19:50:07 loss: 0.9077 Lr: 0.00040
[2025-05-11 13:21:45,653 INFO misc.py line 117 288342] Train: [1/50][1022/2344] Data 0.003 (0.003) Batch 0.602 (0.615) Remain 19:50:05 loss: 1.0125 Lr: 0.00040
[2025-05-11 13:21:46,334 INFO misc.py line 117 288342] Train: [1/50][1023/2344] Data 0.003 (0.003) Batch 0.681 (0.615) Remain 19:50:12 loss: 1.0185 Lr: 0.00040
[2025-05-11 13:21:46,937 INFO misc.py line 117 288342] Train: [1/50][1024/2344] Data 0.003 (0.003) Batch 0.604 (0.615) Remain 19:50:10 loss: 0.9085 Lr: 0.00040
[2025-05-11 13:21:47,450 INFO misc.py line 117 288342] Train: [1/50][1025/2344] Data 0.002 (0.003) Batch 0.513 (0.615) Remain 19:49:58 loss: 0.8017 Lr: 0.00040
[2025-05-11 13:21:48,133 INFO misc.py line 117 288342] Train: [1/50][1026/2344] Data 0.003 (0.003) Batch 0.683 (0.615) Remain 19:50:05 loss: 1.1030 Lr: 0.00040
[2025-05-11 13:21:48,646 INFO misc.py line 117 288342] Train: [1/50][1027/2344] Data 0.002 (0.003) Batch 0.513 (0.615) Remain 19:49:53 loss: 0.8995 Lr: 0.00040
[2025-05-11 13:21:49,212 INFO misc.py line 117 288342] Train: [1/50][1028/2344] Data 0.002 (0.003) Batch 0.565 (0.614) Remain 19:49:46 loss: 1.2661 Lr: 0.00040
[2025-05-11 13:21:49,864 INFO misc.py line 117 288342] Train: [1/50][1029/2344] Data 0.002 (0.003) Batch 0.652 (0.615) Remain 19:49:50 loss: 1.1355 Lr: 0.00040
[2025-05-11 13:21:50,435 INFO misc.py line 117 288342] Train: [1/50][1030/2344] Data 0.002 (0.003) Batch 0.571 (0.614) Remain 19:49:45 loss: 0.9001 Lr: 0.00041
[2025-05-11 13:21:51,121 INFO misc.py line 117 288342] Train: [1/50][1031/2344] Data 0.003 (0.003) Batch 0.686 (0.615) Remain 19:49:52 loss: 0.9272 Lr: 0.00041
[2025-05-11 13:21:51,790 INFO misc.py line 117 288342] Train: [1/50][1032/2344] Data 0.003 (0.003) Batch 0.669 (0.615) Remain 19:49:58 loss: 0.9307 Lr: 0.00041
[2025-05-11 13:21:52,403 INFO misc.py line 117 288342] Train: [1/50][1033/2344] Data 0.003 (0.003) Batch 0.612 (0.615) Remain 19:49:57 loss: 1.4362 Lr: 0.00041
[2025-05-11 13:21:53,001 INFO misc.py line 117 288342] Train: [1/50][1034/2344] Data 0.003 (0.003) Batch 0.598 (0.615) Remain 19:49:54 loss: 1.1156 Lr: 0.00041
[2025-05-11 13:21:53,653 INFO misc.py line 117 288342] Train: [1/50][1035/2344] Data 0.003 (0.003) Batch 0.651 (0.615) Remain 19:49:58 loss: 1.0880 Lr: 0.00041
[2025-05-11 13:21:54,238 INFO misc.py line 117 288342] Train: [1/50][1036/2344] Data 0.003 (0.003) Batch 0.585 (0.615) Remain 19:49:54 loss: 0.9819 Lr: 0.00041
[2025-05-11 13:21:54,820 INFO misc.py line 117 288342] Train: [1/50][1037/2344] Data 0.003 (0.003) Batch 0.582 (0.615) Remain 19:49:50 loss: 1.0830 Lr: 0.00041
[2025-05-11 13:21:55,388 INFO misc.py line 117 288342] Train: [1/50][1038/2344] Data 0.003 (0.003) Batch 0.568 (0.615) Remain 19:49:44 loss: 1.0100 Lr: 0.00041
[2025-05-11 13:21:55,978 INFO misc.py line 117 288342] Train: [1/50][1039/2344] Data 0.003 (0.003) Batch 0.590 (0.614) Remain 19:49:40 loss: 1.0526 Lr: 0.00041
[2025-05-11 13:21:56,529 INFO misc.py line 117 288342] Train: [1/50][1040/2344] Data 0.002 (0.003) Batch 0.551 (0.614) Remain 19:49:33 loss: 0.9041 Lr: 0.00041
[2025-05-11 13:21:57,166 INFO misc.py line 117 288342] Train: [1/50][1041/2344] Data 0.003 (0.003) Batch 0.637 (0.614) Remain 19:49:35 loss: 1.1346 Lr: 0.00041
[2025-05-11 13:21:57,786 INFO misc.py line 117 288342] Train: [1/50][1042/2344] Data 0.003 (0.003) Batch 0.620 (0.614) Remain 19:49:35 loss: 0.8579 Lr: 0.00041
[2025-05-11 13:21:58,342 INFO misc.py line 117 288342] Train: [1/50][1043/2344] Data 0.002 (0.003) Batch 0.556 (0.614) Remain 19:49:28 loss: 1.0111 Lr: 0.00041
[2025-05-11 13:21:58,891 INFO misc.py line 117 288342] Train: [1/50][1044/2344] Data 0.002 (0.003) Batch 0.548 (0.614) Remain 19:49:20 loss: 1.1542 Lr: 0.00041
[2025-05-11 13:21:59,475 INFO misc.py line 117 288342] Train: [1/50][1045/2344] Data 0.003 (0.003) Batch 0.584 (0.614) Remain 19:49:16 loss: 0.8021 Lr: 0.00041
[2025-05-11 13:22:00,041 INFO misc.py line 117 288342] Train: [1/50][1046/2344] Data 0.003 (0.003) Batch 0.567 (0.614) Remain 19:49:10 loss: 0.8349 Lr: 0.00041
[2025-05-11 13:22:00,699 INFO misc.py line 117 288342] Train: [1/50][1047/2344] Data 0.003 (0.003) Batch 0.658 (0.614) Remain 19:49:14 loss: 1.2329 Lr: 0.00041
[2025-05-11 13:22:01,300 INFO misc.py line 117 288342] Train: [1/50][1048/2344] Data 0.003 (0.003) Batch 0.602 (0.614) Remain 19:49:12 loss: 0.9900 Lr: 0.00041
[2025-05-11 13:22:01,876 INFO misc.py line 117 288342] Train: [1/50][1049/2344] Data 0.003 (0.003) Batch 0.575 (0.614) Remain 19:49:07 loss: 1.0505 Lr: 0.00041
[2025-05-11 13:22:02,408 INFO misc.py line 117 288342] Train: [1/50][1050/2344] Data 0.003 (0.003) Batch 0.532 (0.614) Remain 19:48:57 loss: 1.1050 Lr: 0.00041
[2025-05-11 13:22:02,940 INFO misc.py line 117 288342] Train: [1/50][1051/2344] Data 0.002 (0.003) Batch 0.532 (0.614) Remain 19:48:47 loss: 0.9568 Lr: 0.00041
[2025-05-11 13:22:03,548 INFO misc.py line 117 288342] Train: [1/50][1052/2344] Data 0.002 (0.003) Batch 0.608 (0.614) Remain 19:48:46 loss: 1.1045 Lr: 0.00041
[2025-05-11 13:22:04,201 INFO misc.py line 117 288342] Train: [1/50][1053/2344] Data 0.092 (0.003) Batch 0.653 (0.614) Remain 19:48:50 loss: 0.9316 Lr: 0.00041
[2025-05-11 13:22:04,812 INFO misc.py line 117 288342] Train: [1/50][1054/2344] Data 0.003 (0.003) Batch 0.611 (0.614) Remain 19:48:49 loss: 0.8689 Lr: 0.00041
[2025-05-11 13:22:05,386 INFO misc.py line 117 288342] Train: [1/50][1055/2344] Data 0.003 (0.003) Batch 0.574 (0.614) Remain 19:48:44 loss: 0.9595 Lr: 0.00042
[2025-05-11 13:22:06,152 INFO misc.py line 117 288342] Train: [1/50][1056/2344] Data 0.002 (0.003) Batch 0.767 (0.614) Remain 19:49:00 loss: 1.1487 Lr: 0.00042
[2025-05-11 13:22:06,881 INFO misc.py line 117 288342] Train: [1/50][1057/2344] Data 0.002 (0.003) Batch 0.728 (0.614) Remain 19:49:12 loss: 1.1087 Lr: 0.00042
[2025-05-11 13:22:07,406 INFO misc.py line 117 288342] Train: [1/50][1058/2344] Data 0.002 (0.003) Batch 0.525 (0.614) Remain 19:49:02 loss: 0.9425 Lr: 0.00042
[2025-05-11 13:22:08,029 INFO misc.py line 117 288342] Train: [1/50][1059/2344] Data 0.003 (0.003) Batch 0.623 (0.614) Remain 19:49:02 loss: 0.9276 Lr: 0.00042
[2025-05-11 13:22:08,645 INFO misc.py line 117 288342] Train: [1/50][1060/2344] Data 0.003 (0.003) Batch 0.617 (0.614) Remain 19:49:02 loss: 1.0914 Lr: 0.00042
[2025-05-11 13:22:09,303 INFO misc.py line 117 288342] Train: [1/50][1061/2344] Data 0.003 (0.003) Batch 0.658 (0.614) Remain 19:49:06 loss: 0.9294 Lr: 0.00042
[2025-05-11 13:22:10,036 INFO misc.py line 117 288342] Train: [1/50][1062/2344] Data 0.003 (0.003) Batch 0.733 (0.614) Remain 19:49:18 loss: 0.9572 Lr: 0.00042
[2025-05-11 13:22:10,726 INFO misc.py line 117 288342] Train: [1/50][1063/2344] Data 0.003 (0.003) Batch 0.690 (0.615) Remain 19:49:26 loss: 0.5596 Lr: 0.00042
[2025-05-11 13:22:11,239 INFO misc.py line 117 288342] Train: [1/50][1064/2344] Data 0.002 (0.003) Batch 0.513 (0.614) Remain 19:49:14 loss: 0.9565 Lr: 0.00042
[2025-05-11 13:22:11,727 INFO misc.py line 117 288342] Train: [1/50][1065/2344] Data 0.003 (0.003) Batch 0.488 (0.614) Remain 19:49:00 loss: 1.0112 Lr: 0.00042
[2025-05-11 13:22:12,334 INFO misc.py line 117 288342] Train: [1/50][1066/2344] Data 0.003 (0.003) Batch 0.607 (0.614) Remain 19:48:58 loss: 0.8732 Lr: 0.00042
[2025-05-11 13:22:13,033 INFO misc.py line 117 288342] Train: [1/50][1067/2344] Data 0.003 (0.003) Batch 0.699 (0.614) Remain 19:49:07 loss: 1.0100 Lr: 0.00042
[2025-05-11 13:22:13,572 INFO misc.py line 117 288342] Train: [1/50][1068/2344] Data 0.003 (0.003) Batch 0.539 (0.614) Remain 19:48:58 loss: 1.1359 Lr: 0.00042
[2025-05-11 13:22:14,105 INFO misc.py line 117 288342] Train: [1/50][1069/2344] Data 0.003 (0.003) Batch 0.533 (0.614) Remain 19:48:48 loss: 0.9676 Lr: 0.00042
[2025-05-11 13:22:14,647 INFO misc.py line 117 288342] Train: [1/50][1070/2344] Data 0.003 (0.003) Batch 0.542 (0.614) Remain 19:48:40 loss: 0.9716 Lr: 0.00042
[2025-05-11 13:22:15,260 INFO misc.py line 117 288342] Train: [1/50][1071/2344] Data 0.003 (0.003) Batch 0.613 (0.614) Remain 19:48:39 loss: 0.8743 Lr: 0.00042
[2025-05-11 13:22:15,887 INFO misc.py line 117 288342] Train: [1/50][1072/2344] Data 0.002 (0.003) Batch 0.626 (0.614) Remain 19:48:40 loss: 1.2467 Lr: 0.00042
[2025-05-11 13:22:16,618 INFO misc.py line 117 288342] Train: [1/50][1073/2344] Data 0.003 (0.003) Batch 0.732 (0.614) Remain 19:48:52 loss: 0.8166 Lr: 0.00042
[2025-05-11 13:22:17,029 INFO misc.py line 117 288342] Train: [1/50][1074/2344] Data 0.002 (0.003) Batch 0.410 (0.614) Remain 19:48:29 loss: 1.0112 Lr: 0.00042
[2025-05-11 13:22:17,744 INFO misc.py line 117 288342] Train: [1/50][1075/2344] Data 0.002 (0.003) Batch 0.716 (0.614) Remain 19:48:40 loss: 1.0602 Lr: 0.00042
[2025-05-11 13:22:18,329 INFO misc.py line 117 288342] Train: [1/50][1076/2344] Data 0.002 (0.003) Batch 0.584 (0.614) Remain 19:48:36 loss: 0.7778 Lr: 0.00042
[2025-05-11 13:22:18,931 INFO misc.py line 117 288342] Train: [1/50][1077/2344] Data 0.003 (0.003) Batch 0.602 (0.614) Remain 19:48:34 loss: 0.9943 Lr: 0.00042
[2025-05-11 13:22:19,541 INFO misc.py line 117 288342] Train: [1/50][1078/2344] Data 0.003 (0.003) Batch 0.610 (0.614) Remain 19:48:33 loss: 1.0445 Lr: 0.00042
[2025-05-11 13:22:20,171 INFO misc.py line 117 288342] Train: [1/50][1079/2344] Data 0.002 (0.003) Batch 0.630 (0.614) Remain 19:48:34 loss: 0.8825 Lr: 0.00042
[2025-05-11 13:22:20,743 INFO misc.py line 117 288342] Train: [1/50][1080/2344] Data 0.003 (0.003) Batch 0.572 (0.614) Remain 19:48:29 loss: 1.0945 Lr: 0.00042
[2025-05-11 13:22:21,477 INFO misc.py line 117 288342] Train: [1/50][1081/2344] Data 0.003 (0.003) Batch 0.734 (0.614) Remain 19:48:41 loss: 1.0155 Lr: 0.00043
[2025-05-11 13:22:22,160 INFO misc.py line 117 288342] Train: [1/50][1082/2344] Data 0.003 (0.003) Batch 0.683 (0.614) Remain 19:48:48 loss: 0.8462 Lr: 0.00043
[2025-05-11 13:22:22,928 INFO misc.py line 117 288342] Train: [1/50][1083/2344] Data 0.002 (0.003) Batch 0.768 (0.614) Remain 19:49:04 loss: 1.2556 Lr: 0.00043
[2025-05-11 13:22:23,553 INFO misc.py line 117 288342] Train: [1/50][1084/2344] Data 0.003 (0.003) Batch 0.626 (0.614) Remain 19:49:05 loss: 1.1225 Lr: 0.00043
[2025-05-11 13:22:24,165 INFO misc.py line 117 288342] Train: [1/50][1085/2344] Data 0.003 (0.003) Batch 0.611 (0.614) Remain 19:49:04 loss: 1.0335 Lr: 0.00043
[2025-05-11 13:22:24,779 INFO misc.py line 117 288342] Train: [1/50][1086/2344] Data 0.002 (0.003) Batch 0.615 (0.614) Remain 19:49:03 loss: 1.0705 Lr: 0.00043
[2025-05-11 13:22:25,200 INFO misc.py line 117 288342] Train: [1/50][1087/2344] Data 0.003 (0.003) Batch 0.421 (0.614) Remain 19:48:42 loss: 1.1537 Lr: 0.00043
[2025-05-11 13:22:25,699 INFO misc.py line 117 288342] Train: [1/50][1088/2344] Data 0.003 (0.003) Batch 0.499 (0.614) Remain 19:48:29 loss: 1.1618 Lr: 0.00043
[2025-05-11 13:22:26,308 INFO misc.py line 117 288342] Train: [1/50][1089/2344] Data 0.003 (0.003) Batch 0.609 (0.614) Remain 19:48:27 loss: 0.9948 Lr: 0.00043
[2025-05-11 13:22:27,007 INFO misc.py line 117 288342] Train: [1/50][1090/2344] Data 0.002 (0.003) Batch 0.700 (0.614) Remain 19:48:36 loss: 1.0853 Lr: 0.00043
[2025-05-11 13:22:27,625 INFO misc.py line 117 288342] Train: [1/50][1091/2344] Data 0.002 (0.003) Batch 0.618 (0.614) Remain 19:48:36 loss: 0.9122 Lr: 0.00043
[2025-05-11 13:22:28,267 INFO misc.py line 117 288342] Train: [1/50][1092/2344] Data 0.002 (0.003) Batch 0.642 (0.614) Remain 19:48:38 loss: 0.8333 Lr: 0.00043
[2025-05-11 13:22:28,782 INFO misc.py line 117 288342] Train: [1/50][1093/2344] Data 0.002 (0.003) Batch 0.515 (0.614) Remain 19:48:27 loss: 0.7932 Lr: 0.00043
[2025-05-11 13:22:29,401 INFO misc.py line 117 288342] Train: [1/50][1094/2344] Data 0.003 (0.003) Batch 0.619 (0.614) Remain 19:48:27 loss: 1.0314 Lr: 0.00043
[2025-05-11 13:22:30,022 INFO misc.py line 117 288342] Train: [1/50][1095/2344] Data 0.003 (0.003) Batch 0.621 (0.614) Remain 19:48:27 loss: 0.6385 Lr: 0.00043
[2025-05-11 13:22:30,666 INFO misc.py line 117 288342] Train: [1/50][1096/2344] Data 0.003 (0.003) Batch 0.644 (0.614) Remain 19:48:29 loss: 0.9573 Lr: 0.00043
[2025-05-11 13:22:31,415 INFO misc.py line 117 288342] Train: [1/50][1097/2344] Data 0.003 (0.003) Batch 0.750 (0.614) Remain 19:48:43 loss: 1.2551 Lr: 0.00043
[2025-05-11 13:22:32,132 INFO misc.py line 117 288342] Train: [1/50][1098/2344] Data 0.003 (0.003) Batch 0.717 (0.614) Remain 19:48:53 loss: 0.9476 Lr: 0.00043
[2025-05-11 13:22:32,731 INFO misc.py line 117 288342] Train: [1/50][1099/2344] Data 0.002 (0.003) Batch 0.599 (0.614) Remain 19:48:51 loss: 1.0489 Lr: 0.00043
[2025-05-11 13:22:33,415 INFO misc.py line 117 288342] Train: [1/50][1100/2344] Data 0.003 (0.003) Batch 0.685 (0.614) Remain 19:48:58 loss: 1.0569 Lr: 0.00043
[2025-05-11 13:22:33,961 INFO misc.py line 117 288342] Train: [1/50][1101/2344] Data 0.002 (0.003) Batch 0.545 (0.614) Remain 19:48:50 loss: 1.1263 Lr: 0.00043
[2025-05-11 13:22:34,496 INFO misc.py line 117 288342] Train: [1/50][1102/2344] Data 0.003 (0.003) Batch 0.535 (0.614) Remain 19:48:41 loss: 1.0660 Lr: 0.00043
[2025-05-11 13:22:35,209 INFO misc.py line 117 288342] Train: [1/50][1103/2344] Data 0.003 (0.003) Batch 0.713 (0.614) Remain 19:48:51 loss: 0.8402 Lr: 0.00043
[2025-05-11 13:22:35,906 INFO misc.py line 117 288342] Train: [1/50][1104/2344] Data 0.003 (0.003) Batch 0.697 (0.614) Remain 19:48:59 loss: 0.9034 Lr: 0.00043
[2025-05-11 13:22:36,553 INFO misc.py line 117 288342] Train: [1/50][1105/2344] Data 0.003 (0.003) Batch 0.648 (0.615) Remain 19:49:02 loss: 1.2242 Lr: 0.00043
[2025-05-11 13:22:37,261 INFO misc.py line 117 288342] Train: [1/50][1106/2344] Data 0.003 (0.003) Batch 0.708 (0.615) Remain 19:49:11 loss: 0.9798 Lr: 0.00044
[2025-05-11 13:22:37,763 INFO misc.py line 117 288342] Train: [1/50][1107/2344] Data 0.003 (0.003) Batch 0.502 (0.614) Remain 19:48:59 loss: 0.9165 Lr: 0.00044
[2025-05-11 13:22:38,277 INFO misc.py line 117 288342] Train: [1/50][1108/2344] Data 0.003 (0.003) Batch 0.514 (0.614) Remain 19:48:47 loss: 0.9097 Lr: 0.00044
[2025-05-11 13:22:38,960 INFO misc.py line 117 288342] Train: [1/50][1109/2344] Data 0.003 (0.003) Batch 0.683 (0.614) Remain 19:48:54 loss: 1.1282 Lr: 0.00044
[2025-05-11 13:22:39,555 INFO misc.py line 117 288342] Train: [1/50][1110/2344] Data 0.002 (0.003) Batch 0.596 (0.614) Remain 19:48:51 loss: 0.9718 Lr: 0.00044
[2025-05-11 13:22:40,295 INFO misc.py line 117 288342] Train: [1/50][1111/2344] Data 0.002 (0.003) Batch 0.740 (0.615) Remain 19:49:04 loss: 1.0322 Lr: 0.00044
[2025-05-11 13:22:41,057 INFO misc.py line 117 288342] Train: [1/50][1112/2344] Data 0.003 (0.003) Batch 0.762 (0.615) Remain 19:49:19 loss: 0.9904 Lr: 0.00044
[2025-05-11 13:22:41,738 INFO misc.py line 117 288342] Train: [1/50][1113/2344] Data 0.003 (0.003) Batch 0.681 (0.615) Remain 19:49:25 loss: 0.9240 Lr: 0.00044
[2025-05-11 13:22:42,289 INFO misc.py line 117 288342] Train: [1/50][1114/2344] Data 0.003 (0.003) Batch 0.551 (0.615) Remain 19:49:18 loss: 0.9344 Lr: 0.00044
[2025-05-11 13:22:42,930 INFO misc.py line 117 288342] Train: [1/50][1115/2344] Data 0.003 (0.003) Batch 0.641 (0.615) Remain 19:49:20 loss: 0.8283 Lr: 0.00044
[2025-05-11 13:22:43,504 INFO misc.py line 117 288342] Train: [1/50][1116/2344] Data 0.003 (0.003) Batch 0.575 (0.615) Remain 19:49:15 loss: 0.9472 Lr: 0.00044
[2025-05-11 13:22:44,156 INFO misc.py line 117 288342] Train: [1/50][1117/2344] Data 0.002 (0.003) Batch 0.652 (0.615) Remain 19:49:18 loss: 1.0770 Lr: 0.00044
[2025-05-11 13:22:44,763 INFO misc.py line 117 288342] Train: [1/50][1118/2344] Data 0.003 (0.003) Batch 0.606 (0.615) Remain 19:49:17 loss: 1.1327 Lr: 0.00044
[2025-05-11 13:22:45,341 INFO misc.py line 117 288342] Train: [1/50][1119/2344] Data 0.003 (0.003) Batch 0.578 (0.615) Remain 19:49:12 loss: 1.1652 Lr: 0.00044
[2025-05-11 13:22:46,014 INFO misc.py line 117 288342] Train: [1/50][1120/2344] Data 0.003 (0.003) Batch 0.673 (0.615) Remain 19:49:18 loss: 0.9833 Lr: 0.00044
[2025-05-11 13:22:46,527 INFO misc.py line 117 288342] Train: [1/50][1121/2344] Data 0.003 (0.003) Batch 0.513 (0.615) Remain 19:49:07 loss: 1.0722 Lr: 0.00044
[2025-05-11 13:22:47,187 INFO misc.py line 117 288342] Train: [1/50][1122/2344] Data 0.002 (0.003) Batch 0.660 (0.615) Remain 19:49:11 loss: 0.9847 Lr: 0.00044
[2025-05-11 13:22:47,815 INFO misc.py line 117 288342] Train: [1/50][1123/2344] Data 0.002 (0.003) Batch 0.628 (0.615) Remain 19:49:12 loss: 0.9939 Lr: 0.00044
[2025-05-11 13:22:48,406 INFO misc.py line 117 288342] Train: [1/50][1124/2344] Data 0.002 (0.003) Batch 0.590 (0.615) Remain 19:49:08 loss: 1.3072 Lr: 0.00044
[2025-05-11 13:22:49,052 INFO misc.py line 117 288342] Train: [1/50][1125/2344] Data 0.002 (0.003) Batch 0.646 (0.615) Remain 19:49:11 loss: 0.7975 Lr: 0.00044
[2025-05-11 13:22:49,769 INFO misc.py line 117 288342] Train: [1/50][1126/2344] Data 0.002 (0.003) Batch 0.717 (0.615) Remain 19:49:21 loss: 0.9665 Lr: 0.00044
[2025-05-11 13:22:50,361 INFO misc.py line 117 288342] Train: [1/50][1127/2344] Data 0.002 (0.003) Batch 0.592 (0.615) Remain 19:49:18 loss: 0.8325 Lr: 0.00044
[2025-05-11 13:22:50,975 INFO misc.py line 117 288342] Train: [1/50][1128/2344] Data 0.002 (0.003) Batch 0.614 (0.615) Remain 19:49:17 loss: 0.9633 Lr: 0.00044
[2025-05-11 13:22:51,533 INFO misc.py line 117 288342] Train: [1/50][1129/2344] Data 0.002 (0.003) Batch 0.558 (0.615) Remain 19:49:11 loss: 1.0424 Lr: 0.00044
[2025-05-11 13:22:51,996 INFO misc.py line 117 288342] Train: [1/50][1130/2344] Data 0.003 (0.003) Batch 0.463 (0.615) Remain 19:48:55 loss: 0.8922 Lr: 0.00045
[2025-05-11 13:22:52,631 INFO misc.py line 117 288342] Train: [1/50][1131/2344] Data 0.003 (0.003) Batch 0.635 (0.615) Remain 19:48:56 loss: 1.2538 Lr: 0.00045
[2025-05-11 13:22:53,191 INFO misc.py line 117 288342] Train: [1/50][1132/2344] Data 0.003 (0.003) Batch 0.561 (0.615) Remain 19:48:50 loss: 1.0924 Lr: 0.00045
[2025-05-11 13:22:53,899 INFO misc.py line 117 288342] Train: [1/50][1133/2344] Data 0.002 (0.003) Batch 0.708 (0.615) Remain 19:48:59 loss: 0.7826 Lr: 0.00045
[2025-05-11 13:22:54,511 INFO misc.py line 117 288342] Train: [1/50][1134/2344] Data 0.002 (0.003) Batch 0.611 (0.615) Remain 19:48:58 loss: 1.2175 Lr: 0.00045
[2025-05-11 13:22:55,155 INFO misc.py line 117 288342] Train: [1/50][1135/2344] Data 0.003 (0.003) Batch 0.644 (0.615) Remain 19:49:00 loss: 1.1770 Lr: 0.00045
[2025-05-11 13:22:55,892 INFO misc.py line 117 288342] Train: [1/50][1136/2344] Data 0.003 (0.003) Batch 0.737 (0.615) Remain 19:49:12 loss: 1.0618 Lr: 0.00045
[2025-05-11 13:22:56,492 INFO misc.py line 117 288342] Train: [1/50][1137/2344] Data 0.003 (0.003) Batch 0.601 (0.615) Remain 19:49:10 loss: 1.1387 Lr: 0.00045
[2025-05-11 13:22:57,054 INFO misc.py line 117 288342] Train: [1/50][1138/2344] Data 0.002 (0.003) Batch 0.561 (0.615) Remain 19:49:04 loss: 1.0015 Lr: 0.00045
[2025-05-11 13:22:57,675 INFO misc.py line 117 288342] Train: [1/50][1139/2344] Data 0.003 (0.003) Batch 0.622 (0.615) Remain 19:49:04 loss: 1.0253 Lr: 0.00045
[2025-05-11 13:22:58,355 INFO misc.py line 117 288342] Train: [1/50][1140/2344] Data 0.003 (0.003) Batch 0.680 (0.615) Remain 19:49:10 loss: 1.0729 Lr: 0.00045
[2025-05-11 13:22:59,019 INFO misc.py line 117 288342] Train: [1/50][1141/2344] Data 0.003 (0.003) Batch 0.665 (0.615) Remain 19:49:15 loss: 1.0487 Lr: 0.00045
[2025-05-11 13:22:59,702 INFO misc.py line 117 288342] Train: [1/50][1142/2344] Data 0.002 (0.003) Batch 0.683 (0.615) Remain 19:49:21 loss: 0.9120 Lr: 0.00045
[2025-05-11 13:23:00,186 INFO misc.py line 117 288342] Train: [1/50][1143/2344] Data 0.002 (0.003) Batch 0.484 (0.615) Remain 19:49:07 loss: 1.1173 Lr: 0.00045
[2025-05-11 13:23:00,743 INFO misc.py line 117 288342] Train: [1/50][1144/2344] Data 0.002 (0.003) Batch 0.557 (0.615) Remain 19:49:01 loss: 0.9017 Lr: 0.00045
[2025-05-11 13:23:01,260 INFO misc.py line 117 288342] Train: [1/50][1145/2344] Data 0.002 (0.003) Batch 0.517 (0.615) Remain 19:48:50 loss: 0.9104 Lr: 0.00045
[2025-05-11 13:23:01,772 INFO misc.py line 117 288342] Train: [1/50][1146/2344] Data 0.003 (0.003) Batch 0.512 (0.615) Remain 19:48:39 loss: 0.8110 Lr: 0.00045
[2025-05-11 13:23:02,426 INFO misc.py line 117 288342] Train: [1/50][1147/2344] Data 0.003 (0.003) Batch 0.655 (0.615) Remain 19:48:42 loss: 0.9969 Lr: 0.00045
[2025-05-11 13:23:03,197 INFO misc.py line 117 288342] Train: [1/50][1148/2344] Data 0.003 (0.003) Batch 0.771 (0.615) Remain 19:48:58 loss: 0.9662 Lr: 0.00045
[2025-05-11 13:23:03,821 INFO misc.py line 117 288342] Train: [1/50][1149/2344] Data 0.003 (0.003) Batch 0.624 (0.615) Remain 19:48:58 loss: 1.2499 Lr: 0.00045
[2025-05-11 13:23:04,496 INFO misc.py line 117 288342] Train: [1/50][1150/2344] Data 0.002 (0.003) Batch 0.674 (0.615) Remain 19:49:03 loss: 0.8820 Lr: 0.00045
[2025-05-11 13:23:05,070 INFO misc.py line 117 288342] Train: [1/50][1151/2344] Data 0.003 (0.003) Batch 0.574 (0.615) Remain 19:48:59 loss: 0.8664 Lr: 0.00045
[2025-05-11 13:23:05,733 INFO misc.py line 117 288342] Train: [1/50][1152/2344] Data 0.003 (0.003) Batch 0.663 (0.615) Remain 19:49:03 loss: 0.7579 Lr: 0.00045
[2025-05-11 13:23:06,299 INFO misc.py line 117 288342] Train: [1/50][1153/2344] Data 0.002 (0.003) Batch 0.566 (0.615) Remain 19:48:57 loss: 0.7050 Lr: 0.00045
[2025-05-11 13:23:06,911 INFO misc.py line 117 288342] Train: [1/50][1154/2344] Data 0.002 (0.003) Batch 0.612 (0.615) Remain 19:48:57 loss: 0.9857 Lr: 0.00046
[2025-05-11 13:23:07,527 INFO misc.py line 117 288342] Train: [1/50][1155/2344] Data 0.002 (0.003) Batch 0.616 (0.615) Remain 19:48:56 loss: 0.9898 Lr: 0.00046
[2025-05-11 13:23:08,109 INFO misc.py line 117 288342] Train: [1/50][1156/2344] Data 0.002 (0.003) Batch 0.582 (0.615) Remain 19:48:52 loss: 1.0361 Lr: 0.00046
[2025-05-11 13:23:08,663 INFO misc.py line 117 288342] Train: [1/50][1157/2344] Data 0.003 (0.003) Batch 0.554 (0.615) Remain 19:48:45 loss: 0.9077 Lr: 0.00046
[2025-05-11 13:23:09,302 INFO misc.py line 117 288342] Train: [1/50][1158/2344] Data 0.003 (0.003) Batch 0.639 (0.615) Remain 19:48:47 loss: 1.0965 Lr: 0.00046
[2025-05-11 13:23:09,915 INFO misc.py line 117 288342] Train: [1/50][1159/2344] Data 0.003 (0.003) Batch 0.613 (0.615) Remain 19:48:47 loss: 1.0725 Lr: 0.00046
[2025-05-11 13:23:10,738 INFO misc.py line 117 288342] Train: [1/50][1160/2344] Data 0.003 (0.003) Batch 0.823 (0.615) Remain 19:49:07 loss: 1.1429 Lr: 0.00046
[2025-05-11 13:23:11,224 INFO misc.py line 117 288342] Train: [1/50][1161/2344] Data 0.003 (0.003) Batch 0.486 (0.615) Remain 19:48:53 loss: 0.9800 Lr: 0.00046
[2025-05-11 13:23:11,709 INFO misc.py line 117 288342] Train: [1/50][1162/2344] Data 0.003 (0.003) Batch 0.485 (0.615) Remain 19:48:40 loss: 0.9913 Lr: 0.00046
[2025-05-11 13:23:12,262 INFO misc.py line 117 288342] Train: [1/50][1163/2344] Data 0.003 (0.003) Batch 0.552 (0.615) Remain 19:48:33 loss: 1.0988 Lr: 0.00046
[2025-05-11 13:23:12,826 INFO misc.py line 117 288342] Train: [1/50][1164/2344] Data 0.003 (0.003) Batch 0.565 (0.615) Remain 19:48:27 loss: 1.0953 Lr: 0.00046
[2025-05-11 13:23:13,423 INFO misc.py line 117 288342] Train: [1/50][1165/2344] Data 0.002 (0.003) Batch 0.597 (0.615) Remain 19:48:25 loss: 0.8948 Lr: 0.00046
[2025-05-11 13:23:14,031 INFO misc.py line 117 288342] Train: [1/50][1166/2344] Data 0.003 (0.003) Batch 0.608 (0.615) Remain 19:48:24 loss: 0.8185 Lr: 0.00046
[2025-05-11 13:23:14,710 INFO misc.py line 117 288342] Train: [1/50][1167/2344] Data 0.003 (0.003) Batch 0.679 (0.615) Remain 19:48:29 loss: 0.8833 Lr: 0.00046
[2025-05-11 13:23:15,404 INFO misc.py line 117 288342] Train: [1/50][1168/2344] Data 0.003 (0.003) Batch 0.694 (0.615) Remain 19:48:37 loss: 1.0009 Lr: 0.00046
[2025-05-11 13:23:16,075 INFO misc.py line 117 288342] Train: [1/50][1169/2344] Data 0.003 (0.003) Batch 0.671 (0.615) Remain 19:48:42 loss: 0.9988 Lr: 0.00046
[2025-05-11 13:23:16,704 INFO misc.py line 117 288342] Train: [1/50][1170/2344] Data 0.002 (0.003) Batch 0.628 (0.615) Remain 19:48:42 loss: 0.7727 Lr: 0.00046
[2025-05-11 13:23:17,265 INFO misc.py line 117 288342] Train: [1/50][1171/2344] Data 0.003 (0.003) Batch 0.562 (0.615) Remain 19:48:37 loss: 1.2415 Lr: 0.00046
[2025-05-11 13:23:17,808 INFO misc.py line 117 288342] Train: [1/50][1172/2344] Data 0.003 (0.003) Batch 0.543 (0.615) Remain 19:48:29 loss: 0.9978 Lr: 0.00046
[2025-05-11 13:23:18,439 INFO misc.py line 117 288342] Train: [1/50][1173/2344] Data 0.003 (0.003) Batch 0.631 (0.615) Remain 19:48:30 loss: 0.9265 Lr: 0.00046
[2025-05-11 13:23:19,035 INFO misc.py line 117 288342] Train: [1/50][1174/2344] Data 0.003 (0.003) Batch 0.596 (0.615) Remain 19:48:27 loss: 0.8559 Lr: 0.00046
[2025-05-11 13:23:19,667 INFO misc.py line 117 288342] Train: [1/50][1175/2344] Data 0.003 (0.003) Batch 0.632 (0.615) Remain 19:48:28 loss: 0.9754 Lr: 0.00046
[2025-05-11 13:23:20,322 INFO misc.py line 117 288342] Train: [1/50][1176/2344] Data 0.002 (0.003) Batch 0.655 (0.615) Remain 19:48:32 loss: 0.7832 Lr: 0.00046
[2025-05-11 13:23:20,800 INFO misc.py line 117 288342] Train: [1/50][1177/2344] Data 0.003 (0.003) Batch 0.478 (0.615) Remain 19:48:18 loss: 0.8003 Lr: 0.00046
[2025-05-11 13:23:21,548 INFO misc.py line 117 288342] Train: [1/50][1178/2344] Data 0.002 (0.003) Batch 0.748 (0.615) Remain 19:48:30 loss: 0.9557 Lr: 0.00047
[2025-05-11 13:23:22,051 INFO misc.py line 117 288342] Train: [1/50][1179/2344] Data 0.003 (0.003) Batch 0.503 (0.615) Remain 19:48:19 loss: 1.0206 Lr: 0.00047
[2025-05-11 13:23:22,688 INFO misc.py line 117 288342] Train: [1/50][1180/2344] Data 0.003 (0.003) Batch 0.637 (0.615) Remain 19:48:20 loss: 1.0744 Lr: 0.00047
[2025-05-11 13:23:23,380 INFO misc.py line 117 288342] Train: [1/50][1181/2344] Data 0.002 (0.003) Batch 0.691 (0.615) Remain 19:48:27 loss: 0.9846 Lr: 0.00047
[2025-05-11 13:23:24,064 INFO misc.py line 117 288342] Train: [1/50][1182/2344] Data 0.002 (0.003) Batch 0.684 (0.615) Remain 19:48:33 loss: 1.1279 Lr: 0.00047
[2025-05-11 13:23:24,824 INFO misc.py line 117 288342] Train: [1/50][1183/2344] Data 0.003 (0.003) Batch 0.760 (0.615) Remain 19:48:47 loss: 1.0340 Lr: 0.00047
[2025-05-11 13:23:25,517 INFO misc.py line 117 288342] Train: [1/50][1184/2344] Data 0.003 (0.003) Batch 0.693 (0.615) Remain 19:48:54 loss: 0.7771 Lr: 0.00047
[2025-05-11 13:23:26,200 INFO misc.py line 117 288342] Train: [1/50][1185/2344] Data 0.003 (0.003) Batch 0.682 (0.615) Remain 19:49:00 loss: 0.8477 Lr: 0.00047
[2025-05-11 13:23:26,867 INFO misc.py line 117 288342] Train: [1/50][1186/2344] Data 0.003 (0.003) Batch 0.667 (0.615) Remain 19:49:05 loss: 0.9847 Lr: 0.00047
[2025-05-11 13:23:27,395 INFO misc.py line 117 288342] Train: [1/50][1187/2344] Data 0.003 (0.003) Batch 0.528 (0.615) Remain 19:48:56 loss: 1.6121 Lr: 0.00047
[2025-05-11 13:23:28,111 INFO misc.py line 117 288342] Train: [1/50][1188/2344] Data 0.003 (0.003) Batch 0.716 (0.615) Remain 19:49:05 loss: 1.0314 Lr: 0.00047
[2025-05-11 13:23:28,623 INFO misc.py line 117 288342] Train: [1/50][1189/2344] Data 0.002 (0.003) Batch 0.512 (0.615) Remain 19:48:54 loss: 0.9884 Lr: 0.00047
[2025-05-11 13:23:29,192 INFO misc.py line 117 288342] Train: [1/50][1190/2344] Data 0.003 (0.003) Batch 0.569 (0.615) Remain 19:48:49 loss: 0.8681 Lr: 0.00047
[2025-05-11 13:23:29,880 INFO misc.py line 117 288342] Train: [1/50][1191/2344] Data 0.003 (0.003) Batch 0.688 (0.615) Remain 19:48:56 loss: 0.9446 Lr: 0.00047
[2025-05-11 13:23:30,441 INFO misc.py line 117 288342] Train: [1/50][1192/2344] Data 0.003 (0.003) Batch 0.561 (0.615) Remain 19:48:50 loss: 0.7647 Lr: 0.00047
[2025-05-11 13:23:31,144 INFO misc.py line 117 288342] Train: [1/50][1193/2344] Data 0.002 (0.003) Batch 0.702 (0.615) Remain 19:48:58 loss: 1.1547 Lr: 0.00047
[2025-05-11 13:23:31,577 INFO misc.py line 117 288342] Train: [1/50][1194/2344] Data 0.003 (0.003) Batch 0.434 (0.615) Remain 19:48:39 loss: 1.0421 Lr: 0.00047
[2025-05-11 13:23:32,209 INFO misc.py line 117 288342] Train: [1/50][1195/2344] Data 0.003 (0.003) Batch 0.632 (0.615) Remain 19:48:41 loss: 0.9354 Lr: 0.00047
[2025-05-11 13:23:32,839 INFO misc.py line 117 288342] Train: [1/50][1196/2344] Data 0.003 (0.003) Batch 0.629 (0.615) Remain 19:48:41 loss: 1.1587 Lr: 0.00047
[2025-05-11 13:23:33,475 INFO misc.py line 117 288342] Train: [1/50][1197/2344] Data 0.003 (0.003) Batch 0.637 (0.615) Remain 19:48:43 loss: 1.0608 Lr: 0.00047
[2025-05-11 13:23:34,091 INFO misc.py line 117 288342] Train: [1/50][1198/2344] Data 0.003 (0.003) Batch 0.616 (0.615) Remain 19:48:42 loss: 0.8752 Lr: 0.00047
[2025-05-11 13:23:34,586 INFO misc.py line 117 288342] Train: [1/50][1199/2344] Data 0.003 (0.003) Batch 0.495 (0.615) Remain 19:48:30 loss: 0.7228 Lr: 0.00047
[2025-05-11 13:23:35,182 INFO misc.py line 117 288342] Train: [1/50][1200/2344] Data 0.003 (0.003) Batch 0.596 (0.615) Remain 19:48:28 loss: 1.1561 Lr: 0.00047
[2025-05-11 13:23:35,878 INFO misc.py line 117 288342] Train: [1/50][1201/2344] Data 0.002 (0.003) Batch 0.696 (0.615) Remain 19:48:35 loss: 0.9262 Lr: 0.00048
[2025-05-11 13:23:36,505 INFO misc.py line 117 288342] Train: [1/50][1202/2344] Data 0.003 (0.003) Batch 0.627 (0.615) Remain 19:48:35 loss: 0.9320 Lr: 0.00048
[2025-05-11 13:23:37,066 INFO misc.py line 117 288342] Train: [1/50][1203/2344] Data 0.002 (0.003) Batch 0.561 (0.615) Remain 19:48:30 loss: 1.0291 Lr: 0.00048
[2025-05-11 13:23:37,667 INFO misc.py line 117 288342] Train: [1/50][1204/2344] Data 0.002 (0.003) Batch 0.601 (0.615) Remain 19:48:28 loss: 1.0005 Lr: 0.00048
[2025-05-11 13:23:38,305 INFO misc.py line 117 288342] Train: [1/50][1205/2344] Data 0.002 (0.003) Batch 0.638 (0.615) Remain 19:48:29 loss: 0.9623 Lr: 0.00048
[2025-05-11 13:23:38,866 INFO misc.py line 117 288342] Train: [1/50][1206/2344] Data 0.002 (0.003) Batch 0.561 (0.615) Remain 19:48:24 loss: 1.1144 Lr: 0.00048
[2025-05-11 13:23:39,494 INFO misc.py line 117 288342] Train: [1/50][1207/2344] Data 0.002 (0.003) Batch 0.628 (0.615) Remain 19:48:24 loss: 0.9137 Lr: 0.00048
[2025-05-11 13:23:40,149 INFO misc.py line 117 288342] Train: [1/50][1208/2344] Data 0.003 (0.003) Batch 0.655 (0.615) Remain 19:48:27 loss: 1.1102 Lr: 0.00048
[2025-05-11 13:23:40,723 INFO misc.py line 117 288342] Train: [1/50][1209/2344] Data 0.003 (0.003) Batch 0.574 (0.615) Remain 19:48:23 loss: 0.9331 Lr: 0.00048
[2025-05-11 13:23:41,213 INFO misc.py line 117 288342] Train: [1/50][1210/2344] Data 0.003 (0.003) Batch 0.490 (0.615) Remain 19:48:10 loss: 1.0424 Lr: 0.00048
[2025-05-11 13:23:41,890 INFO misc.py line 117 288342] Train: [1/50][1211/2344] Data 0.003 (0.003) Batch 0.677 (0.615) Remain 19:48:16 loss: 0.7820 Lr: 0.00048
[2025-05-11 13:23:42,431 INFO misc.py line 117 288342] Train: [1/50][1212/2344] Data 0.003 (0.003) Batch 0.541 (0.615) Remain 19:48:08 loss: 0.9035 Lr: 0.00048
[2025-05-11 13:23:43,153 INFO misc.py line 117 288342] Train: [1/50][1213/2344] Data 0.002 (0.003) Batch 0.722 (0.615) Remain 19:48:18 loss: 0.8327 Lr: 0.00048
[2025-05-11 13:23:43,924 INFO misc.py line 117 288342] Train: [1/50][1214/2344] Data 0.003 (0.003) Batch 0.771 (0.615) Remain 19:48:32 loss: 1.1144 Lr: 0.00048
[2025-05-11 13:23:44,458 INFO misc.py line 117 288342] Train: [1/50][1215/2344] Data 0.003 (0.003) Batch 0.534 (0.615) Remain 19:48:24 loss: 0.8946 Lr: 0.00048
[2025-05-11 13:23:45,037 INFO misc.py line 117 288342] Train: [1/50][1216/2344] Data 0.003 (0.003) Batch 0.579 (0.615) Remain 19:48:20 loss: 0.8471 Lr: 0.00048
[2025-05-11 13:23:45,654 INFO misc.py line 117 288342] Train: [1/50][1217/2344] Data 0.003 (0.003) Batch 0.617 (0.615) Remain 19:48:19 loss: 0.7753 Lr: 0.00048
[2025-05-11 13:23:46,296 INFO misc.py line 117 288342] Train: [1/50][1218/2344] Data 0.003 (0.003) Batch 0.642 (0.615) Remain 19:48:21 loss: 0.8226 Lr: 0.00048
[2025-05-11 13:23:46,754 INFO misc.py line 117 288342] Train: [1/50][1219/2344] Data 0.002 (0.003) Batch 0.459 (0.615) Remain 19:48:06 loss: 0.7005 Lr: 0.00048
[2025-05-11 13:23:47,413 INFO misc.py line 117 288342] Train: [1/50][1220/2344] Data 0.002 (0.003) Batch 0.659 (0.615) Remain 19:48:09 loss: 0.9787 Lr: 0.00048
[2025-05-11 13:23:48,016 INFO misc.py line 117 288342] Train: [1/50][1221/2344] Data 0.002 (0.003) Batch 0.602 (0.615) Remain 19:48:08 loss: 1.0295 Lr: 0.00048
[2025-05-11 13:23:48,631 INFO misc.py line 117 288342] Train: [1/50][1222/2344] Data 0.002 (0.003) Batch 0.615 (0.615) Remain 19:48:07 loss: 0.9708 Lr: 0.00048
[2025-05-11 13:23:49,217 INFO misc.py line 117 288342] Train: [1/50][1223/2344] Data 0.002 (0.003) Batch 0.586 (0.615) Remain 19:48:04 loss: 1.0031 Lr: 0.00048
[2025-05-11 13:23:49,869 INFO misc.py line 117 288342] Train: [1/50][1224/2344] Data 0.003 (0.003) Batch 0.652 (0.615) Remain 19:48:07 loss: 1.0379 Lr: 0.00049
[2025-05-11 13:23:50,343 INFO misc.py line 117 288342] Train: [1/50][1225/2344] Data 0.003 (0.003) Batch 0.474 (0.615) Remain 19:47:53 loss: 1.0027 Lr: 0.00049
[2025-05-11 13:23:50,924 INFO misc.py line 117 288342] Train: [1/50][1226/2344] Data 0.003 (0.003) Batch 0.581 (0.615) Remain 19:47:49 loss: 0.9620 Lr: 0.00049
[2025-05-11 13:23:51,589 INFO misc.py line 117 288342] Train: [1/50][1227/2344] Data 0.003 (0.003) Batch 0.665 (0.615) Remain 19:47:53 loss: 0.9849 Lr: 0.00049
[2025-05-11 13:23:52,160 INFO misc.py line 117 288342] Train: [1/50][1228/2344] Data 0.003 (0.003) Batch 0.571 (0.615) Remain 19:47:48 loss: 1.0918 Lr: 0.00049
[2025-05-11 13:23:52,810 INFO misc.py line 117 288342] Train: [1/50][1229/2344] Data 0.003 (0.003) Batch 0.650 (0.615) Remain 19:47:51 loss: 1.0497 Lr: 0.00049
[2025-05-11 13:23:53,365 INFO misc.py line 117 288342] Train: [1/50][1230/2344] Data 0.002 (0.003) Batch 0.555 (0.615) Remain 19:47:45 loss: 0.8739 Lr: 0.00049
[2025-05-11 13:23:54,028 INFO misc.py line 117 288342] Train: [1/50][1231/2344] Data 0.002 (0.003) Batch 0.663 (0.615) Remain 19:47:49 loss: 1.0269 Lr: 0.00049
[2025-05-11 13:23:54,761 INFO misc.py line 117 288342] Train: [1/50][1232/2344] Data 0.002 (0.003) Batch 0.733 (0.615) Remain 19:47:59 loss: 1.2838 Lr: 0.00049
[2025-05-11 13:23:55,523 INFO misc.py line 117 288342] Train: [1/50][1233/2344] Data 0.002 (0.003) Batch 0.761 (0.615) Remain 19:48:12 loss: 1.0455 Lr: 0.00049
[2025-05-11 13:23:56,158 INFO misc.py line 117 288342] Train: [1/50][1234/2344] Data 0.003 (0.003) Batch 0.635 (0.615) Remain 19:48:14 loss: 0.9902 Lr: 0.00049
[2025-05-11 13:23:56,797 INFO misc.py line 117 288342] Train: [1/50][1235/2344] Data 0.003 (0.003) Batch 0.639 (0.615) Remain 19:48:15 loss: 1.0079 Lr: 0.00049
[2025-05-11 13:23:57,423 INFO misc.py line 117 288342] Train: [1/50][1236/2344] Data 0.003 (0.003) Batch 0.626 (0.615) Remain 19:48:16 loss: 0.9054 Lr: 0.00049
[2025-05-11 13:23:58,031 INFO misc.py line 117 288342] Train: [1/50][1237/2344] Data 0.003 (0.003) Batch 0.608 (0.615) Remain 19:48:15 loss: 1.0977 Lr: 0.00049
[2025-05-11 13:23:58,636 INFO misc.py line 117 288342] Train: [1/50][1238/2344] Data 0.003 (0.003) Batch 0.606 (0.615) Remain 19:48:13 loss: 1.0294 Lr: 0.00049
[2025-05-11 13:23:59,306 INFO misc.py line 117 288342] Train: [1/50][1239/2344] Data 0.002 (0.003) Batch 0.669 (0.615) Remain 19:48:18 loss: 1.0325 Lr: 0.00049
[2025-05-11 13:23:59,961 INFO misc.py line 117 288342] Train: [1/50][1240/2344] Data 0.003 (0.003) Batch 0.654 (0.615) Remain 19:48:21 loss: 0.8786 Lr: 0.00049
[2025-05-11 13:24:00,561 INFO misc.py line 117 288342] Train: [1/50][1241/2344] Data 0.003 (0.003) Batch 0.601 (0.615) Remain 19:48:19 loss: 1.1408 Lr: 0.00049
[2025-05-11 13:24:01,080 INFO misc.py line 117 288342] Train: [1/50][1242/2344] Data 0.002 (0.003) Batch 0.519 (0.615) Remain 19:48:09 loss: 0.9818 Lr: 0.00049
[2025-05-11 13:24:01,617 INFO misc.py line 117 288342] Train: [1/50][1243/2344] Data 0.002 (0.003) Batch 0.537 (0.615) Remain 19:48:01 loss: 1.1620 Lr: 0.00049
[2025-05-11 13:24:02,120 INFO misc.py line 117 288342] Train: [1/50][1244/2344] Data 0.003 (0.003) Batch 0.503 (0.615) Remain 19:47:50 loss: 1.1313 Lr: 0.00049
[2025-05-11 13:24:02,779 INFO misc.py line 117 288342] Train: [1/50][1245/2344] Data 0.003 (0.003) Batch 0.659 (0.615) Remain 19:47:54 loss: 0.8264 Lr: 0.00049
[2025-05-11 13:24:03,432 INFO misc.py line 117 288342] Train: [1/50][1246/2344] Data 0.003 (0.003) Batch 0.653 (0.615) Remain 19:47:57 loss: 1.0046 Lr: 0.00050
[2025-05-11 13:24:04,001 INFO misc.py line 117 288342] Train: [1/50][1247/2344] Data 0.003 (0.003) Batch 0.569 (0.615) Remain 19:47:52 loss: 0.9972 Lr: 0.00050
[2025-05-11 13:24:04,606 INFO misc.py line 117 288342] Train: [1/50][1248/2344] Data 0.003 (0.003) Batch 0.605 (0.615) Remain 19:47:50 loss: 1.0574 Lr: 0.00050
[2025-05-11 13:24:05,324 INFO misc.py line 117 288342] Train: [1/50][1249/2344] Data 0.003 (0.003) Batch 0.718 (0.615) Remain 19:47:59 loss: 1.0628 Lr: 0.00050
[2025-05-11 13:24:06,055 INFO misc.py line 117 288342] Train: [1/50][1250/2344] Data 0.002 (0.003) Batch 0.731 (0.615) Remain 19:48:10 loss: 0.8213 Lr: 0.00050
[2025-05-11 13:24:06,810 INFO misc.py line 117 288342] Train: [1/50][1251/2344] Data 0.003 (0.003) Batch 0.755 (0.615) Remain 19:48:22 loss: 0.9603 Lr: 0.00050
[2025-05-11 13:24:07,349 INFO misc.py line 117 288342] Train: [1/50][1252/2344] Data 0.003 (0.003) Batch 0.539 (0.615) Remain 19:48:14 loss: 1.2391 Lr: 0.00050
[2025-05-11 13:24:07,855 INFO misc.py line 117 288342] Train: [1/50][1253/2344] Data 0.003 (0.003) Batch 0.506 (0.615) Remain 19:48:04 loss: 1.1290 Lr: 0.00050
[2025-05-11 13:24:08,586 INFO misc.py line 117 288342] Train: [1/50][1254/2344] Data 0.003 (0.003) Batch 0.731 (0.615) Remain 19:48:14 loss: 1.0077 Lr: 0.00050
[2025-05-11 13:24:09,260 INFO misc.py line 117 288342] Train: [1/50][1255/2344] Data 0.003 (0.003) Batch 0.674 (0.615) Remain 19:48:19 loss: 0.8562 Lr: 0.00050
[2025-05-11 13:24:09,771 INFO misc.py line 117 288342] Train: [1/50][1256/2344] Data 0.003 (0.003) Batch 0.511 (0.615) Remain 19:48:08 loss: 1.3395 Lr: 0.00050
[2025-05-11 13:24:10,366 INFO misc.py line 117 288342] Train: [1/50][1257/2344] Data 0.003 (0.003) Batch 0.595 (0.615) Remain 19:48:06 loss: 1.0228 Lr: 0.00050
[2025-05-11 13:24:10,962 INFO misc.py line 117 288342] Train: [1/50][1258/2344] Data 0.002 (0.003) Batch 0.596 (0.615) Remain 19:48:04 loss: 0.9224 Lr: 0.00050
[2025-05-11 13:24:11,561 INFO misc.py line 117 288342] Train: [1/50][1259/2344] Data 0.003 (0.003) Batch 0.600 (0.615) Remain 19:48:02 loss: 0.8872 Lr: 0.00050
[2025-05-11 13:24:12,242 INFO misc.py line 117 288342] Train: [1/50][1260/2344] Data 0.002 (0.003) Batch 0.681 (0.615) Remain 19:48:07 loss: 0.7697 Lr: 0.00050
[2025-05-11 13:24:12,813 INFO misc.py line 117 288342] Train: [1/50][1261/2344] Data 0.002 (0.003) Batch 0.571 (0.615) Remain 19:48:02 loss: 1.2322 Lr: 0.00050
[2025-05-11 13:24:13,359 INFO misc.py line 117 288342] Train: [1/50][1262/2344] Data 0.002 (0.003) Batch 0.546 (0.615) Remain 19:47:55 loss: 1.1383 Lr: 0.00050
[2025-05-11 13:24:14,044 INFO misc.py line 117 288342] Train: [1/50][1263/2344] Data 0.002 (0.003) Batch 0.685 (0.615) Remain 19:48:01 loss: 0.9256 Lr: 0.00050
[2025-05-11 13:24:14,872 INFO misc.py line 117 288342] Train: [1/50][1264/2344] Data 0.002 (0.003) Batch 0.828 (0.615) Remain 19:48:20 loss: 1.0057 Lr: 0.00050
[2025-05-11 13:24:15,573 INFO misc.py line 117 288342] Train: [1/50][1265/2344] Data 0.003 (0.003) Batch 0.701 (0.615) Remain 19:48:28 loss: 1.1537 Lr: 0.00050
[2025-05-11 13:24:16,148 INFO misc.py line 117 288342] Train: [1/50][1266/2344] Data 0.003 (0.003) Batch 0.575 (0.615) Remain 19:48:23 loss: 0.9494 Lr: 0.00050
[2025-05-11 13:24:16,734 INFO misc.py line 117 288342] Train: [1/50][1267/2344] Data 0.002 (0.003) Batch 0.586 (0.615) Remain 19:48:20 loss: 1.4181 Lr: 0.00050
[2025-05-11 13:24:17,391 INFO misc.py line 117 288342] Train: [1/50][1268/2344] Data 0.003 (0.003) Batch 0.657 (0.615) Remain 19:48:23 loss: 0.8947 Lr: 0.00051
[2025-05-11 13:24:18,013 INFO misc.py line 117 288342] Train: [1/50][1269/2344] Data 0.003 (0.003) Batch 0.622 (0.615) Remain 19:48:23 loss: 0.9378 Lr: 0.00051
[2025-05-11 13:24:18,683 INFO misc.py line 117 288342] Train: [1/50][1270/2344] Data 0.002 (0.003) Batch 0.670 (0.615) Remain 19:48:28 loss: 0.8136 Lr: 0.00051
[2025-05-11 13:24:19,315 INFO misc.py line 117 288342] Train: [1/50][1271/2344] Data 0.003 (0.003) Batch 0.632 (0.615) Remain 19:48:29 loss: 0.8808 Lr: 0.00051
[2025-05-11 13:24:19,911 INFO misc.py line 117 288342] Train: [1/50][1272/2344] Data 0.002 (0.003) Batch 0.596 (0.615) Remain 19:48:26 loss: 0.8036 Lr: 0.00051
[2025-05-11 13:24:20,568 INFO misc.py line 117 288342] Train: [1/50][1273/2344] Data 0.003 (0.003) Batch 0.657 (0.615) Remain 19:48:29 loss: 1.0002 Lr: 0.00051
[2025-05-11 13:24:21,266 INFO misc.py line 117 288342] Train: [1/50][1274/2344] Data 0.002 (0.003) Batch 0.697 (0.615) Remain 19:48:36 loss: 0.8181 Lr: 0.00051
[2025-05-11 13:24:21,933 INFO misc.py line 117 288342] Train: [1/50][1275/2344] Data 0.003 (0.003) Batch 0.668 (0.615) Remain 19:48:40 loss: 0.7958 Lr: 0.00051
[2025-05-11 13:24:22,602 INFO misc.py line 117 288342] Train: [1/50][1276/2344] Data 0.003 (0.003) Batch 0.668 (0.615) Remain 19:48:45 loss: 1.1253 Lr: 0.00051
[2025-05-11 13:24:23,163 INFO misc.py line 117 288342] Train: [1/50][1277/2344] Data 0.003 (0.003) Batch 0.561 (0.615) Remain 19:48:39 loss: 1.0303 Lr: 0.00051
[2025-05-11 13:24:23,898 INFO misc.py line 117 288342] Train: [1/50][1278/2344] Data 0.003 (0.003) Batch 0.735 (0.615) Remain 19:48:49 loss: 1.0750 Lr: 0.00051
[2025-05-11 13:24:24,511 INFO misc.py line 117 288342] Train: [1/50][1279/2344] Data 0.003 (0.003) Batch 0.613 (0.615) Remain 19:48:49 loss: 0.9603 Lr: 0.00051
[2025-05-11 13:24:25,032 INFO misc.py line 117 288342] Train: [1/50][1280/2344] Data 0.003 (0.003) Batch 0.520 (0.615) Remain 19:48:39 loss: 0.7897 Lr: 0.00051
[2025-05-11 13:24:25,679 INFO misc.py line 117 288342] Train: [1/50][1281/2344] Data 0.003 (0.003) Batch 0.647 (0.615) Remain 19:48:42 loss: 1.0354 Lr: 0.00051
[2025-05-11 13:24:26,320 INFO misc.py line 117 288342] Train: [1/50][1282/2344] Data 0.003 (0.003) Batch 0.641 (0.615) Remain 19:48:43 loss: 1.1886 Lr: 0.00051
[2025-05-11 13:24:26,808 INFO misc.py line 117 288342] Train: [1/50][1283/2344] Data 0.003 (0.003) Batch 0.488 (0.615) Remain 19:48:31 loss: 1.0258 Lr: 0.00051
[2025-05-11 13:24:27,410 INFO misc.py line 117 288342] Train: [1/50][1284/2344] Data 0.003 (0.003) Batch 0.601 (0.615) Remain 19:48:29 loss: 0.9913 Lr: 0.00051
[2025-05-11 13:24:28,068 INFO misc.py line 117 288342] Train: [1/50][1285/2344] Data 0.003 (0.003) Batch 0.658 (0.615) Remain 19:48:33 loss: 1.1523 Lr: 0.00051
[2025-05-11 13:24:28,685 INFO misc.py line 117 288342] Train: [1/50][1286/2344] Data 0.003 (0.003) Batch 0.618 (0.615) Remain 19:48:32 loss: 0.8044 Lr: 0.00051
[2025-05-11 13:24:29,182 INFO misc.py line 117 288342] Train: [1/50][1287/2344] Data 0.003 (0.003) Batch 0.496 (0.615) Remain 19:48:21 loss: 1.0488 Lr: 0.00051
[2025-05-11 13:24:29,814 INFO misc.py line 117 288342] Train: [1/50][1288/2344] Data 0.002 (0.003) Batch 0.633 (0.615) Remain 19:48:22 loss: 0.9997 Lr: 0.00051
[2025-05-11 13:24:30,522 INFO misc.py line 117 288342] Train: [1/50][1289/2344] Data 0.002 (0.003) Batch 0.708 (0.615) Remain 19:48:30 loss: 1.1758 Lr: 0.00051
[2025-05-11 13:24:31,041 INFO misc.py line 117 288342] Train: [1/50][1290/2344] Data 0.003 (0.003) Batch 0.519 (0.615) Remain 19:48:20 loss: 0.9047 Lr: 0.00052
[2025-05-11 13:24:31,645 INFO misc.py line 117 288342] Train: [1/50][1291/2344] Data 0.002 (0.003) Batch 0.603 (0.615) Remain 19:48:19 loss: 0.7927 Lr: 0.00052
[2025-05-11 13:24:32,268 INFO misc.py line 117 288342] Train: [1/50][1292/2344] Data 0.003 (0.003) Batch 0.624 (0.615) Remain 19:48:19 loss: 0.8324 Lr: 0.00052
[2025-05-11 13:24:32,806 INFO misc.py line 117 288342] Train: [1/50][1293/2344] Data 0.002 (0.003) Batch 0.538 (0.615) Remain 19:48:11 loss: 1.0770 Lr: 0.00052
[2025-05-11 13:24:33,328 INFO misc.py line 117 288342] Train: [1/50][1294/2344] Data 0.003 (0.003) Batch 0.522 (0.615) Remain 19:48:02 loss: 0.9566 Lr: 0.00052
[2025-05-11 13:24:33,933 INFO misc.py line 117 288342] Train: [1/50][1295/2344] Data 0.003 (0.003) Batch 0.605 (0.615) Remain 19:48:01 loss: 0.7650 Lr: 0.00052
[2025-05-11 13:24:34,688 INFO misc.py line 117 288342] Train: [1/50][1296/2344] Data 0.003 (0.003) Batch 0.755 (0.615) Remain 19:48:13 loss: 1.0771 Lr: 0.00052
[2025-05-11 13:24:35,340 INFO misc.py line 117 288342] Train: [1/50][1297/2344] Data 0.002 (0.003) Batch 0.652 (0.615) Remain 19:48:15 loss: 0.8266 Lr: 0.00052
[2025-05-11 13:24:36,093 INFO misc.py line 117 288342] Train: [1/50][1298/2344] Data 0.003 (0.003) Batch 0.753 (0.615) Remain 19:48:27 loss: 0.8089 Lr: 0.00052
[2025-05-11 13:24:36,662 INFO misc.py line 117 288342] Train: [1/50][1299/2344] Data 0.002 (0.003) Batch 0.568 (0.615) Remain 19:48:22 loss: 0.8392 Lr: 0.00052
[2025-05-11 13:24:37,303 INFO misc.py line 117 288342] Train: [1/50][1300/2344] Data 0.003 (0.003) Batch 0.641 (0.615) Remain 19:48:24 loss: 0.9672 Lr: 0.00052
[2025-05-11 13:24:37,962 INFO misc.py line 117 288342] Train: [1/50][1301/2344] Data 0.003 (0.003) Batch 0.660 (0.615) Remain 19:48:27 loss: 0.9949 Lr: 0.00052
[2025-05-11 13:24:38,474 INFO misc.py line 117 288342] Train: [1/50][1302/2344] Data 0.002 (0.003) Batch 0.512 (0.615) Remain 19:48:18 loss: 0.9168 Lr: 0.00052
[2025-05-11 13:24:39,201 INFO misc.py line 117 288342] Train: [1/50][1303/2344] Data 0.002 (0.003) Batch 0.727 (0.615) Remain 19:48:27 loss: 0.9919 Lr: 0.00052
[2025-05-11 13:24:39,789 INFO misc.py line 117 288342] Train: [1/50][1304/2344] Data 0.003 (0.003) Batch 0.588 (0.615) Remain 19:48:24 loss: 0.9214 Lr: 0.00052
[2025-05-11 13:24:40,318 INFO misc.py line 117 288342] Train: [1/50][1305/2344] Data 0.003 (0.003) Batch 0.529 (0.615) Remain 19:48:16 loss: 0.8416 Lr: 0.00052
[2025-05-11 13:24:40,882 INFO misc.py line 117 288342] Train: [1/50][1306/2344] Data 0.003 (0.003) Batch 0.564 (0.615) Remain 19:48:10 loss: 0.8599 Lr: 0.00052
[2025-05-11 13:24:41,560 INFO misc.py line 117 288342] Train: [1/50][1307/2344] Data 0.002 (0.003) Batch 0.679 (0.615) Remain 19:48:15 loss: 0.7995 Lr: 0.00052
[2025-05-11 13:24:42,307 INFO misc.py line 117 288342] Train: [1/50][1308/2344] Data 0.003 (0.003) Batch 0.747 (0.615) Remain 19:48:26 loss: 1.1094 Lr: 0.00052
[2025-05-11 13:24:43,085 INFO misc.py line 117 288342] Train: [1/50][1309/2344] Data 0.003 (0.003) Batch 0.778 (0.615) Remain 19:48:40 loss: 0.9925 Lr: 0.00052
[2025-05-11 13:24:43,724 INFO misc.py line 117 288342] Train: [1/50][1310/2344] Data 0.003 (0.003) Batch 0.639 (0.615) Remain 19:48:42 loss: 0.9379 Lr: 0.00052
[2025-05-11 13:24:44,409 INFO misc.py line 117 288342] Train: [1/50][1311/2344] Data 0.003 (0.003) Batch 0.685 (0.615) Remain 19:48:47 loss: 0.9098 Lr: 0.00052
[2025-05-11 13:24:44,968 INFO misc.py line 117 288342] Train: [1/50][1312/2344] Data 0.003 (0.003) Batch 0.560 (0.615) Remain 19:48:42 loss: 0.9869 Lr: 0.00053
[2025-05-11 13:24:45,459 INFO misc.py line 117 288342] Train: [1/50][1313/2344] Data 0.002 (0.003) Batch 0.490 (0.615) Remain 19:48:30 loss: 0.9002 Lr: 0.00053
[2025-05-11 13:24:46,105 INFO misc.py line 117 288342] Train: [1/50][1314/2344] Data 0.003 (0.003) Batch 0.647 (0.615) Remain 19:48:32 loss: 0.9356 Lr: 0.00053
[2025-05-11 13:24:46,684 INFO misc.py line 117 288342] Train: [1/50][1315/2344] Data 0.003 (0.003) Batch 0.579 (0.615) Remain 19:48:28 loss: 0.8647 Lr: 0.00053
[2025-05-11 13:24:47,174 INFO misc.py line 117 288342] Train: [1/50][1316/2344] Data 0.002 (0.003) Batch 0.490 (0.615) Remain 19:48:17 loss: 1.1722 Lr: 0.00053
[2025-05-11 13:24:47,783 INFO misc.py line 117 288342] Train: [1/50][1317/2344] Data 0.002 (0.003) Batch 0.609 (0.615) Remain 19:48:15 loss: 1.1069 Lr: 0.00053
[2025-05-11 13:24:48,337 INFO misc.py line 117 288342] Train: [1/50][1318/2344] Data 0.003 (0.003) Batch 0.554 (0.615) Remain 19:48:09 loss: 1.1968 Lr: 0.00053
[2025-05-11 13:24:49,078 INFO misc.py line 117 288342] Train: [1/50][1319/2344] Data 0.003 (0.003) Batch 0.741 (0.615) Remain 19:48:20 loss: 0.7953 Lr: 0.00053
[2025-05-11 13:24:49,769 INFO misc.py line 117 288342] Train: [1/50][1320/2344] Data 0.002 (0.003) Batch 0.691 (0.615) Remain 19:48:26 loss: 0.8674 Lr: 0.00053
[2025-05-11 13:24:50,508 INFO misc.py line 117 288342] Train: [1/50][1321/2344] Data 0.003 (0.003) Batch 0.739 (0.615) Remain 19:48:36 loss: 0.8537 Lr: 0.00053
[2025-05-11 13:24:51,022 INFO misc.py line 117 288342] Train: [1/50][1322/2344] Data 0.003 (0.003) Batch 0.514 (0.615) Remain 19:48:27 loss: 0.9958 Lr: 0.00053
[2025-05-11 13:24:51,740 INFO misc.py line 117 288342] Train: [1/50][1323/2344] Data 0.002 (0.003) Batch 0.718 (0.615) Remain 19:48:35 loss: 0.8848 Lr: 0.00053
[2025-05-11 13:24:52,268 INFO misc.py line 117 288342] Train: [1/50][1324/2344] Data 0.002 (0.003) Batch 0.528 (0.615) Remain 19:48:27 loss: 0.9278 Lr: 0.00053
[2025-05-11 13:24:52,849 INFO misc.py line 117 288342] Train: [1/50][1325/2344] Data 0.003 (0.003) Batch 0.582 (0.615) Remain 19:48:23 loss: 0.8999 Lr: 0.00053
[2025-05-11 13:24:53,595 INFO misc.py line 117 288342] Train: [1/50][1326/2344] Data 0.003 (0.003) Batch 0.745 (0.615) Remain 19:48:34 loss: 0.9094 Lr: 0.00053
[2025-05-11 13:24:54,139 INFO misc.py line 117 288342] Train: [1/50][1327/2344] Data 0.003 (0.003) Batch 0.544 (0.615) Remain 19:48:27 loss: 0.8163 Lr: 0.00053
[2025-05-11 13:24:54,750 INFO misc.py line 117 288342] Train: [1/50][1328/2344] Data 0.003 (0.003) Batch 0.611 (0.615) Remain 19:48:26 loss: 0.9019 Lr: 0.00053
[2025-05-11 13:24:55,481 INFO misc.py line 117 288342] Train: [1/50][1329/2344] Data 0.003 (0.003) Batch 0.731 (0.615) Remain 19:48:36 loss: 0.9105 Lr: 0.00053
[2025-05-11 13:24:56,011 INFO misc.py line 117 288342] Train: [1/50][1330/2344] Data 0.003 (0.003) Batch 0.530 (0.615) Remain 19:48:28 loss: 0.7894 Lr: 0.00053
[2025-05-11 13:24:56,677 INFO misc.py line 117 288342] Train: [1/50][1331/2344] Data 0.003 (0.003) Batch 0.667 (0.615) Remain 19:48:31 loss: 0.9116 Lr: 0.00053
[2025-05-11 13:24:57,349 INFO misc.py line 117 288342] Train: [1/50][1332/2344] Data 0.003 (0.003) Batch 0.671 (0.615) Remain 19:48:36 loss: 0.9539 Lr: 0.00053
[2025-05-11 13:24:57,960 INFO misc.py line 117 288342] Train: [1/50][1333/2344] Data 0.003 (0.003) Batch 0.611 (0.615) Remain 19:48:35 loss: 1.0104 Lr: 0.00054
[2025-05-11 13:24:58,512 INFO misc.py line 117 288342] Train: [1/50][1334/2344] Data 0.002 (0.003) Batch 0.552 (0.615) Remain 19:48:29 loss: 0.9258 Lr: 0.00054
[2025-05-11 13:24:59,199 INFO misc.py line 117 288342] Train: [1/50][1335/2344] Data 0.003 (0.003) Batch 0.687 (0.615) Remain 19:48:34 loss: 0.9240 Lr: 0.00054
[2025-05-11 13:24:59,880 INFO misc.py line 117 288342] Train: [1/50][1336/2344] Data 0.003 (0.003) Batch 0.681 (0.616) Remain 19:48:39 loss: 0.9598 Lr: 0.00054
[2025-05-11 13:25:00,366 INFO misc.py line 117 288342] Train: [1/50][1337/2344] Data 0.003 (0.003) Batch 0.486 (0.615) Remain 19:48:27 loss: 1.1023 Lr: 0.00054
[2025-05-11 13:25:01,109 INFO misc.py line 117 288342] Train: [1/50][1338/2344] Data 0.003 (0.003) Batch 0.742 (0.616) Remain 19:48:38 loss: 0.9448 Lr: 0.00054
[2025-05-11 13:25:01,726 INFO misc.py line 117 288342] Train: [1/50][1339/2344] Data 0.003 (0.003) Batch 0.617 (0.616) Remain 19:48:37 loss: 0.7739 Lr: 0.00054
[2025-05-11 13:25:02,422 INFO misc.py line 117 288342] Train: [1/50][1340/2344] Data 0.002 (0.003) Batch 0.696 (0.616) Remain 19:48:44 loss: 0.9138 Lr: 0.00054
[2025-05-11 13:25:02,999 INFO misc.py line 117 288342] Train: [1/50][1341/2344] Data 0.003 (0.003) Batch 0.577 (0.616) Remain 19:48:40 loss: 1.1407 Lr: 0.00054
[2025-05-11 13:25:03,737 INFO misc.py line 117 288342] Train: [1/50][1342/2344] Data 0.003 (0.003) Batch 0.738 (0.616) Remain 19:48:50 loss: 0.9894 Lr: 0.00054
[2025-05-11 13:25:04,365 INFO misc.py line 117 288342] Train: [1/50][1343/2344] Data 0.002 (0.003) Batch 0.628 (0.616) Remain 19:48:50 loss: 0.8955 Lr: 0.00054
[2025-05-11 13:25:04,850 INFO misc.py line 117 288342] Train: [1/50][1344/2344] Data 0.003 (0.003) Batch 0.485 (0.616) Remain 19:48:38 loss: 0.9606 Lr: 0.00054
[2025-05-11 13:25:05,601 INFO misc.py line 117 288342] Train: [1/50][1345/2344] Data 0.003 (0.003) Batch 0.751 (0.616) Remain 19:48:49 loss: 0.8582 Lr: 0.00054
[2025-05-11 13:25:06,205 INFO misc.py line 117 288342] Train: [1/50][1346/2344] Data 0.003 (0.003) Batch 0.604 (0.616) Remain 19:48:48 loss: 1.2733 Lr: 0.00054
[2025-05-11 13:25:06,904 INFO misc.py line 117 288342] Train: [1/50][1347/2344] Data 0.002 (0.003) Batch 0.699 (0.616) Remain 19:48:54 loss: 0.8704 Lr: 0.00054
[2025-05-11 13:25:07,563 INFO misc.py line 117 288342] Train: [1/50][1348/2344] Data 0.002 (0.003) Batch 0.659 (0.616) Remain 19:48:57 loss: 1.0358 Lr: 0.00054
[2025-05-11 13:25:08,161 INFO misc.py line 117 288342] Train: [1/50][1349/2344] Data 0.003 (0.003) Batch 0.598 (0.616) Remain 19:48:55 loss: 0.9304 Lr: 0.00054
[2025-05-11 13:25:08,887 INFO misc.py line 117 288342] Train: [1/50][1350/2344] Data 0.002 (0.003) Batch 0.725 (0.616) Remain 19:49:04 loss: 1.0094 Lr: 0.00054
[2025-05-11 13:25:09,418 INFO misc.py line 117 288342] Train: [1/50][1351/2344] Data 0.003 (0.003) Batch 0.531 (0.616) Remain 19:48:56 loss: 1.0799 Lr: 0.00054
[2025-05-11 13:25:10,007 INFO misc.py line 117 288342] Train: [1/50][1352/2344] Data 0.002 (0.003) Batch 0.589 (0.616) Remain 19:48:53 loss: 0.7643 Lr: 0.00054
[2025-05-11 13:25:10,866 INFO misc.py line 117 288342] Train: [1/50][1353/2344] Data 0.002 (0.003) Batch 0.859 (0.616) Remain 19:49:14 loss: 1.0627 Lr: 0.00054
[2025-05-11 13:25:11,517 INFO misc.py line 117 288342] Train: [1/50][1354/2344] Data 0.003 (0.003) Batch 0.650 (0.616) Remain 19:49:16 loss: 0.7813 Lr: 0.00054
[2025-05-11 13:25:12,171 INFO misc.py line 117 288342] Train: [1/50][1355/2344] Data 0.003 (0.003) Batch 0.654 (0.616) Remain 19:49:19 loss: 1.2259 Lr: 0.00055
[2025-05-11 13:25:12,896 INFO misc.py line 117 288342] Train: [1/50][1356/2344] Data 0.003 (0.003) Batch 0.726 (0.616) Remain 19:49:27 loss: 0.9212 Lr: 0.00055
[2025-05-11 13:25:13,497 INFO misc.py line 117 288342] Train: [1/50][1357/2344] Data 0.002 (0.003) Batch 0.600 (0.616) Remain 19:49:25 loss: 1.0850 Lr: 0.00055
[2025-05-11 13:25:14,004 INFO misc.py line 117 288342] Train: [1/50][1358/2344] Data 0.003 (0.003) Batch 0.508 (0.616) Remain 19:49:15 loss: 1.0306 Lr: 0.00055
[2025-05-11 13:25:14,599 INFO misc.py line 117 288342] Train: [1/50][1359/2344] Data 0.003 (0.003) Batch 0.594 (0.616) Remain 19:49:13 loss: 0.9627 Lr: 0.00055
[2025-05-11 13:25:15,165 INFO misc.py line 117 288342] Train: [1/50][1360/2344] Data 0.002 (0.003) Batch 0.566 (0.616) Remain 19:49:08 loss: 0.9062 Lr: 0.00055
[2025-05-11 13:25:15,848 INFO misc.py line 117 288342] Train: [1/50][1361/2344] Data 0.002 (0.003) Batch 0.683 (0.616) Remain 19:49:13 loss: 1.0640 Lr: 0.00055
[2025-05-11 13:25:16,492 INFO misc.py line 117 288342] Train: [1/50][1362/2344] Data 0.002 (0.003) Batch 0.643 (0.616) Remain 19:49:15 loss: 1.0736 Lr: 0.00055
[2025-05-11 13:25:17,119 INFO misc.py line 117 288342] Train: [1/50][1363/2344] Data 0.003 (0.003) Batch 0.627 (0.616) Remain 19:49:15 loss: 1.0090 Lr: 0.00055
[2025-05-11 13:25:17,721 INFO misc.py line 117 288342] Train: [1/50][1364/2344] Data 0.002 (0.003) Batch 0.602 (0.616) Remain 19:49:14 loss: 0.9406 Lr: 0.00055
[2025-05-11 13:25:18,449 INFO misc.py line 117 288342] Train: [1/50][1365/2344] Data 0.002 (0.003) Batch 0.727 (0.616) Remain 19:49:22 loss: 0.9457 Lr: 0.00055
[2025-05-11 13:25:19,143 INFO misc.py line 117 288342] Train: [1/50][1366/2344] Data 0.003 (0.003) Batch 0.695 (0.616) Remain 19:49:28 loss: 0.8663 Lr: 0.00055
[2025-05-11 13:25:19,648 INFO misc.py line 117 288342] Train: [1/50][1367/2344] Data 0.002 (0.003) Batch 0.504 (0.616) Remain 19:49:18 loss: 1.0830 Lr: 0.00055
[2025-05-11 13:25:20,089 INFO misc.py line 117 288342] Train: [1/50][1368/2344] Data 0.002 (0.003) Batch 0.441 (0.616) Remain 19:49:03 loss: 0.9189 Lr: 0.00055
[2025-05-11 13:25:20,675 INFO misc.py line 117 288342] Train: [1/50][1369/2344] Data 0.003 (0.003) Batch 0.585 (0.616) Remain 19:49:00 loss: 0.9794 Lr: 0.00055
[2025-05-11 13:25:21,416 INFO misc.py line 117 288342] Train: [1/50][1370/2344] Data 0.004 (0.003) Batch 0.742 (0.616) Remain 19:49:10 loss: 0.9755 Lr: 0.00055
[2025-05-11 13:25:22,019 INFO misc.py line 117 288342] Train: [1/50][1371/2344] Data 0.003 (0.003) Batch 0.603 (0.616) Remain 19:49:08 loss: 0.9681 Lr: 0.00055
[2025-05-11 13:25:22,645 INFO misc.py line 117 288342] Train: [1/50][1372/2344] Data 0.002 (0.003) Batch 0.626 (0.616) Remain 19:49:08 loss: 0.8260 Lr: 0.00055
[2025-05-11 13:25:23,285 INFO misc.py line 117 288342] Train: [1/50][1373/2344] Data 0.002 (0.003) Batch 0.640 (0.616) Remain 19:49:10 loss: 1.2019 Lr: 0.00055
[2025-05-11 13:25:23,865 INFO misc.py line 117 288342] Train: [1/50][1374/2344] Data 0.003 (0.003) Batch 0.580 (0.616) Remain 19:49:06 loss: 1.0101 Lr: 0.00055
[2025-05-11 13:25:24,479 INFO misc.py line 117 288342] Train: [1/50][1375/2344] Data 0.002 (0.003) Batch 0.614 (0.616) Remain 19:49:05 loss: 1.0003 Lr: 0.00055
[2025-05-11 13:25:25,055 INFO misc.py line 117 288342] Train: [1/50][1376/2344] Data 0.002 (0.003) Batch 0.576 (0.616) Remain 19:49:01 loss: 0.8316 Lr: 0.00056
[2025-05-11 13:25:25,684 INFO misc.py line 117 288342] Train: [1/50][1377/2344] Data 0.003 (0.003) Batch 0.629 (0.616) Remain 19:49:02 loss: 1.0318 Lr: 0.00056
[2025-05-11 13:25:26,337 INFO misc.py line 117 288342] Train: [1/50][1378/2344] Data 0.002 (0.003) Batch 0.653 (0.616) Remain 19:49:04 loss: 1.0094 Lr: 0.00056
[2025-05-11 13:25:26,953 INFO misc.py line 117 288342] Train: [1/50][1379/2344] Data 0.002 (0.003) Batch 0.617 (0.616) Remain 19:49:04 loss: 0.9077 Lr: 0.00056
[2025-05-11 13:25:27,553 INFO misc.py line 117 288342] Train: [1/50][1380/2344] Data 0.002 (0.003) Batch 0.599 (0.616) Remain 19:49:02 loss: 1.0409 Lr: 0.00056
[2025-05-11 13:25:28,291 INFO misc.py line 117 288342] Train: [1/50][1381/2344] Data 0.002 (0.003) Batch 0.738 (0.616) Remain 19:49:11 loss: 0.9889 Lr: 0.00056
[2025-05-11 13:25:28,948 INFO misc.py line 117 288342] Train: [1/50][1382/2344] Data 0.003 (0.003) Batch 0.657 (0.616) Remain 19:49:14 loss: 0.8851 Lr: 0.00056
[2025-05-11 13:25:29,628 INFO misc.py line 117 288342] Train: [1/50][1383/2344] Data 0.003 (0.003) Batch 0.681 (0.616) Remain 19:49:19 loss: 0.9800 Lr: 0.00056
[2025-05-11 13:25:30,396 INFO misc.py line 117 288342] Train: [1/50][1384/2344] Data 0.002 (0.003) Batch 0.768 (0.616) Remain 19:49:31 loss: 0.9168 Lr: 0.00056
[2025-05-11 13:25:31,070 INFO misc.py line 117 288342] Train: [1/50][1385/2344] Data 0.002 (0.003) Batch 0.674 (0.616) Remain 19:49:35 loss: 0.9168 Lr: 0.00056
[2025-05-11 13:25:31,737 INFO misc.py line 117 288342] Train: [1/50][1386/2344] Data 0.003 (0.003) Batch 0.667 (0.616) Remain 19:49:39 loss: 0.8896 Lr: 0.00056
[2025-05-11 13:25:32,321 INFO misc.py line 117 288342] Train: [1/50][1387/2344] Data 0.003 (0.003) Batch 0.585 (0.616) Remain 19:49:36 loss: 0.8439 Lr: 0.00056
[2025-05-11 13:25:32,885 INFO misc.py line 117 288342] Train: [1/50][1388/2344] Data 0.002 (0.003) Batch 0.564 (0.616) Remain 19:49:31 loss: 0.8874 Lr: 0.00056
[2025-05-11 13:25:33,421 INFO misc.py line 117 288342] Train: [1/50][1389/2344] Data 0.002 (0.003) Batch 0.535 (0.616) Remain 19:49:23 loss: 0.8468 Lr: 0.00056
[2025-05-11 13:25:34,123 INFO misc.py line 117 288342] Train: [1/50][1390/2344] Data 0.003 (0.003) Batch 0.703 (0.616) Remain 19:49:30 loss: 1.0251 Lr: 0.00056
[2025-05-11 13:25:34,683 INFO misc.py line 117 288342] Train: [1/50][1391/2344] Data 0.003 (0.003) Batch 0.559 (0.616) Remain 19:49:24 loss: 0.8700 Lr: 0.00056
[2025-05-11 13:25:35,276 INFO misc.py line 117 288342] Train: [1/50][1392/2344] Data 0.003 (0.003) Batch 0.593 (0.616) Remain 19:49:22 loss: 0.9137 Lr: 0.00056
[2025-05-11 13:25:35,800 INFO misc.py line 117 288342] Train: [1/50][1393/2344] Data 0.002 (0.003) Batch 0.524 (0.616) Remain 19:49:14 loss: 0.8913 Lr: 0.00056
[2025-05-11 13:25:36,430 INFO misc.py line 117 288342] Train: [1/50][1394/2344] Data 0.003 (0.003) Batch 0.630 (0.616) Remain 19:49:14 loss: 1.0093 Lr: 0.00056
[2025-05-11 13:25:37,120 INFO misc.py line 117 288342] Train: [1/50][1395/2344] Data 0.003 (0.003) Batch 0.690 (0.616) Remain 19:49:20 loss: 0.9020 Lr: 0.00056
[2025-05-11 13:25:37,676 INFO misc.py line 117 288342] Train: [1/50][1396/2344] Data 0.003 (0.003) Batch 0.556 (0.616) Remain 19:49:14 loss: 0.7327 Lr: 0.00057
[2025-05-11 13:25:38,312 INFO misc.py line 117 288342] Train: [1/50][1397/2344] Data 0.003 (0.003) Batch 0.637 (0.616) Remain 19:49:15 loss: 0.7961 Lr: 0.00057
[2025-05-11 13:25:38,808 INFO misc.py line 117 288342] Train: [1/50][1398/2344] Data 0.002 (0.003) Batch 0.496 (0.616) Remain 19:49:05 loss: 1.4018 Lr: 0.00057
[2025-05-11 13:25:39,403 INFO misc.py line 117 288342] Train: [1/50][1399/2344] Data 0.002 (0.003) Batch 0.595 (0.616) Remain 19:49:02 loss: 0.9600 Lr: 0.00057
[2025-05-11 13:25:40,027 INFO misc.py line 117 288342] Train: [1/50][1400/2344] Data 0.003 (0.003) Batch 0.624 (0.616) Remain 19:49:02 loss: 0.9439 Lr: 0.00057
[2025-05-11 13:25:40,599 INFO misc.py line 117 288342] Train: [1/50][1401/2344] Data 0.002 (0.003) Batch 0.572 (0.616) Remain 19:48:58 loss: 0.7697 Lr: 0.00057
[2025-05-11 13:25:41,206 INFO misc.py line 117 288342] Train: [1/50][1402/2344] Data 0.002 (0.003) Batch 0.607 (0.616) Remain 19:48:57 loss: 0.9186 Lr: 0.00057
[2025-05-11 13:25:41,745 INFO misc.py line 117 288342] Train: [1/50][1403/2344] Data 0.002 (0.003) Batch 0.539 (0.616) Remain 19:48:50 loss: 1.0171 Lr: 0.00057
[2025-05-11 13:25:42,444 INFO misc.py line 117 288342] Train: [1/50][1404/2344] Data 0.002 (0.003) Batch 0.699 (0.616) Remain 19:48:56 loss: 0.7693 Lr: 0.00057
[2025-05-11 13:25:42,963 INFO misc.py line 117 288342] Train: [1/50][1405/2344] Data 0.002 (0.003) Batch 0.520 (0.616) Remain 19:48:47 loss: 0.8894 Lr: 0.00057
[2025-05-11 13:25:43,543 INFO misc.py line 117 288342] Train: [1/50][1406/2344] Data 0.003 (0.003) Batch 0.579 (0.616) Remain 19:48:44 loss: 1.2047 Lr: 0.00057
[2025-05-11 13:25:44,197 INFO misc.py line 117 288342] Train: [1/50][1407/2344] Data 0.003 (0.003) Batch 0.655 (0.616) Remain 19:48:46 loss: 0.9233 Lr: 0.00057
[2025-05-11 13:25:44,918 INFO misc.py line 117 288342] Train: [1/50][1408/2344] Data 0.002 (0.003) Batch 0.721 (0.616) Remain 19:48:54 loss: 0.9883 Lr: 0.00057
[2025-05-11 13:25:45,516 INFO misc.py line 117 288342] Train: [1/50][1409/2344] Data 0.002 (0.003) Batch 0.598 (0.616) Remain 19:48:52 loss: 0.9264 Lr: 0.00057
[2025-05-11 13:25:46,084 INFO misc.py line 117 288342] Train: [1/50][1410/2344] Data 0.002 (0.003) Batch 0.567 (0.616) Remain 19:48:47 loss: 1.0653 Lr: 0.00057
[2025-05-11 13:25:46,776 INFO misc.py line 117 288342] Train: [1/50][1411/2344] Data 0.003 (0.003) Batch 0.692 (0.616) Remain 19:48:53 loss: 1.1121 Lr: 0.00057
[2025-05-11 13:25:47,360 INFO misc.py line 117 288342] Train: [1/50][1412/2344] Data 0.003 (0.003) Batch 0.584 (0.616) Remain 19:48:50 loss: 1.1404 Lr: 0.00057
[2025-05-11 13:25:47,966 INFO misc.py line 117 288342] Train: [1/50][1413/2344] Data 0.002 (0.003) Batch 0.606 (0.616) Remain 19:48:48 loss: 1.0929 Lr: 0.00057
[2025-05-11 13:25:48,525 INFO misc.py line 117 288342] Train: [1/50][1414/2344] Data 0.003 (0.003) Batch 0.559 (0.616) Remain 19:48:43 loss: 0.7971 Lr: 0.00057
[2025-05-11 13:25:49,257 INFO misc.py line 117 288342] Train: [1/50][1415/2344] Data 0.003 (0.003) Batch 0.732 (0.616) Remain 19:48:52 loss: 0.9877 Lr: 0.00057
[2025-05-11 13:25:49,927 INFO misc.py line 117 288342] Train: [1/50][1416/2344] Data 0.003 (0.003) Batch 0.670 (0.616) Remain 19:48:56 loss: 1.0789 Lr: 0.00057
[2025-05-11 13:25:50,520 INFO misc.py line 117 288342] Train: [1/50][1417/2344] Data 0.003 (0.003) Batch 0.593 (0.616) Remain 19:48:53 loss: 0.9645 Lr: 0.00058
[2025-05-11 13:25:51,190 INFO misc.py line 117 288342] Train: [1/50][1418/2344] Data 0.003 (0.003) Batch 0.669 (0.616) Remain 19:48:57 loss: 1.1711 Lr: 0.00058
[2025-05-11 13:25:51,746 INFO misc.py line 117 288342] Train: [1/50][1419/2344] Data 0.003 (0.003) Batch 0.556 (0.616) Remain 19:48:52 loss: 1.0317 Lr: 0.00058
[2025-05-11 13:25:52,350 INFO misc.py line 117 288342] Train: [1/50][1420/2344] Data 0.002 (0.003) Batch 0.604 (0.616) Remain 19:48:50 loss: 0.9336 Lr: 0.00058
[2025-05-11 13:25:52,936 INFO misc.py line 117 288342] Train: [1/50][1421/2344] Data 0.003 (0.003) Batch 0.586 (0.616) Remain 19:48:47 loss: 0.9518 Lr: 0.00058
[2025-05-11 13:25:53,615 INFO misc.py line 117 288342] Train: [1/50][1422/2344] Data 0.002 (0.003) Batch 0.679 (0.616) Remain 19:48:51 loss: 0.7835 Lr: 0.00058
[2025-05-11 13:25:54,288 INFO misc.py line 117 288342] Train: [1/50][1423/2344] Data 0.002 (0.003) Batch 0.673 (0.616) Remain 19:48:55 loss: 0.9195 Lr: 0.00058
[2025-05-11 13:25:54,805 INFO misc.py line 117 288342] Train: [1/50][1424/2344] Data 0.002 (0.003) Batch 0.517 (0.616) Remain 19:48:47 loss: 1.1199 Lr: 0.00058
[2025-05-11 13:25:55,613 INFO misc.py line 117 288342] Train: [1/50][1425/2344] Data 0.003 (0.003) Batch 0.808 (0.616) Remain 19:49:02 loss: 0.9589 Lr: 0.00058
[2025-05-11 13:25:56,192 INFO misc.py line 117 288342] Train: [1/50][1426/2344] Data 0.002 (0.003) Batch 0.578 (0.616) Remain 19:48:58 loss: 1.0441 Lr: 0.00058
[2025-05-11 13:25:56,801 INFO misc.py line 117 288342] Train: [1/50][1427/2344] Data 0.002 (0.003) Batch 0.610 (0.616) Remain 19:48:57 loss: 1.0540 Lr: 0.00058
[2025-05-11 13:25:57,425 INFO misc.py line 117 288342] Train: [1/50][1428/2344] Data 0.003 (0.003) Batch 0.624 (0.616) Remain 19:48:57 loss: 1.0398 Lr: 0.00058
[2025-05-11 13:25:57,993 INFO misc.py line 117 288342] Train: [1/50][1429/2344] Data 0.002 (0.003) Batch 0.567 (0.616) Remain 19:48:52 loss: 0.8026 Lr: 0.00058
[2025-05-11 13:25:58,561 INFO misc.py line 117 288342] Train: [1/50][1430/2344] Data 0.002 (0.003) Batch 0.568 (0.616) Remain 19:48:48 loss: 1.1682 Lr: 0.00058
[2025-05-11 13:25:59,210 INFO misc.py line 117 288342] Train: [1/50][1431/2344] Data 0.002 (0.003) Batch 0.649 (0.616) Remain 19:48:50 loss: 1.0534 Lr: 0.00058
[2025-05-11 13:25:59,900 INFO misc.py line 117 288342] Train: [1/50][1432/2344] Data 0.002 (0.003) Batch 0.691 (0.616) Remain 19:48:55 loss: 0.9103 Lr: 0.00058
[2025-05-11 13:26:00,608 INFO misc.py line 117 288342] Train: [1/50][1433/2344] Data 0.003 (0.003) Batch 0.707 (0.616) Remain 19:49:02 loss: 1.4900 Lr: 0.00058
[2025-05-11 13:26:01,262 INFO misc.py line 117 288342] Train: [1/50][1434/2344] Data 0.002 (0.003) Batch 0.654 (0.616) Remain 19:49:05 loss: 0.9109 Lr: 0.00058
[2025-05-11 13:26:01,756 INFO misc.py line 117 288342] Train: [1/50][1435/2344] Data 0.002 (0.003) Batch 0.494 (0.616) Remain 19:48:54 loss: 1.0122 Lr: 0.00058
[2025-05-11 13:26:02,368 INFO misc.py line 117 288342] Train: [1/50][1436/2344] Data 0.003 (0.003) Batch 0.612 (0.616) Remain 19:48:53 loss: 0.9325 Lr: 0.00058
[2025-05-11 13:26:03,107 INFO misc.py line 117 288342] Train: [1/50][1437/2344] Data 0.003 (0.003) Batch 0.740 (0.616) Remain 19:49:02 loss: 0.8091 Lr: 0.00059
[2025-05-11 13:26:03,604 INFO misc.py line 117 288342] Train: [1/50][1438/2344] Data 0.003 (0.003) Batch 0.497 (0.616) Remain 19:48:52 loss: 1.2576 Lr: 0.00059
[2025-05-11 13:26:04,218 INFO misc.py line 117 288342] Train: [1/50][1439/2344] Data 0.003 (0.003) Batch 0.614 (0.616) Remain 19:48:51 loss: 0.7956 Lr: 0.00059
[2025-05-11 13:26:04,829 INFO misc.py line 117 288342] Train: [1/50][1440/2344] Data 0.003 (0.003) Batch 0.611 (0.616) Remain 19:48:50 loss: 1.0285 Lr: 0.00059
[2025-05-11 13:26:05,466 INFO misc.py line 117 288342] Train: [1/50][1441/2344] Data 0.003 (0.003) Batch 0.637 (0.616) Remain 19:48:51 loss: 0.7976 Lr: 0.00059
[2025-05-11 13:26:06,118 INFO misc.py line 117 288342] Train: [1/50][1442/2344] Data 0.003 (0.003) Batch 0.653 (0.616) Remain 19:48:54 loss: 1.0066 Lr: 0.00059
[2025-05-11 13:26:06,846 INFO misc.py line 117 288342] Train: [1/50][1443/2344] Data 0.003 (0.003) Batch 0.727 (0.616) Remain 19:49:02 loss: 1.1645 Lr: 0.00059
[2025-05-11 13:26:07,379 INFO misc.py line 117 288342] Train: [1/50][1444/2344] Data 0.003 (0.003) Batch 0.533 (0.616) Remain 19:48:55 loss: 1.1318 Lr: 0.00059
[2025-05-11 13:26:07,832 INFO misc.py line 117 288342] Train: [1/50][1445/2344] Data 0.003 (0.003) Batch 0.454 (0.616) Remain 19:48:41 loss: 0.9209 Lr: 0.00059
[2025-05-11 13:26:08,407 INFO misc.py line 117 288342] Train: [1/50][1446/2344] Data 0.003 (0.003) Batch 0.575 (0.616) Remain 19:48:37 loss: 0.9862 Lr: 0.00059
[2025-05-11 13:26:08,971 INFO misc.py line 117 288342] Train: [1/50][1447/2344] Data 0.002 (0.003) Batch 0.564 (0.616) Remain 19:48:32 loss: 0.9400 Lr: 0.00059
[2025-05-11 13:26:09,503 INFO misc.py line 117 288342] Train: [1/50][1448/2344] Data 0.003 (0.003) Batch 0.532 (0.616) Remain 19:48:25 loss: 0.8761 Lr: 0.00059
[2025-05-11 13:26:10,074 INFO misc.py line 117 288342] Train: [1/50][1449/2344] Data 0.003 (0.003) Batch 0.571 (0.616) Remain 19:48:21 loss: 0.9329 Lr: 0.00059
[2025-05-11 13:26:10,505 INFO misc.py line 117 288342] Train: [1/50][1450/2344] Data 0.003 (0.003) Batch 0.431 (0.616) Remain 19:48:05 loss: 0.7988 Lr: 0.00059
[2025-05-11 13:26:11,011 INFO misc.py line 117 288342] Train: [1/50][1451/2344] Data 0.003 (0.003) Batch 0.506 (0.616) Remain 19:47:56 loss: 1.3548 Lr: 0.00059
[2025-05-11 13:26:11,701 INFO misc.py line 117 288342] Train: [1/50][1452/2344] Data 0.003 (0.003) Batch 0.690 (0.616) Remain 19:48:01 loss: 0.9132 Lr: 0.00059
[2025-05-11 13:26:12,241 INFO misc.py line 117 288342] Train: [1/50][1453/2344] Data 0.002 (0.003) Batch 0.539 (0.616) Remain 19:47:54 loss: 0.9333 Lr: 0.00059
[2025-05-11 13:26:12,930 INFO misc.py line 117 288342] Train: [1/50][1454/2344] Data 0.003 (0.003) Batch 0.690 (0.616) Remain 19:48:00 loss: 0.8999 Lr: 0.00059
[2025-05-11 13:26:13,456 INFO misc.py line 117 288342] Train: [1/50][1455/2344] Data 0.003 (0.003) Batch 0.526 (0.616) Remain 19:47:52 loss: 1.1282 Lr: 0.00059
[2025-05-11 13:26:13,912 INFO misc.py line 117 288342] Train: [1/50][1456/2344] Data 0.003 (0.003) Batch 0.456 (0.616) Remain 19:47:39 loss: 0.8479 Lr: 0.00059
[2025-05-11 13:26:14,538 INFO misc.py line 117 288342] Train: [1/50][1457/2344] Data 0.003 (0.003) Batch 0.625 (0.616) Remain 19:47:39 loss: 0.8899 Lr: 0.00060
[2025-05-11 13:26:15,287 INFO misc.py line 117 288342] Train: [1/50][1458/2344] Data 0.003 (0.003) Batch 0.749 (0.616) Remain 19:47:49 loss: 0.9832 Lr: 0.00060
[2025-05-11 13:26:15,750 INFO misc.py line 117 288342] Train: [1/50][1459/2344] Data 0.002 (0.003) Batch 0.464 (0.616) Remain 19:47:36 loss: 0.7920 Lr: 0.00060
[2025-05-11 13:26:16,310 INFO misc.py line 117 288342] Train: [1/50][1460/2344] Data 0.003 (0.003) Batch 0.559 (0.616) Remain 19:47:31 loss: 1.0498 Lr: 0.00060
[2025-05-11 13:26:16,984 INFO misc.py line 117 288342] Train: [1/50][1461/2344] Data 0.003 (0.003) Batch 0.675 (0.616) Remain 19:47:35 loss: 0.9217 Lr: 0.00060
[2025-05-11 13:26:17,760 INFO misc.py line 117 288342] Train: [1/50][1462/2344] Data 0.002 (0.003) Batch 0.776 (0.616) Remain 19:47:47 loss: 0.9963 Lr: 0.00060
[2025-05-11 13:26:18,307 INFO misc.py line 117 288342] Train: [1/50][1463/2344] Data 0.003 (0.003) Batch 0.547 (0.616) Remain 19:47:41 loss: 0.8759 Lr: 0.00060
[2025-05-11 13:26:18,960 INFO misc.py line 117 288342] Train: [1/50][1464/2344] Data 0.002 (0.003) Batch 0.653 (0.616) Remain 19:47:43 loss: 0.9769 Lr: 0.00060
[2025-05-11 13:26:19,463 INFO misc.py line 117 288342] Train: [1/50][1465/2344] Data 0.026 (0.003) Batch 0.503 (0.616) Remain 19:47:34 loss: 1.0433 Lr: 0.00060
[2025-05-11 13:26:20,077 INFO misc.py line 117 288342] Train: [1/50][1466/2344] Data 0.002 (0.003) Batch 0.613 (0.616) Remain 19:47:33 loss: 0.9202 Lr: 0.00060
[2025-05-11 13:26:20,622 INFO misc.py line 117 288342] Train: [1/50][1467/2344] Data 0.005 (0.003) Batch 0.545 (0.616) Remain 19:47:27 loss: 0.7815 Lr: 0.00060
[2025-05-11 13:26:21,196 INFO misc.py line 117 288342] Train: [1/50][1468/2344] Data 0.003 (0.003) Batch 0.574 (0.616) Remain 19:47:23 loss: 0.9188 Lr: 0.00060
[2025-05-11 13:26:21,828 INFO misc.py line 117 288342] Train: [1/50][1469/2344] Data 0.003 (0.003) Batch 0.632 (0.616) Remain 19:47:24 loss: 0.8461 Lr: 0.00060
[2025-05-11 13:26:22,444 INFO misc.py line 117 288342] Train: [1/50][1470/2344] Data 0.003 (0.003) Batch 0.616 (0.616) Remain 19:47:23 loss: 0.8252 Lr: 0.00060
[2025-05-11 13:26:23,048 INFO misc.py line 117 288342] Train: [1/50][1471/2344] Data 0.003 (0.003) Batch 0.604 (0.616) Remain 19:47:22 loss: 1.0292 Lr: 0.00060
[2025-05-11 13:26:23,706 INFO misc.py line 117 288342] Train: [1/50][1472/2344] Data 0.002 (0.003) Batch 0.658 (0.616) Remain 19:47:24 loss: 1.0230 Lr: 0.00060
[2025-05-11 13:26:24,268 INFO misc.py line 117 288342] Train: [1/50][1473/2344] Data 0.002 (0.003) Batch 0.561 (0.616) Remain 19:47:19 loss: 0.9299 Lr: 0.00060
[2025-05-11 13:26:25,027 INFO misc.py line 117 288342] Train: [1/50][1474/2344] Data 0.002 (0.003) Batch 0.759 (0.616) Remain 19:47:30 loss: 1.0862 Lr: 0.00060
[2025-05-11 13:26:25,701 INFO misc.py line 117 288342] Train: [1/50][1475/2344] Data 0.003 (0.003) Batch 0.675 (0.616) Remain 19:47:34 loss: 0.8026 Lr: 0.00060
[2025-05-11 13:26:26,237 INFO misc.py line 117 288342] Train: [1/50][1476/2344] Data 0.003 (0.003) Batch 0.535 (0.616) Remain 19:47:27 loss: 0.7920 Lr: 0.00060
[2025-05-11 13:26:26,913 INFO misc.py line 117 288342] Train: [1/50][1477/2344] Data 0.003 (0.003) Batch 0.676 (0.616) Remain 19:47:31 loss: 1.0180 Lr: 0.00061
[2025-05-11 13:26:27,513 INFO misc.py line 117 288342] Train: [1/50][1478/2344] Data 0.003 (0.003) Batch 0.600 (0.616) Remain 19:47:29 loss: 0.9296 Lr: 0.00061
[2025-05-11 13:26:28,016 INFO misc.py line 117 288342] Train: [1/50][1479/2344] Data 0.003 (0.003) Batch 0.503 (0.616) Remain 19:47:20 loss: 0.7638 Lr: 0.00061
[2025-05-11 13:26:28,740 INFO misc.py line 117 288342] Train: [1/50][1480/2344] Data 0.003 (0.003) Batch 0.723 (0.616) Remain 19:47:28 loss: 1.0323 Lr: 0.00061
[2025-05-11 13:26:29,363 INFO misc.py line 117 288342] Train: [1/50][1481/2344] Data 0.003 (0.003) Batch 0.624 (0.616) Remain 19:47:28 loss: 0.9518 Lr: 0.00061
[2025-05-11 13:26:29,982 INFO misc.py line 117 288342] Train: [1/50][1482/2344] Data 0.002 (0.003) Batch 0.619 (0.616) Remain 19:47:28 loss: 0.9313 Lr: 0.00061
[2025-05-11 13:26:30,607 INFO misc.py line 117 288342] Train: [1/50][1483/2344] Data 0.002 (0.003) Batch 0.625 (0.616) Remain 19:47:28 loss: 1.0953 Lr: 0.00061
[2025-05-11 13:26:31,183 INFO misc.py line 117 288342] Train: [1/50][1484/2344] Data 0.002 (0.003) Batch 0.576 (0.616) Remain 19:47:24 loss: 0.8749 Lr: 0.00061
[2025-05-11 13:26:31,707 INFO misc.py line 117 288342] Train: [1/50][1485/2344] Data 0.003 (0.003) Batch 0.524 (0.616) Remain 19:47:16 loss: 0.6834 Lr: 0.00061
[2025-05-11 13:26:32,273 INFO misc.py line 117 288342] Train: [1/50][1486/2344] Data 0.002 (0.003) Batch 0.565 (0.616) Remain 19:47:12 loss: 0.8721 Lr: 0.00061
[2025-05-11 13:26:32,815 INFO misc.py line 117 288342] Train: [1/50][1487/2344] Data 0.003 (0.003) Batch 0.542 (0.616) Remain 19:47:05 loss: 0.6316 Lr: 0.00061
[2025-05-11 13:26:33,333 INFO misc.py line 117 288342] Train: [1/50][1488/2344] Data 0.002 (0.003) Batch 0.519 (0.615) Remain 19:46:57 loss: 0.7947 Lr: 0.00061
[2025-05-11 13:26:33,982 INFO misc.py line 117 288342] Train: [1/50][1489/2344] Data 0.003 (0.003) Batch 0.649 (0.615) Remain 19:46:59 loss: 0.9124 Lr: 0.00061
[2025-05-11 13:26:34,419 INFO misc.py line 117 288342] Train: [1/50][1490/2344] Data 0.002 (0.003) Batch 0.437 (0.615) Remain 19:46:45 loss: 1.2140 Lr: 0.00061
[2025-05-11 13:26:34,885 INFO misc.py line 117 288342] Train: [1/50][1491/2344] Data 0.003 (0.003) Batch 0.466 (0.615) Remain 19:46:32 loss: 1.1863 Lr: 0.00061
[2025-05-11 13:26:35,488 INFO misc.py line 117 288342] Train: [1/50][1492/2344] Data 0.003 (0.003) Batch 0.603 (0.615) Remain 19:46:31 loss: 1.1197 Lr: 0.00061
[2025-05-11 13:26:36,237 INFO misc.py line 117 288342] Train: [1/50][1493/2344] Data 0.003 (0.003) Batch 0.749 (0.615) Remain 19:46:41 loss: 0.8412 Lr: 0.00061
[2025-05-11 13:26:36,826 INFO misc.py line 117 288342] Train: [1/50][1494/2344] Data 0.002 (0.003) Batch 0.589 (0.615) Remain 19:46:38 loss: 0.9370 Lr: 0.00061
[2025-05-11 13:26:37,459 INFO misc.py line 117 288342] Train: [1/50][1495/2344] Data 0.003 (0.003) Batch 0.633 (0.615) Remain 19:46:39 loss: 0.9976 Lr: 0.00061
[2025-05-11 13:26:38,164 INFO misc.py line 117 288342] Train: [1/50][1496/2344] Data 0.003 (0.003) Batch 0.706 (0.615) Remain 19:46:45 loss: 0.7686 Lr: 0.00061
[2025-05-11 13:26:38,772 INFO misc.py line 117 288342] Train: [1/50][1497/2344] Data 0.002 (0.003) Batch 0.608 (0.615) Remain 19:46:44 loss: 0.8720 Lr: 0.00062
[2025-05-11 13:26:39,371 INFO misc.py line 117 288342] Train: [1/50][1498/2344] Data 0.002 (0.003) Batch 0.599 (0.615) Remain 19:46:42 loss: 0.9555 Lr: 0.00062
[2025-05-11 13:26:39,940 INFO misc.py line 117 288342] Train: [1/50][1499/2344] Data 0.002 (0.003) Batch 0.569 (0.615) Remain 19:46:38 loss: 0.8961 Lr: 0.00062
[2025-05-11 13:26:40,459 INFO misc.py line 117 288342] Train: [1/50][1500/2344] Data 0.002 (0.003) Batch 0.519 (0.615) Remain 19:46:30 loss: 1.1383 Lr: 0.00062
[2025-05-11 13:26:40,995 INFO misc.py line 117 288342] Train: [1/50][1501/2344] Data 0.003 (0.003) Batch 0.536 (0.615) Remain 19:46:23 loss: 0.8642 Lr: 0.00062
[2025-05-11 13:26:41,577 INFO misc.py line 117 288342] Train: [1/50][1502/2344] Data 0.003 (0.003) Batch 0.582 (0.615) Remain 19:46:20 loss: 0.9127 Lr: 0.00062
[2025-05-11 13:26:42,199 INFO misc.py line 117 288342] Train: [1/50][1503/2344] Data 0.002 (0.003) Batch 0.622 (0.615) Remain 19:46:20 loss: 0.9290 Lr: 0.00062
[2025-05-11 13:26:42,798 INFO misc.py line 117 288342] Train: [1/50][1504/2344] Data 0.003 (0.003) Batch 0.599 (0.615) Remain 19:46:18 loss: 0.8581 Lr: 0.00062
[2025-05-11 13:26:43,521 INFO misc.py line 117 288342] Train: [1/50][1505/2344] Data 0.002 (0.003) Batch 0.723 (0.615) Remain 19:46:25 loss: 1.0216 Lr: 0.00062
[2025-05-11 13:26:44,040 INFO misc.py line 117 288342] Train: [1/50][1506/2344] Data 0.003 (0.003) Batch 0.519 (0.615) Remain 19:46:17 loss: 0.9951 Lr: 0.00062
[2025-05-11 13:26:44,546 INFO misc.py line 117 288342] Train: [1/50][1507/2344] Data 0.003 (0.003) Batch 0.506 (0.615) Remain 19:46:08 loss: 0.9601 Lr: 0.00062
[2025-05-11 13:26:45,130 INFO misc.py line 117 288342] Train: [1/50][1508/2344] Data 0.003 (0.003) Batch 0.584 (0.615) Remain 19:46:05 loss: 1.0651 Lr: 0.00062
[2025-05-11 13:26:45,704 INFO misc.py line 117 288342] Train: [1/50][1509/2344] Data 0.003 (0.003) Batch 0.574 (0.615) Remain 19:46:02 loss: 0.8279 Lr: 0.00062
[2025-05-11 13:26:46,312 INFO misc.py line 117 288342] Train: [1/50][1510/2344] Data 0.003 (0.003) Batch 0.608 (0.615) Remain 19:46:00 loss: 1.1606 Lr: 0.00062
[2025-05-11 13:26:46,842 INFO misc.py line 117 288342] Train: [1/50][1511/2344] Data 0.003 (0.003) Batch 0.530 (0.615) Remain 19:45:53 loss: 0.8226 Lr: 0.00062
[2025-05-11 13:26:47,526 INFO misc.py line 117 288342] Train: [1/50][1512/2344] Data 0.002 (0.003) Batch 0.684 (0.615) Remain 19:45:58 loss: 0.9361 Lr: 0.00062
[2025-05-11 13:26:48,139 INFO misc.py line 117 288342] Train: [1/50][1513/2344] Data 0.002 (0.003) Batch 0.614 (0.615) Remain 19:45:57 loss: 0.8897 Lr: 0.00062
[2025-05-11 13:26:48,705 INFO misc.py line 117 288342] Train: [1/50][1514/2344] Data 0.003 (0.003) Batch 0.565 (0.615) Remain 19:45:53 loss: 0.9068 Lr: 0.00062
[2025-05-11 13:26:49,386 INFO misc.py line 117 288342] Train: [1/50][1515/2344] Data 0.003 (0.003) Batch 0.681 (0.615) Remain 19:45:57 loss: 0.9047 Lr: 0.00062
[2025-05-11 13:26:49,988 INFO misc.py line 117 288342] Train: [1/50][1516/2344] Data 0.003 (0.003) Batch 0.602 (0.615) Remain 19:45:56 loss: 0.9228 Lr: 0.00062
[2025-05-11 13:26:50,596 INFO misc.py line 117 288342] Train: [1/50][1517/2344] Data 0.003 (0.003) Batch 0.608 (0.615) Remain 19:45:54 loss: 0.8661 Lr: 0.00063
[2025-05-11 13:26:51,304 INFO misc.py line 117 288342] Train: [1/50][1518/2344] Data 0.002 (0.003) Batch 0.708 (0.615) Remain 19:46:01 loss: 1.0735 Lr: 0.00063
[2025-05-11 13:26:51,946 INFO misc.py line 117 288342] Train: [1/50][1519/2344] Data 0.002 (0.003) Batch 0.642 (0.615) Remain 19:46:02 loss: 0.9271 Lr: 0.00063
[2025-05-11 13:26:52,577 INFO misc.py line 117 288342] Train: [1/50][1520/2344] Data 0.002 (0.003) Batch 0.631 (0.615) Remain 19:46:03 loss: 0.9139 Lr: 0.00063
[2025-05-11 13:26:53,196 INFO misc.py line 117 288342] Train: [1/50][1521/2344] Data 0.003 (0.003) Batch 0.618 (0.615) Remain 19:46:03 loss: 0.8993 Lr: 0.00063
[2025-05-11 13:26:53,826 INFO misc.py line 117 288342] Train: [1/50][1522/2344] Data 0.002 (0.003) Batch 0.631 (0.615) Remain 19:46:03 loss: 0.9396 Lr: 0.00063
[2025-05-11 13:26:54,307 INFO misc.py line 117 288342] Train: [1/50][1523/2344] Data 0.002 (0.003) Batch 0.481 (0.615) Remain 19:45:52 loss: 1.0601 Lr: 0.00063
[2025-05-11 13:26:54,991 INFO misc.py line 117 288342] Train: [1/50][1524/2344] Data 0.003 (0.003) Batch 0.684 (0.615) Remain 19:45:57 loss: 0.8454 Lr: 0.00063
[2025-05-11 13:26:55,563 INFO misc.py line 117 288342] Train: [1/50][1525/2344] Data 0.003 (0.003) Batch 0.572 (0.615) Remain 19:45:53 loss: 1.0921 Lr: 0.00063
[2025-05-11 13:26:56,131 INFO misc.py line 117 288342] Train: [1/50][1526/2344] Data 0.003 (0.003) Batch 0.568 (0.615) Remain 19:45:49 loss: 0.8110 Lr: 0.00063
[2025-05-11 13:26:56,833 INFO misc.py line 117 288342] Train: [1/50][1527/2344] Data 0.003 (0.003) Batch 0.703 (0.615) Remain 19:45:55 loss: 0.9355 Lr: 0.00063
[2025-05-11 13:26:57,320 INFO misc.py line 117 288342] Train: [1/50][1528/2344] Data 0.003 (0.003) Batch 0.487 (0.615) Remain 19:45:44 loss: 0.8691 Lr: 0.00063
[2025-05-11 13:26:57,956 INFO misc.py line 117 288342] Train: [1/50][1529/2344] Data 0.003 (0.003) Batch 0.636 (0.615) Remain 19:45:45 loss: 0.9280 Lr: 0.00063
[2025-05-11 13:26:58,480 INFO misc.py line 117 288342] Train: [1/50][1530/2344] Data 0.003 (0.003) Batch 0.523 (0.615) Remain 19:45:38 loss: 1.0739 Lr: 0.00063
[2025-05-11 13:26:59,157 INFO misc.py line 117 288342] Train: [1/50][1531/2344] Data 0.002 (0.003) Batch 0.677 (0.615) Remain 19:45:42 loss: 1.1226 Lr: 0.00063
[2025-05-11 13:26:59,819 INFO misc.py line 117 288342] Train: [1/50][1532/2344] Data 0.002 (0.003) Batch 0.662 (0.615) Remain 19:45:45 loss: 0.8974 Lr: 0.00063
[2025-05-11 13:27:00,493 INFO misc.py line 117 288342] Train: [1/50][1533/2344] Data 0.002 (0.003) Batch 0.674 (0.615) Remain 19:45:49 loss: 1.0996 Lr: 0.00063
[2025-05-11 13:27:01,147 INFO misc.py line 117 288342] Train: [1/50][1534/2344] Data 0.003 (0.003) Batch 0.654 (0.615) Remain 19:45:51 loss: 0.8568 Lr: 0.00063
[2025-05-11 13:27:01,725 INFO misc.py line 117 288342] Train: [1/50][1535/2344] Data 0.003 (0.003) Batch 0.579 (0.615) Remain 19:45:48 loss: 0.7281 Lr: 0.00063
[2025-05-11 13:27:02,411 INFO misc.py line 117 288342] Train: [1/50][1536/2344] Data 0.003 (0.003) Batch 0.686 (0.615) Remain 19:45:52 loss: 1.0851 Lr: 0.00064
[2025-05-11 13:27:02,975 INFO misc.py line 117 288342] Train: [1/50][1537/2344] Data 0.002 (0.003) Batch 0.563 (0.615) Remain 19:45:48 loss: 1.0480 Lr: 0.00064
[2025-05-11 13:27:03,472 INFO misc.py line 117 288342] Train: [1/50][1538/2344] Data 0.002 (0.003) Batch 0.497 (0.615) Remain 19:45:38 loss: 0.8769 Lr: 0.00064
[2025-05-11 13:27:04,102 INFO misc.py line 117 288342] Train: [1/50][1539/2344] Data 0.003 (0.003) Batch 0.630 (0.615) Remain 19:45:39 loss: 0.7128 Lr: 0.00064
[2025-05-11 13:27:04,787 INFO misc.py line 117 288342] Train: [1/50][1540/2344] Data 0.003 (0.003) Batch 0.684 (0.615) Remain 19:45:44 loss: 0.8328 Lr: 0.00064
[2025-05-11 13:27:05,315 INFO misc.py line 117 288342] Train: [1/50][1541/2344] Data 0.002 (0.003) Batch 0.528 (0.615) Remain 19:45:36 loss: 0.9709 Lr: 0.00064
[2025-05-11 13:27:06,008 INFO misc.py line 117 288342] Train: [1/50][1542/2344] Data 0.003 (0.003) Batch 0.693 (0.615) Remain 19:45:42 loss: 0.9969 Lr: 0.00064
[2025-05-11 13:27:06,541 INFO misc.py line 117 288342] Train: [1/50][1543/2344] Data 0.002 (0.003) Batch 0.533 (0.615) Remain 19:45:35 loss: 0.8513 Lr: 0.00064
[2025-05-11 13:27:07,364 INFO misc.py line 117 288342] Train: [1/50][1544/2344] Data 0.003 (0.003) Batch 0.823 (0.615) Remain 19:45:50 loss: 0.9643 Lr: 0.00064
[2025-05-11 13:27:08,009 INFO misc.py line 117 288342] Train: [1/50][1545/2344] Data 0.002 (0.003) Batch 0.645 (0.615) Remain 19:45:52 loss: 0.8002 Lr: 0.00064
[2025-05-11 13:27:08,646 INFO misc.py line 117 288342] Train: [1/50][1546/2344] Data 0.003 (0.003) Batch 0.637 (0.615) Remain 19:45:53 loss: 0.9576 Lr: 0.00064
[2025-05-11 13:27:09,267 INFO misc.py line 117 288342] Train: [1/50][1547/2344] Data 0.003 (0.003) Batch 0.622 (0.615) Remain 19:45:52 loss: 1.1531 Lr: 0.00064
[2025-05-11 13:27:09,989 INFO misc.py line 117 288342] Train: [1/50][1548/2344] Data 0.002 (0.003) Batch 0.722 (0.615) Remain 19:46:00 loss: 1.0793 Lr: 0.00064
[2025-05-11 13:27:10,550 INFO misc.py line 117 288342] Train: [1/50][1549/2344] Data 0.002 (0.003) Batch 0.561 (0.615) Remain 19:45:55 loss: 0.9038 Lr: 0.00064
[2025-05-11 13:27:11,173 INFO misc.py line 117 288342] Train: [1/50][1550/2344] Data 0.002 (0.003) Batch 0.623 (0.615) Remain 19:45:55 loss: 0.9782 Lr: 0.00064
[2025-05-11 13:27:11,789 INFO misc.py line 117 288342] Train: [1/50][1551/2344] Data 0.003 (0.003) Batch 0.616 (0.615) Remain 19:45:54 loss: 0.7831 Lr: 0.00064
[2025-05-11 13:27:12,445 INFO misc.py line 117 288342] Train: [1/50][1552/2344] Data 0.003 (0.003) Batch 0.656 (0.615) Remain 19:45:57 loss: 0.9818 Lr: 0.00064
[2025-05-11 13:27:13,006 INFO misc.py line 117 288342] Train: [1/50][1553/2344] Data 0.003 (0.003) Batch 0.561 (0.615) Remain 19:45:52 loss: 0.8792 Lr: 0.00064
[2025-05-11 13:27:13,629 INFO misc.py line 117 288342] Train: [1/50][1554/2344] Data 0.003 (0.003) Batch 0.623 (0.615) Remain 19:45:52 loss: 0.8128 Lr: 0.00064
[2025-05-11 13:27:14,343 INFO misc.py line 117 288342] Train: [1/50][1555/2344] Data 0.003 (0.003) Batch 0.714 (0.615) Remain 19:45:59 loss: 1.0195 Lr: 0.00065
[2025-05-11 13:27:14,930 INFO misc.py line 117 288342] Train: [1/50][1556/2344] Data 0.003 (0.003) Batch 0.587 (0.615) Remain 19:45:56 loss: 0.9345 Lr: 0.00065
[2025-05-11 13:27:15,573 INFO misc.py line 117 288342] Train: [1/50][1557/2344] Data 0.003 (0.003) Batch 0.643 (0.615) Remain 19:45:58 loss: 0.8917 Lr: 0.00065
[2025-05-11 13:27:16,166 INFO misc.py line 117 288342] Train: [1/50][1558/2344] Data 0.003 (0.003) Batch 0.593 (0.615) Remain 19:45:55 loss: 0.9343 Lr: 0.00065
[2025-05-11 13:27:16,883 INFO misc.py line 117 288342] Train: [1/50][1559/2344] Data 0.002 (0.003) Batch 0.716 (0.615) Remain 19:46:02 loss: 0.7920 Lr: 0.00065
[2025-05-11 13:27:17,460 INFO misc.py line 117 288342] Train: [1/50][1560/2344] Data 0.003 (0.003) Batch 0.578 (0.615) Remain 19:45:59 loss: 0.8451 Lr: 0.00065
[2025-05-11 13:27:18,072 INFO misc.py line 117 288342] Train: [1/50][1561/2344] Data 0.003 (0.003) Batch 0.612 (0.615) Remain 19:45:58 loss: 0.8192 Lr: 0.00065
[2025-05-11 13:27:18,652 INFO misc.py line 117 288342] Train: [1/50][1562/2344] Data 0.003 (0.003) Batch 0.580 (0.615) Remain 19:45:55 loss: 1.0583 Lr: 0.00065
[2025-05-11 13:27:19,117 INFO misc.py line 117 288342] Train: [1/50][1563/2344] Data 0.003 (0.003) Batch 0.465 (0.615) Remain 19:45:43 loss: 0.8150 Lr: 0.00065
[2025-05-11 13:27:19,773 INFO misc.py line 117 288342] Train: [1/50][1564/2344] Data 0.002 (0.003) Batch 0.656 (0.615) Remain 19:45:45 loss: 0.8173 Lr: 0.00065
[2025-05-11 13:27:20,489 INFO misc.py line 117 288342] Train: [1/50][1565/2344] Data 0.002 (0.003) Batch 0.716 (0.615) Remain 19:45:52 loss: 0.9609 Lr: 0.00065
[2025-05-11 13:27:20,925 INFO misc.py line 117 288342] Train: [1/50][1566/2344] Data 0.003 (0.003) Batch 0.436 (0.615) Remain 19:45:38 loss: 0.9592 Lr: 0.00065
[2025-05-11 13:27:21,541 INFO misc.py line 117 288342] Train: [1/50][1567/2344] Data 0.003 (0.003) Batch 0.616 (0.615) Remain 19:45:38 loss: 1.0946 Lr: 0.00065
[2025-05-11 13:27:22,197 INFO misc.py line 117 288342] Train: [1/50][1568/2344] Data 0.002 (0.003) Batch 0.657 (0.615) Remain 19:45:40 loss: 0.9848 Lr: 0.00065
[2025-05-11 13:27:23,040 INFO misc.py line 117 288342] Train: [1/50][1569/2344] Data 0.002 (0.003) Batch 0.842 (0.615) Remain 19:45:56 loss: 0.9491 Lr: 0.00065
[2025-05-11 13:27:23,483 INFO misc.py line 117 288342] Train: [1/50][1570/2344] Data 0.002 (0.003) Batch 0.443 (0.615) Remain 19:45:43 loss: 0.9816 Lr: 0.00065
[2025-05-11 13:27:23,945 INFO misc.py line 117 288342] Train: [1/50][1571/2344] Data 0.003 (0.003) Batch 0.463 (0.615) Remain 19:45:31 loss: 1.0699 Lr: 0.00065
[2025-05-11 13:27:24,625 INFO misc.py line 117 288342] Train: [1/50][1572/2344] Data 0.029 (0.003) Batch 0.680 (0.615) Remain 19:45:35 loss: 1.1101 Lr: 0.00065
[2025-05-11 13:27:25,279 INFO misc.py line 117 288342] Train: [1/50][1573/2344] Data 0.003 (0.003) Batch 0.654 (0.615) Remain 19:45:38 loss: 0.9066 Lr: 0.00065
[2025-05-11 13:27:25,948 INFO misc.py line 117 288342] Train: [1/50][1574/2344] Data 0.003 (0.003) Batch 0.670 (0.615) Remain 19:45:41 loss: 0.9559 Lr: 0.00066
[2025-05-11 13:27:26,575 INFO misc.py line 117 288342] Train: [1/50][1575/2344] Data 0.003 (0.003) Batch 0.627 (0.615) Remain 19:45:41 loss: 0.7868 Lr: 0.00066
[2025-05-11 13:27:27,292 INFO misc.py line 117 288342] Train: [1/50][1576/2344] Data 0.003 (0.003) Batch 0.717 (0.615) Remain 19:45:48 loss: 0.7417 Lr: 0.00066
[2025-05-11 13:27:27,982 INFO misc.py line 117 288342] Train: [1/50][1577/2344] Data 0.003 (0.003) Batch 0.689 (0.615) Remain 19:45:53 loss: 1.0778 Lr: 0.00066
[2025-05-11 13:27:28,612 INFO misc.py line 117 288342] Train: [1/50][1578/2344] Data 0.003 (0.003) Batch 0.630 (0.615) Remain 19:45:53 loss: 1.1013 Lr: 0.00066
[2025-05-11 13:27:29,166 INFO misc.py line 117 288342] Train: [1/50][1579/2344] Data 0.003 (0.003) Batch 0.554 (0.615) Remain 19:45:48 loss: 0.9264 Lr: 0.00066
[2025-05-11 13:27:29,722 INFO misc.py line 117 288342] Train: [1/50][1580/2344] Data 0.003 (0.003) Batch 0.556 (0.615) Remain 19:45:43 loss: 1.2295 Lr: 0.00066
[2025-05-11 13:27:30,302 INFO misc.py line 117 288342] Train: [1/50][1581/2344] Data 0.002 (0.003) Batch 0.581 (0.615) Remain 19:45:40 loss: 0.8390 Lr: 0.00066
[2025-05-11 13:27:30,964 INFO misc.py line 117 288342] Train: [1/50][1582/2344] Data 0.002 (0.003) Batch 0.661 (0.615) Remain 19:45:43 loss: 0.8351 Lr: 0.00066
[2025-05-11 13:27:31,520 INFO misc.py line 117 288342] Train: [1/50][1583/2344] Data 0.003 (0.003) Batch 0.556 (0.615) Remain 19:45:38 loss: 0.9226 Lr: 0.00066
[2025-05-11 13:27:32,241 INFO misc.py line 117 288342] Train: [1/50][1584/2344] Data 0.002 (0.003) Batch 0.721 (0.615) Remain 19:45:45 loss: 1.2422 Lr: 0.00066
[2025-05-11 13:27:32,899 INFO misc.py line 117 288342] Train: [1/50][1585/2344] Data 0.002 (0.003) Batch 0.658 (0.615) Remain 19:45:48 loss: 1.1527 Lr: 0.00066
[2025-05-11 13:27:33,603 INFO misc.py line 117 288342] Train: [1/50][1586/2344] Data 0.003 (0.003) Batch 0.704 (0.615) Remain 19:45:53 loss: 0.9234 Lr: 0.00066
[2025-05-11 13:27:34,238 INFO misc.py line 117 288342] Train: [1/50][1587/2344] Data 0.003 (0.003) Batch 0.635 (0.615) Remain 19:45:54 loss: 0.8469 Lr: 0.00066
[2025-05-11 13:27:34,976 INFO misc.py line 117 288342] Train: [1/50][1588/2344] Data 0.003 (0.003) Batch 0.738 (0.616) Remain 19:46:02 loss: 0.9598 Lr: 0.00066
[2025-05-11 13:27:35,746 INFO misc.py line 117 288342] Train: [1/50][1589/2344] Data 0.003 (0.003) Batch 0.770 (0.616) Remain 19:46:13 loss: 0.9387 Lr: 0.00066
[2025-05-11 13:27:36,380 INFO misc.py line 117 288342] Train: [1/50][1590/2344] Data 0.003 (0.003) Batch 0.634 (0.616) Remain 19:46:14 loss: 0.9137 Lr: 0.00066
[2025-05-11 13:27:36,927 INFO misc.py line 117 288342] Train: [1/50][1591/2344] Data 0.003 (0.003) Batch 0.547 (0.616) Remain 19:46:08 loss: 1.3970 Lr: 0.00066
[2025-05-11 13:27:37,482 INFO misc.py line 117 288342] Train: [1/50][1592/2344] Data 0.003 (0.003) Batch 0.555 (0.616) Remain 19:46:03 loss: 1.0092 Lr: 0.00066
[2025-05-11 13:27:38,147 INFO misc.py line 117 288342] Train: [1/50][1593/2344] Data 0.003 (0.003) Batch 0.665 (0.616) Remain 19:46:06 loss: 0.7810 Lr: 0.00067
[2025-05-11 13:27:38,707 INFO misc.py line 117 288342] Train: [1/50][1594/2344] Data 0.003 (0.003) Batch 0.561 (0.616) Remain 19:46:02 loss: 0.9745 Lr: 0.00067
[2025-05-11 13:27:39,435 INFO misc.py line 117 288342] Train: [1/50][1595/2344] Data 0.002 (0.003) Batch 0.727 (0.616) Remain 19:46:09 loss: 0.9829 Lr: 0.00067
[2025-05-11 13:27:39,989 INFO misc.py line 117 288342] Train: [1/50][1596/2344] Data 0.003 (0.003) Batch 0.554 (0.616) Remain 19:46:04 loss: 0.7573 Lr: 0.00067
[2025-05-11 13:27:40,631 INFO misc.py line 117 288342] Train: [1/50][1597/2344] Data 0.002 (0.003) Batch 0.642 (0.616) Remain 19:46:05 loss: 0.9956 Lr: 0.00067
[2025-05-11 13:27:41,192 INFO misc.py line 117 288342] Train: [1/50][1598/2344] Data 0.003 (0.003) Batch 0.561 (0.616) Remain 19:46:01 loss: 0.9841 Lr: 0.00067
[2025-05-11 13:27:41,811 INFO misc.py line 117 288342] Train: [1/50][1599/2344] Data 0.002 (0.003) Batch 0.619 (0.616) Remain 19:46:00 loss: 1.0083 Lr: 0.00067
[2025-05-11 13:27:42,542 INFO misc.py line 117 288342] Train: [1/50][1600/2344] Data 0.002 (0.003) Batch 0.731 (0.616) Remain 19:46:08 loss: 0.9925 Lr: 0.00067
[2025-05-11 13:27:43,210 INFO misc.py line 117 288342] Train: [1/50][1601/2344] Data 0.002 (0.003) Batch 0.667 (0.616) Remain 19:46:11 loss: 0.9922 Lr: 0.00067
[2025-05-11 13:27:44,033 INFO misc.py line 117 288342] Train: [1/50][1602/2344] Data 0.003 (0.003) Batch 0.823 (0.616) Remain 19:46:26 loss: 0.8447 Lr: 0.00067
[2025-05-11 13:27:44,824 INFO misc.py line 117 288342] Train: [1/50][1603/2344] Data 0.003 (0.003) Batch 0.792 (0.616) Remain 19:46:38 loss: 0.9205 Lr: 0.00067
[2025-05-11 13:27:45,299 INFO misc.py line 117 288342] Train: [1/50][1604/2344] Data 0.003 (0.003) Batch 0.475 (0.616) Remain 19:46:27 loss: 0.8094 Lr: 0.00067
[2025-05-11 13:27:46,003 INFO misc.py line 117 288342] Train: [1/50][1605/2344] Data 0.003 (0.003) Batch 0.704 (0.616) Remain 19:46:33 loss: 1.0170 Lr: 0.00067
[2025-05-11 13:27:46,654 INFO misc.py line 117 288342] Train: [1/50][1606/2344] Data 0.003 (0.003) Batch 0.651 (0.616) Remain 19:46:35 loss: 0.7693 Lr: 0.00067
[2025-05-11 13:27:47,299 INFO misc.py line 117 288342] Train: [1/50][1607/2344] Data 0.003 (0.003) Batch 0.645 (0.616) Remain 19:46:36 loss: 0.9819 Lr: 0.00067
[2025-05-11 13:27:47,811 INFO misc.py line 117 288342] Train: [1/50][1608/2344] Data 0.003 (0.003) Batch 0.512 (0.616) Remain 19:46:28 loss: 1.1938 Lr: 0.00067
[2025-05-11 13:27:48,436 INFO misc.py line 117 288342] Train: [1/50][1609/2344] Data 0.002 (0.003) Batch 0.624 (0.616) Remain 19:46:28 loss: 0.7519 Lr: 0.00067
[2025-05-11 13:27:49,009 INFO misc.py line 117 288342] Train: [1/50][1610/2344] Data 0.003 (0.003) Batch 0.573 (0.616) Remain 19:46:24 loss: 0.8503 Lr: 0.00067
[2025-05-11 13:27:49,607 INFO misc.py line 117 288342] Train: [1/50][1611/2344] Data 0.003 (0.003) Batch 0.598 (0.616) Remain 19:46:22 loss: 0.8880 Lr: 0.00067
[2025-05-11 13:27:50,196 INFO misc.py line 117 288342] Train: [1/50][1612/2344] Data 0.003 (0.003) Batch 0.589 (0.616) Remain 19:46:20 loss: 0.9319 Lr: 0.00068
[2025-05-11 13:27:50,811 INFO misc.py line 117 288342] Train: [1/50][1613/2344] Data 0.003 (0.003) Batch 0.615 (0.616) Remain 19:46:19 loss: 0.8941 Lr: 0.00068
[2025-05-11 13:27:51,402 INFO misc.py line 117 288342] Train: [1/50][1614/2344] Data 0.003 (0.003) Batch 0.591 (0.616) Remain 19:46:17 loss: 0.9682 Lr: 0.00068
[2025-05-11 13:27:52,060 INFO misc.py line 117 288342] Train: [1/50][1615/2344] Data 0.003 (0.003) Batch 0.658 (0.616) Remain 19:46:19 loss: 0.8517 Lr: 0.00068
[2025-05-11 13:27:52,689 INFO misc.py line 117 288342] Train: [1/50][1616/2344] Data 0.003 (0.003) Batch 0.629 (0.616) Remain 19:46:20 loss: 0.8185 Lr: 0.00068
[2025-05-11 13:27:53,279 INFO misc.py line 117 288342] Train: [1/50][1617/2344] Data 0.003 (0.003) Batch 0.590 (0.616) Remain 19:46:17 loss: 0.8045 Lr: 0.00068
[2025-05-11 13:27:53,737 INFO misc.py line 117 288342] Train: [1/50][1618/2344] Data 0.002 (0.003) Batch 0.458 (0.616) Remain 19:46:05 loss: 0.9778 Lr: 0.00068
[2025-05-11 13:27:54,424 INFO misc.py line 117 288342] Train: [1/50][1619/2344] Data 0.002 (0.003) Batch 0.687 (0.616) Remain 19:46:10 loss: 1.1169 Lr: 0.00068
[2025-05-11 13:27:54,924 INFO misc.py line 117 288342] Train: [1/50][1620/2344] Data 0.003 (0.003) Batch 0.499 (0.616) Remain 19:46:01 loss: 0.9985 Lr: 0.00068
[2025-05-11 13:27:55,466 INFO misc.py line 117 288342] Train: [1/50][1621/2344] Data 0.003 (0.003) Batch 0.543 (0.616) Remain 19:45:55 loss: 0.8947 Lr: 0.00068
[2025-05-11 13:27:56,104 INFO misc.py line 117 288342] Train: [1/50][1622/2344] Data 0.002 (0.003) Batch 0.637 (0.616) Remain 19:45:56 loss: 0.7278 Lr: 0.00068
[2025-05-11 13:27:56,778 INFO misc.py line 117 288342] Train: [1/50][1623/2344] Data 0.002 (0.003) Batch 0.674 (0.616) Remain 19:45:59 loss: 0.8229 Lr: 0.00068
[2025-05-11 13:27:57,395 INFO misc.py line 117 288342] Train: [1/50][1624/2344] Data 0.002 (0.003) Batch 0.617 (0.616) Remain 19:45:59 loss: 0.9110 Lr: 0.00068
[2025-05-11 13:27:58,106 INFO misc.py line 117 288342] Train: [1/50][1625/2344] Data 0.002 (0.003) Batch 0.711 (0.616) Remain 19:46:05 loss: 0.8654 Lr: 0.00068
[2025-05-11 13:27:58,674 INFO misc.py line 117 288342] Train: [1/50][1626/2344] Data 0.002 (0.003) Batch 0.569 (0.616) Remain 19:46:01 loss: 0.9717 Lr: 0.00068
[2025-05-11 13:28:00,851 INFO misc.py line 117 288342] Train: [1/50][1627/2344] Data 0.002 (0.003) Batch 2.176 (0.617) Remain 19:47:51 loss: 0.7857 Lr: 0.00068
[2025-05-11 13:28:01,374 INFO misc.py line 117 288342] Train: [1/50][1628/2344] Data 0.003 (0.003) Batch 0.524 (0.617) Remain 19:47:44 loss: 0.9809 Lr: 0.00068
[2025-05-11 13:28:02,077 INFO misc.py line 117 288342] Train: [1/50][1629/2344] Data 0.003 (0.003) Batch 0.702 (0.617) Remain 19:47:50 loss: 0.9486 Lr: 0.00068
[2025-05-11 13:28:02,663 INFO misc.py line 117 288342] Train: [1/50][1630/2344] Data 0.002 (0.003) Batch 0.586 (0.617) Remain 19:47:47 loss: 0.9984 Lr: 0.00068
[2025-05-11 13:28:03,323 INFO misc.py line 117 288342] Train: [1/50][1631/2344] Data 0.002 (0.003) Batch 0.660 (0.617) Remain 19:47:49 loss: 1.0857 Lr: 0.00069
[2025-05-11 13:28:04,144 INFO misc.py line 117 288342] Train: [1/50][1632/2344] Data 0.002 (0.003) Batch 0.821 (0.617) Remain 19:48:03 loss: 0.7926 Lr: 0.00069
[2025-05-11 13:28:04,772 INFO misc.py line 117 288342] Train: [1/50][1633/2344] Data 0.003 (0.003) Batch 0.627 (0.617) Remain 19:48:03 loss: 0.8140 Lr: 0.00069
[2025-05-11 13:28:05,415 INFO misc.py line 117 288342] Train: [1/50][1634/2344] Data 0.003 (0.003) Batch 0.643 (0.617) Remain 19:48:05 loss: 0.8734 Lr: 0.00069
[2025-05-11 13:28:05,964 INFO misc.py line 117 288342] Train: [1/50][1635/2344] Data 0.003 (0.003) Batch 0.549 (0.617) Remain 19:47:59 loss: 1.2178 Lr: 0.00069
[2025-05-11 13:28:06,483 INFO misc.py line 117 288342] Train: [1/50][1636/2344] Data 0.002 (0.003) Batch 0.519 (0.617) Remain 19:47:52 loss: 0.9697 Lr: 0.00069
[2025-05-11 13:28:07,154 INFO misc.py line 117 288342] Train: [1/50][1637/2344] Data 0.002 (0.003) Batch 0.671 (0.617) Remain 19:47:55 loss: 0.8516 Lr: 0.00069
[2025-05-11 13:28:07,655 INFO misc.py line 117 288342] Train: [1/50][1638/2344] Data 0.002 (0.003) Batch 0.501 (0.617) Remain 19:47:46 loss: 0.9142 Lr: 0.00069
[2025-05-11 13:28:08,357 INFO misc.py line 117 288342] Train: [1/50][1639/2344] Data 0.003 (0.003) Batch 0.702 (0.617) Remain 19:47:52 loss: 0.9072 Lr: 0.00069
[2025-05-11 13:28:08,842 INFO misc.py line 117 288342] Train: [1/50][1640/2344] Data 0.002 (0.003) Batch 0.484 (0.617) Remain 19:47:42 loss: 1.0871 Lr: 0.00069
[2025-05-11 13:28:09,404 INFO misc.py line 117 288342] Train: [1/50][1641/2344] Data 0.003 (0.003) Batch 0.563 (0.617) Remain 19:47:37 loss: 0.8234 Lr: 0.00069
[2025-05-11 13:28:10,041 INFO misc.py line 117 288342] Train: [1/50][1642/2344] Data 0.003 (0.003) Batch 0.637 (0.617) Remain 19:47:38 loss: 0.8694 Lr: 0.00069
[2025-05-11 13:28:10,676 INFO misc.py line 117 288342] Train: [1/50][1643/2344] Data 0.003 (0.003) Batch 0.634 (0.617) Remain 19:47:39 loss: 0.9300 Lr: 0.00069
[2025-05-11 13:28:11,392 INFO misc.py line 117 288342] Train: [1/50][1644/2344] Data 0.003 (0.003) Batch 0.716 (0.617) Remain 19:47:45 loss: 0.9857 Lr: 0.00069
[2025-05-11 13:28:12,055 INFO misc.py line 117 288342] Train: [1/50][1645/2344] Data 0.003 (0.003) Batch 0.663 (0.617) Remain 19:47:48 loss: 0.9332 Lr: 0.00069
[2025-05-11 13:28:12,728 INFO misc.py line 117 288342] Train: [1/50][1646/2344] Data 0.003 (0.003) Batch 0.672 (0.617) Remain 19:47:51 loss: 1.0004 Lr: 0.00069
[2025-05-11 13:28:13,471 INFO misc.py line 117 288342] Train: [1/50][1647/2344] Data 0.003 (0.003) Batch 0.743 (0.617) Remain 19:47:59 loss: 1.0858 Lr: 0.00069
[2025-05-11 13:28:14,171 INFO misc.py line 117 288342] Train: [1/50][1648/2344] Data 0.003 (0.003) Batch 0.701 (0.617) Remain 19:48:05 loss: 0.9863 Lr: 0.00069
[2025-05-11 13:28:14,809 INFO misc.py line 117 288342] Train: [1/50][1649/2344] Data 0.003 (0.003) Batch 0.637 (0.617) Remain 19:48:05 loss: 0.7774 Lr: 0.00069
[2025-05-11 13:28:15,401 INFO misc.py line 117 288342] Train: [1/50][1650/2344] Data 0.003 (0.003) Batch 0.592 (0.617) Remain 19:48:03 loss: 0.9581 Lr: 0.00070
[2025-05-11 13:28:15,908 INFO misc.py line 117 288342] Train: [1/50][1651/2344] Data 0.003 (0.003) Batch 0.507 (0.617) Remain 19:47:55 loss: 0.9234 Lr: 0.00070
[2025-05-11 13:28:16,474 INFO misc.py line 117 288342] Train: [1/50][1652/2344] Data 0.003 (0.003) Batch 0.566 (0.617) Remain 19:47:50 loss: 0.8478 Lr: 0.00070
[2025-05-11 13:28:17,130 INFO misc.py line 117 288342] Train: [1/50][1653/2344] Data 0.003 (0.003) Batch 0.656 (0.617) Remain 19:47:53 loss: 0.8429 Lr: 0.00070
[2025-05-11 13:28:17,937 INFO misc.py line 117 288342] Train: [1/50][1654/2344] Data 0.003 (0.003) Batch 0.808 (0.617) Remain 19:48:05 loss: 0.9915 Lr: 0.00070
[2025-05-11 13:28:18,558 INFO misc.py line 117 288342] Train: [1/50][1655/2344] Data 0.003 (0.003) Batch 0.621 (0.617) Remain 19:48:05 loss: 1.0724 Lr: 0.00070
[2025-05-11 13:28:18,997 INFO misc.py line 117 288342] Train: [1/50][1656/2344] Data 0.003 (0.003) Batch 0.439 (0.617) Remain 19:47:52 loss: 0.9777 Lr: 0.00070
[2025-05-11 13:28:19,524 INFO misc.py line 117 288342] Train: [1/50][1657/2344] Data 0.002 (0.003) Batch 0.527 (0.617) Remain 19:47:45 loss: 0.8615 Lr: 0.00070
[2025-05-11 13:28:20,170 INFO misc.py line 117 288342] Train: [1/50][1658/2344] Data 0.003 (0.003) Batch 0.646 (0.617) Remain 19:47:46 loss: 0.8415 Lr: 0.00070
[2025-05-11 13:28:20,838 INFO misc.py line 117 288342] Train: [1/50][1659/2344] Data 0.002 (0.003) Batch 0.668 (0.617) Remain 19:47:49 loss: 1.0633 Lr: 0.00070
[2025-05-11 13:28:21,479 INFO misc.py line 117 288342] Train: [1/50][1660/2344] Data 0.002 (0.003) Batch 0.641 (0.617) Remain 19:47:50 loss: 0.9422 Lr: 0.00070
[2025-05-11 13:28:22,183 INFO misc.py line 117 288342] Train: [1/50][1661/2344] Data 0.002 (0.003) Batch 0.704 (0.617) Remain 19:47:56 loss: 0.8153 Lr: 0.00070
[2025-05-11 13:28:22,768 INFO misc.py line 117 288342] Train: [1/50][1662/2344] Data 0.002 (0.003) Batch 0.585 (0.617) Remain 19:47:53 loss: 0.7711 Lr: 0.00070
[2025-05-11 13:28:23,557 INFO misc.py line 117 288342] Train: [1/50][1663/2344] Data 0.002 (0.003) Batch 0.789 (0.617) Remain 19:48:04 loss: 0.7998 Lr: 0.00070
[2025-05-11 13:28:24,285 INFO misc.py line 117 288342] Train: [1/50][1664/2344] Data 0.002 (0.003) Batch 0.728 (0.617) Remain 19:48:12 loss: 0.9551 Lr: 0.00070
[2025-05-11 13:28:24,881 INFO misc.py line 117 288342] Train: [1/50][1665/2344] Data 0.003 (0.003) Batch 0.596 (0.617) Remain 19:48:10 loss: 0.8139 Lr: 0.00070
[2025-05-11 13:28:25,446 INFO misc.py line 117 288342] Train: [1/50][1666/2344] Data 0.002 (0.003) Batch 0.564 (0.617) Remain 19:48:05 loss: 0.9161 Lr: 0.00070
[2025-05-11 13:28:25,913 INFO misc.py line 117 288342] Train: [1/50][1667/2344] Data 0.002 (0.003) Batch 0.467 (0.617) Remain 19:47:54 loss: 0.9293 Lr: 0.00070
[2025-05-11 13:28:26,467 INFO misc.py line 117 288342] Train: [1/50][1668/2344] Data 0.003 (0.003) Batch 0.554 (0.617) Remain 19:47:49 loss: 0.8136 Lr: 0.00071
[2025-05-11 13:28:27,124 INFO misc.py line 117 288342] Train: [1/50][1669/2344] Data 0.003 (0.003) Batch 0.656 (0.617) Remain 19:47:51 loss: 1.0184 Lr: 0.00071
[2025-05-11 13:28:27,803 INFO misc.py line 117 288342] Train: [1/50][1670/2344] Data 0.003 (0.003) Batch 0.680 (0.617) Remain 19:47:55 loss: 0.8775 Lr: 0.00071
[2025-05-11 13:28:28,501 INFO misc.py line 117 288342] Train: [1/50][1671/2344] Data 0.003 (0.003) Batch 0.697 (0.617) Remain 19:48:00 loss: 0.9463 Lr: 0.00071
[2025-05-11 13:28:29,152 INFO misc.py line 117 288342] Train: [1/50][1672/2344] Data 0.002 (0.003) Batch 0.650 (0.617) Remain 19:48:02 loss: 0.9371 Lr: 0.00071
[2025-05-11 13:28:29,705 INFO misc.py line 117 288342] Train: [1/50][1673/2344] Data 0.005 (0.003) Batch 0.554 (0.617) Remain 19:47:57 loss: 1.2291 Lr: 0.00071
[2025-05-11 13:28:30,390 INFO misc.py line 117 288342] Train: [1/50][1674/2344] Data 0.003 (0.003) Batch 0.686 (0.617) Remain 19:48:01 loss: 0.9502 Lr: 0.00071
[2025-05-11 13:28:30,942 INFO misc.py line 117 288342] Train: [1/50][1675/2344] Data 0.003 (0.003) Batch 0.551 (0.617) Remain 19:47:56 loss: 1.1037 Lr: 0.00071
[2025-05-11 13:28:31,722 INFO misc.py line 117 288342] Train: [1/50][1676/2344] Data 0.003 (0.003) Batch 0.780 (0.617) Remain 19:48:06 loss: 1.0852 Lr: 0.00071
[2025-05-11 13:28:32,333 INFO misc.py line 117 288342] Train: [1/50][1677/2344] Data 0.003 (0.003) Batch 0.611 (0.617) Remain 19:48:05 loss: 0.9086 Lr: 0.00071
[2025-05-11 13:28:32,976 INFO misc.py line 117 288342] Train: [1/50][1678/2344] Data 0.003 (0.003) Batch 0.643 (0.617) Remain 19:48:07 loss: 0.9663 Lr: 0.00071
[2025-05-11 13:28:33,601 INFO misc.py line 117 288342] Train: [1/50][1679/2344] Data 0.003 (0.003) Batch 0.625 (0.617) Remain 19:48:06 loss: 0.9018 Lr: 0.00071
[2025-05-11 13:28:34,138 INFO misc.py line 117 288342] Train: [1/50][1680/2344] Data 0.003 (0.003) Batch 0.537 (0.617) Remain 19:48:00 loss: 0.9564 Lr: 0.00071
[2025-05-11 13:28:34,780 INFO misc.py line 117 288342] Train: [1/50][1681/2344] Data 0.003 (0.003) Batch 0.642 (0.617) Remain 19:48:01 loss: 0.9276 Lr: 0.00071
[2025-05-11 13:28:35,354 INFO misc.py line 117 288342] Train: [1/50][1682/2344] Data 0.003 (0.003) Batch 0.575 (0.617) Remain 19:47:58 loss: 0.8719 Lr: 0.00071
[2025-05-11 13:28:35,933 INFO misc.py line 117 288342] Train: [1/50][1683/2344] Data 0.003 (0.003) Batch 0.579 (0.617) Remain 19:47:55 loss: 0.9342 Lr: 0.00071
[2025-05-11 13:28:36,418 INFO misc.py line 117 288342] Train: [1/50][1684/2344] Data 0.002 (0.003) Batch 0.484 (0.617) Remain 19:47:45 loss: 0.9314 Lr: 0.00071
[2025-05-11 13:28:37,034 INFO misc.py line 117 288342] Train: [1/50][1685/2344] Data 0.002 (0.003) Batch 0.617 (0.617) Remain 19:47:44 loss: 0.9341 Lr: 0.00071
[2025-05-11 13:28:37,517 INFO misc.py line 117 288342] Train: [1/50][1686/2344] Data 0.002 (0.003) Batch 0.483 (0.617) Remain 19:47:34 loss: 0.9657 Lr: 0.00071
[2025-05-11 13:28:38,050 INFO misc.py line 117 288342] Train: [1/50][1687/2344] Data 0.003 (0.003) Batch 0.533 (0.617) Remain 19:47:28 loss: 0.8047 Lr: 0.00072
[2025-05-11 13:28:38,616 INFO misc.py line 117 288342] Train: [1/50][1688/2344] Data 0.003 (0.003) Batch 0.566 (0.617) Remain 19:47:24 loss: 0.8483 Lr: 0.00072
[2025-05-11 13:28:39,261 INFO misc.py line 117 288342] Train: [1/50][1689/2344] Data 0.003 (0.003) Batch 0.645 (0.617) Remain 19:47:25 loss: 0.8006 Lr: 0.00072
[2025-05-11 13:28:39,986 INFO misc.py line 117 288342] Train: [1/50][1690/2344] Data 0.003 (0.003) Batch 0.725 (0.617) Remain 19:47:32 loss: 1.0215 Lr: 0.00072
[2025-05-11 13:28:40,597 INFO misc.py line 117 288342] Train: [1/50][1691/2344] Data 0.003 (0.003) Batch 0.612 (0.617) Remain 19:47:31 loss: 1.0556 Lr: 0.00072
[2025-05-11 13:28:41,302 INFO misc.py line 117 288342] Train: [1/50][1692/2344] Data 0.003 (0.003) Batch 0.705 (0.617) Remain 19:47:36 loss: 0.9561 Lr: 0.00072
[2025-05-11 13:28:41,838 INFO misc.py line 117 288342] Train: [1/50][1693/2344] Data 0.003 (0.003) Batch 0.536 (0.617) Remain 19:47:30 loss: 0.8187 Lr: 0.00072
[2025-05-11 13:28:42,406 INFO misc.py line 117 288342] Train: [1/50][1694/2344] Data 0.003 (0.003) Batch 0.568 (0.617) Remain 19:47:26 loss: 1.0018 Lr: 0.00072
[2025-05-11 13:28:43,061 INFO misc.py line 117 288342] Train: [1/50][1695/2344] Data 0.002 (0.003) Batch 0.655 (0.617) Remain 19:47:28 loss: 1.0731 Lr: 0.00072
[2025-05-11 13:28:44,246 INFO misc.py line 117 288342] Train: [1/50][1696/2344] Data 0.003 (0.003) Batch 1.185 (0.617) Remain 19:48:07 loss: 0.8306 Lr: 0.00072
[2025-05-11 13:28:44,927 INFO misc.py line 117 288342] Train: [1/50][1697/2344] Data 0.002 (0.003) Batch 0.681 (0.617) Remain 19:48:10 loss: 0.7578 Lr: 0.00072
[2025-05-11 13:28:45,536 INFO misc.py line 117 288342] Train: [1/50][1698/2344] Data 0.003 (0.003) Batch 0.609 (0.617) Remain 19:48:09 loss: 0.8489 Lr: 0.00072
[2025-05-11 13:28:46,127 INFO misc.py line 117 288342] Train: [1/50][1699/2344] Data 0.002 (0.003) Batch 0.591 (0.617) Remain 19:48:07 loss: 1.0610 Lr: 0.00072
[2025-05-11 13:28:46,818 INFO misc.py line 117 288342] Train: [1/50][1700/2344] Data 0.002 (0.003) Batch 0.692 (0.617) Remain 19:48:11 loss: 0.9358 Lr: 0.00072
[2025-05-11 13:28:47,468 INFO misc.py line 117 288342] Train: [1/50][1701/2344] Data 0.002 (0.003) Batch 0.649 (0.617) Remain 19:48:13 loss: 0.7090 Lr: 0.00072
[2025-05-11 13:28:48,129 INFO misc.py line 117 288342] Train: [1/50][1702/2344] Data 0.002 (0.003) Batch 0.661 (0.617) Remain 19:48:15 loss: 1.0521 Lr: 0.00072
[2025-05-11 13:28:48,811 INFO misc.py line 117 288342] Train: [1/50][1703/2344] Data 0.002 (0.003) Batch 0.682 (0.617) Remain 19:48:19 loss: 0.9198 Lr: 0.00072
[2025-05-11 13:28:49,325 INFO misc.py line 117 288342] Train: [1/50][1704/2344] Data 0.003 (0.003) Batch 0.515 (0.617) Remain 19:48:11 loss: 0.9086 Lr: 0.00072
[2025-05-11 13:28:50,065 INFO misc.py line 117 288342] Train: [1/50][1705/2344] Data 0.002 (0.003) Batch 0.739 (0.617) Remain 19:48:19 loss: 0.9548 Lr: 0.00073
[2025-05-11 13:28:50,638 INFO misc.py line 117 288342] Train: [1/50][1706/2344] Data 0.002 (0.003) Batch 0.574 (0.617) Remain 19:48:15 loss: 1.0658 Lr: 0.00073
[2025-05-11 13:28:51,369 INFO misc.py line 117 288342] Train: [1/50][1707/2344] Data 0.002 (0.003) Batch 0.731 (0.617) Remain 19:48:22 loss: 0.7878 Lr: 0.00073
[2025-05-11 13:28:51,934 INFO misc.py line 117 288342] Train: [1/50][1708/2344] Data 0.002 (0.003) Batch 0.565 (0.617) Remain 19:48:18 loss: 1.0612 Lr: 0.00073
[2025-05-11 13:28:52,541 INFO misc.py line 117 288342] Train: [1/50][1709/2344] Data 0.002 (0.003) Batch 0.606 (0.617) Remain 19:48:17 loss: 1.1113 Lr: 0.00073
[2025-05-11 13:28:53,207 INFO misc.py line 117 288342] Train: [1/50][1710/2344] Data 0.003 (0.003) Batch 0.667 (0.617) Remain 19:48:20 loss: 0.7054 Lr: 0.00073
[2025-05-11 13:28:53,828 INFO misc.py line 117 288342] Train: [1/50][1711/2344] Data 0.003 (0.003) Batch 0.620 (0.617) Remain 19:48:19 loss: 1.0527 Lr: 0.00073
[2025-05-11 13:28:54,445 INFO misc.py line 117 288342] Train: [1/50][1712/2344] Data 0.003 (0.003) Batch 0.617 (0.617) Remain 19:48:19 loss: 1.2686 Lr: 0.00073
[2025-05-11 13:28:55,168 INFO misc.py line 117 288342] Train: [1/50][1713/2344] Data 0.003 (0.003) Batch 0.723 (0.617) Remain 19:48:25 loss: 0.9788 Lr: 0.00073
[2025-05-11 13:28:55,742 INFO misc.py line 117 288342] Train: [1/50][1714/2344] Data 0.003 (0.003) Batch 0.574 (0.617) Remain 19:48:22 loss: 1.1201 Lr: 0.00073
[2025-05-11 13:28:56,401 INFO misc.py line 117 288342] Train: [1/50][1715/2344] Data 0.003 (0.003) Batch 0.659 (0.617) Remain 19:48:24 loss: 1.0330 Lr: 0.00073
[2025-05-11 13:28:57,032 INFO misc.py line 117 288342] Train: [1/50][1716/2344] Data 0.003 (0.003) Batch 0.631 (0.617) Remain 19:48:24 loss: 1.0101 Lr: 0.00073
[2025-05-11 13:28:57,687 INFO misc.py line 117 288342] Train: [1/50][1717/2344] Data 0.003 (0.003) Batch 0.655 (0.617) Remain 19:48:26 loss: 0.8955 Lr: 0.00073
[2025-05-11 13:28:58,205 INFO misc.py line 117 288342] Train: [1/50][1718/2344] Data 0.004 (0.003) Batch 0.518 (0.617) Remain 19:48:19 loss: 0.9062 Lr: 0.00073
[2025-05-11 13:28:58,917 INFO misc.py line 117 288342] Train: [1/50][1719/2344] Data 0.003 (0.003) Batch 0.712 (0.617) Remain 19:48:24 loss: 0.8171 Lr: 0.00073
[2025-05-11 13:28:59,571 INFO misc.py line 117 288342] Train: [1/50][1720/2344] Data 0.003 (0.003) Batch 0.654 (0.617) Remain 19:48:26 loss: 1.0152 Lr: 0.00073
[2025-05-11 13:29:00,162 INFO misc.py line 117 288342] Train: [1/50][1721/2344] Data 0.003 (0.003) Batch 0.591 (0.617) Remain 19:48:24 loss: 1.1679 Lr: 0.00073
[2025-05-11 13:29:00,839 INFO misc.py line 117 288342] Train: [1/50][1722/2344] Data 0.003 (0.003) Batch 0.677 (0.617) Remain 19:48:27 loss: 0.8473 Lr: 0.00073
[2025-05-11 13:29:01,448 INFO misc.py line 117 288342] Train: [1/50][1723/2344] Data 0.003 (0.003) Batch 0.609 (0.617) Remain 19:48:26 loss: 0.7252 Lr: 0.00074
[2025-05-11 13:29:02,150 INFO misc.py line 117 288342] Train: [1/50][1724/2344] Data 0.003 (0.003) Batch 0.702 (0.618) Remain 19:48:31 loss: 0.7740 Lr: 0.00074
[2025-05-11 13:29:02,698 INFO misc.py line 117 288342] Train: [1/50][1725/2344] Data 0.003 (0.003) Batch 0.548 (0.618) Remain 19:48:26 loss: 0.7561 Lr: 0.00074
[2025-05-11 13:29:03,303 INFO misc.py line 117 288342] Train: [1/50][1726/2344] Data 0.003 (0.003) Batch 0.605 (0.617) Remain 19:48:24 loss: 0.6574 Lr: 0.00074
[2025-05-11 13:29:03,962 INFO misc.py line 117 288342] Train: [1/50][1727/2344] Data 0.003 (0.003) Batch 0.659 (0.618) Remain 19:48:26 loss: 0.8033 Lr: 0.00074
[2025-05-11 13:29:04,520 INFO misc.py line 117 288342] Train: [1/50][1728/2344] Data 0.003 (0.003) Batch 0.558 (0.617) Remain 19:48:22 loss: 0.8809 Lr: 0.00074
[2025-05-11 13:29:05,105 INFO misc.py line 117 288342] Train: [1/50][1729/2344] Data 0.002 (0.003) Batch 0.585 (0.617) Remain 19:48:19 loss: 0.8466 Lr: 0.00074
[2025-05-11 13:29:05,737 INFO misc.py line 117 288342] Train: [1/50][1730/2344] Data 0.002 (0.003) Batch 0.632 (0.617) Remain 19:48:19 loss: 1.0666 Lr: 0.00074
[2025-05-11 13:29:07,137 INFO misc.py line 117 288342] Train: [1/50][1731/2344] Data 0.003 (0.003) Batch 1.399 (0.618) Remain 19:49:11 loss: 0.9402 Lr: 0.00074
[2025-05-11 13:29:07,706 INFO misc.py line 117 288342] Train: [1/50][1732/2344] Data 0.002 (0.003) Batch 0.570 (0.618) Remain 19:49:07 loss: 0.9056 Lr: 0.00074
[2025-05-11 13:29:08,454 INFO misc.py line 117 288342] Train: [1/50][1733/2344] Data 0.003 (0.003) Batch 0.747 (0.618) Remain 19:49:15 loss: 0.8035 Lr: 0.00074
[2025-05-11 13:29:09,075 INFO misc.py line 117 288342] Train: [1/50][1734/2344] Data 0.003 (0.003) Batch 0.621 (0.618) Remain 19:49:15 loss: 1.1338 Lr: 0.00074
[2025-05-11 13:29:09,614 INFO misc.py line 117 288342] Train: [1/50][1735/2344] Data 0.003 (0.003) Batch 0.540 (0.618) Remain 19:49:09 loss: 0.8952 Lr: 0.00074
[2025-05-11 13:29:10,157 INFO misc.py line 117 288342] Train: [1/50][1736/2344] Data 0.002 (0.003) Batch 0.543 (0.618) Remain 19:49:03 loss: 0.9034 Lr: 0.00074
[2025-05-11 13:29:10,827 INFO misc.py line 117 288342] Train: [1/50][1737/2344] Data 0.002 (0.003) Batch 0.670 (0.618) Remain 19:49:06 loss: 0.8162 Lr: 0.00074
[2025-05-11 13:29:12,034 INFO misc.py line 117 288342] Train: [1/50][1738/2344] Data 0.002 (0.003) Batch 1.206 (0.618) Remain 19:49:45 loss: 1.0782 Lr: 0.00074
[2025-05-11 13:29:12,612 INFO misc.py line 117 288342] Train: [1/50][1739/2344] Data 0.002 (0.003) Batch 0.578 (0.618) Remain 19:49:41 loss: 0.7515 Lr: 0.00074
[2025-05-11 13:29:13,254 INFO misc.py line 117 288342] Train: [1/50][1740/2344] Data 0.003 (0.003) Batch 0.642 (0.618) Remain 19:49:42 loss: 1.0465 Lr: 0.00074
[2025-05-11 13:29:13,887 INFO misc.py line 117 288342] Train: [1/50][1741/2344] Data 0.003 (0.003) Batch 0.633 (0.618) Remain 19:49:43 loss: 0.9328 Lr: 0.00075
[2025-05-11 13:29:14,562 INFO misc.py line 117 288342] Train: [1/50][1742/2344] Data 0.003 (0.003) Batch 0.675 (0.618) Remain 19:49:46 loss: 0.8175 Lr: 0.00075
[2025-05-11 13:29:14,991 INFO misc.py line 117 288342] Train: [1/50][1743/2344] Data 0.003 (0.003) Batch 0.428 (0.618) Remain 19:49:33 loss: 1.0792 Lr: 0.00075
[2025-05-11 13:29:15,480 INFO misc.py line 117 288342] Train: [1/50][1744/2344] Data 0.002 (0.003) Batch 0.490 (0.618) Remain 19:49:24 loss: 0.9502 Lr: 0.00075
[2025-05-11 13:29:16,138 INFO misc.py line 117 288342] Train: [1/50][1745/2344] Data 0.003 (0.003) Batch 0.658 (0.618) Remain 19:49:26 loss: 1.0910 Lr: 0.00075
[2025-05-11 13:29:16,694 INFO misc.py line 117 288342] Train: [1/50][1746/2344] Data 0.003 (0.003) Batch 0.555 (0.618) Remain 19:49:21 loss: 1.1754 Lr: 0.00075
[2025-05-11 13:29:17,268 INFO misc.py line 117 288342] Train: [1/50][1747/2344] Data 0.004 (0.003) Batch 0.575 (0.618) Remain 19:49:17 loss: 0.9374 Lr: 0.00075
[2025-05-11 13:29:17,883 INFO misc.py line 117 288342] Train: [1/50][1748/2344] Data 0.002 (0.003) Batch 0.615 (0.618) Remain 19:49:17 loss: 0.9266 Lr: 0.00075
[2025-05-11 13:29:18,482 INFO misc.py line 117 288342] Train: [1/50][1749/2344] Data 0.003 (0.003) Batch 0.600 (0.618) Remain 19:49:15 loss: 0.7825 Lr: 0.00075
[2025-05-11 13:29:19,146 INFO misc.py line 117 288342] Train: [1/50][1750/2344] Data 0.003 (0.003) Batch 0.663 (0.618) Remain 19:49:17 loss: 0.7105 Lr: 0.00075
[2025-05-11 13:29:19,661 INFO misc.py line 117 288342] Train: [1/50][1751/2344] Data 0.002 (0.003) Batch 0.515 (0.618) Remain 19:49:10 loss: 1.0355 Lr: 0.00075
[2025-05-11 13:29:20,247 INFO misc.py line 117 288342] Train: [1/50][1752/2344] Data 0.002 (0.003) Batch 0.586 (0.618) Remain 19:49:07 loss: 0.7513 Lr: 0.00075
[2025-05-11 13:29:20,836 INFO misc.py line 117 288342] Train: [1/50][1753/2344] Data 0.003 (0.003) Batch 0.588 (0.618) Remain 19:49:04 loss: 1.0802 Lr: 0.00075
[2025-05-11 13:29:21,508 INFO misc.py line 117 288342] Train: [1/50][1754/2344] Data 0.003 (0.003) Batch 0.673 (0.618) Remain 19:49:07 loss: 0.9561 Lr: 0.00075
[2025-05-11 13:29:22,088 INFO misc.py line 117 288342] Train: [1/50][1755/2344] Data 0.003 (0.003) Batch 0.579 (0.618) Remain 19:49:04 loss: 0.8688 Lr: 0.00075
[2025-05-11 13:29:22,594 INFO misc.py line 117 288342] Train: [1/50][1756/2344] Data 0.003 (0.003) Batch 0.506 (0.618) Remain 19:48:56 loss: 0.9002 Lr: 0.00075
[2025-05-11 13:29:23,254 INFO misc.py line 117 288342] Train: [1/50][1757/2344] Data 0.003 (0.003) Batch 0.660 (0.618) Remain 19:48:58 loss: 0.9972 Lr: 0.00075
[2025-05-11 13:29:23,853 INFO misc.py line 117 288342] Train: [1/50][1758/2344] Data 0.003 (0.003) Batch 0.599 (0.618) Remain 19:48:57 loss: 0.8316 Lr: 0.00075
[2025-05-11 13:29:24,484 INFO misc.py line 117 288342] Train: [1/50][1759/2344] Data 0.002 (0.003) Batch 0.631 (0.618) Remain 19:48:57 loss: 0.8691 Lr: 0.00076
[2025-05-11 13:29:25,147 INFO misc.py line 117 288342] Train: [1/50][1760/2344] Data 0.002 (0.003) Batch 0.663 (0.618) Remain 19:48:59 loss: 1.0107 Lr: 0.00076
[2025-05-11 13:29:25,736 INFO misc.py line 117 288342] Train: [1/50][1761/2344] Data 0.002 (0.003) Batch 0.589 (0.618) Remain 19:48:57 loss: 0.8409 Lr: 0.00076
[2025-05-11 13:29:26,329 INFO misc.py line 117 288342] Train: [1/50][1762/2344] Data 0.002 (0.003) Batch 0.592 (0.618) Remain 19:48:54 loss: 0.8200 Lr: 0.00076
[2025-05-11 13:29:26,925 INFO misc.py line 117 288342] Train: [1/50][1763/2344] Data 0.003 (0.003) Batch 0.596 (0.618) Remain 19:48:52 loss: 0.8994 Lr: 0.00076
[2025-05-11 13:29:27,542 INFO misc.py line 117 288342] Train: [1/50][1764/2344] Data 0.003 (0.003) Batch 0.617 (0.618) Remain 19:48:52 loss: 1.1570 Lr: 0.00076
[2025-05-11 13:29:28,225 INFO misc.py line 117 288342] Train: [1/50][1765/2344] Data 0.002 (0.003) Batch 0.683 (0.618) Remain 19:48:55 loss: 0.7211 Lr: 0.00076
[2025-05-11 13:29:28,828 INFO misc.py line 117 288342] Train: [1/50][1766/2344] Data 0.003 (0.003) Batch 0.603 (0.618) Remain 19:48:54 loss: 0.7476 Lr: 0.00076
[2025-05-11 13:29:29,378 INFO misc.py line 117 288342] Train: [1/50][1767/2344] Data 0.003 (0.003) Batch 0.550 (0.618) Remain 19:48:49 loss: 1.0444 Lr: 0.00076
[2025-05-11 13:29:29,850 INFO misc.py line 117 288342] Train: [1/50][1768/2344] Data 0.003 (0.003) Batch 0.472 (0.618) Remain 19:48:38 loss: 1.0217 Lr: 0.00076
[2025-05-11 13:29:30,406 INFO misc.py line 117 288342] Train: [1/50][1769/2344] Data 0.003 (0.003) Batch 0.556 (0.618) Remain 19:48:34 loss: 0.7371 Lr: 0.00076
[2025-05-11 13:29:31,095 INFO misc.py line 117 288342] Train: [1/50][1770/2344] Data 0.003 (0.003) Batch 0.689 (0.618) Remain 19:48:38 loss: 0.7157 Lr: 0.00076
[2025-05-11 13:29:31,640 INFO misc.py line 117 288342] Train: [1/50][1771/2344] Data 0.002 (0.003) Batch 0.545 (0.618) Remain 19:48:32 loss: 0.6634 Lr: 0.00076
[2025-05-11 13:29:32,115 INFO misc.py line 117 288342] Train: [1/50][1772/2344] Data 0.002 (0.003) Batch 0.476 (0.618) Remain 19:48:22 loss: 0.8729 Lr: 0.00076
[2025-05-11 13:29:32,816 INFO misc.py line 117 288342] Train: [1/50][1773/2344] Data 0.003 (0.003) Batch 0.701 (0.618) Remain 19:48:27 loss: 0.8827 Lr: 0.00076
[2025-05-11 13:29:33,422 INFO misc.py line 117 288342] Train: [1/50][1774/2344] Data 0.003 (0.003) Batch 0.605 (0.618) Remain 19:48:26 loss: 0.8867 Lr: 0.00076
[2025-05-11 13:29:33,987 INFO misc.py line 117 288342] Train: [1/50][1775/2344] Data 0.003 (0.003) Batch 0.565 (0.618) Remain 19:48:22 loss: 0.8677 Lr: 0.00076
[2025-05-11 13:29:34,623 INFO misc.py line 117 288342] Train: [1/50][1776/2344] Data 0.003 (0.003) Batch 0.636 (0.618) Remain 19:48:22 loss: 0.8592 Lr: 0.00076
[2025-05-11 13:29:35,130 INFO misc.py line 117 288342] Train: [1/50][1777/2344] Data 0.003 (0.003) Batch 0.507 (0.618) Remain 19:48:15 loss: 0.8684 Lr: 0.00077
[2025-05-11 13:29:35,800 INFO misc.py line 117 288342] Train: [1/50][1778/2344] Data 0.003 (0.003) Batch 0.670 (0.618) Remain 19:48:17 loss: 1.0227 Lr: 0.00077
[2025-05-11 13:29:36,534 INFO misc.py line 117 288342] Train: [1/50][1779/2344] Data 0.003 (0.003) Batch 0.734 (0.618) Remain 19:48:24 loss: 0.9272 Lr: 0.00077
[2025-05-11 13:29:37,227 INFO misc.py line 117 288342] Train: [1/50][1780/2344] Data 0.002 (0.003) Batch 0.693 (0.618) Remain 19:48:29 loss: 0.7334 Lr: 0.00077
[2025-05-11 13:29:37,724 INFO misc.py line 117 288342] Train: [1/50][1781/2344] Data 0.002 (0.003) Batch 0.497 (0.618) Remain 19:48:20 loss: 0.7543 Lr: 0.00077
[2025-05-11 13:29:38,199 INFO misc.py line 117 288342] Train: [1/50][1782/2344] Data 0.002 (0.003) Batch 0.474 (0.618) Remain 19:48:10 loss: 0.8426 Lr: 0.00077
[2025-05-11 13:29:38,835 INFO misc.py line 117 288342] Train: [1/50][1783/2344] Data 0.003 (0.003) Batch 0.637 (0.618) Remain 19:48:11 loss: 0.8908 Lr: 0.00077
[2025-05-11 13:29:39,460 INFO misc.py line 117 288342] Train: [1/50][1784/2344] Data 0.003 (0.003) Batch 0.625 (0.618) Remain 19:48:11 loss: 0.8040 Lr: 0.00077
[2025-05-11 13:29:39,912 INFO misc.py line 117 288342] Train: [1/50][1785/2344] Data 0.002 (0.003) Batch 0.452 (0.618) Remain 19:47:59 loss: 1.1369 Lr: 0.00077
[2025-05-11 13:29:40,423 INFO misc.py line 117 288342] Train: [1/50][1786/2344] Data 0.002 (0.003) Batch 0.511 (0.618) Remain 19:47:52 loss: 1.0575 Lr: 0.00077
[2025-05-11 13:29:40,925 INFO misc.py line 117 288342] Train: [1/50][1787/2344] Data 0.003 (0.003) Batch 0.502 (0.617) Remain 19:47:44 loss: 0.9416 Lr: 0.00077
[2025-05-11 13:29:41,569 INFO misc.py line 117 288342] Train: [1/50][1788/2344] Data 0.003 (0.003) Batch 0.644 (0.617) Remain 19:47:45 loss: 0.9320 Lr: 0.00077
[2025-05-11 13:29:42,183 INFO misc.py line 117 288342] Train: [1/50][1789/2344] Data 0.003 (0.003) Batch 0.614 (0.617) Remain 19:47:44 loss: 0.9334 Lr: 0.00077
[2025-05-11 13:29:42,799 INFO misc.py line 117 288342] Train: [1/50][1790/2344] Data 0.002 (0.003) Batch 0.616 (0.617) Remain 19:47:43 loss: 0.7995 Lr: 0.00077
[2025-05-11 13:29:43,277 INFO misc.py line 117 288342] Train: [1/50][1791/2344] Data 0.003 (0.003) Batch 0.478 (0.617) Remain 19:47:34 loss: 1.1151 Lr: 0.00077
[2025-05-11 13:29:44,043 INFO misc.py line 117 288342] Train: [1/50][1792/2344] Data 0.003 (0.003) Batch 0.766 (0.617) Remain 19:47:43 loss: 0.8691 Lr: 0.00077
[2025-05-11 13:29:44,715 INFO misc.py line 117 288342] Train: [1/50][1793/2344] Data 0.002 (0.003) Batch 0.672 (0.618) Remain 19:47:45 loss: 1.1007 Lr: 0.00077
[2025-05-11 13:29:45,353 INFO misc.py line 117 288342] Train: [1/50][1794/2344] Data 0.002 (0.003) Batch 0.638 (0.618) Remain 19:47:46 loss: 0.9436 Lr: 0.00077
[2025-05-11 13:29:45,863 INFO misc.py line 117 288342] Train: [1/50][1795/2344] Data 0.003 (0.003) Batch 0.510 (0.617) Remain 19:47:39 loss: 1.0478 Lr: 0.00078
[2025-05-11 13:29:46,423 INFO misc.py line 117 288342] Train: [1/50][1796/2344] Data 0.003 (0.003) Batch 0.560 (0.617) Remain 19:47:34 loss: 1.0678 Lr: 0.00078
[2025-05-11 13:29:47,045 INFO misc.py line 117 288342] Train: [1/50][1797/2344] Data 0.003 (0.003) Batch 0.622 (0.617) Remain 19:47:34 loss: 1.0872 Lr: 0.00078
[2025-05-11 13:29:47,550 INFO misc.py line 117 288342] Train: [1/50][1798/2344] Data 0.003 (0.003) Batch 0.504 (0.617) Remain 19:47:26 loss: 1.1995 Lr: 0.00078
[2025-05-11 13:29:48,190 INFO misc.py line 117 288342] Train: [1/50][1799/2344] Data 0.003 (0.003) Batch 0.640 (0.617) Remain 19:47:27 loss: 0.7691 Lr: 0.00078
[2025-05-11 13:29:48,770 INFO misc.py line 117 288342] Train: [1/50][1800/2344] Data 0.003 (0.003) Batch 0.580 (0.617) Remain 19:47:24 loss: 1.2716 Lr: 0.00078
[2025-05-11 13:29:49,303 INFO misc.py line 117 288342] Train: [1/50][1801/2344] Data 0.003 (0.003) Batch 0.533 (0.617) Remain 19:47:18 loss: 1.1126 Lr: 0.00078
[2025-05-11 13:29:49,975 INFO misc.py line 117 288342] Train: [1/50][1802/2344] Data 0.002 (0.003) Batch 0.672 (0.617) Remain 19:47:21 loss: 0.9787 Lr: 0.00078
[2025-05-11 13:29:50,702 INFO misc.py line 117 288342] Train: [1/50][1803/2344] Data 0.003 (0.003) Batch 0.727 (0.617) Remain 19:47:27 loss: 0.9405 Lr: 0.00078
[2025-05-11 13:29:51,385 INFO misc.py line 117 288342] Train: [1/50][1804/2344] Data 0.002 (0.003) Batch 0.683 (0.617) Remain 19:47:31 loss: 0.9380 Lr: 0.00078
[2025-05-11 13:29:51,967 INFO misc.py line 117 288342] Train: [1/50][1805/2344] Data 0.003 (0.003) Batch 0.583 (0.617) Remain 19:47:28 loss: 0.8799 Lr: 0.00078
[2025-05-11 13:29:52,634 INFO misc.py line 117 288342] Train: [1/50][1806/2344] Data 0.002 (0.003) Batch 0.666 (0.617) Remain 19:47:30 loss: 1.1918 Lr: 0.00078
[2025-05-11 13:29:53,220 INFO misc.py line 117 288342] Train: [1/50][1807/2344] Data 0.002 (0.003) Batch 0.587 (0.617) Remain 19:47:28 loss: 1.1604 Lr: 0.00078
[2025-05-11 13:29:53,766 INFO misc.py line 117 288342] Train: [1/50][1808/2344] Data 0.003 (0.003) Batch 0.546 (0.617) Remain 19:47:23 loss: 0.7434 Lr: 0.00078
[2025-05-11 13:29:54,599 INFO misc.py line 117 288342] Train: [1/50][1809/2344] Data 0.002 (0.003) Batch 0.833 (0.618) Remain 19:47:36 loss: 0.8789 Lr: 0.00078
[2025-05-11 13:29:55,065 INFO misc.py line 117 288342] Train: [1/50][1810/2344] Data 0.002 (0.003) Batch 0.465 (0.617) Remain 19:47:26 loss: 0.6792 Lr: 0.00078
[2025-05-11 13:29:55,550 INFO misc.py line 117 288342] Train: [1/50][1811/2344] Data 0.002 (0.003) Batch 0.485 (0.617) Remain 19:47:16 loss: 0.9940 Lr: 0.00078
[2025-05-11 13:29:56,160 INFO misc.py line 117 288342] Train: [1/50][1812/2344] Data 0.003 (0.003) Batch 0.610 (0.617) Remain 19:47:15 loss: 0.6685 Lr: 0.00078
[2025-05-11 13:29:56,838 INFO misc.py line 117 288342] Train: [1/50][1813/2344] Data 0.003 (0.003) Batch 0.678 (0.617) Remain 19:47:19 loss: 1.0096 Lr: 0.00079
[2025-05-11 13:29:57,592 INFO misc.py line 117 288342] Train: [1/50][1814/2344] Data 0.003 (0.003) Batch 0.755 (0.617) Remain 19:47:27 loss: 0.8323 Lr: 0.00079
[2025-05-11 13:29:58,229 INFO misc.py line 117 288342] Train: [1/50][1815/2344] Data 0.002 (0.003) Batch 0.636 (0.617) Remain 19:47:27 loss: 0.8371 Lr: 0.00079
[2025-05-11 13:29:58,896 INFO misc.py line 117 288342] Train: [1/50][1816/2344] Data 0.003 (0.003) Batch 0.667 (0.618) Remain 19:47:30 loss: 1.1873 Lr: 0.00079
[2025-05-11 13:29:59,557 INFO misc.py line 117 288342] Train: [1/50][1817/2344] Data 0.003 (0.003) Batch 0.661 (0.618) Remain 19:47:32 loss: 0.9296 Lr: 0.00079
[2025-05-11 13:30:00,219 INFO misc.py line 117 288342] Train: [1/50][1818/2344] Data 0.002 (0.003) Batch 0.663 (0.618) Remain 19:47:34 loss: 0.7344 Lr: 0.00079
[2025-05-11 13:30:00,913 INFO misc.py line 117 288342] Train: [1/50][1819/2344] Data 0.002 (0.003) Batch 0.694 (0.618) Remain 19:47:38 loss: 1.1097 Lr: 0.00079
[2025-05-11 13:30:01,539 INFO misc.py line 117 288342] Train: [1/50][1820/2344] Data 0.002 (0.003) Batch 0.626 (0.618) Remain 19:47:38 loss: 0.9863 Lr: 0.00079
[2025-05-11 13:30:02,150 INFO misc.py line 117 288342] Train: [1/50][1821/2344] Data 0.002 (0.003) Batch 0.611 (0.618) Remain 19:47:37 loss: 0.8343 Lr: 0.00079
[2025-05-11 13:30:02,649 INFO misc.py line 117 288342] Train: [1/50][1822/2344] Data 0.002 (0.003) Batch 0.499 (0.618) Remain 19:47:29 loss: 0.7694 Lr: 0.00079
[2025-05-11 13:30:03,405 INFO misc.py line 117 288342] Train: [1/50][1823/2344] Data 0.002 (0.003) Batch 0.756 (0.618) Remain 19:47:37 loss: 0.9775 Lr: 0.00079
[2025-05-11 13:30:04,016 INFO misc.py line 117 288342] Train: [1/50][1824/2344] Data 0.002 (0.003) Batch 0.611 (0.618) Remain 19:47:36 loss: 0.8029 Lr: 0.00079
[2025-05-11 13:30:04,598 INFO misc.py line 117 288342] Train: [1/50][1825/2344] Data 0.002 (0.003) Batch 0.582 (0.618) Remain 19:47:33 loss: 0.9713 Lr: 0.00079
[2025-05-11 13:30:05,368 INFO misc.py line 117 288342] Train: [1/50][1826/2344] Data 0.003 (0.003) Batch 0.770 (0.618) Remain 19:47:42 loss: 1.0254 Lr: 0.00079
[2025-05-11 13:30:06,000 INFO misc.py line 117 288342] Train: [1/50][1827/2344] Data 0.003 (0.003) Batch 0.632 (0.618) Remain 19:47:43 loss: 0.9039 Lr: 0.00079
[2025-05-11 13:30:06,655 INFO misc.py line 117 288342] Train: [1/50][1828/2344] Data 0.002 (0.003) Batch 0.655 (0.618) Remain 19:47:45 loss: 0.6286 Lr: 0.00079
[2025-05-11 13:30:07,197 INFO misc.py line 117 288342] Train: [1/50][1829/2344] Data 0.002 (0.003) Batch 0.542 (0.618) Remain 19:47:39 loss: 0.8741 Lr: 0.00079
[2025-05-11 13:30:07,836 INFO misc.py line 117 288342] Train: [1/50][1830/2344] Data 0.003 (0.003) Batch 0.639 (0.618) Remain 19:47:40 loss: 0.9510 Lr: 0.00080
[2025-05-11 13:30:08,400 INFO misc.py line 117 288342] Train: [1/50][1831/2344] Data 0.002 (0.003) Batch 0.564 (0.618) Remain 19:47:36 loss: 0.7683 Lr: 0.00080
[2025-05-11 13:30:09,058 INFO misc.py line 117 288342] Train: [1/50][1832/2344] Data 0.003 (0.003) Batch 0.659 (0.618) Remain 19:47:38 loss: 0.9171 Lr: 0.00080
[2025-05-11 13:30:09,748 INFO misc.py line 117 288342] Train: [1/50][1833/2344] Data 0.003 (0.003) Batch 0.690 (0.618) Remain 19:47:42 loss: 0.8662 Lr: 0.00080
[2025-05-11 13:30:10,344 INFO misc.py line 117 288342] Train: [1/50][1834/2344] Data 0.003 (0.003) Batch 0.596 (0.618) Remain 19:47:40 loss: 1.0484 Lr: 0.00080
[2025-05-11 13:30:10,929 INFO misc.py line 117 288342] Train: [1/50][1835/2344] Data 0.003 (0.003) Batch 0.584 (0.618) Remain 19:47:37 loss: 0.6872 Lr: 0.00080
[2025-05-11 13:30:11,395 INFO misc.py line 117 288342] Train: [1/50][1836/2344] Data 0.003 (0.003) Batch 0.466 (0.618) Remain 19:47:27 loss: 0.8127 Lr: 0.00080
[2025-05-11 13:30:12,121 INFO misc.py line 117 288342] Train: [1/50][1837/2344] Data 0.003 (0.003) Batch 0.727 (0.618) Remain 19:47:33 loss: 0.9542 Lr: 0.00080
[2025-05-11 13:30:12,780 INFO misc.py line 117 288342] Train: [1/50][1838/2344] Data 0.002 (0.003) Batch 0.659 (0.618) Remain 19:47:35 loss: 0.9810 Lr: 0.00080
[2025-05-11 13:30:13,553 INFO misc.py line 117 288342] Train: [1/50][1839/2344] Data 0.002 (0.003) Batch 0.773 (0.618) Remain 19:47:44 loss: 0.8507 Lr: 0.00080
[2025-05-11 13:30:14,071 INFO misc.py line 117 288342] Train: [1/50][1840/2344] Data 0.003 (0.003) Batch 0.518 (0.618) Remain 19:47:37 loss: 0.8537 Lr: 0.00080
[2025-05-11 13:30:14,709 INFO misc.py line 117 288342] Train: [1/50][1841/2344] Data 0.003 (0.003) Batch 0.638 (0.618) Remain 19:47:38 loss: 0.8701 Lr: 0.00080
[2025-05-11 13:30:15,387 INFO misc.py line 117 288342] Train: [1/50][1842/2344] Data 0.002 (0.003) Batch 0.677 (0.618) Remain 19:47:41 loss: 1.1055 Lr: 0.00080
[2025-05-11 13:30:15,983 INFO misc.py line 117 288342] Train: [1/50][1843/2344] Data 0.002 (0.003) Batch 0.597 (0.618) Remain 19:47:39 loss: 0.8002 Lr: 0.00080
[2025-05-11 13:30:16,786 INFO misc.py line 117 288342] Train: [1/50][1844/2344] Data 0.002 (0.003) Batch 0.802 (0.618) Remain 19:47:50 loss: 0.9414 Lr: 0.00080
[2025-05-11 13:30:17,418 INFO misc.py line 117 288342] Train: [1/50][1845/2344] Data 0.003 (0.003) Batch 0.632 (0.618) Remain 19:47:50 loss: 0.7288 Lr: 0.00080
[2025-05-11 13:30:17,977 INFO misc.py line 117 288342] Train: [1/50][1846/2344] Data 0.003 (0.003) Batch 0.559 (0.618) Remain 19:47:46 loss: 0.8010 Lr: 0.00080
[2025-05-11 13:30:18,503 INFO misc.py line 117 288342] Train: [1/50][1847/2344] Data 0.002 (0.003) Batch 0.526 (0.618) Remain 19:47:40 loss: 0.8120 Lr: 0.00080
[2025-05-11 13:30:19,139 INFO misc.py line 117 288342] Train: [1/50][1848/2344] Data 0.003 (0.003) Batch 0.636 (0.618) Remain 19:47:40 loss: 0.9573 Lr: 0.00081
[2025-05-11 13:30:19,760 INFO misc.py line 117 288342] Train: [1/50][1849/2344] Data 0.003 (0.003) Batch 0.622 (0.618) Remain 19:47:40 loss: 1.0558 Lr: 0.00081
[2025-05-11 13:30:20,227 INFO misc.py line 117 288342] Train: [1/50][1850/2344] Data 0.003 (0.003) Batch 0.466 (0.618) Remain 19:47:30 loss: 0.7724 Lr: 0.00081
[2025-05-11 13:30:20,793 INFO misc.py line 117 288342] Train: [1/50][1851/2344] Data 0.002 (0.003) Batch 0.567 (0.618) Remain 19:47:26 loss: 1.0140 Lr: 0.00081
[2025-05-11 13:30:21,431 INFO misc.py line 117 288342] Train: [1/50][1852/2344] Data 0.002 (0.003) Batch 0.638 (0.618) Remain 19:47:27 loss: 0.8900 Lr: 0.00081
[2025-05-11 13:30:21,974 INFO misc.py line 117 288342] Train: [1/50][1853/2344] Data 0.002 (0.003) Batch 0.542 (0.618) Remain 19:47:21 loss: 0.8523 Lr: 0.00081
[2025-05-11 13:30:22,636 INFO misc.py line 117 288342] Train: [1/50][1854/2344] Data 0.003 (0.003) Batch 0.662 (0.618) Remain 19:47:24 loss: 0.7351 Lr: 0.00081
[2025-05-11 13:30:23,130 INFO misc.py line 117 288342] Train: [1/50][1855/2344] Data 0.003 (0.003) Batch 0.494 (0.618) Remain 19:47:15 loss: 0.7985 Lr: 0.00081
[2025-05-11 13:30:23,822 INFO misc.py line 117 288342] Train: [1/50][1856/2344] Data 0.002 (0.003) Batch 0.692 (0.618) Remain 19:47:19 loss: 0.8808 Lr: 0.00081
[2025-05-11 13:30:24,547 INFO misc.py line 117 288342] Train: [1/50][1857/2344] Data 0.002 (0.003) Batch 0.725 (0.618) Remain 19:47:25 loss: 0.8144 Lr: 0.00081
[2025-05-11 13:30:25,075 INFO misc.py line 117 288342] Train: [1/50][1858/2344] Data 0.002 (0.003) Batch 0.528 (0.618) Remain 19:47:19 loss: 0.8482 Lr: 0.00081
[2025-05-11 13:30:25,773 INFO misc.py line 117 288342] Train: [1/50][1859/2344] Data 0.003 (0.003) Batch 0.698 (0.618) Remain 19:47:23 loss: 0.9454 Lr: 0.00081
[2025-05-11 13:30:26,434 INFO misc.py line 117 288342] Train: [1/50][1860/2344] Data 0.002 (0.003) Batch 0.662 (0.618) Remain 19:47:26 loss: 0.9065 Lr: 0.00081
[2025-05-11 13:30:26,947 INFO misc.py line 117 288342] Train: [1/50][1861/2344] Data 0.002 (0.003) Batch 0.512 (0.618) Remain 19:47:18 loss: 0.7451 Lr: 0.00081
[2025-05-11 13:30:27,520 INFO misc.py line 117 288342] Train: [1/50][1862/2344] Data 0.003 (0.003) Batch 0.573 (0.618) Remain 19:47:15 loss: 0.8320 Lr: 0.00081
[2025-05-11 13:30:28,112 INFO misc.py line 117 288342] Train: [1/50][1863/2344] Data 0.003 (0.003) Batch 0.592 (0.618) Remain 19:47:13 loss: 0.9981 Lr: 0.00081
[2025-05-11 13:30:28,776 INFO misc.py line 117 288342] Train: [1/50][1864/2344] Data 0.003 (0.003) Batch 0.664 (0.618) Remain 19:47:15 loss: 0.8219 Lr: 0.00081
[2025-05-11 13:30:29,418 INFO misc.py line 117 288342] Train: [1/50][1865/2344] Data 0.003 (0.003) Batch 0.642 (0.618) Remain 19:47:16 loss: 0.7966 Lr: 0.00082
[2025-05-11 13:30:30,058 INFO misc.py line 117 288342] Train: [1/50][1866/2344] Data 0.002 (0.003) Batch 0.640 (0.618) Remain 19:47:17 loss: 0.9042 Lr: 0.00082
[2025-05-11 13:30:30,669 INFO misc.py line 117 288342] Train: [1/50][1867/2344] Data 0.003 (0.003) Batch 0.610 (0.618) Remain 19:47:16 loss: 1.0169 Lr: 0.00082
[2025-05-11 13:30:31,236 INFO misc.py line 117 288342] Train: [1/50][1868/2344] Data 0.003 (0.003) Batch 0.568 (0.618) Remain 19:47:12 loss: 0.6909 Lr: 0.00082
[2025-05-11 13:30:31,779 INFO misc.py line 117 288342] Train: [1/50][1869/2344] Data 0.003 (0.003) Batch 0.542 (0.618) Remain 19:47:07 loss: 0.8869 Lr: 0.00082
[2025-05-11 13:30:32,353 INFO misc.py line 117 288342] Train: [1/50][1870/2344] Data 0.002 (0.003) Batch 0.574 (0.618) Remain 19:47:03 loss: 0.9969 Lr: 0.00082
[2025-05-11 13:30:33,022 INFO misc.py line 117 288342] Train: [1/50][1871/2344] Data 0.002 (0.003) Batch 0.669 (0.618) Remain 19:47:06 loss: 0.9955 Lr: 0.00082
[2025-05-11 13:30:33,512 INFO misc.py line 117 288342] Train: [1/50][1872/2344] Data 0.002 (0.003) Batch 0.490 (0.618) Remain 19:46:57 loss: 1.1105 Lr: 0.00082
[2025-05-11 13:30:34,090 INFO misc.py line 117 288342] Train: [1/50][1873/2344] Data 0.002 (0.003) Batch 0.578 (0.618) Remain 19:46:54 loss: 1.0081 Lr: 0.00082
[2025-05-11 13:30:34,589 INFO misc.py line 117 288342] Train: [1/50][1874/2344] Data 0.003 (0.003) Batch 0.499 (0.617) Remain 19:46:46 loss: 0.8173 Lr: 0.00082
[2025-05-11 13:30:35,276 INFO misc.py line 117 288342] Train: [1/50][1875/2344] Data 0.003 (0.003) Batch 0.687 (0.617) Remain 19:46:50 loss: 1.0673 Lr: 0.00082
[2025-05-11 13:30:35,916 INFO misc.py line 117 288342] Train: [1/50][1876/2344] Data 0.003 (0.003) Batch 0.640 (0.617) Remain 19:46:51 loss: 0.7438 Lr: 0.00082
[2025-05-11 13:30:36,613 INFO misc.py line 117 288342] Train: [1/50][1877/2344] Data 0.003 (0.003) Batch 0.697 (0.618) Remain 19:46:55 loss: 0.8694 Lr: 0.00082
[2025-05-11 13:30:37,201 INFO misc.py line 117 288342] Train: [1/50][1878/2344] Data 0.003 (0.003) Batch 0.588 (0.618) Remain 19:46:53 loss: 0.8531 Lr: 0.00082
[2025-05-11 13:30:37,823 INFO misc.py line 117 288342] Train: [1/50][1879/2344] Data 0.003 (0.003) Batch 0.621 (0.618) Remain 19:46:52 loss: 1.1580 Lr: 0.00082
[2025-05-11 13:30:38,434 INFO misc.py line 117 288342] Train: [1/50][1880/2344] Data 0.003 (0.003) Batch 0.611 (0.618) Remain 19:46:51 loss: 0.9250 Lr: 0.00082
[2025-05-11 13:30:39,017 INFO misc.py line 117 288342] Train: [1/50][1881/2344] Data 0.003 (0.003) Batch 0.584 (0.617) Remain 19:46:49 loss: 0.8373 Lr: 0.00082
[2025-05-11 13:30:39,736 INFO misc.py line 117 288342] Train: [1/50][1882/2344] Data 0.003 (0.003) Batch 0.719 (0.618) Remain 19:46:54 loss: 0.7492 Lr: 0.00082
[2025-05-11 13:30:40,208 INFO misc.py line 117 288342] Train: [1/50][1883/2344] Data 0.003 (0.003) Batch 0.472 (0.617) Remain 19:46:45 loss: 0.8010 Lr: 0.00083
[2025-05-11 13:30:40,830 INFO misc.py line 117 288342] Train: [1/50][1884/2344] Data 0.003 (0.003) Batch 0.622 (0.617) Remain 19:46:44 loss: 1.0970 Lr: 0.00083
[2025-05-11 13:30:41,430 INFO misc.py line 117 288342] Train: [1/50][1885/2344] Data 0.003 (0.003) Batch 0.600 (0.617) Remain 19:46:43 loss: 0.9535 Lr: 0.00083
[2025-05-11 13:30:41,964 INFO misc.py line 117 288342] Train: [1/50][1886/2344] Data 0.002 (0.003) Batch 0.534 (0.617) Remain 19:46:37 loss: 1.0461 Lr: 0.00083
[2025-05-11 13:30:42,642 INFO misc.py line 117 288342] Train: [1/50][1887/2344] Data 0.003 (0.003) Batch 0.677 (0.617) Remain 19:46:40 loss: 1.0738 Lr: 0.00083
[2025-05-11 13:30:43,224 INFO misc.py line 117 288342] Train: [1/50][1888/2344] Data 0.003 (0.003) Batch 0.582 (0.617) Remain 19:46:37 loss: 0.9195 Lr: 0.00083
[2025-05-11 13:30:43,808 INFO misc.py line 117 288342] Train: [1/50][1889/2344] Data 0.003 (0.003) Batch 0.584 (0.617) Remain 19:46:35 loss: 0.8369 Lr: 0.00083
[2025-05-11 13:30:44,492 INFO misc.py line 117 288342] Train: [1/50][1890/2344] Data 0.003 (0.003) Batch 0.684 (0.617) Remain 19:46:38 loss: 0.8102 Lr: 0.00083
[2025-05-11 13:30:45,155 INFO misc.py line 117 288342] Train: [1/50][1891/2344] Data 0.003 (0.003) Batch 0.663 (0.617) Remain 19:46:40 loss: 1.0461 Lr: 0.00083
[2025-05-11 13:30:45,618 INFO misc.py line 117 288342] Train: [1/50][1892/2344] Data 0.003 (0.003) Batch 0.463 (0.617) Remain 19:46:30 loss: 0.8502 Lr: 0.00083
[2025-05-11 13:30:46,272 INFO misc.py line 117 288342] Train: [1/50][1893/2344] Data 0.003 (0.003) Batch 0.654 (0.617) Remain 19:46:32 loss: 1.0506 Lr: 0.00083
[2025-05-11 13:30:46,978 INFO misc.py line 117 288342] Train: [1/50][1894/2344] Data 0.003 (0.003) Batch 0.707 (0.617) Remain 19:46:37 loss: 0.9639 Lr: 0.00083
[2025-05-11 13:30:47,638 INFO misc.py line 117 288342] Train: [1/50][1895/2344] Data 0.003 (0.003) Batch 0.659 (0.617) Remain 19:46:39 loss: 0.7209 Lr: 0.00083
[2025-05-11 13:30:48,350 INFO misc.py line 117 288342] Train: [1/50][1896/2344] Data 0.003 (0.003) Batch 0.713 (0.618) Remain 19:46:44 loss: 0.7436 Lr: 0.00083
[2025-05-11 13:30:49,103 INFO misc.py line 117 288342] Train: [1/50][1897/2344] Data 0.003 (0.003) Batch 0.752 (0.618) Remain 19:46:51 loss: 1.4757 Lr: 0.00083
[2025-05-11 13:30:49,701 INFO misc.py line 117 288342] Train: [1/50][1898/2344] Data 0.003 (0.003) Batch 0.598 (0.618) Remain 19:46:50 loss: 1.0669 Lr: 0.00083
[2025-05-11 13:30:50,355 INFO misc.py line 117 288342] Train: [1/50][1899/2344] Data 0.003 (0.003) Batch 0.654 (0.618) Remain 19:46:51 loss: 0.9027 Lr: 0.00083
[2025-05-11 13:30:51,122 INFO misc.py line 117 288342] Train: [1/50][1900/2344] Data 0.003 (0.003) Batch 0.767 (0.618) Remain 19:47:00 loss: 1.0344 Lr: 0.00084
[2025-05-11 13:30:51,634 INFO misc.py line 117 288342] Train: [1/50][1901/2344] Data 0.002 (0.003) Batch 0.512 (0.618) Remain 19:46:53 loss: 0.9516 Lr: 0.00084
[2025-05-11 13:30:52,093 INFO misc.py line 117 288342] Train: [1/50][1902/2344] Data 0.003 (0.003) Batch 0.459 (0.618) Remain 19:46:42 loss: 0.8102 Lr: 0.00084
[2025-05-11 13:30:52,729 INFO misc.py line 117 288342] Train: [1/50][1903/2344] Data 0.003 (0.003) Batch 0.636 (0.618) Remain 19:46:43 loss: 1.0468 Lr: 0.00084
[2025-05-11 13:30:53,198 INFO misc.py line 117 288342] Train: [1/50][1904/2344] Data 0.003 (0.003) Batch 0.469 (0.617) Remain 19:46:33 loss: 0.9240 Lr: 0.00084
[2025-05-11 13:30:53,823 INFO misc.py line 117 288342] Train: [1/50][1905/2344] Data 0.003 (0.003) Batch 0.626 (0.617) Remain 19:46:33 loss: 0.9212 Lr: 0.00084
[2025-05-11 13:30:54,577 INFO misc.py line 117 288342] Train: [1/50][1906/2344] Data 0.002 (0.003) Batch 0.754 (0.618) Remain 19:46:41 loss: 0.9638 Lr: 0.00084
[2025-05-11 13:30:55,334 INFO misc.py line 117 288342] Train: [1/50][1907/2344] Data 0.002 (0.003) Batch 0.756 (0.618) Remain 19:46:48 loss: 1.1678 Lr: 0.00084
[2025-05-11 13:30:56,013 INFO misc.py line 117 288342] Train: [1/50][1908/2344] Data 0.003 (0.003) Batch 0.679 (0.618) Remain 19:46:52 loss: 0.7805 Lr: 0.00084
[2025-05-11 13:30:56,749 INFO misc.py line 117 288342] Train: [1/50][1909/2344] Data 0.003 (0.003) Batch 0.736 (0.618) Remain 19:46:58 loss: 0.9587 Lr: 0.00084
[2025-05-11 13:30:57,360 INFO misc.py line 117 288342] Train: [1/50][1910/2344] Data 0.003 (0.003) Batch 0.610 (0.618) Remain 19:46:57 loss: 0.8539 Lr: 0.00084
[2025-05-11 13:30:57,840 INFO misc.py line 117 288342] Train: [1/50][1911/2344] Data 0.003 (0.003) Batch 0.481 (0.618) Remain 19:46:48 loss: 0.8859 Lr: 0.00084
[2025-05-11 13:30:58,458 INFO misc.py line 117 288342] Train: [1/50][1912/2344] Data 0.003 (0.003) Batch 0.618 (0.618) Remain 19:46:48 loss: 0.8593 Lr: 0.00084
[2025-05-11 13:30:59,176 INFO misc.py line 117 288342] Train: [1/50][1913/2344] Data 0.003 (0.003) Batch 0.718 (0.618) Remain 19:46:53 loss: 0.7730 Lr: 0.00084
[2025-05-11 13:30:59,735 INFO misc.py line 117 288342] Train: [1/50][1914/2344] Data 0.002 (0.003) Batch 0.559 (0.618) Remain 19:46:49 loss: 0.8045 Lr: 0.00084
[2025-05-11 13:31:00,381 INFO misc.py line 117 288342] Train: [1/50][1915/2344] Data 0.003 (0.003) Batch 0.646 (0.618) Remain 19:46:50 loss: 0.7308 Lr: 0.00084
[2025-05-11 13:31:00,985 INFO misc.py line 117 288342] Train: [1/50][1916/2344] Data 0.002 (0.003) Batch 0.604 (0.618) Remain 19:46:48 loss: 0.7252 Lr: 0.00084
[2025-05-11 13:31:01,600 INFO misc.py line 117 288342] Train: [1/50][1917/2344] Data 0.002 (0.003) Batch 0.616 (0.618) Remain 19:46:48 loss: 1.1733 Lr: 0.00085
[2025-05-11 13:31:02,089 INFO misc.py line 117 288342] Train: [1/50][1918/2344] Data 0.002 (0.003) Batch 0.489 (0.618) Remain 19:46:39 loss: 0.9415 Lr: 0.00085
[2025-05-11 13:31:02,874 INFO misc.py line 117 288342] Train: [1/50][1919/2344] Data 0.003 (0.003) Batch 0.785 (0.618) Remain 19:46:49 loss: 0.9054 Lr: 0.00085
[2025-05-11 13:31:03,422 INFO misc.py line 117 288342] Train: [1/50][1920/2344] Data 0.002 (0.003) Batch 0.547 (0.618) Remain 19:46:44 loss: 0.9116 Lr: 0.00085
[2025-05-11 13:31:04,019 INFO misc.py line 117 288342] Train: [1/50][1921/2344] Data 0.003 (0.003) Batch 0.597 (0.618) Remain 19:46:42 loss: 0.9927 Lr: 0.00085
[2025-05-11 13:31:04,773 INFO misc.py line 117 288342] Train: [1/50][1922/2344] Data 0.003 (0.003) Batch 0.754 (0.618) Remain 19:46:50 loss: 0.7602 Lr: 0.00085
[2025-05-11 13:31:05,288 INFO misc.py line 117 288342] Train: [1/50][1923/2344] Data 0.002 (0.003) Batch 0.516 (0.618) Remain 19:46:43 loss: 0.9266 Lr: 0.00085
[2025-05-11 13:31:05,940 INFO misc.py line 117 288342] Train: [1/50][1924/2344] Data 0.003 (0.003) Batch 0.652 (0.618) Remain 19:46:44 loss: 0.8496 Lr: 0.00085
[2025-05-11 13:31:06,542 INFO misc.py line 117 288342] Train: [1/50][1925/2344] Data 0.003 (0.003) Batch 0.602 (0.618) Remain 19:46:43 loss: 0.9014 Lr: 0.00085
[2025-05-11 13:31:07,172 INFO misc.py line 117 288342] Train: [1/50][1926/2344] Data 0.002 (0.003) Batch 0.630 (0.618) Remain 19:46:43 loss: 0.9055 Lr: 0.00085
[2025-05-11 13:31:07,795 INFO misc.py line 117 288342] Train: [1/50][1927/2344] Data 0.003 (0.003) Batch 0.623 (0.618) Remain 19:46:43 loss: 0.8079 Lr: 0.00085
[2025-05-11 13:31:08,474 INFO misc.py line 117 288342] Train: [1/50][1928/2344] Data 0.003 (0.003) Batch 0.679 (0.618) Remain 19:46:46 loss: 0.9406 Lr: 0.00085
[2025-05-11 13:31:09,092 INFO misc.py line 117 288342] Train: [1/50][1929/2344] Data 0.003 (0.003) Batch 0.618 (0.618) Remain 19:46:45 loss: 0.8420 Lr: 0.00085
[2025-05-11 13:31:09,595 INFO misc.py line 117 288342] Train: [1/50][1930/2344] Data 0.003 (0.003) Batch 0.503 (0.618) Remain 19:46:38 loss: 0.8348 Lr: 0.00085
[2025-05-11 13:31:10,250 INFO misc.py line 117 288342] Train: [1/50][1931/2344] Data 0.003 (0.003) Batch 0.655 (0.618) Remain 19:46:39 loss: 0.9017 Lr: 0.00085
[2025-05-11 13:31:10,947 INFO misc.py line 117 288342] Train: [1/50][1932/2344] Data 0.003 (0.003) Batch 0.697 (0.618) Remain 19:46:43 loss: 0.8761 Lr: 0.00085
[2025-05-11 13:31:11,625 INFO misc.py line 117 288342] Train: [1/50][1933/2344] Data 0.003 (0.003) Batch 0.678 (0.618) Remain 19:46:46 loss: 0.7762 Lr: 0.00085
[2025-05-11 13:31:12,255 INFO misc.py line 117 288342] Train: [1/50][1934/2344] Data 0.003 (0.003) Batch 0.631 (0.618) Remain 19:46:46 loss: 0.8296 Lr: 0.00085
[2025-05-11 13:31:13,082 INFO misc.py line 117 288342] Train: [1/50][1935/2344] Data 0.003 (0.003) Batch 0.827 (0.618) Remain 19:46:58 loss: 0.7675 Lr: 0.00086
[2025-05-11 13:31:13,562 INFO misc.py line 117 288342] Train: [1/50][1936/2344] Data 0.003 (0.003) Batch 0.480 (0.618) Remain 19:46:49 loss: 0.7936 Lr: 0.00086
[2025-05-11 13:31:14,252 INFO misc.py line 117 288342] Train: [1/50][1937/2344] Data 0.002 (0.003) Batch 0.690 (0.618) Remain 19:46:53 loss: 0.9642 Lr: 0.00086
[2025-05-11 13:31:14,987 INFO misc.py line 117 288342] Train: [1/50][1938/2344] Data 0.003 (0.003) Batch 0.734 (0.618) Remain 19:46:59 loss: 0.7842 Lr: 0.00086
[2025-05-11 13:31:15,652 INFO misc.py line 117 288342] Train: [1/50][1939/2344] Data 0.003 (0.003) Batch 0.665 (0.618) Remain 19:47:02 loss: 0.6759 Lr: 0.00086
[2025-05-11 13:31:16,233 INFO misc.py line 117 288342] Train: [1/50][1940/2344] Data 0.003 (0.003) Batch 0.581 (0.618) Remain 19:46:59 loss: 1.0870 Lr: 0.00086
[2025-05-11 13:31:16,754 INFO misc.py line 117 288342] Train: [1/50][1941/2344] Data 0.003 (0.003) Batch 0.521 (0.618) Remain 19:46:53 loss: 0.8432 Lr: 0.00086
[2025-05-11 13:31:17,462 INFO misc.py line 117 288342] Train: [1/50][1942/2344] Data 0.002 (0.003) Batch 0.708 (0.618) Remain 19:46:57 loss: 0.9418 Lr: 0.00086
[2025-05-11 13:31:18,145 INFO misc.py line 117 288342] Train: [1/50][1943/2344] Data 0.006 (0.003) Batch 0.683 (0.618) Remain 19:47:00 loss: 0.7910 Lr: 0.00086
[2025-05-11 13:31:18,623 INFO misc.py line 117 288342] Train: [1/50][1944/2344] Data 0.003 (0.003) Batch 0.478 (0.618) Remain 19:46:52 loss: 1.1432 Lr: 0.00086
[2025-05-11 13:31:19,254 INFO misc.py line 117 288342] Train: [1/50][1945/2344] Data 0.002 (0.003) Batch 0.631 (0.618) Remain 19:46:52 loss: 0.8543 Lr: 0.00086
[2025-05-11 13:31:19,735 INFO misc.py line 117 288342] Train: [1/50][1946/2344] Data 0.002 (0.003) Batch 0.480 (0.618) Remain 19:46:43 loss: 1.1294 Lr: 0.00086
[2025-05-11 13:31:20,197 INFO misc.py line 117 288342] Train: [1/50][1947/2344] Data 0.003 (0.003) Batch 0.463 (0.618) Remain 19:46:33 loss: 0.9801 Lr: 0.00086
[2025-05-11 13:31:20,726 INFO misc.py line 117 288342] Train: [1/50][1948/2344] Data 0.003 (0.003) Batch 0.529 (0.618) Remain 19:46:27 loss: 1.0979 Lr: 0.00086
[2025-05-11 13:31:21,486 INFO misc.py line 117 288342] Train: [1/50][1949/2344] Data 0.003 (0.003) Batch 0.760 (0.618) Remain 19:46:35 loss: 1.1436 Lr: 0.00086
[2025-05-11 13:31:22,025 INFO misc.py line 117 288342] Train: [1/50][1950/2344] Data 0.003 (0.003) Batch 0.539 (0.618) Remain 19:46:30 loss: 0.8344 Lr: 0.00086
[2025-05-11 13:31:22,833 INFO misc.py line 117 288342] Train: [1/50][1951/2344] Data 0.002 (0.003) Batch 0.807 (0.618) Remain 19:46:40 loss: 0.9780 Lr: 0.00086
[2025-05-11 13:31:23,334 INFO misc.py line 117 288342] Train: [1/50][1952/2344] Data 0.003 (0.003) Batch 0.502 (0.618) Remain 19:46:33 loss: 0.9189 Lr: 0.00087
[2025-05-11 13:31:23,921 INFO misc.py line 117 288342] Train: [1/50][1953/2344] Data 0.003 (0.003) Batch 0.587 (0.618) Remain 19:46:30 loss: 0.8494 Lr: 0.00087
[2025-05-11 13:31:24,898 INFO misc.py line 117 288342] Train: [1/50][1954/2344] Data 0.002 (0.003) Batch 0.976 (0.618) Remain 19:46:51 loss: 0.9431 Lr: 0.00087
[2025-05-11 13:31:25,538 INFO misc.py line 117 288342] Train: [1/50][1955/2344] Data 0.029 (0.003) Batch 0.641 (0.618) Remain 19:46:52 loss: 0.7835 Lr: 0.00087
[2025-05-11 13:31:26,156 INFO misc.py line 117 288342] Train: [1/50][1956/2344] Data 0.003 (0.003) Batch 0.618 (0.618) Remain 19:46:51 loss: 0.8467 Lr: 0.00087
[2025-05-11 13:31:26,831 INFO misc.py line 117 288342] Train: [1/50][1957/2344] Data 0.002 (0.003) Batch 0.675 (0.618) Remain 19:46:54 loss: 1.0210 Lr: 0.00087
[2025-05-11 13:31:27,433 INFO misc.py line 117 288342] Train: [1/50][1958/2344] Data 0.002 (0.003) Batch 0.602 (0.618) Remain 19:46:52 loss: 0.8485 Lr: 0.00087
[2025-05-11 13:31:27,912 INFO misc.py line 117 288342] Train: [1/50][1959/2344] Data 0.002 (0.003) Batch 0.479 (0.618) Remain 19:46:44 loss: 1.1940 Lr: 0.00087
[2025-05-11 13:31:28,529 INFO misc.py line 117 288342] Train: [1/50][1960/2344] Data 0.003 (0.003) Batch 0.617 (0.618) Remain 19:46:43 loss: 0.9321 Lr: 0.00087
[2025-05-11 13:31:29,064 INFO misc.py line 117 288342] Train: [1/50][1961/2344] Data 0.002 (0.003) Batch 0.536 (0.618) Remain 19:46:37 loss: 0.8788 Lr: 0.00087
[2025-05-11 13:31:29,717 INFO misc.py line 117 288342] Train: [1/50][1962/2344] Data 0.002 (0.003) Batch 0.652 (0.618) Remain 19:46:39 loss: 1.0662 Lr: 0.00087
[2025-05-11 13:31:30,420 INFO misc.py line 117 288342] Train: [1/50][1963/2344] Data 0.002 (0.003) Batch 0.703 (0.618) Remain 19:46:43 loss: 1.1727 Lr: 0.00087
[2025-05-11 13:31:31,008 INFO misc.py line 117 288342] Train: [1/50][1964/2344] Data 0.002 (0.003) Batch 0.588 (0.618) Remain 19:46:41 loss: 0.9201 Lr: 0.00087
[2025-05-11 13:31:31,636 INFO misc.py line 117 288342] Train: [1/50][1965/2344] Data 0.002 (0.003) Batch 0.628 (0.618) Remain 19:46:41 loss: 1.1449 Lr: 0.00087
[2025-05-11 13:31:32,293 INFO misc.py line 117 288342] Train: [1/50][1966/2344] Data 0.002 (0.003) Batch 0.658 (0.618) Remain 19:46:43 loss: 0.8797 Lr: 0.00087
[2025-05-11 13:31:32,966 INFO misc.py line 117 288342] Train: [1/50][1967/2344] Data 0.002 (0.003) Batch 0.672 (0.618) Remain 19:46:45 loss: 0.8575 Lr: 0.00087
[2025-05-11 13:31:33,456 INFO misc.py line 117 288342] Train: [1/50][1968/2344] Data 0.002 (0.003) Batch 0.490 (0.618) Remain 19:46:37 loss: 0.8931 Lr: 0.00087
[2025-05-11 13:31:34,086 INFO misc.py line 117 288342] Train: [1/50][1969/2344] Data 0.003 (0.003) Batch 0.631 (0.618) Remain 19:46:37 loss: 0.9084 Lr: 0.00088
[2025-05-11 13:31:34,723 INFO misc.py line 117 288342] Train: [1/50][1970/2344] Data 0.003 (0.003) Batch 0.637 (0.618) Remain 19:46:38 loss: 0.7522 Lr: 0.00088
[2025-05-11 13:31:35,390 INFO misc.py line 117 288342] Train: [1/50][1971/2344] Data 0.003 (0.003) Batch 0.666 (0.618) Remain 19:46:40 loss: 0.8780 Lr: 0.00088
[2025-05-11 13:31:36,035 INFO misc.py line 117 288342] Train: [1/50][1972/2344] Data 0.003 (0.003) Batch 0.646 (0.618) Remain 19:46:41 loss: 0.7837 Lr: 0.00088
[2025-05-11 13:31:36,575 INFO misc.py line 117 288342] Train: [1/50][1973/2344] Data 0.003 (0.003) Batch 0.539 (0.618) Remain 19:46:36 loss: 0.7239 Lr: 0.00088
[2025-05-11 13:31:37,124 INFO misc.py line 117 288342] Train: [1/50][1974/2344] Data 0.003 (0.003) Batch 0.549 (0.618) Remain 19:46:31 loss: 0.8278 Lr: 0.00088
[2025-05-11 13:31:37,696 INFO misc.py line 117 288342] Train: [1/50][1975/2344] Data 0.003 (0.003) Batch 0.573 (0.618) Remain 19:46:28 loss: 0.9019 Lr: 0.00088
[2025-05-11 13:31:38,391 INFO misc.py line 117 288342] Train: [1/50][1976/2344] Data 0.003 (0.003) Batch 0.695 (0.618) Remain 19:46:32 loss: 0.6788 Lr: 0.00088
[2025-05-11 13:31:39,112 INFO misc.py line 117 288342] Train: [1/50][1977/2344] Data 0.002 (0.003) Batch 0.721 (0.618) Remain 19:46:37 loss: 0.8047 Lr: 0.00088
[2025-05-11 13:31:39,693 INFO misc.py line 117 288342] Train: [1/50][1978/2344] Data 0.003 (0.003) Batch 0.581 (0.618) Remain 19:46:34 loss: 0.7876 Lr: 0.00088
[2025-05-11 13:31:40,283 INFO misc.py line 117 288342] Train: [1/50][1979/2344] Data 0.002 (0.003) Batch 0.590 (0.618) Remain 19:46:32 loss: 0.6306 Lr: 0.00088
[2025-05-11 13:31:40,951 INFO misc.py line 117 288342] Train: [1/50][1980/2344] Data 0.002 (0.003) Batch 0.668 (0.618) Remain 19:46:34 loss: 0.7472 Lr: 0.00088
[2025-05-11 13:31:41,594 INFO misc.py line 117 288342] Train: [1/50][1981/2344] Data 0.002 (0.003) Batch 0.643 (0.618) Remain 19:46:35 loss: 1.1250 Lr: 0.00088
[2025-05-11 13:31:42,107 INFO misc.py line 117 288342] Train: [1/50][1982/2344] Data 0.002 (0.003) Batch 0.513 (0.618) Remain 19:46:28 loss: 0.7806 Lr: 0.00088
[2025-05-11 13:31:42,770 INFO misc.py line 117 288342] Train: [1/50][1983/2344] Data 0.003 (0.003) Batch 0.663 (0.618) Remain 19:46:30 loss: 0.9598 Lr: 0.00088
[2025-05-11 13:31:43,399 INFO misc.py line 117 288342] Train: [1/50][1984/2344] Data 0.002 (0.003) Batch 0.629 (0.618) Remain 19:46:30 loss: 1.1180 Lr: 0.00088
[2025-05-11 13:31:44,011 INFO misc.py line 117 288342] Train: [1/50][1985/2344] Data 0.002 (0.003) Batch 0.612 (0.618) Remain 19:46:29 loss: 0.8478 Lr: 0.00088
[2025-05-11 13:31:44,619 INFO misc.py line 117 288342] Train: [1/50][1986/2344] Data 0.002 (0.003) Batch 0.608 (0.618) Remain 19:46:28 loss: 0.8379 Lr: 0.00089
[2025-05-11 13:31:45,202 INFO misc.py line 117 288342] Train: [1/50][1987/2344] Data 0.003 (0.003) Batch 0.583 (0.618) Remain 19:46:26 loss: 0.9755 Lr: 0.00089
[2025-05-11 13:31:45,706 INFO misc.py line 117 288342] Train: [1/50][1988/2344] Data 0.003 (0.003) Batch 0.504 (0.618) Remain 19:46:18 loss: 0.8667 Lr: 0.00089
[2025-05-11 13:31:46,258 INFO misc.py line 117 288342] Train: [1/50][1989/2344] Data 0.003 (0.003) Batch 0.552 (0.618) Remain 19:46:14 loss: 0.9259 Lr: 0.00089
[2025-05-11 13:31:46,982 INFO misc.py line 117 288342] Train: [1/50][1990/2344] Data 0.003 (0.003) Batch 0.724 (0.618) Remain 19:46:20 loss: 0.9455 Lr: 0.00089
[2025-05-11 13:31:47,625 INFO misc.py line 117 288342] Train: [1/50][1991/2344] Data 0.003 (0.003) Batch 0.643 (0.618) Remain 19:46:20 loss: 0.7244 Lr: 0.00089
[2025-05-11 13:31:48,407 INFO misc.py line 117 288342] Train: [1/50][1992/2344] Data 0.003 (0.003) Batch 0.781 (0.618) Remain 19:46:29 loss: 0.7967 Lr: 0.00089
[2025-05-11 13:31:49,036 INFO misc.py line 117 288342] Train: [1/50][1993/2344] Data 0.003 (0.003) Batch 0.630 (0.618) Remain 19:46:29 loss: 0.9353 Lr: 0.00089
[2025-05-11 13:31:49,578 INFO misc.py line 117 288342] Train: [1/50][1994/2344] Data 0.003 (0.003) Batch 0.542 (0.618) Remain 19:46:24 loss: 0.7219 Lr: 0.00089
[2025-05-11 13:31:50,227 INFO misc.py line 117 288342] Train: [1/50][1995/2344] Data 0.003 (0.003) Batch 0.649 (0.618) Remain 19:46:25 loss: 0.8714 Lr: 0.00089
[2025-05-11 13:31:50,983 INFO misc.py line 117 288342] Train: [1/50][1996/2344] Data 0.003 (0.003) Batch 0.756 (0.618) Remain 19:46:33 loss: 0.9069 Lr: 0.00089
[2025-05-11 13:31:51,667 INFO misc.py line 117 288342] Train: [1/50][1997/2344] Data 0.003 (0.003) Batch 0.684 (0.618) Remain 19:46:36 loss: 1.1617 Lr: 0.00089
[2025-05-11 13:31:52,298 INFO misc.py line 117 288342] Train: [1/50][1998/2344] Data 0.003 (0.003) Batch 0.630 (0.618) Remain 19:46:36 loss: 0.8570 Lr: 0.00089
[2025-05-11 13:31:52,876 INFO misc.py line 117 288342] Train: [1/50][1999/2344] Data 0.003 (0.003) Batch 0.578 (0.618) Remain 19:46:33 loss: 0.7847 Lr: 0.00089
[2025-05-11 13:31:53,480 INFO misc.py line 117 288342] Train: [1/50][2000/2344] Data 0.002 (0.003) Batch 0.604 (0.618) Remain 19:46:32 loss: 0.9423 Lr: 0.00089
[2025-05-11 13:31:54,054 INFO misc.py line 117 288342] Train: [1/50][2001/2344] Data 0.003 (0.003) Batch 0.574 (0.618) Remain 19:46:29 loss: 1.2795 Lr: 0.00089
[2025-05-11 13:31:54,711 INFO misc.py line 117 288342] Train: [1/50][2002/2344] Data 0.003 (0.003) Batch 0.657 (0.618) Remain 19:46:30 loss: 0.9626 Lr: 0.00089
[2025-05-11 13:31:55,335 INFO misc.py line 117 288342] Train: [1/50][2003/2344] Data 0.003 (0.003) Batch 0.624 (0.618) Remain 19:46:30 loss: 0.8199 Lr: 0.00090
[2025-05-11 13:31:56,021 INFO misc.py line 117 288342] Train: [1/50][2004/2344] Data 0.003 (0.003) Batch 0.686 (0.618) Remain 19:46:33 loss: 1.0370 Lr: 0.00090
[2025-05-11 13:31:56,728 INFO misc.py line 117 288342] Train: [1/50][2005/2344] Data 0.003 (0.003) Batch 0.707 (0.618) Remain 19:46:38 loss: 0.9592 Lr: 0.00090
[2025-05-11 13:31:57,233 INFO misc.py line 117 288342] Train: [1/50][2006/2344] Data 0.003 (0.003) Batch 0.506 (0.618) Remain 19:46:31 loss: 1.2299 Lr: 0.00090
[2025-05-11 13:31:57,836 INFO misc.py line 117 288342] Train: [1/50][2007/2344] Data 0.002 (0.003) Batch 0.603 (0.618) Remain 19:46:29 loss: 0.9262 Lr: 0.00090
[2025-05-11 13:31:58,368 INFO misc.py line 117 288342] Train: [1/50][2008/2344] Data 0.002 (0.003) Batch 0.532 (0.618) Remain 19:46:24 loss: 0.9527 Lr: 0.00090
[2025-05-11 13:31:58,914 INFO misc.py line 117 288342] Train: [1/50][2009/2344] Data 0.002 (0.003) Batch 0.545 (0.618) Remain 19:46:19 loss: 0.8054 Lr: 0.00090
[2025-05-11 13:31:59,498 INFO misc.py line 117 288342] Train: [1/50][2010/2344] Data 0.002 (0.003) Batch 0.584 (0.618) Remain 19:46:16 loss: 0.8058 Lr: 0.00090
[2025-05-11 13:32:00,183 INFO misc.py line 117 288342] Train: [1/50][2011/2344] Data 0.003 (0.003) Batch 0.685 (0.618) Remain 19:46:20 loss: 1.1779 Lr: 0.00090
[2025-05-11 13:32:00,867 INFO misc.py line 117 288342] Train: [1/50][2012/2344] Data 0.002 (0.003) Batch 0.684 (0.618) Remain 19:46:23 loss: 0.7818 Lr: 0.00090
[2025-05-11 13:32:01,473 INFO misc.py line 117 288342] Train: [1/50][2013/2344] Data 0.002 (0.003) Batch 0.606 (0.618) Remain 19:46:21 loss: 0.9180 Lr: 0.00090
[2025-05-11 13:32:02,126 INFO misc.py line 117 288342] Train: [1/50][2014/2344] Data 0.002 (0.003) Batch 0.653 (0.618) Remain 19:46:23 loss: 1.0987 Lr: 0.00090
[2025-05-11 13:32:02,691 INFO misc.py line 117 288342] Train: [1/50][2015/2344] Data 0.003 (0.003) Batch 0.564 (0.618) Remain 19:46:19 loss: 0.7593 Lr: 0.00090
[2025-05-11 13:32:03,295 INFO misc.py line 117 288342] Train: [1/50][2016/2344] Data 0.003 (0.003) Batch 0.605 (0.618) Remain 19:46:18 loss: 0.7491 Lr: 0.00090
[2025-05-11 13:32:03,910 INFO misc.py line 117 288342] Train: [1/50][2017/2344] Data 0.003 (0.003) Batch 0.615 (0.618) Remain 19:46:17 loss: 0.8465 Lr: 0.00090
[2025-05-11 13:32:04,541 INFO misc.py line 117 288342] Train: [1/50][2018/2344] Data 0.003 (0.003) Batch 0.631 (0.618) Remain 19:46:17 loss: 0.9160 Lr: 0.00090
[2025-05-11 13:32:05,201 INFO misc.py line 117 288342] Train: [1/50][2019/2344] Data 0.003 (0.003) Batch 0.660 (0.618) Remain 19:46:19 loss: 0.6861 Lr: 0.00090
[2025-05-11 13:32:05,748 INFO misc.py line 117 288342] Train: [1/50][2020/2344] Data 0.003 (0.003) Batch 0.546 (0.618) Remain 19:46:14 loss: 0.9210 Lr: 0.00091
[2025-05-11 13:32:06,344 INFO misc.py line 117 288342] Train: [1/50][2021/2344] Data 0.003 (0.003) Batch 0.596 (0.618) Remain 19:46:12 loss: 0.6760 Lr: 0.00091
[2025-05-11 13:32:07,015 INFO misc.py line 117 288342] Train: [1/50][2022/2344] Data 0.002 (0.003) Batch 0.671 (0.618) Remain 19:46:15 loss: 0.8147 Lr: 0.00091
[2025-05-11 13:32:07,595 INFO misc.py line 117 288342] Train: [1/50][2023/2344] Data 0.003 (0.003) Batch 0.580 (0.618) Remain 19:46:12 loss: 0.9228 Lr: 0.00091
[2025-05-11 13:32:08,268 INFO misc.py line 117 288342] Train: [1/50][2024/2344] Data 0.003 (0.003) Batch 0.673 (0.618) Remain 19:46:14 loss: 1.0545 Lr: 0.00091
[2025-05-11 13:32:09,003 INFO misc.py line 117 288342] Train: [1/50][2025/2344] Data 0.003 (0.003) Batch 0.735 (0.618) Remain 19:46:21 loss: 0.7646 Lr: 0.00091
[2025-05-11 13:32:09,642 INFO misc.py line 117 288342] Train: [1/50][2026/2344] Data 0.003 (0.003) Batch 0.639 (0.618) Remain 19:46:21 loss: 0.8789 Lr: 0.00091
[2025-05-11 13:32:10,313 INFO misc.py line 117 288342] Train: [1/50][2027/2344] Data 0.003 (0.003) Batch 0.671 (0.618) Remain 19:46:23 loss: 0.7935 Lr: 0.00091
[2025-05-11 13:32:10,926 INFO misc.py line 117 288342] Train: [1/50][2028/2344] Data 0.003 (0.003) Batch 0.613 (0.618) Remain 19:46:23 loss: 0.8718 Lr: 0.00091
[2025-05-11 13:32:11,456 INFO misc.py line 117 288342] Train: [1/50][2029/2344] Data 0.003 (0.003) Batch 0.530 (0.618) Remain 19:46:17 loss: 0.7286 Lr: 0.00091
[2025-05-11 13:32:11,962 INFO misc.py line 117 288342] Train: [1/50][2030/2344] Data 0.002 (0.003) Batch 0.506 (0.618) Remain 19:46:10 loss: 0.9260 Lr: 0.00091
[2025-05-11 13:32:12,660 INFO misc.py line 117 288342] Train: [1/50][2031/2344] Data 0.003 (0.003) Batch 0.698 (0.618) Remain 19:46:14 loss: 0.8090 Lr: 0.00091
[2025-05-11 13:32:13,302 INFO misc.py line 117 288342] Train: [1/50][2032/2344] Data 0.002 (0.003) Batch 0.642 (0.618) Remain 19:46:15 loss: 0.8216 Lr: 0.00091
[2025-05-11 13:32:13,779 INFO misc.py line 117 288342] Train: [1/50][2033/2344] Data 0.002 (0.003) Batch 0.476 (0.618) Remain 19:46:06 loss: 0.8799 Lr: 0.00091
[2025-05-11 13:32:14,401 INFO misc.py line 117 288342] Train: [1/50][2034/2344] Data 0.003 (0.003) Batch 0.623 (0.618) Remain 19:46:06 loss: 0.8750 Lr: 0.00091
[2025-05-11 13:32:15,059 INFO misc.py line 117 288342] Train: [1/50][2035/2344] Data 0.003 (0.003) Batch 0.657 (0.618) Remain 19:46:07 loss: 0.9689 Lr: 0.00091
[2025-05-11 13:32:15,519 INFO misc.py line 117 288342] Train: [1/50][2036/2344] Data 0.003 (0.003) Batch 0.460 (0.618) Remain 19:45:58 loss: 0.8686 Lr: 0.00091
[2025-05-11 13:32:16,064 INFO misc.py line 117 288342] Train: [1/50][2037/2344] Data 0.003 (0.003) Batch 0.545 (0.618) Remain 19:45:53 loss: 0.8311 Lr: 0.00092
[2025-05-11 13:32:16,650 INFO misc.py line 117 288342] Train: [1/50][2038/2344] Data 0.003 (0.003) Batch 0.586 (0.618) Remain 19:45:51 loss: 0.8404 Lr: 0.00092
[2025-05-11 13:32:17,191 INFO misc.py line 117 288342] Train: [1/50][2039/2344] Data 0.002 (0.003) Batch 0.541 (0.618) Remain 19:45:46 loss: 0.7706 Lr: 0.00092
[2025-05-11 13:32:17,911 INFO misc.py line 117 288342] Train: [1/50][2040/2344] Data 0.002 (0.003) Batch 0.720 (0.618) Remain 19:45:51 loss: 0.8006 Lr: 0.00092
[2025-05-11 13:32:18,444 INFO misc.py line 117 288342] Train: [1/50][2041/2344] Data 0.002 (0.003) Batch 0.533 (0.618) Remain 19:45:45 loss: 0.7723 Lr: 0.00092
[2025-05-11 13:32:19,103 INFO misc.py line 117 288342] Train: [1/50][2042/2344] Data 0.003 (0.003) Batch 0.659 (0.618) Remain 19:45:47 loss: 0.8236 Lr: 0.00092
[2025-05-11 13:32:19,680 INFO misc.py line 117 288342] Train: [1/50][2043/2344] Data 0.002 (0.003) Batch 0.578 (0.618) Remain 19:45:44 loss: 0.7498 Lr: 0.00092
[2025-05-11 13:32:20,283 INFO misc.py line 117 288342] Train: [1/50][2044/2344] Data 0.002 (0.003) Batch 0.601 (0.618) Remain 19:45:43 loss: 1.0957 Lr: 0.00092
[2025-05-11 13:32:20,876 INFO misc.py line 117 288342] Train: [1/50][2045/2344] Data 0.003 (0.003) Batch 0.594 (0.618) Remain 19:45:41 loss: 0.8408 Lr: 0.00092
[2025-05-11 13:32:21,495 INFO misc.py line 117 288342] Train: [1/50][2046/2344] Data 0.003 (0.003) Batch 0.619 (0.618) Remain 19:45:40 loss: 0.8316 Lr: 0.00092
[2025-05-11 13:32:22,118 INFO misc.py line 117 288342] Train: [1/50][2047/2344] Data 0.003 (0.003) Batch 0.623 (0.618) Remain 19:45:40 loss: 0.7823 Lr: 0.00092
[2025-05-11 13:32:22,785 INFO misc.py line 117 288342] Train: [1/50][2048/2344] Data 0.003 (0.003) Batch 0.667 (0.618) Remain 19:45:42 loss: 0.9841 Lr: 0.00092
[2025-05-11 13:32:23,485 INFO misc.py line 117 288342] Train: [1/50][2049/2344] Data 0.003 (0.003) Batch 0.699 (0.618) Remain 19:45:46 loss: 0.7385 Lr: 0.00092
[2025-05-11 13:32:24,095 INFO misc.py line 117 288342] Train: [1/50][2050/2344] Data 0.002 (0.003) Batch 0.610 (0.618) Remain 19:45:45 loss: 1.0550 Lr: 0.00092
[2025-05-11 13:32:24,757 INFO misc.py line 117 288342] Train: [1/50][2051/2344] Data 0.003 (0.003) Batch 0.662 (0.618) Remain 19:45:47 loss: 1.0235 Lr: 0.00092
[2025-05-11 13:32:25,188 INFO misc.py line 117 288342] Train: [1/50][2052/2344] Data 0.003 (0.003) Batch 0.431 (0.618) Remain 19:45:36 loss: 0.9121 Lr: 0.00092
[2025-05-11 13:32:25,836 INFO misc.py line 117 288342] Train: [1/50][2053/2344] Data 0.002 (0.003) Batch 0.648 (0.618) Remain 19:45:37 loss: 0.9039 Lr: 0.00092
[2025-05-11 13:32:26,460 INFO misc.py line 117 288342] Train: [1/50][2054/2344] Data 0.003 (0.003) Batch 0.624 (0.618) Remain 19:45:36 loss: 0.8404 Lr: 0.00093
[2025-05-11 13:32:27,038 INFO misc.py line 117 288342] Train: [1/50][2055/2344] Data 0.003 (0.003) Batch 0.578 (0.618) Remain 19:45:34 loss: 0.9219 Lr: 0.00093
[2025-05-11 13:32:27,553 INFO misc.py line 117 288342] Train: [1/50][2056/2344] Data 0.002 (0.003) Batch 0.514 (0.618) Remain 19:45:27 loss: 0.9881 Lr: 0.00093
[2025-05-11 13:32:28,219 INFO misc.py line 117 288342] Train: [1/50][2057/2344] Data 0.003 (0.003) Batch 0.666 (0.618) Remain 19:45:29 loss: 1.0309 Lr: 0.00093
[2025-05-11 13:32:28,760 INFO misc.py line 117 288342] Train: [1/50][2058/2344] Data 0.002 (0.003) Batch 0.541 (0.618) Remain 19:45:24 loss: 0.7935 Lr: 0.00093
[2025-05-11 13:32:29,354 INFO misc.py line 117 288342] Train: [1/50][2059/2344] Data 0.002 (0.003) Batch 0.594 (0.618) Remain 19:45:22 loss: 1.0012 Lr: 0.00093
[2025-05-11 13:32:30,062 INFO misc.py line 117 288342] Train: [1/50][2060/2344] Data 0.002 (0.003) Batch 0.708 (0.618) Remain 19:45:27 loss: 1.0186 Lr: 0.00093
[2025-05-11 13:32:30,571 INFO misc.py line 117 288342] Train: [1/50][2061/2344] Data 0.003 (0.003) Batch 0.509 (0.618) Remain 19:45:20 loss: 0.7573 Lr: 0.00093
[2025-05-11 13:32:31,237 INFO misc.py line 117 288342] Train: [1/50][2062/2344] Data 0.003 (0.003) Batch 0.666 (0.618) Remain 19:45:22 loss: 0.9419 Lr: 0.00093
[2025-05-11 13:32:31,753 INFO misc.py line 117 288342] Train: [1/50][2063/2344] Data 0.003 (0.003) Batch 0.516 (0.618) Remain 19:45:16 loss: 0.8960 Lr: 0.00093
[2025-05-11 13:32:32,295 INFO misc.py line 117 288342] Train: [1/50][2064/2344] Data 0.003 (0.003) Batch 0.542 (0.618) Remain 19:45:11 loss: 0.7716 Lr: 0.00093
[2025-05-11 13:32:32,990 INFO misc.py line 117 288342] Train: [1/50][2065/2344] Data 0.003 (0.003) Batch 0.695 (0.618) Remain 19:45:15 loss: 0.9431 Lr: 0.00093
[2025-05-11 13:32:33,631 INFO misc.py line 117 288342] Train: [1/50][2066/2344] Data 0.003 (0.003) Batch 0.641 (0.618) Remain 19:45:15 loss: 0.8526 Lr: 0.00093
[2025-05-11 13:32:34,130 INFO misc.py line 117 288342] Train: [1/50][2067/2344] Data 0.003 (0.003) Batch 0.499 (0.618) Remain 19:45:08 loss: 0.8191 Lr: 0.00093
[2025-05-11 13:32:34,746 INFO misc.py line 117 288342] Train: [1/50][2068/2344] Data 0.002 (0.003) Batch 0.616 (0.618) Remain 19:45:08 loss: 0.9372 Lr: 0.00093
[2025-05-11 13:32:35,239 INFO misc.py line 117 288342] Train: [1/50][2069/2344] Data 0.003 (0.003) Batch 0.493 (0.618) Remain 19:45:00 loss: 0.8433 Lr: 0.00093
[2025-05-11 13:32:35,890 INFO misc.py line 117 288342] Train: [1/50][2070/2344] Data 0.005 (0.003) Batch 0.651 (0.618) Remain 19:45:01 loss: 0.9670 Lr: 0.00093
[2025-05-11 13:32:36,501 INFO misc.py line 117 288342] Train: [1/50][2071/2344] Data 0.002 (0.003) Batch 0.611 (0.618) Remain 19:45:00 loss: 0.6734 Lr: 0.00094
[2025-05-11 13:32:37,000 INFO misc.py line 117 288342] Train: [1/50][2072/2344] Data 0.003 (0.003) Batch 0.499 (0.618) Remain 19:44:53 loss: 0.7166 Lr: 0.00094
[2025-05-11 13:32:37,573 INFO misc.py line 117 288342] Train: [1/50][2073/2344] Data 0.003 (0.003) Batch 0.573 (0.617) Remain 19:44:50 loss: 0.8081 Lr: 0.00094
[2025-05-11 13:32:38,228 INFO misc.py line 117 288342] Train: [1/50][2074/2344] Data 0.002 (0.003) Batch 0.654 (0.618) Remain 19:44:51 loss: 1.0508 Lr: 0.00094
[2025-05-11 13:32:38,877 INFO misc.py line 117 288342] Train: [1/50][2075/2344] Data 0.003 (0.003) Batch 0.649 (0.618) Remain 19:44:53 loss: 0.8168 Lr: 0.00094
[2025-05-11 13:32:39,469 INFO misc.py line 117 288342] Train: [1/50][2076/2344] Data 0.003 (0.003) Batch 0.592 (0.618) Remain 19:44:50 loss: 0.9852 Lr: 0.00094
[2025-05-11 13:32:40,096 INFO misc.py line 117 288342] Train: [1/50][2077/2344] Data 0.003 (0.003) Batch 0.627 (0.618) Remain 19:44:50 loss: 0.9197 Lr: 0.00094
[2025-05-11 13:32:40,706 INFO misc.py line 117 288342] Train: [1/50][2078/2344] Data 0.003 (0.003) Batch 0.610 (0.618) Remain 19:44:49 loss: 0.9414 Lr: 0.00094
[2025-05-11 13:32:41,400 INFO misc.py line 117 288342] Train: [1/50][2079/2344] Data 0.003 (0.003) Batch 0.694 (0.618) Remain 19:44:53 loss: 0.6603 Lr: 0.00094
[2025-05-11 13:32:41,994 INFO misc.py line 117 288342] Train: [1/50][2080/2344] Data 0.002 (0.003) Batch 0.594 (0.618) Remain 19:44:51 loss: 0.6930 Lr: 0.00094
[2025-05-11 13:32:42,639 INFO misc.py line 117 288342] Train: [1/50][2081/2344] Data 0.003 (0.003) Batch 0.646 (0.618) Remain 19:44:52 loss: 0.7979 Lr: 0.00094
[2025-05-11 13:32:43,272 INFO misc.py line 117 288342] Train: [1/50][2082/2344] Data 0.002 (0.003) Batch 0.632 (0.618) Remain 19:44:52 loss: 0.7630 Lr: 0.00094
[2025-05-11 13:32:43,829 INFO misc.py line 117 288342] Train: [1/50][2083/2344] Data 0.002 (0.003) Batch 0.556 (0.618) Remain 19:44:48 loss: 0.8097 Lr: 0.00094
[2025-05-11 13:32:44,468 INFO misc.py line 117 288342] Train: [1/50][2084/2344] Data 0.003 (0.003) Batch 0.640 (0.618) Remain 19:44:49 loss: 0.7103 Lr: 0.00094
[2025-05-11 13:32:44,918 INFO misc.py line 117 288342] Train: [1/50][2085/2344] Data 0.002 (0.003) Batch 0.448 (0.617) Remain 19:44:39 loss: 0.7847 Lr: 0.00094
[2025-05-11 13:32:45,495 INFO misc.py line 117 288342] Train: [1/50][2086/2344] Data 0.004 (0.003) Batch 0.578 (0.617) Remain 19:44:36 loss: 0.9475 Lr: 0.00094
[2025-05-11 13:32:46,090 INFO misc.py line 117 288342] Train: [1/50][2087/2344] Data 0.003 (0.003) Batch 0.595 (0.617) Remain 19:44:34 loss: 0.7147 Lr: 0.00094
[2025-05-11 13:32:46,721 INFO misc.py line 117 288342] Train: [1/50][2088/2344] Data 0.003 (0.003) Batch 0.631 (0.617) Remain 19:44:34 loss: 0.7995 Lr: 0.00095
[2025-05-11 13:32:47,217 INFO misc.py line 117 288342] Train: [1/50][2089/2344] Data 0.004 (0.003) Batch 0.496 (0.617) Remain 19:44:27 loss: 0.8522 Lr: 0.00095
[2025-05-11 13:32:47,868 INFO misc.py line 117 288342] Train: [1/50][2090/2344] Data 0.003 (0.003) Batch 0.651 (0.617) Remain 19:44:28 loss: 1.0788 Lr: 0.00095
[2025-05-11 13:32:48,399 INFO misc.py line 117 288342] Train: [1/50][2091/2344] Data 0.003 (0.003) Batch 0.531 (0.617) Remain 19:44:23 loss: 1.0707 Lr: 0.00095
[2025-05-11 13:32:48,969 INFO misc.py line 117 288342] Train: [1/50][2092/2344] Data 0.003 (0.003) Batch 0.569 (0.617) Remain 19:44:20 loss: 0.8483 Lr: 0.00095
[2025-05-11 13:32:49,552 INFO misc.py line 117 288342] Train: [1/50][2093/2344] Data 0.003 (0.003) Batch 0.583 (0.617) Remain 19:44:17 loss: 0.8475 Lr: 0.00095
[2025-05-11 13:32:50,082 INFO misc.py line 117 288342] Train: [1/50][2094/2344] Data 0.002 (0.003) Batch 0.530 (0.617) Remain 19:44:12 loss: 0.7409 Lr: 0.00095
[2025-05-11 13:32:50,858 INFO misc.py line 117 288342] Train: [1/50][2095/2344] Data 0.003 (0.003) Batch 0.777 (0.617) Remain 19:44:20 loss: 0.8899 Lr: 0.00095
[2025-05-11 13:32:51,508 INFO misc.py line 117 288342] Train: [1/50][2096/2344] Data 0.002 (0.003) Batch 0.649 (0.617) Remain 19:44:21 loss: 0.7026 Lr: 0.00095
[2025-05-11 13:32:52,098 INFO misc.py line 117 288342] Train: [1/50][2097/2344] Data 0.003 (0.003) Batch 0.590 (0.617) Remain 19:44:19 loss: 0.9471 Lr: 0.00095
[2025-05-11 13:32:52,814 INFO misc.py line 117 288342] Train: [1/50][2098/2344] Data 0.003 (0.003) Batch 0.716 (0.617) Remain 19:44:24 loss: 0.7949 Lr: 0.00095
[2025-05-11 13:32:53,490 INFO misc.py line 117 288342] Train: [1/50][2099/2344] Data 0.002 (0.003) Batch 0.675 (0.617) Remain 19:44:26 loss: 0.7858 Lr: 0.00095
[2025-05-11 13:32:54,131 INFO misc.py line 117 288342] Train: [1/50][2100/2344] Data 0.002 (0.003) Batch 0.642 (0.617) Remain 19:44:27 loss: 1.1066 Lr: 0.00095
[2025-05-11 13:32:54,743 INFO misc.py line 117 288342] Train: [1/50][2101/2344] Data 0.002 (0.003) Batch 0.612 (0.617) Remain 19:44:26 loss: 0.7757 Lr: 0.00095
[2025-05-11 13:32:55,420 INFO misc.py line 117 288342] Train: [1/50][2102/2344] Data 0.002 (0.003) Batch 0.677 (0.617) Remain 19:44:29 loss: 0.8097 Lr: 0.00095
[2025-05-11 13:32:56,016 INFO misc.py line 117 288342] Train: [1/50][2103/2344] Data 0.002 (0.003) Batch 0.596 (0.617) Remain 19:44:27 loss: 1.2640 Lr: 0.00095
[2025-05-11 13:32:56,736 INFO misc.py line 117 288342] Train: [1/50][2104/2344] Data 0.002 (0.003) Batch 0.720 (0.618) Remain 19:44:32 loss: 0.6439 Lr: 0.00095
[2025-05-11 13:32:57,390 INFO misc.py line 117 288342] Train: [1/50][2105/2344] Data 0.002 (0.003) Batch 0.654 (0.618) Remain 19:44:33 loss: 1.0182 Lr: 0.00096
[2025-05-11 13:32:57,974 INFO misc.py line 117 288342] Train: [1/50][2106/2344] Data 0.002 (0.003) Batch 0.583 (0.618) Remain 19:44:31 loss: 0.7501 Lr: 0.00096
[2025-05-11 13:32:58,741 INFO misc.py line 117 288342] Train: [1/50][2107/2344] Data 0.003 (0.003) Batch 0.767 (0.618) Remain 19:44:38 loss: 0.9218 Lr: 0.00096
[2025-05-11 13:32:59,425 INFO misc.py line 117 288342] Train: [1/50][2108/2344] Data 0.002 (0.003) Batch 0.684 (0.618) Remain 19:44:41 loss: 1.2353 Lr: 0.00096
[2025-05-11 13:32:59,978 INFO misc.py line 117 288342] Train: [1/50][2109/2344] Data 0.002 (0.003) Batch 0.553 (0.618) Remain 19:44:37 loss: 0.9887 Lr: 0.00096
[2025-05-11 13:33:00,562 INFO misc.py line 117 288342] Train: [1/50][2110/2344] Data 0.005 (0.003) Batch 0.584 (0.618) Remain 19:44:35 loss: 0.8024 Lr: 0.00096
[2025-05-11 13:33:01,123 INFO misc.py line 117 288342] Train: [1/50][2111/2344] Data 0.002 (0.003) Batch 0.561 (0.618) Remain 19:44:31 loss: 0.6285 Lr: 0.00096
[2025-05-11 13:33:01,789 INFO misc.py line 117 288342] Train: [1/50][2112/2344] Data 0.002 (0.003) Batch 0.666 (0.618) Remain 19:44:33 loss: 0.7453 Lr: 0.00096
[2025-05-11 13:33:02,295 INFO misc.py line 117 288342] Train: [1/50][2113/2344] Data 0.002 (0.003) Batch 0.507 (0.618) Remain 19:44:26 loss: 1.0170 Lr: 0.00096
[2025-05-11 13:33:02,908 INFO misc.py line 117 288342] Train: [1/50][2114/2344] Data 0.002 (0.003) Batch 0.613 (0.618) Remain 19:44:26 loss: 1.1226 Lr: 0.00096
[2025-05-11 13:33:03,562 INFO misc.py line 117 288342] Train: [1/50][2115/2344] Data 0.002 (0.003) Batch 0.654 (0.618) Remain 19:44:27 loss: 0.9391 Lr: 0.00096
[2025-05-11 13:33:04,231 INFO misc.py line 117 288342] Train: [1/50][2116/2344] Data 0.002 (0.003) Batch 0.669 (0.618) Remain 19:44:29 loss: 1.0119 Lr: 0.00096
[2025-05-11 13:33:04,751 INFO misc.py line 117 288342] Train: [1/50][2117/2344] Data 0.002 (0.003) Batch 0.520 (0.617) Remain 19:44:23 loss: 0.8357 Lr: 0.00096
[2025-05-11 13:33:05,328 INFO misc.py line 117 288342] Train: [1/50][2118/2344] Data 0.003 (0.003) Batch 0.576 (0.617) Remain 19:44:20 loss: 1.0263 Lr: 0.00096
[2025-05-11 13:33:06,040 INFO misc.py line 117 288342] Train: [1/50][2119/2344] Data 0.003 (0.003) Batch 0.712 (0.618) Remain 19:44:25 loss: 1.0069 Lr: 0.00096
[2025-05-11 13:33:06,690 INFO misc.py line 117 288342] Train: [1/50][2120/2344] Data 0.003 (0.003) Batch 0.650 (0.618) Remain 19:44:26 loss: 0.7237 Lr: 0.00096
[2025-05-11 13:33:07,274 INFO misc.py line 117 288342] Train: [1/50][2121/2344] Data 0.003 (0.003) Batch 0.584 (0.618) Remain 19:44:24 loss: 0.6246 Lr: 0.00097
[2025-05-11 13:33:07,924 INFO misc.py line 117 288342] Train: [1/50][2122/2344] Data 0.003 (0.003) Batch 0.650 (0.618) Remain 19:44:25 loss: 0.7787 Lr: 0.00097
[2025-05-11 13:33:08,569 INFO misc.py line 117 288342] Train: [1/50][2123/2344] Data 0.003 (0.003) Batch 0.645 (0.618) Remain 19:44:26 loss: 0.8773 Lr: 0.00097
[2025-05-11 13:33:09,266 INFO misc.py line 117 288342] Train: [1/50][2124/2344] Data 0.003 (0.003) Batch 0.697 (0.618) Remain 19:44:29 loss: 0.9046 Lr: 0.00097
[2025-05-11 13:33:09,946 INFO misc.py line 117 288342] Train: [1/50][2125/2344] Data 0.003 (0.003) Batch 0.680 (0.618) Remain 19:44:32 loss: 1.1416 Lr: 0.00097
[2025-05-11 13:33:10,568 INFO misc.py line 117 288342] Train: [1/50][2126/2344] Data 0.003 (0.003) Batch 0.623 (0.618) Remain 19:44:32 loss: 1.0080 Lr: 0.00097
[2025-05-11 13:33:11,185 INFO misc.py line 117 288342] Train: [1/50][2127/2344] Data 0.003 (0.003) Batch 0.617 (0.618) Remain 19:44:31 loss: 0.8644 Lr: 0.00097
[2025-05-11 13:33:11,699 INFO misc.py line 117 288342] Train: [1/50][2128/2344] Data 0.003 (0.003) Batch 0.514 (0.618) Remain 19:44:25 loss: 1.0470 Lr: 0.00097
[2025-05-11 13:33:12,388 INFO misc.py line 117 288342] Train: [1/50][2129/2344] Data 0.003 (0.003) Batch 0.690 (0.618) Remain 19:44:28 loss: 0.7838 Lr: 0.00097
[2025-05-11 13:33:12,819 INFO misc.py line 117 288342] Train: [1/50][2130/2344] Data 0.002 (0.003) Batch 0.430 (0.618) Remain 19:44:17 loss: 1.1217 Lr: 0.00097
[2025-05-11 13:33:13,505 INFO misc.py line 117 288342] Train: [1/50][2131/2344] Data 0.003 (0.003) Batch 0.686 (0.618) Remain 19:44:20 loss: 0.8199 Lr: 0.00097
[2025-05-11 13:33:14,109 INFO misc.py line 117 288342] Train: [1/50][2132/2344] Data 0.002 (0.003) Batch 0.604 (0.618) Remain 19:44:19 loss: 0.6562 Lr: 0.00097
[2025-05-11 13:33:14,667 INFO misc.py line 117 288342] Train: [1/50][2133/2344] Data 0.002 (0.003) Batch 0.558 (0.618) Remain 19:44:15 loss: 0.7269 Lr: 0.00097
[2025-05-11 13:33:15,338 INFO misc.py line 117 288342] Train: [1/50][2134/2344] Data 0.003 (0.003) Batch 0.671 (0.618) Remain 19:44:18 loss: 0.8235 Lr: 0.00097
[2025-05-11 13:33:15,867 INFO misc.py line 117 288342] Train: [1/50][2135/2344] Data 0.002 (0.003) Batch 0.529 (0.617) Remain 19:44:12 loss: 0.9330 Lr: 0.00097
[2025-05-11 13:33:16,588 INFO misc.py line 117 288342] Train: [1/50][2136/2344] Data 0.003 (0.003) Batch 0.722 (0.618) Remain 19:44:17 loss: 0.8385 Lr: 0.00097
[2025-05-11 13:33:17,255 INFO misc.py line 117 288342] Train: [1/50][2137/2344] Data 0.002 (0.003) Batch 0.667 (0.618) Remain 19:44:19 loss: 1.5070 Lr: 0.00097
[2025-05-11 13:33:17,947 INFO misc.py line 117 288342] Train: [1/50][2138/2344] Data 0.002 (0.003) Batch 0.692 (0.618) Remain 19:44:23 loss: 0.8168 Lr: 0.00098
[2025-05-11 13:33:18,528 INFO misc.py line 117 288342] Train: [1/50][2139/2344] Data 0.003 (0.003) Batch 0.580 (0.618) Remain 19:44:20 loss: 1.1971 Lr: 0.00098
[2025-05-11 13:33:19,059 INFO misc.py line 117 288342] Train: [1/50][2140/2344] Data 0.002 (0.003) Batch 0.530 (0.618) Remain 19:44:15 loss: 0.8893 Lr: 0.00098
[2025-05-11 13:33:19,647 INFO misc.py line 117 288342] Train: [1/50][2141/2344] Data 0.004 (0.003) Batch 0.589 (0.618) Remain 19:44:12 loss: 0.8345 Lr: 0.00098
[2025-05-11 13:33:20,283 INFO misc.py line 117 288342] Train: [1/50][2142/2344] Data 0.003 (0.003) Batch 0.636 (0.618) Remain 19:44:13 loss: 1.0818 Lr: 0.00098
[2025-05-11 13:33:20,984 INFO misc.py line 117 288342] Train: [1/50][2143/2344] Data 0.003 (0.003) Batch 0.701 (0.618) Remain 19:44:17 loss: 1.0988 Lr: 0.00098
[2025-05-11 13:33:21,517 INFO misc.py line 117 288342] Train: [1/50][2144/2344] Data 0.002 (0.003) Batch 0.533 (0.618) Remain 19:44:12 loss: 0.9937 Lr: 0.00098
[2025-05-11 13:33:22,220 INFO misc.py line 117 288342] Train: [1/50][2145/2344] Data 0.003 (0.003) Batch 0.702 (0.618) Remain 19:44:15 loss: 0.6455 Lr: 0.00098
[2025-05-11 13:33:22,881 INFO misc.py line 117 288342] Train: [1/50][2146/2344] Data 0.003 (0.003) Batch 0.661 (0.618) Remain 19:44:17 loss: 1.1112 Lr: 0.00098
[2025-05-11 13:33:23,593 INFO misc.py line 117 288342] Train: [1/50][2147/2344] Data 0.003 (0.003) Batch 0.713 (0.618) Remain 19:44:22 loss: 0.7435 Lr: 0.00098
[2025-05-11 13:33:24,080 INFO misc.py line 117 288342] Train: [1/50][2148/2344] Data 0.003 (0.003) Batch 0.487 (0.618) Remain 19:44:14 loss: 0.9434 Lr: 0.00098
[2025-05-11 13:33:24,795 INFO misc.py line 117 288342] Train: [1/50][2149/2344] Data 0.003 (0.003) Batch 0.715 (0.618) Remain 19:44:19 loss: 0.8841 Lr: 0.00098
[2025-05-11 13:33:25,355 INFO misc.py line 117 288342] Train: [1/50][2150/2344] Data 0.003 (0.003) Batch 0.560 (0.618) Remain 19:44:15 loss: 0.8511 Lr: 0.00098
[2025-05-11 13:33:26,072 INFO misc.py line 117 288342] Train: [1/50][2151/2344] Data 0.003 (0.003) Batch 0.717 (0.618) Remain 19:44:20 loss: 1.0579 Lr: 0.00098
[2025-05-11 13:33:26,805 INFO misc.py line 117 288342] Train: [1/50][2152/2344] Data 0.003 (0.003) Batch 0.734 (0.618) Remain 19:44:25 loss: 0.9124 Lr: 0.00098
[2025-05-11 13:33:27,342 INFO misc.py line 117 288342] Train: [1/50][2153/2344] Data 0.002 (0.003) Batch 0.537 (0.618) Remain 19:44:20 loss: 0.9417 Lr: 0.00098
[2025-05-11 13:33:27,908 INFO misc.py line 117 288342] Train: [1/50][2154/2344] Data 0.003 (0.003) Batch 0.566 (0.618) Remain 19:44:17 loss: 1.0122 Lr: 0.00098
[2025-05-11 13:33:28,462 INFO misc.py line 117 288342] Train: [1/50][2155/2344] Data 0.003 (0.003) Batch 0.554 (0.618) Remain 19:44:13 loss: 0.9385 Lr: 0.00099
[2025-05-11 13:33:29,041 INFO misc.py line 117 288342] Train: [1/50][2156/2344] Data 0.003 (0.003) Batch 0.579 (0.618) Remain 19:44:10 loss: 0.8997 Lr: 0.00099
[2025-05-11 13:33:29,936 INFO misc.py line 117 288342] Train: [1/50][2157/2344] Data 0.002 (0.003) Batch 0.895 (0.618) Remain 19:44:24 loss: 0.9480 Lr: 0.00099
[2025-05-11 13:33:30,688 INFO misc.py line 117 288342] Train: [1/50][2158/2344] Data 0.003 (0.003) Batch 0.751 (0.618) Remain 19:44:31 loss: 0.9326 Lr: 0.00099
[2025-05-11 13:33:31,348 INFO misc.py line 117 288342] Train: [1/50][2159/2344] Data 0.003 (0.003) Batch 0.660 (0.618) Remain 19:44:33 loss: 1.0793 Lr: 0.00099
[2025-05-11 13:33:31,974 INFO misc.py line 117 288342] Train: [1/50][2160/2344] Data 0.003 (0.003) Batch 0.626 (0.618) Remain 19:44:32 loss: 0.8863 Lr: 0.00099
[2025-05-11 13:33:32,601 INFO misc.py line 117 288342] Train: [1/50][2161/2344] Data 0.003 (0.003) Batch 0.627 (0.618) Remain 19:44:32 loss: 1.0132 Lr: 0.00099
[2025-05-11 13:33:33,210 INFO misc.py line 117 288342] Train: [1/50][2162/2344] Data 0.003 (0.003) Batch 0.609 (0.618) Remain 19:44:31 loss: 1.0024 Lr: 0.00099
[2025-05-11 13:33:33,756 INFO misc.py line 117 288342] Train: [1/50][2163/2344] Data 0.003 (0.003) Batch 0.546 (0.618) Remain 19:44:27 loss: 0.9803 Lr: 0.00099
[2025-05-11 13:33:34,328 INFO misc.py line 117 288342] Train: [1/50][2164/2344] Data 0.003 (0.003) Batch 0.572 (0.618) Remain 19:44:24 loss: 1.0298 Lr: 0.00099
[2025-05-11 13:33:34,978 INFO misc.py line 117 288342] Train: [1/50][2165/2344] Data 0.002 (0.003) Batch 0.650 (0.618) Remain 19:44:25 loss: 1.0531 Lr: 0.00099
[2025-05-11 13:33:35,562 INFO misc.py line 117 288342] Train: [1/50][2166/2344] Data 0.003 (0.003) Batch 0.584 (0.618) Remain 19:44:22 loss: 0.9345 Lr: 0.00099
[2025-05-11 13:33:36,234 INFO misc.py line 117 288342] Train: [1/50][2167/2344] Data 0.002 (0.003) Batch 0.672 (0.618) Remain 19:44:25 loss: 0.7752 Lr: 0.00099
[2025-05-11 13:33:36,834 INFO misc.py line 117 288342] Train: [1/50][2168/2344] Data 0.003 (0.003) Batch 0.601 (0.618) Remain 19:44:23 loss: 0.8259 Lr: 0.00099
[2025-05-11 13:33:37,434 INFO misc.py line 117 288342] Train: [1/50][2169/2344] Data 0.002 (0.003) Batch 0.600 (0.618) Remain 19:44:22 loss: 0.6671 Lr: 0.00099
[2025-05-11 13:33:37,970 INFO misc.py line 117 288342] Train: [1/50][2170/2344] Data 0.002 (0.003) Batch 0.536 (0.618) Remain 19:44:17 loss: 0.8997 Lr: 0.00099
[2025-05-11 13:33:38,533 INFO misc.py line 117 288342] Train: [1/50][2171/2344] Data 0.002 (0.003) Batch 0.563 (0.618) Remain 19:44:13 loss: 0.7945 Lr: 0.00099
[2025-05-11 13:33:39,010 INFO misc.py line 117 288342] Train: [1/50][2172/2344] Data 0.002 (0.003) Batch 0.478 (0.618) Remain 19:44:05 loss: 0.8457 Lr: 0.00100
[2025-05-11 13:33:39,417 INFO misc.py line 117 288342] Train: [1/50][2173/2344] Data 0.003 (0.003) Batch 0.407 (0.618) Remain 19:43:53 loss: 1.4479 Lr: 0.00100
[2025-05-11 13:33:39,915 INFO misc.py line 117 288342] Train: [1/50][2174/2344] Data 0.002 (0.003) Batch 0.498 (0.617) Remain 19:43:46 loss: 0.8019 Lr: 0.00100
[2025-05-11 13:33:40,564 INFO misc.py line 117 288342] Train: [1/50][2175/2344] Data 0.003 (0.003) Batch 0.649 (0.617) Remain 19:43:47 loss: 0.8776 Lr: 0.00100
[2025-05-11 13:33:41,144 INFO misc.py line 117 288342] Train: [1/50][2176/2344] Data 0.002 (0.003) Batch 0.580 (0.617) Remain 19:43:45 loss: 0.8752 Lr: 0.00100
[2025-05-11 13:33:41,751 INFO misc.py line 117 288342] Train: [1/50][2177/2344] Data 0.003 (0.003) Batch 0.607 (0.617) Remain 19:43:43 loss: 0.9834 Lr: 0.00100
[2025-05-11 13:33:42,209 INFO misc.py line 117 288342] Train: [1/50][2178/2344] Data 0.002 (0.003) Batch 0.458 (0.617) Remain 19:43:34 loss: 0.7640 Lr: 0.00100
[2025-05-11 13:33:42,886 INFO misc.py line 117 288342] Train: [1/50][2179/2344] Data 0.003 (0.003) Batch 0.677 (0.617) Remain 19:43:37 loss: 0.8563 Lr: 0.00100
[2025-05-11 13:33:43,554 INFO misc.py line 117 288342] Train: [1/50][2180/2344] Data 0.003 (0.003) Batch 0.669 (0.617) Remain 19:43:39 loss: 0.9323 Lr: 0.00100
[2025-05-11 13:33:44,076 INFO misc.py line 117 288342] Train: [1/50][2181/2344] Data 0.002 (0.003) Batch 0.522 (0.617) Remain 19:43:33 loss: 0.8575 Lr: 0.00100
[2025-05-11 13:33:44,665 INFO misc.py line 117 288342] Train: [1/50][2182/2344] Data 0.002 (0.003) Batch 0.589 (0.617) Remain 19:43:31 loss: 1.0178 Lr: 0.00100
[2025-05-11 13:33:45,258 INFO misc.py line 117 288342] Train: [1/50][2183/2344] Data 0.003 (0.003) Batch 0.593 (0.617) Remain 19:43:29 loss: 0.7956 Lr: 0.00100
[2025-05-11 13:33:45,802 INFO misc.py line 117 288342] Train: [1/50][2184/2344] Data 0.002 (0.003) Batch 0.544 (0.617) Remain 19:43:25 loss: 0.7549 Lr: 0.00100
[2025-05-11 13:33:46,415 INFO misc.py line 117 288342] Train: [1/50][2185/2344] Data 0.002 (0.003) Batch 0.612 (0.617) Remain 19:43:24 loss: 1.2463 Lr: 0.00100
[2025-05-11 13:33:47,071 INFO misc.py line 117 288342] Train: [1/50][2186/2344] Data 0.002 (0.003) Batch 0.656 (0.617) Remain 19:43:25 loss: 0.8148 Lr: 0.00100
[2025-05-11 13:33:47,768 INFO misc.py line 117 288342] Train: [1/50][2187/2344] Data 0.002 (0.003) Batch 0.697 (0.617) Remain 19:43:29 loss: 0.8587 Lr: 0.00100
[2025-05-11 13:33:48,228 INFO misc.py line 117 288342] Train: [1/50][2188/2344] Data 0.002 (0.003) Batch 0.460 (0.617) Remain 19:43:20 loss: 0.8756 Lr: 0.00101
[2025-05-11 13:33:48,778 INFO misc.py line 117 288342] Train: [1/50][2189/2344] Data 0.003 (0.003) Batch 0.550 (0.617) Remain 19:43:16 loss: 0.8413 Lr: 0.00101
[2025-05-11 13:33:49,289 INFO misc.py line 117 288342] Train: [1/50][2190/2344] Data 0.003 (0.003) Batch 0.511 (0.617) Remain 19:43:10 loss: 0.8852 Lr: 0.00101
[2025-05-11 13:33:50,041 INFO misc.py line 117 288342] Train: [1/50][2191/2344] Data 0.003 (0.003) Batch 0.752 (0.617) Remain 19:43:16 loss: 0.8104 Lr: 0.00101
[2025-05-11 13:33:50,671 INFO misc.py line 117 288342] Train: [1/50][2192/2344] Data 0.002 (0.003) Batch 0.631 (0.617) Remain 19:43:16 loss: 1.1901 Lr: 0.00101
[2025-05-11 13:33:51,236 INFO misc.py line 117 288342] Train: [1/50][2193/2344] Data 0.003 (0.003) Batch 0.565 (0.617) Remain 19:43:13 loss: 0.9176 Lr: 0.00101
[2025-05-11 13:33:51,999 INFO misc.py line 117 288342] Train: [1/50][2194/2344] Data 0.003 (0.003) Batch 0.763 (0.617) Remain 19:43:20 loss: 0.8767 Lr: 0.00101
[2025-05-11 13:33:52,544 INFO misc.py line 117 288342] Train: [1/50][2195/2344] Data 0.003 (0.003) Batch 0.545 (0.617) Remain 19:43:16 loss: 0.7426 Lr: 0.00101
[2025-05-11 13:33:53,172 INFO misc.py line 117 288342] Train: [1/50][2196/2344] Data 0.003 (0.003) Batch 0.628 (0.617) Remain 19:43:15 loss: 1.2240 Lr: 0.00101
[2025-05-11 13:33:53,699 INFO misc.py line 117 288342] Train: [1/50][2197/2344] Data 0.002 (0.003) Batch 0.528 (0.617) Remain 19:43:10 loss: 1.0433 Lr: 0.00101
[2025-05-11 13:33:54,347 INFO misc.py line 117 288342] Train: [1/50][2198/2344] Data 0.002 (0.003) Batch 0.647 (0.617) Remain 19:43:11 loss: 1.1957 Lr: 0.00101
[2025-05-11 13:33:54,956 INFO misc.py line 117 288342] Train: [1/50][2199/2344] Data 0.002 (0.003) Batch 0.610 (0.617) Remain 19:43:10 loss: 0.8409 Lr: 0.00101
[2025-05-11 13:33:55,485 INFO misc.py line 117 288342] Train: [1/50][2200/2344] Data 0.002 (0.003) Batch 0.529 (0.617) Remain 19:43:05 loss: 0.7920 Lr: 0.00101
[2025-05-11 13:33:56,112 INFO misc.py line 117 288342] Train: [1/50][2201/2344] Data 0.002 (0.003) Batch 0.627 (0.617) Remain 19:43:05 loss: 1.0220 Lr: 0.00101
[2025-05-11 13:33:56,765 INFO misc.py line 117 288342] Train: [1/50][2202/2344] Data 0.002 (0.003) Batch 0.653 (0.617) Remain 19:43:06 loss: 0.8202 Lr: 0.00101
[2025-05-11 13:33:57,421 INFO misc.py line 117 288342] Train: [1/50][2203/2344] Data 0.002 (0.003) Batch 0.656 (0.617) Remain 19:43:07 loss: 0.9460 Lr: 0.00101
[2025-05-11 13:33:57,977 INFO misc.py line 117 288342] Train: [1/50][2204/2344] Data 0.002 (0.003) Batch 0.556 (0.617) Remain 19:43:04 loss: 0.8478 Lr: 0.00101
[2025-05-11 13:33:58,514 INFO misc.py line 117 288342] Train: [1/50][2205/2344] Data 0.002 (0.003) Batch 0.537 (0.617) Remain 19:42:59 loss: 0.6532 Lr: 0.00102
[2025-05-11 13:33:59,189 INFO misc.py line 117 288342] Train: [1/50][2206/2344] Data 0.003 (0.003) Batch 0.675 (0.617) Remain 19:43:01 loss: 0.8366 Lr: 0.00102
[2025-05-11 13:33:59,838 INFO misc.py line 117 288342] Train: [1/50][2207/2344] Data 0.003 (0.003) Batch 0.649 (0.617) Remain 19:43:02 loss: 0.8641 Lr: 0.00102
[2025-05-11 13:34:00,447 INFO misc.py line 117 288342] Train: [1/50][2208/2344] Data 0.003 (0.003) Batch 0.609 (0.617) Remain 19:43:01 loss: 0.9110 Lr: 0.00102
[2025-05-11 13:34:01,118 INFO misc.py line 117 288342] Train: [1/50][2209/2344] Data 0.003 (0.003) Batch 0.670 (0.617) Remain 19:43:03 loss: 0.8923 Lr: 0.00102
[2025-05-11 13:34:01,792 INFO misc.py line 117 288342] Train: [1/50][2210/2344] Data 0.003 (0.003) Batch 0.674 (0.617) Remain 19:43:06 loss: 0.9862 Lr: 0.00102
[2025-05-11 13:34:02,425 INFO misc.py line 117 288342] Train: [1/50][2211/2344] Data 0.003 (0.003) Batch 0.633 (0.617) Remain 19:43:06 loss: 0.8834 Lr: 0.00102
[2025-05-11 13:34:02,991 INFO misc.py line 117 288342] Train: [1/50][2212/2344] Data 0.002 (0.003) Batch 0.567 (0.617) Remain 19:43:03 loss: 0.9532 Lr: 0.00102
[2025-05-11 13:34:03,508 INFO misc.py line 117 288342] Train: [1/50][2213/2344] Data 0.003 (0.003) Batch 0.517 (0.617) Remain 19:42:57 loss: 0.9175 Lr: 0.00102
[2025-05-11 13:34:04,261 INFO misc.py line 117 288342] Train: [1/50][2214/2344] Data 0.003 (0.003) Batch 0.753 (0.617) Remain 19:43:03 loss: 0.8420 Lr: 0.00102
[2025-05-11 13:34:04,917 INFO misc.py line 117 288342] Train: [1/50][2215/2344] Data 0.003 (0.003) Batch 0.656 (0.617) Remain 19:43:05 loss: 0.7607 Lr: 0.00102
[2025-05-11 13:34:05,668 INFO misc.py line 117 288342] Train: [1/50][2216/2344] Data 0.003 (0.003) Batch 0.751 (0.617) Remain 19:43:11 loss: 0.9774 Lr: 0.00102
[2025-05-11 13:34:06,314 INFO misc.py line 117 288342] Train: [1/50][2217/2344] Data 0.003 (0.003) Batch 0.646 (0.617) Remain 19:43:12 loss: 0.8555 Lr: 0.00102
[2025-05-11 13:34:07,067 INFO misc.py line 117 288342] Train: [1/50][2218/2344] Data 0.003 (0.003) Batch 0.753 (0.617) Remain 19:43:18 loss: 0.8263 Lr: 0.00102
[2025-05-11 13:34:07,671 INFO misc.py line 117 288342] Train: [1/50][2219/2344] Data 0.002 (0.003) Batch 0.604 (0.617) Remain 19:43:17 loss: 0.8762 Lr: 0.00102
[2025-05-11 13:34:08,182 INFO misc.py line 117 288342] Train: [1/50][2220/2344] Data 0.003 (0.003) Batch 0.511 (0.617) Remain 19:43:11 loss: 0.9689 Lr: 0.00102
[2025-05-11 13:34:08,816 INFO misc.py line 117 288342] Train: [1/50][2221/2344] Data 0.003 (0.003) Batch 0.634 (0.617) Remain 19:43:11 loss: 1.1545 Lr: 0.00102
[2025-05-11 13:34:09,526 INFO misc.py line 117 288342] Train: [1/50][2222/2344] Data 0.003 (0.003) Batch 0.710 (0.617) Remain 19:43:15 loss: 1.1443 Lr: 0.00103
[2025-05-11 13:34:10,191 INFO misc.py line 117 288342] Train: [1/50][2223/2344] Data 0.002 (0.003) Batch 0.665 (0.617) Remain 19:43:17 loss: 0.9948 Lr: 0.00103
[2025-05-11 13:34:10,793 INFO misc.py line 117 288342] Train: [1/50][2224/2344] Data 0.003 (0.003) Batch 0.602 (0.617) Remain 19:43:16 loss: 0.9716 Lr: 0.00103
[2025-05-11 13:34:11,324 INFO misc.py line 117 288342] Train: [1/50][2225/2344] Data 0.003 (0.003) Batch 0.530 (0.617) Remain 19:43:10 loss: 0.7437 Lr: 0.00103
[2025-05-11 13:34:11,908 INFO misc.py line 117 288342] Train: [1/50][2226/2344] Data 0.003 (0.003) Batch 0.584 (0.617) Remain 19:43:08 loss: 0.8615 Lr: 0.00103
[2025-05-11 13:34:12,423 INFO misc.py line 117 288342] Train: [1/50][2227/2344] Data 0.003 (0.003) Batch 0.516 (0.617) Remain 19:43:02 loss: 0.9595 Lr: 0.00103
[2025-05-11 13:34:13,046 INFO misc.py line 117 288342] Train: [1/50][2228/2344] Data 0.002 (0.003) Batch 0.623 (0.617) Remain 19:43:02 loss: 0.7759 Lr: 0.00103
[2025-05-11 13:34:13,600 INFO misc.py line 117 288342] Train: [1/50][2229/2344] Data 0.002 (0.003) Batch 0.554 (0.617) Remain 19:42:58 loss: 0.8271 Lr: 0.00103
[2025-05-11 13:34:14,297 INFO misc.py line 117 288342] Train: [1/50][2230/2344] Data 0.002 (0.003) Batch 0.696 (0.617) Remain 19:43:01 loss: 1.1482 Lr: 0.00103
[2025-05-11 13:34:14,929 INFO misc.py line 117 288342] Train: [1/50][2231/2344] Data 0.003 (0.003) Batch 0.633 (0.617) Remain 19:43:02 loss: 0.9509 Lr: 0.00103
[2025-05-11 13:34:15,481 INFO misc.py line 117 288342] Train: [1/50][2232/2344] Data 0.002 (0.003) Batch 0.552 (0.617) Remain 19:42:58 loss: 1.2226 Lr: 0.00103
[2025-05-11 13:34:16,091 INFO misc.py line 117 288342] Train: [1/50][2233/2344] Data 0.002 (0.003) Batch 0.609 (0.617) Remain 19:42:57 loss: 0.8472 Lr: 0.00103
[2025-05-11 13:34:16,658 INFO misc.py line 117 288342] Train: [1/50][2234/2344] Data 0.002 (0.003) Batch 0.567 (0.617) Remain 19:42:53 loss: 0.7048 Lr: 0.00103
[2025-05-11 13:34:17,308 INFO misc.py line 117 288342] Train: [1/50][2235/2344] Data 0.003 (0.003) Batch 0.651 (0.617) Remain 19:42:54 loss: 0.9597 Lr: 0.00103
[2025-05-11 13:34:17,881 INFO misc.py line 117 288342] Train: [1/50][2236/2344] Data 0.003 (0.003) Batch 0.573 (0.617) Remain 19:42:52 loss: 0.8614 Lr: 0.00103
[2025-05-11 13:34:18,453 INFO misc.py line 117 288342] Train: [1/50][2237/2344] Data 0.003 (0.003) Batch 0.572 (0.617) Remain 19:42:49 loss: 0.8661 Lr: 0.00103
[2025-05-11 13:34:18,919 INFO misc.py line 117 288342] Train: [1/50][2238/2344] Data 0.002 (0.003) Batch 0.466 (0.617) Remain 19:42:40 loss: 0.9721 Lr: 0.00104
[2025-05-11 13:34:19,502 INFO misc.py line 117 288342] Train: [1/50][2239/2344] Data 0.002 (0.003) Batch 0.583 (0.617) Remain 19:42:38 loss: 0.9005 Lr: 0.00104
[2025-05-11 13:34:20,031 INFO misc.py line 117 288342] Train: [1/50][2240/2344] Data 0.002 (0.003) Batch 0.529 (0.617) Remain 19:42:33 loss: 0.9198 Lr: 0.00104
[2025-05-11 13:34:20,763 INFO misc.py line 117 288342] Train: [1/50][2241/2344] Data 0.003 (0.003) Batch 0.733 (0.617) Remain 19:42:38 loss: 0.9243 Lr: 0.00104
[2025-05-11 13:34:21,373 INFO misc.py line 117 288342] Train: [1/50][2242/2344] Data 0.002 (0.003) Batch 0.609 (0.617) Remain 19:42:37 loss: 1.0080 Lr: 0.00104
[2025-05-11 13:34:21,900 INFO misc.py line 117 288342] Train: [1/50][2243/2344] Data 0.002 (0.003) Batch 0.527 (0.617) Remain 19:42:32 loss: 0.7589 Lr: 0.00104
[2025-05-11 13:34:22,524 INFO misc.py line 117 288342] Train: [1/50][2244/2344] Data 0.003 (0.003) Batch 0.625 (0.617) Remain 19:42:31 loss: 1.0663 Lr: 0.00104
[2025-05-11 13:34:23,223 INFO misc.py line 117 288342] Train: [1/50][2245/2344] Data 0.002 (0.003) Batch 0.699 (0.617) Remain 19:42:35 loss: 0.7644 Lr: 0.00104
[2025-05-11 13:34:23,823 INFO misc.py line 117 288342] Train: [1/50][2246/2344] Data 0.002 (0.003) Batch 0.600 (0.617) Remain 19:42:34 loss: 0.7682 Lr: 0.00104
[2025-05-11 13:34:24,445 INFO misc.py line 117 288342] Train: [1/50][2247/2344] Data 0.003 (0.003) Batch 0.622 (0.617) Remain 19:42:33 loss: 1.0043 Lr: 0.00104
[2025-05-11 13:34:25,171 INFO misc.py line 117 288342] Train: [1/50][2248/2344] Data 0.002 (0.003) Batch 0.727 (0.617) Remain 19:42:38 loss: 0.8550 Lr: 0.00104
[2025-05-11 13:34:25,690 INFO misc.py line 117 288342] Train: [1/50][2249/2344] Data 0.002 (0.003) Batch 0.519 (0.617) Remain 19:42:32 loss: 1.0102 Lr: 0.00104
[2025-05-11 13:34:26,210 INFO misc.py line 117 288342] Train: [1/50][2250/2344] Data 0.003 (0.003) Batch 0.520 (0.617) Remain 19:42:27 loss: 0.7266 Lr: 0.00104
[2025-05-11 13:34:26,776 INFO misc.py line 117 288342] Train: [1/50][2251/2344] Data 0.003 (0.003) Batch 0.566 (0.617) Remain 19:42:24 loss: 1.0808 Lr: 0.00104
[2025-05-11 13:34:27,472 INFO misc.py line 117 288342] Train: [1/50][2252/2344] Data 0.003 (0.003) Batch 0.696 (0.617) Remain 19:42:27 loss: 0.9510 Lr: 0.00104
[2025-05-11 13:34:28,152 INFO misc.py line 117 288342] Train: [1/50][2253/2344] Data 0.003 (0.003) Batch 0.681 (0.617) Remain 19:42:30 loss: 0.8330 Lr: 0.00104
[2025-05-11 13:34:28,830 INFO misc.py line 117 288342] Train: [1/50][2254/2344] Data 0.003 (0.003) Batch 0.678 (0.617) Remain 19:42:32 loss: 0.7336 Lr: 0.00104
[2025-05-11 13:34:29,313 INFO misc.py line 117 288342] Train: [1/50][2255/2344] Data 0.003 (0.003) Batch 0.483 (0.617) Remain 19:42:25 loss: 0.5700 Lr: 0.00105
[2025-05-11 13:34:29,902 INFO misc.py line 117 288342] Train: [1/50][2256/2344] Data 0.002 (0.003) Batch 0.589 (0.617) Remain 19:42:23 loss: 0.9933 Lr: 0.00105
[2025-05-11 13:34:30,473 INFO misc.py line 117 288342] Train: [1/50][2257/2344] Data 0.002 (0.003) Batch 0.571 (0.617) Remain 19:42:20 loss: 0.8394 Lr: 0.00105
[2025-05-11 13:34:31,045 INFO misc.py line 117 288342] Train: [1/50][2258/2344] Data 0.002 (0.003) Batch 0.573 (0.617) Remain 19:42:17 loss: 0.8369 Lr: 0.00105
[2025-05-11 13:34:31,642 INFO misc.py line 117 288342] Train: [1/50][2259/2344] Data 0.002 (0.003) Batch 0.597 (0.617) Remain 19:42:15 loss: 0.9607 Lr: 0.00105
[2025-05-11 13:34:32,279 INFO misc.py line 117 288342] Train: [1/50][2260/2344] Data 0.002 (0.003) Batch 0.636 (0.617) Remain 19:42:15 loss: 0.8962 Lr: 0.00105
[2025-05-11 13:34:32,840 INFO misc.py line 117 288342] Train: [1/50][2261/2344] Data 0.002 (0.003) Batch 0.561 (0.617) Remain 19:42:12 loss: 1.0139 Lr: 0.00105
[2025-05-11 13:34:33,464 INFO misc.py line 117 288342] Train: [1/50][2262/2344] Data 0.003 (0.003) Batch 0.624 (0.617) Remain 19:42:12 loss: 0.8154 Lr: 0.00105
[2025-05-11 13:34:34,109 INFO misc.py line 117 288342] Train: [1/50][2263/2344] Data 0.003 (0.003) Batch 0.644 (0.617) Remain 19:42:12 loss: 0.9796 Lr: 0.00105
[2025-05-11 13:34:34,682 INFO misc.py line 117 288342] Train: [1/50][2264/2344] Data 0.003 (0.003) Batch 0.574 (0.617) Remain 19:42:10 loss: 0.7166 Lr: 0.00105
[2025-05-11 13:34:35,222 INFO misc.py line 117 288342] Train: [1/50][2265/2344] Data 0.003 (0.003) Batch 0.540 (0.617) Remain 19:42:05 loss: 0.7907 Lr: 0.00105
[2025-05-11 13:34:35,815 INFO misc.py line 117 288342] Train: [1/50][2266/2344] Data 0.003 (0.003) Batch 0.593 (0.617) Remain 19:42:03 loss: 0.9621 Lr: 0.00105
[2025-05-11 13:34:36,377 INFO misc.py line 117 288342] Train: [1/50][2267/2344] Data 0.002 (0.003) Batch 0.562 (0.617) Remain 19:42:00 loss: 1.0339 Lr: 0.00105
[2025-05-11 13:34:36,929 INFO misc.py line 117 288342] Train: [1/50][2268/2344] Data 0.003 (0.003) Batch 0.552 (0.617) Remain 19:41:56 loss: 0.8410 Lr: 0.00105
[2025-05-11 13:34:37,527 INFO misc.py line 117 288342] Train: [1/50][2269/2344] Data 0.002 (0.003) Batch 0.599 (0.617) Remain 19:41:54 loss: 0.7421 Lr: 0.00105
[2025-05-11 13:34:37,992 INFO misc.py line 117 288342] Train: [1/50][2270/2344] Data 0.002 (0.003) Batch 0.465 (0.617) Remain 19:41:46 loss: 0.9046 Lr: 0.00105
[2025-05-11 13:34:38,494 INFO misc.py line 117 288342] Train: [1/50][2271/2344] Data 0.003 (0.003) Batch 0.501 (0.617) Remain 19:41:40 loss: 1.0346 Lr: 0.00106
[2025-05-11 13:34:39,135 INFO misc.py line 117 288342] Train: [1/50][2272/2344] Data 0.003 (0.003) Batch 0.641 (0.617) Remain 19:41:40 loss: 0.7382 Lr: 0.00106
[2025-05-11 13:34:39,790 INFO misc.py line 117 288342] Train: [1/50][2273/2344] Data 0.003 (0.003) Batch 0.655 (0.617) Remain 19:41:41 loss: 0.8623 Lr: 0.00106
[2025-05-11 13:34:40,415 INFO misc.py line 117 288342] Train: [1/50][2274/2344] Data 0.003 (0.003) Batch 0.626 (0.617) Remain 19:41:41 loss: 0.8587 Lr: 0.00106
[2025-05-11 13:34:41,073 INFO misc.py line 117 288342] Train: [1/50][2275/2344] Data 0.003 (0.003) Batch 0.657 (0.617) Remain 19:41:43 loss: 0.9415 Lr: 0.00106
[2025-05-11 13:34:41,571 INFO misc.py line 117 288342] Train: [1/50][2276/2344] Data 0.003 (0.003) Batch 0.499 (0.617) Remain 19:41:36 loss: 0.7684 Lr: 0.00106
[2025-05-11 13:34:42,249 INFO misc.py line 117 288342] Train: [1/50][2277/2344] Data 0.002 (0.003) Batch 0.677 (0.617) Remain 19:41:39 loss: 0.7172 Lr: 0.00106
[2025-05-11 13:34:42,851 INFO misc.py line 117 288342] Train: [1/50][2278/2344] Data 0.002 (0.003) Batch 0.603 (0.617) Remain 19:41:37 loss: 0.8183 Lr: 0.00106
[2025-05-11 13:34:43,536 INFO misc.py line 117 288342] Train: [1/50][2279/2344] Data 0.002 (0.003) Batch 0.685 (0.617) Remain 19:41:40 loss: 0.8749 Lr: 0.00106
[2025-05-11 13:34:44,159 INFO misc.py line 117 288342] Train: [1/50][2280/2344] Data 0.002 (0.003) Batch 0.623 (0.617) Remain 19:41:40 loss: 0.6811 Lr: 0.00106
[2025-05-11 13:34:44,811 INFO misc.py line 117 288342] Train: [1/50][2281/2344] Data 0.002 (0.003) Batch 0.653 (0.617) Remain 19:41:41 loss: 0.7461 Lr: 0.00106
[2025-05-11 13:34:45,260 INFO misc.py line 117 288342] Train: [1/50][2282/2344] Data 0.002 (0.003) Batch 0.448 (0.617) Remain 19:41:32 loss: 0.8276 Lr: 0.00106
[2025-05-11 13:34:45,968 INFO misc.py line 117 288342] Train: [1/50][2283/2344] Data 0.002 (0.003) Batch 0.708 (0.617) Remain 19:41:36 loss: 1.1884 Lr: 0.00106
[2025-05-11 13:34:46,449 INFO misc.py line 117 288342] Train: [1/50][2284/2344] Data 0.002 (0.003) Batch 0.481 (0.617) Remain 19:41:28 loss: 0.9421 Lr: 0.00106
[2025-05-11 13:34:47,133 INFO misc.py line 117 288342] Train: [1/50][2285/2344] Data 0.002 (0.003) Batch 0.683 (0.617) Remain 19:41:31 loss: 0.9969 Lr: 0.00106
[2025-05-11 13:34:47,639 INFO misc.py line 117 288342] Train: [1/50][2286/2344] Data 0.002 (0.003) Batch 0.506 (0.617) Remain 19:41:25 loss: 0.9055 Lr: 0.00106
[2025-05-11 13:34:48,096 INFO misc.py line 117 288342] Train: [1/50][2287/2344] Data 0.003 (0.003) Batch 0.458 (0.617) Remain 19:41:16 loss: 0.9145 Lr: 0.00106
[2025-05-11 13:34:48,776 INFO misc.py line 117 288342] Train: [1/50][2288/2344] Data 0.003 (0.003) Batch 0.679 (0.617) Remain 19:41:19 loss: 0.8031 Lr: 0.00107
[2025-05-11 13:34:49,416 INFO misc.py line 117 288342] Train: [1/50][2289/2344] Data 0.003 (0.003) Batch 0.640 (0.617) Remain 19:41:19 loss: 0.6404 Lr: 0.00107
[2025-05-11 13:34:50,082 INFO misc.py line 117 288342] Train: [1/50][2290/2344] Data 0.003 (0.003) Batch 0.666 (0.617) Remain 19:41:21 loss: 0.9177 Lr: 0.00107
[2025-05-11 13:34:50,778 INFO misc.py line 117 288342] Train: [1/50][2291/2344] Data 0.002 (0.003) Batch 0.696 (0.617) Remain 19:41:25 loss: 0.7623 Lr: 0.00107
[2025-05-11 13:34:51,388 INFO misc.py line 117 288342] Train: [1/50][2292/2344] Data 0.003 (0.003) Batch 0.610 (0.617) Remain 19:41:24 loss: 0.9180 Lr: 0.00107
[2025-05-11 13:34:51,988 INFO misc.py line 117 288342] Train: [1/50][2293/2344] Data 0.003 (0.003) Batch 0.601 (0.617) Remain 19:41:22 loss: 0.9049 Lr: 0.00107
[2025-05-11 13:34:52,669 INFO misc.py line 117 288342] Train: [1/50][2294/2344] Data 0.003 (0.003) Batch 0.680 (0.617) Remain 19:41:25 loss: 1.0478 Lr: 0.00107
[2025-05-11 13:34:53,426 INFO misc.py line 117 288342] Train: [1/50][2295/2344] Data 0.003 (0.003) Batch 0.757 (0.617) Remain 19:41:31 loss: 0.6356 Lr: 0.00107
[2025-05-11 13:34:53,875 INFO misc.py line 117 288342] Train: [1/50][2296/2344] Data 0.027 (0.003) Batch 0.450 (0.617) Remain 19:41:22 loss: 1.3444 Lr: 0.00107
[2025-05-11 13:34:54,528 INFO misc.py line 117 288342] Train: [1/50][2297/2344] Data 0.003 (0.003) Batch 0.652 (0.617) Remain 19:41:23 loss: 1.2309 Lr: 0.00107
[2025-05-11 13:34:55,193 INFO misc.py line 117 288342] Train: [1/50][2298/2344] Data 0.002 (0.003) Batch 0.665 (0.617) Remain 19:41:25 loss: 0.7184 Lr: 0.00107
[2025-05-11 13:34:55,819 INFO misc.py line 117 288342] Train: [1/50][2299/2344] Data 0.002 (0.003) Batch 0.626 (0.617) Remain 19:41:25 loss: 0.8300 Lr: 0.00107
[2025-05-11 13:34:56,385 INFO misc.py line 117 288342] Train: [1/50][2300/2344] Data 0.002 (0.003) Batch 0.566 (0.617) Remain 19:41:22 loss: 0.8055 Lr: 0.00107
[2025-05-11 13:34:57,079 INFO misc.py line 117 288342] Train: [1/50][2301/2344] Data 0.002 (0.003) Batch 0.694 (0.617) Remain 19:41:25 loss: 0.9036 Lr: 0.00107
[2025-05-11 13:34:57,604 INFO misc.py line 117 288342] Train: [1/50][2302/2344] Data 0.002 (0.003) Batch 0.526 (0.617) Remain 19:41:20 loss: 0.8966 Lr: 0.00107
[2025-05-11 13:34:58,228 INFO misc.py line 117 288342] Train: [1/50][2303/2344] Data 0.002 (0.003) Batch 0.623 (0.617) Remain 19:41:19 loss: 1.0288 Lr: 0.00107
[2025-05-11 13:34:58,790 INFO misc.py line 117 288342] Train: [1/50][2304/2344] Data 0.003 (0.003) Batch 0.563 (0.617) Remain 19:41:16 loss: 0.8899 Lr: 0.00107
[2025-05-11 13:34:59,303 INFO misc.py line 117 288342] Train: [1/50][2305/2344] Data 0.002 (0.003) Batch 0.513 (0.617) Remain 19:41:10 loss: 0.8704 Lr: 0.00108
[2025-05-11 13:34:59,940 INFO misc.py line 117 288342] Train: [1/50][2306/2344] Data 0.003 (0.003) Batch 0.636 (0.617) Remain 19:41:11 loss: 1.1260 Lr: 0.00108
[2025-05-11 13:35:00,452 INFO misc.py line 117 288342] Train: [1/50][2307/2344] Data 0.003 (0.003) Batch 0.512 (0.617) Remain 19:41:05 loss: 1.2327 Lr: 0.00108
[2025-05-11 13:35:01,148 INFO misc.py line 117 288342] Train: [1/50][2308/2344] Data 0.003 (0.003) Batch 0.696 (0.617) Remain 19:41:08 loss: 0.7348 Lr: 0.00108
[2025-05-11 13:35:01,675 INFO misc.py line 117 288342] Train: [1/50][2309/2344] Data 0.003 (0.003) Batch 0.527 (0.617) Remain 19:41:03 loss: 0.8312 Lr: 0.00108
[2025-05-11 13:35:02,293 INFO misc.py line 117 288342] Train: [1/50][2310/2344] Data 0.003 (0.003) Batch 0.618 (0.617) Remain 19:41:03 loss: 0.9364 Lr: 0.00108
[2025-05-11 13:35:02,837 INFO misc.py line 117 288342] Train: [1/50][2311/2344] Data 0.002 (0.003) Batch 0.544 (0.617) Remain 19:40:58 loss: 0.8265 Lr: 0.00108
[2025-05-11 13:35:03,496 INFO misc.py line 117 288342] Train: [1/50][2312/2344] Data 0.003 (0.003) Batch 0.660 (0.617) Remain 19:41:00 loss: 0.8561 Lr: 0.00108
[2025-05-11 13:35:04,010 INFO misc.py line 117 288342] Train: [1/50][2313/2344] Data 0.002 (0.003) Batch 0.513 (0.617) Remain 19:40:54 loss: 0.8950 Lr: 0.00108
[2025-05-11 13:35:04,669 INFO misc.py line 117 288342] Train: [1/50][2314/2344] Data 0.003 (0.003) Batch 0.659 (0.617) Remain 19:40:56 loss: 0.8474 Lr: 0.00108
[2025-05-11 13:35:05,210 INFO misc.py line 117 288342] Train: [1/50][2315/2344] Data 0.003 (0.003) Batch 0.541 (0.617) Remain 19:40:51 loss: 0.9223 Lr: 0.00108
[2025-05-11 13:35:05,871 INFO misc.py line 117 288342] Train: [1/50][2316/2344] Data 0.003 (0.003) Batch 0.661 (0.617) Remain 19:40:53 loss: 0.6985 Lr: 0.00108
[2025-05-11 13:35:06,541 INFO misc.py line 117 288342] Train: [1/50][2317/2344] Data 0.003 (0.003) Batch 0.669 (0.617) Remain 19:40:55 loss: 0.8517 Lr: 0.00108
[2025-05-11 13:35:07,212 INFO misc.py line 117 288342] Train: [1/50][2318/2344] Data 0.003 (0.003) Batch 0.671 (0.617) Remain 19:40:57 loss: 0.7114 Lr: 0.00108
[2025-05-11 13:35:07,873 INFO misc.py line 117 288342] Train: [1/50][2319/2344] Data 0.003 (0.003) Batch 0.661 (0.617) Remain 19:40:58 loss: 0.8535 Lr: 0.00108
[2025-05-11 13:35:08,379 INFO misc.py line 117 288342] Train: [1/50][2320/2344] Data 0.003 (0.003) Batch 0.506 (0.617) Remain 19:40:52 loss: 0.9356 Lr: 0.00108
[2025-05-11 13:35:08,988 INFO misc.py line 117 288342] Train: [1/50][2321/2344] Data 0.003 (0.003) Batch 0.610 (0.617) Remain 19:40:51 loss: 0.9743 Lr: 0.00109
[2025-05-11 13:35:09,637 INFO misc.py line 117 288342] Train: [1/50][2322/2344] Data 0.002 (0.003) Batch 0.649 (0.617) Remain 19:40:52 loss: 0.7576 Lr: 0.00109
[2025-05-11 13:35:10,223 INFO misc.py line 117 288342] Train: [1/50][2323/2344] Data 0.002 (0.003) Batch 0.586 (0.617) Remain 19:40:50 loss: 0.8691 Lr: 0.00109
[2025-05-11 13:35:10,849 INFO misc.py line 117 288342] Train: [1/50][2324/2344] Data 0.002 (0.003) Batch 0.626 (0.617) Remain 19:40:50 loss: 1.3080 Lr: 0.00109
[2025-05-11 13:35:11,510 INFO misc.py line 117 288342] Train: [1/50][2325/2344] Data 0.003 (0.003) Batch 0.661 (0.617) Remain 19:40:52 loss: 0.7832 Lr: 0.00109
[2025-05-11 13:35:12,028 INFO misc.py line 117 288342] Train: [1/50][2326/2344] Data 0.003 (0.003) Batch 0.518 (0.617) Remain 19:40:46 loss: 0.8494 Lr: 0.00109
[2025-05-11 13:35:12,893 INFO misc.py line 117 288342] Train: [1/50][2327/2344] Data 0.003 (0.003) Batch 0.865 (0.617) Remain 19:40:58 loss: 0.9247 Lr: 0.00109
[2025-05-11 13:35:13,439 INFO misc.py line 117 288342] Train: [1/50][2328/2344] Data 0.002 (0.003) Batch 0.546 (0.617) Remain 19:40:54 loss: 0.7927 Lr: 0.00109
[2025-05-11 13:35:14,146 INFO misc.py line 117 288342] Train: [1/50][2329/2344] Data 0.003 (0.003) Batch 0.708 (0.617) Remain 19:40:57 loss: 0.9853 Lr: 0.00109
[2025-05-11 13:35:14,848 INFO misc.py line 117 288342] Train: [1/50][2330/2344] Data 0.002 (0.003) Batch 0.702 (0.617) Remain 19:41:01 loss: 0.6463 Lr: 0.00109
[2025-05-11 13:35:15,397 INFO misc.py line 117 288342] Train: [1/50][2331/2344] Data 0.002 (0.003) Batch 0.549 (0.617) Remain 19:40:57 loss: 0.8118 Lr: 0.00109
[2025-05-11 13:35:15,974 INFO misc.py line 117 288342] Train: [1/50][2332/2344] Data 0.002 (0.003) Batch 0.577 (0.617) Remain 19:40:54 loss: 1.1088 Lr: 0.00109
[2025-05-11 13:35:16,549 INFO misc.py line 117 288342] Train: [1/50][2333/2344] Data 0.002 (0.003) Batch 0.575 (0.617) Remain 19:40:52 loss: 0.8416 Lr: 0.00109
[2025-05-11 13:35:17,175 INFO misc.py line 117 288342] Train: [1/50][2334/2344] Data 0.003 (0.003) Batch 0.627 (0.617) Remain 19:40:52 loss: 0.8846 Lr: 0.00109
[2025-05-11 13:35:17,624 INFO misc.py line 117 288342] Train: [1/50][2335/2344] Data 0.003 (0.003) Batch 0.449 (0.617) Remain 19:40:43 loss: 0.8964 Lr: 0.00109
[2025-05-11 13:35:18,121 INFO misc.py line 117 288342] Train: [1/50][2336/2344] Data 0.003 (0.003) Batch 0.497 (0.617) Remain 19:40:36 loss: 0.7729 Lr: 0.00109
[2025-05-11 13:35:18,623 INFO misc.py line 117 288342] Train: [1/50][2337/2344] Data 0.003 (0.003) Batch 0.502 (0.617) Remain 19:40:30 loss: 0.6970 Lr: 0.00109
[2025-05-11 13:35:19,357 INFO misc.py line 117 288342] Train: [1/50][2338/2344] Data 0.003 (0.003) Batch 0.734 (0.617) Remain 19:40:35 loss: 0.8613 Lr: 0.00110
[2025-05-11 13:35:20,052 INFO misc.py line 117 288342] Train: [1/50][2339/2344] Data 0.003 (0.003) Batch 0.695 (0.617) Remain 19:40:38 loss: 0.6601 Lr: 0.00110
[2025-05-11 13:35:20,561 INFO misc.py line 117 288342] Train: [1/50][2340/2344] Data 0.002 (0.003) Batch 0.509 (0.617) Remain 19:40:32 loss: 0.8206 Lr: 0.00110
[2025-05-11 13:35:21,183 INFO misc.py line 117 288342] Train: [1/50][2341/2344] Data 0.002 (0.003) Batch 0.622 (0.617) Remain 19:40:32 loss: 1.0546 Lr: 0.00110
[2025-05-11 13:35:21,844 INFO misc.py line 117 288342] Train: [1/50][2342/2344] Data 0.002 (0.003) Batch 0.661 (0.617) Remain 19:40:34 loss: 0.7748 Lr: 0.00110
[2025-05-11 13:35:22,460 INFO misc.py line 117 288342] Train: [1/50][2343/2344] Data 0.002 (0.003) Batch 0.616 (0.617) Remain 19:40:33 loss: 1.1432 Lr: 0.00110
[2025-05-11 13:35:22,977 INFO misc.py line 117 288342] Train: [1/50][2344/2344] Data 0.002 (0.003) Batch 0.517 (0.617) Remain 19:40:28 loss: 0.8759 Lr: 0.00110
[2025-05-11 13:35:22,978 INFO misc.py line 147 288342] Train result: loss: 1.1044 
[2025-05-11 13:35:22,979 INFO evaluator.py line 120 288342] >>>>>>>>>>>>>>>> Start Evaluation >>>>>>>>>>>>>>>>
[2025-05-11 13:37:45,442 INFO evaluator.py line 167 288342] Test: [1/1505] Loss 0.6691 
[2025-05-11 13:37:45,604 INFO evaluator.py line 167 288342] Test: [2/1505] Loss 0.7130 
[2025-05-11 13:37:45,734 INFO evaluator.py line 167 288342] Test: [3/1505] Loss 0.7074 
[2025-05-11 13:37:45,872 INFO evaluator.py line 167 288342] Test: [4/1505] Loss 0.7185 
[2025-05-11 13:37:46,050 INFO evaluator.py line 167 288342] Test: [5/1505] Loss 0.6757 
[2025-05-11 13:37:46,223 INFO evaluator.py line 167 288342] Test: [6/1505] Loss 0.6383 
[2025-05-11 13:37:46,381 INFO evaluator.py line 167 288342] Test: [7/1505] Loss 0.8506 
[2025-05-11 13:37:46,541 INFO evaluator.py line 167 288342] Test: [8/1505] Loss 1.3004 
[2025-05-11 13:37:46,714 INFO evaluator.py line 167 288342] Test: [9/1505] Loss 0.7923 
[2025-05-11 13:37:46,842 INFO evaluator.py line 167 288342] Test: [10/1505] Loss 0.7865 
[2025-05-11 13:37:46,972 INFO evaluator.py line 167 288342] Test: [11/1505] Loss 0.9464 
[2025-05-11 13:37:47,126 INFO evaluator.py line 167 288342] Test: [12/1505] Loss 0.7752 
[2025-05-11 13:37:47,259 INFO evaluator.py line 167 288342] Test: [13/1505] Loss 0.6576 
[2025-05-11 13:37:47,426 INFO evaluator.py line 167 288342] Test: [14/1505] Loss 1.0561 
[2025-05-11 13:37:47,556 INFO evaluator.py line 167 288342] Test: [15/1505] Loss 0.7830 
[2025-05-11 13:37:47,735 INFO evaluator.py line 167 288342] Test: [16/1505] Loss 0.7910 
[2025-05-11 13:37:47,848 INFO evaluator.py line 167 288342] Test: [17/1505] Loss 0.5305 
[2025-05-11 13:37:47,987 INFO evaluator.py line 167 288342] Test: [18/1505] Loss 0.7692 
[2025-05-11 13:37:48,168 INFO evaluator.py line 167 288342] Test: [19/1505] Loss 0.8159 
[2025-05-11 13:37:48,294 INFO evaluator.py line 167 288342] Test: [20/1505] Loss 0.7429 
[2025-05-11 13:37:48,443 INFO evaluator.py line 167 288342] Test: [21/1505] Loss 0.8336 
[2025-05-11 13:37:48,590 INFO evaluator.py line 167 288342] Test: [22/1505] Loss 0.9790 
[2025-05-11 13:37:48,777 INFO evaluator.py line 167 288342] Test: [23/1505] Loss 0.8554 
[2025-05-11 13:37:48,944 INFO evaluator.py line 167 288342] Test: [24/1505] Loss 0.6975 
[2025-05-11 13:37:49,130 INFO evaluator.py line 167 288342] Test: [25/1505] Loss 0.7728 
[2025-05-11 13:37:49,284 INFO evaluator.py line 167 288342] Test: [26/1505] Loss 0.4991 
[2025-05-11 13:37:49,457 INFO evaluator.py line 167 288342] Test: [27/1505] Loss 0.5008 
[2025-05-11 13:37:49,590 INFO evaluator.py line 167 288342] Test: [28/1505] Loss 0.5676 
[2025-05-11 13:37:49,770 INFO evaluator.py line 167 288342] Test: [29/1505] Loss 0.9009 
[2025-05-11 13:37:49,931 INFO evaluator.py line 167 288342] Test: [30/1505] Loss 0.8181 
[2025-05-11 13:37:50,097 INFO evaluator.py line 167 288342] Test: [31/1505] Loss 0.6754 
[2025-05-11 13:37:50,250 INFO evaluator.py line 167 288342] Test: [32/1505] Loss 0.9874 
[2025-05-11 13:37:50,395 INFO evaluator.py line 167 288342] Test: [33/1505] Loss 0.5794 
[2025-05-11 13:37:50,587 INFO evaluator.py line 167 288342] Test: [34/1505] Loss 0.6281 
[2025-05-11 13:37:50,740 INFO evaluator.py line 167 288342] Test: [35/1505] Loss 0.8278 
[2025-05-11 13:37:50,870 INFO evaluator.py line 167 288342] Test: [36/1505] Loss 0.8539 
[2025-05-11 13:37:51,012 INFO evaluator.py line 167 288342] Test: [37/1505] Loss 0.7286 
[2025-05-11 13:37:51,166 INFO evaluator.py line 167 288342] Test: [38/1505] Loss 1.0768 
[2025-05-11 13:37:51,304 INFO evaluator.py line 167 288342] Test: [39/1505] Loss 0.9057 
[2025-05-11 13:37:51,449 INFO evaluator.py line 167 288342] Test: [40/1505] Loss 1.0242 
[2025-05-11 13:37:51,620 INFO evaluator.py line 167 288342] Test: [41/1505] Loss 0.7980 
[2025-05-11 13:37:51,781 INFO evaluator.py line 167 288342] Test: [42/1505] Loss 0.7691 
[2025-05-11 13:37:51,951 INFO evaluator.py line 167 288342] Test: [43/1505] Loss 1.3775 
[2025-05-11 13:37:52,142 INFO evaluator.py line 167 288342] Test: [44/1505] Loss 0.7835 
[2025-05-11 13:37:52,301 INFO evaluator.py line 167 288342] Test: [45/1505] Loss 0.5912 
[2025-05-11 13:37:52,466 INFO evaluator.py line 167 288342] Test: [46/1505] Loss 0.9369 
[2025-05-11 13:37:52,645 INFO evaluator.py line 167 288342] Test: [47/1505] Loss 0.6939 
[2025-05-11 13:37:52,781 INFO evaluator.py line 167 288342] Test: [48/1505] Loss 0.6945 
[2025-05-11 13:37:52,942 INFO evaluator.py line 167 288342] Test: [49/1505] Loss 0.9010 
[2025-05-11 13:37:53,084 INFO evaluator.py line 167 288342] Test: [50/1505] Loss 0.6038 
[2025-05-11 13:37:53,255 INFO evaluator.py line 167 288342] Test: [51/1505] Loss 0.5157 
[2025-05-11 13:37:53,408 INFO evaluator.py line 167 288342] Test: [52/1505] Loss 0.9033 
[2025-05-11 13:37:53,554 INFO evaluator.py line 167 288342] Test: [53/1505] Loss 0.8921 
[2025-05-11 13:37:53,692 INFO evaluator.py line 167 288342] Test: [54/1505] Loss 0.7593 
[2025-05-11 13:37:53,846 INFO evaluator.py line 167 288342] Test: [55/1505] Loss 0.7079 
[2025-05-11 13:37:54,017 INFO evaluator.py line 167 288342] Test: [56/1505] Loss 0.5918 
[2025-05-11 13:37:54,176 INFO evaluator.py line 167 288342] Test: [57/1505] Loss 0.6956 
[2025-05-11 13:37:54,381 INFO evaluator.py line 167 288342] Test: [58/1505] Loss 0.7578 
[2025-05-11 13:37:54,533 INFO evaluator.py line 167 288342] Test: [59/1505] Loss 1.1040 
[2025-05-11 13:37:54,648 INFO evaluator.py line 167 288342] Test: [60/1505] Loss 0.8825 
[2025-05-11 13:37:54,780 INFO evaluator.py line 167 288342] Test: [61/1505] Loss 0.7423 
[2025-05-11 13:37:54,956 INFO evaluator.py line 167 288342] Test: [62/1505] Loss 0.7261 
[2025-05-11 13:37:55,121 INFO evaluator.py line 167 288342] Test: [63/1505] Loss 0.7409 
[2025-05-11 13:37:55,270 INFO evaluator.py line 167 288342] Test: [64/1505] Loss 0.5202 
[2025-05-11 13:37:55,414 INFO evaluator.py line 167 288342] Test: [65/1505] Loss 0.6227 
[2025-05-11 13:37:55,531 INFO evaluator.py line 167 288342] Test: [66/1505] Loss 0.8214 
[2025-05-11 13:37:55,673 INFO evaluator.py line 167 288342] Test: [67/1505] Loss 0.7656 
[2025-05-11 13:37:55,818 INFO evaluator.py line 167 288342] Test: [68/1505] Loss 0.7029 
[2025-05-11 13:37:55,975 INFO evaluator.py line 167 288342] Test: [69/1505] Loss 0.8998 
[2025-05-11 13:37:56,129 INFO evaluator.py line 167 288342] Test: [70/1505] Loss 0.8158 
[2025-05-11 13:37:56,291 INFO evaluator.py line 167 288342] Test: [71/1505] Loss 0.6889 
[2025-05-11 13:37:56,436 INFO evaluator.py line 167 288342] Test: [72/1505] Loss 0.7285 
[2025-05-11 13:37:56,570 INFO evaluator.py line 167 288342] Test: [73/1505] Loss 0.8309 
[2025-05-11 13:37:56,745 INFO evaluator.py line 167 288342] Test: [74/1505] Loss 0.8810 
[2025-05-11 13:37:56,867 INFO evaluator.py line 167 288342] Test: [75/1505] Loss 0.8728 
[2025-05-11 13:37:57,068 INFO evaluator.py line 167 288342] Test: [76/1505] Loss 0.7554 
[2025-05-11 13:37:57,223 INFO evaluator.py line 167 288342] Test: [77/1505] Loss 0.7851 
[2025-05-11 13:37:57,370 INFO evaluator.py line 167 288342] Test: [78/1505] Loss 0.8254 
[2025-05-11 13:37:57,510 INFO evaluator.py line 167 288342] Test: [79/1505] Loss 0.6743 
[2025-05-11 13:37:57,673 INFO evaluator.py line 167 288342] Test: [80/1505] Loss 0.8464 
[2025-05-11 13:37:57,797 INFO evaluator.py line 167 288342] Test: [81/1505] Loss 1.0457 
[2025-05-11 13:37:57,931 INFO evaluator.py line 167 288342] Test: [82/1505] Loss 0.8260 
[2025-05-11 13:37:58,042 INFO evaluator.py line 167 288342] Test: [83/1505] Loss 1.0478 
[2025-05-11 13:37:58,186 INFO evaluator.py line 167 288342] Test: [84/1505] Loss 0.5587 
[2025-05-11 13:37:58,349 INFO evaluator.py line 167 288342] Test: [85/1505] Loss 1.1696 
[2025-05-11 13:37:58,506 INFO evaluator.py line 167 288342] Test: [86/1505] Loss 0.5619 
[2025-05-11 13:37:58,654 INFO evaluator.py line 167 288342] Test: [87/1505] Loss 0.8339 
[2025-05-11 13:37:58,786 INFO evaluator.py line 167 288342] Test: [88/1505] Loss 0.8541 
[2025-05-11 13:37:58,965 INFO evaluator.py line 167 288342] Test: [89/1505] Loss 0.9344 
[2025-05-11 13:37:59,108 INFO evaluator.py line 167 288342] Test: [90/1505] Loss 0.6598 
[2025-05-11 13:37:59,280 INFO evaluator.py line 167 288342] Test: [91/1505] Loss 0.5647 
[2025-05-11 13:37:59,411 INFO evaluator.py line 167 288342] Test: [92/1505] Loss 0.7602 
[2025-05-11 13:37:59,567 INFO evaluator.py line 167 288342] Test: [93/1505] Loss 0.9015 
[2025-05-11 13:37:59,713 INFO evaluator.py line 167 288342] Test: [94/1505] Loss 0.7104 
[2025-05-11 13:37:59,880 INFO evaluator.py line 167 288342] Test: [95/1505] Loss 0.7991 
[2025-05-11 13:38:00,037 INFO evaluator.py line 167 288342] Test: [96/1505] Loss 0.4791 
[2025-05-11 13:38:00,207 INFO evaluator.py line 167 288342] Test: [97/1505] Loss 1.0053 
[2025-05-11 13:38:00,334 INFO evaluator.py line 167 288342] Test: [98/1505] Loss 0.7629 
[2025-05-11 13:38:00,475 INFO evaluator.py line 167 288342] Test: [99/1505] Loss 1.1301 
[2025-05-11 13:38:00,681 INFO evaluator.py line 167 288342] Test: [100/1505] Loss 0.8979 
[2025-05-11 13:38:00,841 INFO evaluator.py line 167 288342] Test: [101/1505] Loss 0.9877 
[2025-05-11 13:38:01,013 INFO evaluator.py line 167 288342] Test: [102/1505] Loss 0.6494 
[2025-05-11 13:38:01,172 INFO evaluator.py line 167 288342] Test: [103/1505] Loss 1.6574 
[2025-05-11 13:38:01,334 INFO evaluator.py line 167 288342] Test: [104/1505] Loss 0.8306 
[2025-05-11 13:38:01,465 INFO evaluator.py line 167 288342] Test: [105/1505] Loss 0.7312 
[2025-05-11 13:38:01,586 INFO evaluator.py line 167 288342] Test: [106/1505] Loss 1.0863 
[2025-05-11 13:38:01,743 INFO evaluator.py line 167 288342] Test: [107/1505] Loss 0.7084 
[2025-05-11 13:38:01,894 INFO evaluator.py line 167 288342] Test: [108/1505] Loss 0.6965 
[2025-05-11 13:38:02,046 INFO evaluator.py line 167 288342] Test: [109/1505] Loss 0.3892 
[2025-05-11 13:38:02,168 INFO evaluator.py line 167 288342] Test: [110/1505] Loss 0.8809 
[2025-05-11 13:38:02,346 INFO evaluator.py line 167 288342] Test: [111/1505] Loss 0.5491 
[2025-05-11 13:38:02,506 INFO evaluator.py line 167 288342] Test: [112/1505] Loss 0.8848 
[2025-05-11 13:38:02,676 INFO evaluator.py line 167 288342] Test: [113/1505] Loss 0.7903 
[2025-05-11 13:38:02,827 INFO evaluator.py line 167 288342] Test: [114/1505] Loss 0.6659 
[2025-05-11 13:38:02,978 INFO evaluator.py line 167 288342] Test: [115/1505] Loss 0.7536 
[2025-05-11 13:38:03,106 INFO evaluator.py line 167 288342] Test: [116/1505] Loss 0.9248 
[2025-05-11 13:38:03,236 INFO evaluator.py line 167 288342] Test: [117/1505] Loss 1.2895 
[2025-05-11 13:38:03,414 INFO evaluator.py line 167 288342] Test: [118/1505] Loss 0.7364 
[2025-05-11 13:38:03,570 INFO evaluator.py line 167 288342] Test: [119/1505] Loss 0.6066 
[2025-05-11 13:38:03,733 INFO evaluator.py line 167 288342] Test: [120/1505] Loss 0.5286 
[2025-05-11 13:38:03,899 INFO evaluator.py line 167 288342] Test: [121/1505] Loss 0.6242 
[2025-05-11 13:38:04,081 INFO evaluator.py line 167 288342] Test: [122/1505] Loss 0.7814 
[2025-05-11 13:38:04,253 INFO evaluator.py line 167 288342] Test: [123/1505] Loss 0.9676 
[2025-05-11 13:38:04,412 INFO evaluator.py line 167 288342] Test: [124/1505] Loss 0.8270 
[2025-05-11 13:38:04,544 INFO evaluator.py line 167 288342] Test: [125/1505] Loss 0.8215 
[2025-05-11 13:38:04,718 INFO evaluator.py line 167 288342] Test: [126/1505] Loss 1.0739 
[2025-05-11 13:38:04,878 INFO evaluator.py line 167 288342] Test: [127/1505] Loss 0.8517 
[2025-05-11 13:38:05,048 INFO evaluator.py line 167 288342] Test: [128/1505] Loss 0.5712 
[2025-05-11 13:38:05,200 INFO evaluator.py line 167 288342] Test: [129/1505] Loss 0.6348 
[2025-05-11 13:38:05,335 INFO evaluator.py line 167 288342] Test: [130/1505] Loss 0.6929 
[2025-05-11 13:38:05,504 INFO evaluator.py line 167 288342] Test: [131/1505] Loss 0.8347 
[2025-05-11 13:38:05,659 INFO evaluator.py line 167 288342] Test: [132/1505] Loss 0.5746 
[2025-05-11 13:38:05,801 INFO evaluator.py line 167 288342] Test: [133/1505] Loss 0.7880 
[2025-05-11 13:38:05,931 INFO evaluator.py line 167 288342] Test: [134/1505] Loss 0.6269 
[2025-05-11 13:38:06,069 INFO evaluator.py line 167 288342] Test: [135/1505] Loss 0.5956 
[2025-05-11 13:38:06,206 INFO evaluator.py line 167 288342] Test: [136/1505] Loss 0.7350 
[2025-05-11 13:38:06,292 INFO evaluator.py line 167 288342] Test: [137/1505] Loss 0.9964 
[2025-05-11 13:38:06,428 INFO evaluator.py line 167 288342] Test: [138/1505] Loss 0.8391 
[2025-05-11 13:38:06,585 INFO evaluator.py line 167 288342] Test: [139/1505] Loss 0.7440 
[2025-05-11 13:38:06,725 INFO evaluator.py line 167 288342] Test: [140/1505] Loss 0.8500 
[2025-05-11 13:38:06,873 INFO evaluator.py line 167 288342] Test: [141/1505] Loss 1.1538 
[2025-05-11 13:38:07,014 INFO evaluator.py line 167 288342] Test: [142/1505] Loss 0.7077 
[2025-05-11 13:38:07,202 INFO evaluator.py line 167 288342] Test: [143/1505] Loss 0.8564 
[2025-05-11 13:38:07,357 INFO evaluator.py line 167 288342] Test: [144/1505] Loss 0.9551 
[2025-05-11 13:38:07,548 INFO evaluator.py line 167 288342] Test: [145/1505] Loss 0.7633 
[2025-05-11 13:38:07,707 INFO evaluator.py line 167 288342] Test: [146/1505] Loss 0.8644 
[2025-05-11 13:38:07,833 INFO evaluator.py line 167 288342] Test: [147/1505] Loss 0.8484 
[2025-05-11 13:38:08,005 INFO evaluator.py line 167 288342] Test: [148/1505] Loss 0.7612 
[2025-05-11 13:38:08,152 INFO evaluator.py line 167 288342] Test: [149/1505] Loss 1.0889 
[2025-05-11 13:38:08,309 INFO evaluator.py line 167 288342] Test: [150/1505] Loss 0.6748 
[2025-05-11 13:38:08,451 INFO evaluator.py line 167 288342] Test: [151/1505] Loss 0.6167 
[2025-05-11 13:38:08,584 INFO evaluator.py line 167 288342] Test: [152/1505] Loss 0.9484 
[2025-05-11 13:38:08,759 INFO evaluator.py line 167 288342] Test: [153/1505] Loss 0.5880 
[2025-05-11 13:38:08,908 INFO evaluator.py line 167 288342] Test: [154/1505] Loss 0.6190 
[2025-05-11 13:38:09,067 INFO evaluator.py line 167 288342] Test: [155/1505] Loss 1.3150 
[2025-05-11 13:38:09,202 INFO evaluator.py line 167 288342] Test: [156/1505] Loss 1.2381 
[2025-05-11 13:38:09,384 INFO evaluator.py line 167 288342] Test: [157/1505] Loss 0.9116 
[2025-05-11 13:38:09,558 INFO evaluator.py line 167 288342] Test: [158/1505] Loss 0.8359 
[2025-05-11 13:38:09,710 INFO evaluator.py line 167 288342] Test: [159/1505] Loss 0.6826 
[2025-05-11 13:38:09,856 INFO evaluator.py line 167 288342] Test: [160/1505] Loss 0.6198 
[2025-05-11 13:38:10,054 INFO evaluator.py line 167 288342] Test: [161/1505] Loss 0.8164 
[2025-05-11 13:38:10,231 INFO evaluator.py line 167 288342] Test: [162/1505] Loss 0.7836 
[2025-05-11 13:38:10,405 INFO evaluator.py line 167 288342] Test: [163/1505] Loss 0.7269 
[2025-05-11 13:38:10,550 INFO evaluator.py line 167 288342] Test: [164/1505] Loss 0.7120 
[2025-05-11 13:38:10,684 INFO evaluator.py line 167 288342] Test: [165/1505] Loss 0.5444 
[2025-05-11 13:38:10,833 INFO evaluator.py line 167 288342] Test: [166/1505] Loss 0.6494 
[2025-05-11 13:38:10,982 INFO evaluator.py line 167 288342] Test: [167/1505] Loss 0.7535 
[2025-05-11 13:38:11,180 INFO evaluator.py line 167 288342] Test: [168/1505] Loss 1.1819 
[2025-05-11 13:38:11,346 INFO evaluator.py line 167 288342] Test: [169/1505] Loss 0.7575 
[2025-05-11 13:38:11,530 INFO evaluator.py line 167 288342] Test: [170/1505] Loss 0.5928 
[2025-05-11 13:38:11,698 INFO evaluator.py line 167 288342] Test: [171/1505] Loss 0.6674 
[2025-05-11 13:38:11,849 INFO evaluator.py line 167 288342] Test: [172/1505] Loss 0.7715 
[2025-05-11 13:38:11,998 INFO evaluator.py line 167 288342] Test: [173/1505] Loss 0.8772 
[2025-05-11 13:38:12,158 INFO evaluator.py line 167 288342] Test: [174/1505] Loss 1.1093 
[2025-05-11 13:38:12,305 INFO evaluator.py line 167 288342] Test: [175/1505] Loss 0.9017 
[2025-05-11 13:38:12,432 INFO evaluator.py line 167 288342] Test: [176/1505] Loss 0.7949 
[2025-05-11 13:38:12,571 INFO evaluator.py line 167 288342] Test: [177/1505] Loss 0.6066 
[2025-05-11 13:38:12,688 INFO evaluator.py line 167 288342] Test: [178/1505] Loss 0.9649 
[2025-05-11 13:38:12,871 INFO evaluator.py line 167 288342] Test: [179/1505] Loss 1.0405 
[2025-05-11 13:38:13,011 INFO evaluator.py line 167 288342] Test: [180/1505] Loss 0.4946 
[2025-05-11 13:38:13,168 INFO evaluator.py line 167 288342] Test: [181/1505] Loss 0.5887 
[2025-05-11 13:38:13,290 INFO evaluator.py line 167 288342] Test: [182/1505] Loss 0.7421 
[2025-05-11 13:38:13,440 INFO evaluator.py line 167 288342] Test: [183/1505] Loss 0.6325 
[2025-05-11 13:38:13,609 INFO evaluator.py line 167 288342] Test: [184/1505] Loss 0.8988 
[2025-05-11 13:38:13,767 INFO evaluator.py line 167 288342] Test: [185/1505] Loss 0.8836 
[2025-05-11 13:38:13,934 INFO evaluator.py line 167 288342] Test: [186/1505] Loss 0.6627 
[2025-05-11 13:38:14,097 INFO evaluator.py line 167 288342] Test: [187/1505] Loss 0.8577 
[2025-05-11 13:38:14,232 INFO evaluator.py line 167 288342] Test: [188/1505] Loss 0.8606 
[2025-05-11 13:38:14,433 INFO evaluator.py line 167 288342] Test: [189/1505] Loss 0.5930 
[2025-05-11 13:38:14,574 INFO evaluator.py line 167 288342] Test: [190/1505] Loss 1.0631 
[2025-05-11 13:38:14,744 INFO evaluator.py line 167 288342] Test: [191/1505] Loss 0.7335 
[2025-05-11 13:38:14,896 INFO evaluator.py line 167 288342] Test: [192/1505] Loss 0.7835 
[2025-05-11 13:38:15,050 INFO evaluator.py line 167 288342] Test: [193/1505] Loss 1.2920 
[2025-05-11 13:38:15,199 INFO evaluator.py line 167 288342] Test: [194/1505] Loss 0.8229 
[2025-05-11 13:38:15,347 INFO evaluator.py line 167 288342] Test: [195/1505] Loss 0.6290 
[2025-05-11 13:38:15,480 INFO evaluator.py line 167 288342] Test: [196/1505] Loss 0.7359 
[2025-05-11 13:38:15,658 INFO evaluator.py line 167 288342] Test: [197/1505] Loss 0.8402 
[2025-05-11 13:38:15,801 INFO evaluator.py line 167 288342] Test: [198/1505] Loss 0.9276 
[2025-05-11 13:38:15,963 INFO evaluator.py line 167 288342] Test: [199/1505] Loss 0.7033 
[2025-05-11 13:38:16,142 INFO evaluator.py line 167 288342] Test: [200/1505] Loss 0.5722 
[2025-05-11 13:38:16,318 INFO evaluator.py line 167 288342] Test: [201/1505] Loss 0.9292 
[2025-05-11 13:38:16,493 INFO evaluator.py line 167 288342] Test: [202/1505] Loss 0.6237 
[2025-05-11 13:38:16,637 INFO evaluator.py line 167 288342] Test: [203/1505] Loss 0.7026 
[2025-05-11 13:38:16,781 INFO evaluator.py line 167 288342] Test: [204/1505] Loss 1.1268 
[2025-05-11 13:38:16,909 INFO evaluator.py line 167 288342] Test: [205/1505] Loss 0.8554 
[2025-05-11 13:38:17,051 INFO evaluator.py line 167 288342] Test: [206/1505] Loss 1.0565 
[2025-05-11 13:38:17,193 INFO evaluator.py line 167 288342] Test: [207/1505] Loss 1.6303 
[2025-05-11 13:38:17,320 INFO evaluator.py line 167 288342] Test: [208/1505] Loss 0.4557 
[2025-05-11 13:38:17,448 INFO evaluator.py line 167 288342] Test: [209/1505] Loss 0.6211 
[2025-05-11 13:38:17,614 INFO evaluator.py line 167 288342] Test: [210/1505] Loss 0.5686 
[2025-05-11 13:38:17,775 INFO evaluator.py line 167 288342] Test: [211/1505] Loss 0.7123 
[2025-05-11 13:38:17,961 INFO evaluator.py line 167 288342] Test: [212/1505] Loss 1.0481 
[2025-05-11 13:38:18,107 INFO evaluator.py line 167 288342] Test: [213/1505] Loss 0.6918 
[2025-05-11 13:38:18,285 INFO evaluator.py line 167 288342] Test: [214/1505] Loss 1.0350 
[2025-05-11 13:38:18,453 INFO evaluator.py line 167 288342] Test: [215/1505] Loss 0.9013 
[2025-05-11 13:38:18,578 INFO evaluator.py line 167 288342] Test: [216/1505] Loss 0.5727 
[2025-05-11 13:38:18,757 INFO evaluator.py line 167 288342] Test: [217/1505] Loss 0.4927 
[2025-05-11 13:38:18,927 INFO evaluator.py line 167 288342] Test: [218/1505] Loss 0.5452 
[2025-05-11 13:38:19,086 INFO evaluator.py line 167 288342] Test: [219/1505] Loss 0.3348 
[2025-05-11 13:38:19,234 INFO evaluator.py line 167 288342] Test: [220/1505] Loss 0.7564 
[2025-05-11 13:38:19,373 INFO evaluator.py line 167 288342] Test: [221/1505] Loss 0.7351 
[2025-05-11 13:38:19,513 INFO evaluator.py line 167 288342] Test: [222/1505] Loss 0.5949 
[2025-05-11 13:38:19,686 INFO evaluator.py line 167 288342] Test: [223/1505] Loss 0.5063 
[2025-05-11 13:38:19,849 INFO evaluator.py line 167 288342] Test: [224/1505] Loss 0.6764 
[2025-05-11 13:38:20,008 INFO evaluator.py line 167 288342] Test: [225/1505] Loss 0.7811 
[2025-05-11 13:38:20,134 INFO evaluator.py line 167 288342] Test: [226/1505] Loss 0.5930 
[2025-05-11 13:38:20,279 INFO evaluator.py line 167 288342] Test: [227/1505] Loss 0.8469 
[2025-05-11 13:38:20,444 INFO evaluator.py line 167 288342] Test: [228/1505] Loss 0.9343 
[2025-05-11 13:38:20,555 INFO evaluator.py line 167 288342] Test: [229/1505] Loss 0.9879 
[2025-05-11 13:38:20,678 INFO evaluator.py line 167 288342] Test: [230/1505] Loss 0.5498 
[2025-05-11 13:38:20,819 INFO evaluator.py line 167 288342] Test: [231/1505] Loss 0.9120 
[2025-05-11 13:38:20,956 INFO evaluator.py line 167 288342] Test: [232/1505] Loss 0.5386 
[2025-05-11 13:38:21,084 INFO evaluator.py line 167 288342] Test: [233/1505] Loss 0.7277 
[2025-05-11 13:38:21,292 INFO evaluator.py line 167 288342] Test: [234/1505] Loss 0.7229 
[2025-05-11 13:38:21,440 INFO evaluator.py line 167 288342] Test: [235/1505] Loss 0.8269 
[2025-05-11 13:38:21,530 INFO evaluator.py line 167 288342] Test: [236/1505] Loss 1.0395 
[2025-05-11 13:38:21,691 INFO evaluator.py line 167 288342] Test: [237/1505] Loss 0.6843 
[2025-05-11 13:38:21,800 INFO evaluator.py line 167 288342] Test: [238/1505] Loss 0.4469 
[2025-05-11 13:38:21,918 INFO evaluator.py line 167 288342] Test: [239/1505] Loss 1.2393 
[2025-05-11 13:38:22,085 INFO evaluator.py line 167 288342] Test: [240/1505] Loss 1.0998 
[2025-05-11 13:38:22,288 INFO evaluator.py line 167 288342] Test: [241/1505] Loss 0.8136 
[2025-05-11 13:38:22,480 INFO evaluator.py line 167 288342] Test: [242/1505] Loss 0.8473 
[2025-05-11 13:38:22,642 INFO evaluator.py line 167 288342] Test: [243/1505] Loss 0.3152 
[2025-05-11 13:38:22,779 INFO evaluator.py line 167 288342] Test: [244/1505] Loss 1.1188 
[2025-05-11 13:38:22,924 INFO evaluator.py line 167 288342] Test: [245/1505] Loss 1.1633 
[2025-05-11 13:38:23,098 INFO evaluator.py line 167 288342] Test: [246/1505] Loss 0.9413 
[2025-05-11 13:38:23,234 INFO evaluator.py line 167 288342] Test: [247/1505] Loss 0.9152 
[2025-05-11 13:38:23,370 INFO evaluator.py line 167 288342] Test: [248/1505] Loss 0.6901 
[2025-05-11 13:38:23,526 INFO evaluator.py line 167 288342] Test: [249/1505] Loss 0.5915 
[2025-05-11 13:38:23,691 INFO evaluator.py line 167 288342] Test: [250/1505] Loss 0.8570 
[2025-05-11 13:38:23,840 INFO evaluator.py line 167 288342] Test: [251/1505] Loss 0.6641 
[2025-05-11 13:38:24,009 INFO evaluator.py line 167 288342] Test: [252/1505] Loss 1.2008 
[2025-05-11 13:38:24,168 INFO evaluator.py line 167 288342] Test: [253/1505] Loss 0.9978 
[2025-05-11 13:38:24,307 INFO evaluator.py line 167 288342] Test: [254/1505] Loss 1.0026 
[2025-05-11 13:38:24,442 INFO evaluator.py line 167 288342] Test: [255/1505] Loss 0.8159 
[2025-05-11 13:38:24,584 INFO evaluator.py line 167 288342] Test: [256/1505] Loss 1.1057 
[2025-05-11 13:38:24,734 INFO evaluator.py line 167 288342] Test: [257/1505] Loss 0.9532 
[2025-05-11 13:38:24,867 INFO evaluator.py line 167 288342] Test: [258/1505] Loss 0.7886 
[2025-05-11 13:38:25,022 INFO evaluator.py line 167 288342] Test: [259/1505] Loss 0.5372 
[2025-05-11 13:38:25,168 INFO evaluator.py line 167 288342] Test: [260/1505] Loss 0.9339 
[2025-05-11 13:38:25,291 INFO evaluator.py line 167 288342] Test: [261/1505] Loss 0.9719 
[2025-05-11 13:38:25,467 INFO evaluator.py line 167 288342] Test: [262/1505] Loss 0.8118 
[2025-05-11 13:38:25,630 INFO evaluator.py line 167 288342] Test: [263/1505] Loss 0.6857 
[2025-05-11 13:38:25,801 INFO evaluator.py line 167 288342] Test: [264/1505] Loss 0.7076 
[2025-05-11 13:38:25,961 INFO evaluator.py line 167 288342] Test: [265/1505] Loss 0.9082 
[2025-05-11 13:38:26,123 INFO evaluator.py line 167 288342] Test: [266/1505] Loss 0.6905 
[2025-05-11 13:38:26,233 INFO evaluator.py line 167 288342] Test: [267/1505] Loss 1.0635 
[2025-05-11 13:38:26,386 INFO evaluator.py line 167 288342] Test: [268/1505] Loss 0.8312 
[2025-05-11 13:38:26,518 INFO evaluator.py line 167 288342] Test: [269/1505] Loss 0.7970 
[2025-05-11 13:38:26,659 INFO evaluator.py line 167 288342] Test: [270/1505] Loss 0.7123 
[2025-05-11 13:38:26,853 INFO evaluator.py line 167 288342] Test: [271/1505] Loss 0.8640 
[2025-05-11 13:38:27,006 INFO evaluator.py line 167 288342] Test: [272/1505] Loss 0.8392 
[2025-05-11 13:38:27,190 INFO evaluator.py line 167 288342] Test: [273/1505] Loss 0.8543 
[2025-05-11 13:38:27,303 INFO evaluator.py line 167 288342] Test: [274/1505] Loss 0.7705 
[2025-05-11 13:38:27,458 INFO evaluator.py line 167 288342] Test: [275/1505] Loss 0.7705 
[2025-05-11 13:38:27,604 INFO evaluator.py line 167 288342] Test: [276/1505] Loss 0.9840 
[2025-05-11 13:38:27,728 INFO evaluator.py line 167 288342] Test: [277/1505] Loss 0.4042 
[2025-05-11 13:38:27,889 INFO evaluator.py line 167 288342] Test: [278/1505] Loss 0.8341 
[2025-05-11 13:38:28,050 INFO evaluator.py line 167 288342] Test: [279/1505] Loss 0.6498 
[2025-05-11 13:38:28,210 INFO evaluator.py line 167 288342] Test: [280/1505] Loss 0.7107 
[2025-05-11 13:38:28,342 INFO evaluator.py line 167 288342] Test: [281/1505] Loss 0.8755 
[2025-05-11 13:38:28,509 INFO evaluator.py line 167 288342] Test: [282/1505] Loss 0.8513 
[2025-05-11 13:38:28,676 INFO evaluator.py line 167 288342] Test: [283/1505] Loss 0.8275 
[2025-05-11 13:38:28,860 INFO evaluator.py line 167 288342] Test: [284/1505] Loss 0.5802 
[2025-05-11 13:38:29,045 INFO evaluator.py line 167 288342] Test: [285/1505] Loss 0.9913 
[2025-05-11 13:38:29,181 INFO evaluator.py line 167 288342] Test: [286/1505] Loss 0.6115 
[2025-05-11 13:38:29,375 INFO evaluator.py line 167 288342] Test: [287/1505] Loss 0.6831 
[2025-05-11 13:38:29,521 INFO evaluator.py line 167 288342] Test: [288/1505] Loss 0.7895 
[2025-05-11 13:38:29,662 INFO evaluator.py line 167 288342] Test: [289/1505] Loss 0.9698 
[2025-05-11 13:38:29,796 INFO evaluator.py line 167 288342] Test: [290/1505] Loss 0.9792 
[2025-05-11 13:38:29,946 INFO evaluator.py line 167 288342] Test: [291/1505] Loss 0.6936 
[2025-05-11 13:38:30,119 INFO evaluator.py line 167 288342] Test: [292/1505] Loss 0.6544 
[2025-05-11 13:38:30,279 INFO evaluator.py line 167 288342] Test: [293/1505] Loss 1.2313 
[2025-05-11 13:38:30,435 INFO evaluator.py line 167 288342] Test: [294/1505] Loss 0.5659 
[2025-05-11 13:38:30,568 INFO evaluator.py line 167 288342] Test: [295/1505] Loss 0.7553 
[2025-05-11 13:38:30,737 INFO evaluator.py line 167 288342] Test: [296/1505] Loss 1.0752 
[2025-05-11 13:38:30,885 INFO evaluator.py line 167 288342] Test: [297/1505] Loss 1.0411 
[2025-05-11 13:38:31,056 INFO evaluator.py line 167 288342] Test: [298/1505] Loss 0.8039 
[2025-05-11 13:38:31,234 INFO evaluator.py line 167 288342] Test: [299/1505] Loss 0.9909 
[2025-05-11 13:38:31,431 INFO evaluator.py line 167 288342] Test: [300/1505] Loss 0.7524 
[2025-05-11 13:38:31,636 INFO evaluator.py line 167 288342] Test: [301/1505] Loss 0.9081 
[2025-05-11 13:38:31,790 INFO evaluator.py line 167 288342] Test: [302/1505] Loss 0.7434 
[2025-05-11 13:38:31,949 INFO evaluator.py line 167 288342] Test: [303/1505] Loss 0.9393 
[2025-05-11 13:38:32,081 INFO evaluator.py line 167 288342] Test: [304/1505] Loss 1.0812 
[2025-05-11 13:38:32,218 INFO evaluator.py line 167 288342] Test: [305/1505] Loss 0.8566 
[2025-05-11 13:38:32,350 INFO evaluator.py line 167 288342] Test: [306/1505] Loss 0.5701 
[2025-05-11 13:38:32,507 INFO evaluator.py line 167 288342] Test: [307/1505] Loss 0.7477 
[2025-05-11 13:38:32,662 INFO evaluator.py line 167 288342] Test: [308/1505] Loss 0.6945 
[2025-05-11 13:38:32,814 INFO evaluator.py line 167 288342] Test: [309/1505] Loss 0.8662 
[2025-05-11 13:38:33,000 INFO evaluator.py line 167 288342] Test: [310/1505] Loss 0.8577 
[2025-05-11 13:38:33,162 INFO evaluator.py line 167 288342] Test: [311/1505] Loss 0.6171 
[2025-05-11 13:38:33,310 INFO evaluator.py line 167 288342] Test: [312/1505] Loss 0.7783 
[2025-05-11 13:38:33,482 INFO evaluator.py line 167 288342] Test: [313/1505] Loss 0.7782 
[2025-05-11 13:38:33,610 INFO evaluator.py line 167 288342] Test: [314/1505] Loss 1.1655 
[2025-05-11 13:38:33,766 INFO evaluator.py line 167 288342] Test: [315/1505] Loss 0.9147 
[2025-05-11 13:38:33,914 INFO evaluator.py line 167 288342] Test: [316/1505] Loss 0.6411 
[2025-05-11 13:38:34,067 INFO evaluator.py line 167 288342] Test: [317/1505] Loss 0.6392 
[2025-05-11 13:38:34,205 INFO evaluator.py line 167 288342] Test: [318/1505] Loss 0.6213 
[2025-05-11 13:38:34,361 INFO evaluator.py line 167 288342] Test: [319/1505] Loss 0.8068 
[2025-05-11 13:38:34,514 INFO evaluator.py line 167 288342] Test: [320/1505] Loss 1.0222 
[2025-05-11 13:38:34,682 INFO evaluator.py line 167 288342] Test: [321/1505] Loss 0.9149 
[2025-05-11 13:38:34,843 INFO evaluator.py line 167 288342] Test: [322/1505] Loss 0.6368 
[2025-05-11 13:38:34,954 INFO evaluator.py line 167 288342] Test: [323/1505] Loss 0.9216 
[2025-05-11 13:38:35,095 INFO evaluator.py line 167 288342] Test: [324/1505] Loss 0.9183 
[2025-05-11 13:38:35,270 INFO evaluator.py line 167 288342] Test: [325/1505] Loss 1.6902 
[2025-05-11 13:38:35,413 INFO evaluator.py line 167 288342] Test: [326/1505] Loss 0.6368 
[2025-05-11 13:38:35,518 INFO evaluator.py line 167 288342] Test: [327/1505] Loss 0.8337 
[2025-05-11 13:38:35,635 INFO evaluator.py line 167 288342] Test: [328/1505] Loss 0.7310 
[2025-05-11 13:38:35,802 INFO evaluator.py line 167 288342] Test: [329/1505] Loss 0.7502 
[2025-05-11 13:38:35,927 INFO evaluator.py line 167 288342] Test: [330/1505] Loss 0.8420 
[2025-05-11 13:38:36,062 INFO evaluator.py line 167 288342] Test: [331/1505] Loss 0.3823 
[2025-05-11 13:38:36,223 INFO evaluator.py line 167 288342] Test: [332/1505] Loss 1.0234 
[2025-05-11 13:38:36,398 INFO evaluator.py line 167 288342] Test: [333/1505] Loss 0.4899 
[2025-05-11 13:38:36,579 INFO evaluator.py line 167 288342] Test: [334/1505] Loss 0.4529 
[2025-05-11 13:38:36,708 INFO evaluator.py line 167 288342] Test: [335/1505] Loss 0.9903 
[2025-05-11 13:38:36,890 INFO evaluator.py line 167 288342] Test: [336/1505] Loss 1.6375 
[2025-05-11 13:38:37,063 INFO evaluator.py line 167 288342] Test: [337/1505] Loss 0.6668 
[2025-05-11 13:38:37,257 INFO evaluator.py line 167 288342] Test: [338/1505] Loss 0.4687 
[2025-05-11 13:38:37,411 INFO evaluator.py line 167 288342] Test: [339/1505] Loss 0.5551 
[2025-05-11 13:38:37,567 INFO evaluator.py line 167 288342] Test: [340/1505] Loss 0.7641 
[2025-05-11 13:38:37,686 INFO evaluator.py line 167 288342] Test: [341/1505] Loss 0.5659 
[2025-05-11 13:38:37,855 INFO evaluator.py line 167 288342] Test: [342/1505] Loss 0.6890 
[2025-05-11 13:38:37,980 INFO evaluator.py line 167 288342] Test: [343/1505] Loss 0.8351 
[2025-05-11 13:38:38,133 INFO evaluator.py line 167 288342] Test: [344/1505] Loss 0.5278 
[2025-05-11 13:38:38,290 INFO evaluator.py line 167 288342] Test: [345/1505] Loss 0.5496 
[2025-05-11 13:38:38,488 INFO evaluator.py line 167 288342] Test: [346/1505] Loss 0.8534 
[2025-05-11 13:38:38,636 INFO evaluator.py line 167 288342] Test: [347/1505] Loss 0.8239 
[2025-05-11 13:38:38,805 INFO evaluator.py line 167 288342] Test: [348/1505] Loss 0.6850 
[2025-05-11 13:38:38,931 INFO evaluator.py line 167 288342] Test: [349/1505] Loss 0.7276 
[2025-05-11 13:38:39,090 INFO evaluator.py line 167 288342] Test: [350/1505] Loss 0.6405 
[2025-05-11 13:38:39,234 INFO evaluator.py line 167 288342] Test: [351/1505] Loss 0.6984 
[2025-05-11 13:38:39,400 INFO evaluator.py line 167 288342] Test: [352/1505] Loss 0.8214 
[2025-05-11 13:38:39,581 INFO evaluator.py line 167 288342] Test: [353/1505] Loss 0.6522 
[2025-05-11 13:38:39,711 INFO evaluator.py line 167 288342] Test: [354/1505] Loss 0.8462 
[2025-05-11 13:38:39,836 INFO evaluator.py line 167 288342] Test: [355/1505] Loss 0.7523 
[2025-05-11 13:38:39,996 INFO evaluator.py line 167 288342] Test: [356/1505] Loss 0.8201 
[2025-05-11 13:38:40,124 INFO evaluator.py line 167 288342] Test: [357/1505] Loss 0.8513 
[2025-05-11 13:38:40,276 INFO evaluator.py line 167 288342] Test: [358/1505] Loss 0.6908 
[2025-05-11 13:38:40,443 INFO evaluator.py line 167 288342] Test: [359/1505] Loss 1.0148 
[2025-05-11 13:38:40,585 INFO evaluator.py line 167 288342] Test: [360/1505] Loss 0.8349 
[2025-05-11 13:38:40,740 INFO evaluator.py line 167 288342] Test: [361/1505] Loss 0.7323 
[2025-05-11 13:38:40,867 INFO evaluator.py line 167 288342] Test: [362/1505] Loss 0.4063 
[2025-05-11 13:38:41,020 INFO evaluator.py line 167 288342] Test: [363/1505] Loss 0.8098 
[2025-05-11 13:38:41,139 INFO evaluator.py line 167 288342] Test: [364/1505] Loss 0.7597 
[2025-05-11 13:38:41,278 INFO evaluator.py line 167 288342] Test: [365/1505] Loss 0.7889 
[2025-05-11 13:38:41,437 INFO evaluator.py line 167 288342] Test: [366/1505] Loss 0.5935 
[2025-05-11 13:38:41,558 INFO evaluator.py line 167 288342] Test: [367/1505] Loss 0.7303 
[2025-05-11 13:38:41,713 INFO evaluator.py line 167 288342] Test: [368/1505] Loss 0.8878 
[2025-05-11 13:38:41,876 INFO evaluator.py line 167 288342] Test: [369/1505] Loss 0.8508 
[2025-05-11 13:38:42,029 INFO evaluator.py line 167 288342] Test: [370/1505] Loss 0.7853 
[2025-05-11 13:38:42,153 INFO evaluator.py line 167 288342] Test: [371/1505] Loss 0.8456 
[2025-05-11 13:38:42,308 INFO evaluator.py line 167 288342] Test: [372/1505] Loss 0.6623 
[2025-05-11 13:38:42,451 INFO evaluator.py line 167 288342] Test: [373/1505] Loss 0.4868 
[2025-05-11 13:38:42,573 INFO evaluator.py line 167 288342] Test: [374/1505] Loss 1.0644 
[2025-05-11 13:38:42,683 INFO evaluator.py line 167 288342] Test: [375/1505] Loss 0.4820 
[2025-05-11 13:38:42,830 INFO evaluator.py line 167 288342] Test: [376/1505] Loss 0.6434 
[2025-05-11 13:38:42,975 INFO evaluator.py line 167 288342] Test: [377/1505] Loss 0.6274 
[2025-05-11 13:38:43,142 INFO evaluator.py line 167 288342] Test: [378/1505] Loss 0.5849 
[2025-05-11 13:38:43,294 INFO evaluator.py line 167 288342] Test: [379/1505] Loss 0.7010 
[2025-05-11 13:38:43,444 INFO evaluator.py line 167 288342] Test: [380/1505] Loss 0.7515 
[2025-05-11 13:38:43,552 INFO evaluator.py line 167 288342] Test: [381/1505] Loss 0.6004 
[2025-05-11 13:38:43,662 INFO evaluator.py line 167 288342] Test: [382/1505] Loss 0.9846 
[2025-05-11 13:38:43,846 INFO evaluator.py line 167 288342] Test: [383/1505] Loss 0.7372 
[2025-05-11 13:38:43,995 INFO evaluator.py line 167 288342] Test: [384/1505] Loss 0.8664 
[2025-05-11 13:38:44,153 INFO evaluator.py line 167 288342] Test: [385/1505] Loss 0.9871 
[2025-05-11 13:38:44,352 INFO evaluator.py line 167 288342] Test: [386/1505] Loss 0.7430 
[2025-05-11 13:38:44,474 INFO evaluator.py line 167 288342] Test: [387/1505] Loss 0.9413 
[2025-05-11 13:38:44,604 INFO evaluator.py line 167 288342] Test: [388/1505] Loss 0.9278 
[2025-05-11 13:38:44,739 INFO evaluator.py line 167 288342] Test: [389/1505] Loss 0.7605 
[2025-05-11 13:38:44,903 INFO evaluator.py line 167 288342] Test: [390/1505] Loss 0.8921 
[2025-05-11 13:38:45,011 INFO evaluator.py line 167 288342] Test: [391/1505] Loss 0.8849 
[2025-05-11 13:38:45,172 INFO evaluator.py line 167 288342] Test: [392/1505] Loss 0.5702 
[2025-05-11 13:38:45,346 INFO evaluator.py line 167 288342] Test: [393/1505] Loss 0.6559 
[2025-05-11 13:38:45,515 INFO evaluator.py line 167 288342] Test: [394/1505] Loss 0.8448 
[2025-05-11 13:38:45,700 INFO evaluator.py line 167 288342] Test: [395/1505] Loss 0.7767 
[2025-05-11 13:38:45,826 INFO evaluator.py line 167 288342] Test: [396/1505] Loss 0.9942 
[2025-05-11 13:38:46,024 INFO evaluator.py line 167 288342] Test: [397/1505] Loss 0.6645 
[2025-05-11 13:38:46,178 INFO evaluator.py line 167 288342] Test: [398/1505] Loss 0.8447 
[2025-05-11 13:38:46,301 INFO evaluator.py line 167 288342] Test: [399/1505] Loss 0.4765 
[2025-05-11 13:38:46,483 INFO evaluator.py line 167 288342] Test: [400/1505] Loss 0.9238 
[2025-05-11 13:38:46,648 INFO evaluator.py line 167 288342] Test: [401/1505] Loss 0.5899 
[2025-05-11 13:38:46,796 INFO evaluator.py line 167 288342] Test: [402/1505] Loss 0.4546 
[2025-05-11 13:38:46,972 INFO evaluator.py line 167 288342] Test: [403/1505] Loss 0.7065 
[2025-05-11 13:38:47,107 INFO evaluator.py line 167 288342] Test: [404/1505] Loss 0.8682 
[2025-05-11 13:38:47,272 INFO evaluator.py line 167 288342] Test: [405/1505] Loss 0.5610 
[2025-05-11 13:38:47,410 INFO evaluator.py line 167 288342] Test: [406/1505] Loss 0.5100 
[2025-05-11 13:38:47,532 INFO evaluator.py line 167 288342] Test: [407/1505] Loss 1.1735 
[2025-05-11 13:38:47,672 INFO evaluator.py line 167 288342] Test: [408/1505] Loss 0.5829 
[2025-05-11 13:38:47,824 INFO evaluator.py line 167 288342] Test: [409/1505] Loss 0.7831 
[2025-05-11 13:38:47,963 INFO evaluator.py line 167 288342] Test: [410/1505] Loss 0.7287 
[2025-05-11 13:38:48,096 INFO evaluator.py line 167 288342] Test: [411/1505] Loss 0.8003 
[2025-05-11 13:38:48,269 INFO evaluator.py line 167 288342] Test: [412/1505] Loss 0.4707 
[2025-05-11 13:38:48,432 INFO evaluator.py line 167 288342] Test: [413/1505] Loss 0.8242 
[2025-05-11 13:38:48,568 INFO evaluator.py line 167 288342] Test: [414/1505] Loss 0.8377 
[2025-05-11 13:38:48,726 INFO evaluator.py line 167 288342] Test: [415/1505] Loss 0.8785 
[2025-05-11 13:38:48,901 INFO evaluator.py line 167 288342] Test: [416/1505] Loss 0.7057 
[2025-05-11 13:38:49,079 INFO evaluator.py line 167 288342] Test: [417/1505] Loss 0.8977 
[2025-05-11 13:38:49,218 INFO evaluator.py line 167 288342] Test: [418/1505] Loss 0.7710 
[2025-05-11 13:38:49,390 INFO evaluator.py line 167 288342] Test: [419/1505] Loss 0.7325 
[2025-05-11 13:38:49,575 INFO evaluator.py line 167 288342] Test: [420/1505] Loss 1.1705 
[2025-05-11 13:38:49,721 INFO evaluator.py line 167 288342] Test: [421/1505] Loss 0.5371 
[2025-05-11 13:38:49,878 INFO evaluator.py line 167 288342] Test: [422/1505] Loss 0.5417 
[2025-05-11 13:38:50,008 INFO evaluator.py line 167 288342] Test: [423/1505] Loss 0.7381 
[2025-05-11 13:38:50,194 INFO evaluator.py line 167 288342] Test: [424/1505] Loss 0.6023 
[2025-05-11 13:38:50,373 INFO evaluator.py line 167 288342] Test: [425/1505] Loss 0.7032 
[2025-05-11 13:38:50,494 INFO evaluator.py line 167 288342] Test: [426/1505] Loss 0.4138 
[2025-05-11 13:38:50,612 INFO evaluator.py line 167 288342] Test: [427/1505] Loss 0.8398 
[2025-05-11 13:38:50,769 INFO evaluator.py line 167 288342] Test: [428/1505] Loss 1.0215 
[2025-05-11 13:38:50,916 INFO evaluator.py line 167 288342] Test: [429/1505] Loss 0.9361 
[2025-05-11 13:38:51,074 INFO evaluator.py line 167 288342] Test: [430/1505] Loss 0.6602 
[2025-05-11 13:38:51,234 INFO evaluator.py line 167 288342] Test: [431/1505] Loss 1.2917 
[2025-05-11 13:38:51,382 INFO evaluator.py line 167 288342] Test: [432/1505] Loss 0.6101 
[2025-05-11 13:38:51,525 INFO evaluator.py line 167 288342] Test: [433/1505] Loss 0.5567 
[2025-05-11 13:38:51,649 INFO evaluator.py line 167 288342] Test: [434/1505] Loss 0.8713 
[2025-05-11 13:38:51,817 INFO evaluator.py line 167 288342] Test: [435/1505] Loss 0.7893 
[2025-05-11 13:38:51,973 INFO evaluator.py line 167 288342] Test: [436/1505] Loss 0.7600 
[2025-05-11 13:38:52,141 INFO evaluator.py line 167 288342] Test: [437/1505] Loss 0.7520 
[2025-05-11 13:38:52,289 INFO evaluator.py line 167 288342] Test: [438/1505] Loss 1.2863 
[2025-05-11 13:38:52,414 INFO evaluator.py line 167 288342] Test: [439/1505] Loss 1.1871 
[2025-05-11 13:38:52,587 INFO evaluator.py line 167 288342] Test: [440/1505] Loss 0.7893 
[2025-05-11 13:38:52,740 INFO evaluator.py line 167 288342] Test: [441/1505] Loss 0.8588 
[2025-05-11 13:38:52,859 INFO evaluator.py line 167 288342] Test: [442/1505] Loss 0.4102 
[2025-05-11 13:38:53,008 INFO evaluator.py line 167 288342] Test: [443/1505] Loss 0.8544 
[2025-05-11 13:38:53,166 INFO evaluator.py line 167 288342] Test: [444/1505] Loss 1.1695 
[2025-05-11 13:38:53,331 INFO evaluator.py line 167 288342] Test: [445/1505] Loss 0.8103 
[2025-05-11 13:38:53,473 INFO evaluator.py line 167 288342] Test: [446/1505] Loss 0.7183 
[2025-05-11 13:38:53,623 INFO evaluator.py line 167 288342] Test: [447/1505] Loss 0.7202 
[2025-05-11 13:38:53,768 INFO evaluator.py line 167 288342] Test: [448/1505] Loss 0.8614 
[2025-05-11 13:38:53,976 INFO evaluator.py line 167 288342] Test: [449/1505] Loss 0.9678 
[2025-05-11 13:38:54,134 INFO evaluator.py line 167 288342] Test: [450/1505] Loss 1.5181 
[2025-05-11 13:38:54,278 INFO evaluator.py line 167 288342] Test: [451/1505] Loss 0.7632 
[2025-05-11 13:38:54,441 INFO evaluator.py line 167 288342] Test: [452/1505] Loss 0.7470 
[2025-05-11 13:38:54,564 INFO evaluator.py line 167 288342] Test: [453/1505] Loss 0.4948 
[2025-05-11 13:38:54,681 INFO evaluator.py line 167 288342] Test: [454/1505] Loss 0.8370 
[2025-05-11 13:38:54,847 INFO evaluator.py line 167 288342] Test: [455/1505] Loss 1.1441 
[2025-05-11 13:38:54,989 INFO evaluator.py line 167 288342] Test: [456/1505] Loss 0.9576 
[2025-05-11 13:38:55,157 INFO evaluator.py line 167 288342] Test: [457/1505] Loss 0.7350 
[2025-05-11 13:38:55,306 INFO evaluator.py line 167 288342] Test: [458/1505] Loss 0.8724 
[2025-05-11 13:38:55,468 INFO evaluator.py line 167 288342] Test: [459/1505] Loss 0.6539 
[2025-05-11 13:38:55,603 INFO evaluator.py line 167 288342] Test: [460/1505] Loss 0.9176 
[2025-05-11 13:38:55,775 INFO evaluator.py line 167 288342] Test: [461/1505] Loss 0.7001 
[2025-05-11 13:38:55,936 INFO evaluator.py line 167 288342] Test: [462/1505] Loss 1.2883 
[2025-05-11 13:38:56,082 INFO evaluator.py line 167 288342] Test: [463/1505] Loss 0.7241 
[2025-05-11 13:38:56,262 INFO evaluator.py line 167 288342] Test: [464/1505] Loss 1.0090 
[2025-05-11 13:38:56,377 INFO evaluator.py line 167 288342] Test: [465/1505] Loss 0.8547 
[2025-05-11 13:38:56,556 INFO evaluator.py line 167 288342] Test: [466/1505] Loss 1.0478 
[2025-05-11 13:38:56,693 INFO evaluator.py line 167 288342] Test: [467/1505] Loss 0.5611 
[2025-05-11 13:38:56,863 INFO evaluator.py line 167 288342] Test: [468/1505] Loss 0.4325 
[2025-05-11 13:38:57,045 INFO evaluator.py line 167 288342] Test: [469/1505] Loss 0.9734 
[2025-05-11 13:38:57,173 INFO evaluator.py line 167 288342] Test: [470/1505] Loss 0.6541 
[2025-05-11 13:38:57,315 INFO evaluator.py line 167 288342] Test: [471/1505] Loss 0.7039 
[2025-05-11 13:38:57,478 INFO evaluator.py line 167 288342] Test: [472/1505] Loss 0.5835 
[2025-05-11 13:38:57,694 INFO evaluator.py line 167 288342] Test: [473/1505] Loss 0.7398 
[2025-05-11 13:38:57,840 INFO evaluator.py line 167 288342] Test: [474/1505] Loss 0.7580 
[2025-05-11 13:38:57,971 INFO evaluator.py line 167 288342] Test: [475/1505] Loss 0.6553 
[2025-05-11 13:38:58,135 INFO evaluator.py line 167 288342] Test: [476/1505] Loss 0.6645 
[2025-05-11 13:38:58,306 INFO evaluator.py line 167 288342] Test: [477/1505] Loss 0.3633 
[2025-05-11 13:38:58,454 INFO evaluator.py line 167 288342] Test: [478/1505] Loss 0.5817 
[2025-05-11 13:38:58,638 INFO evaluator.py line 167 288342] Test: [479/1505] Loss 0.8916 
[2025-05-11 13:38:58,767 INFO evaluator.py line 167 288342] Test: [480/1505] Loss 0.6247 
[2025-05-11 13:38:58,910 INFO evaluator.py line 167 288342] Test: [481/1505] Loss 0.8367 
[2025-05-11 13:38:59,044 INFO evaluator.py line 167 288342] Test: [482/1505] Loss 0.8309 
[2025-05-11 13:38:59,208 INFO evaluator.py line 167 288342] Test: [483/1505] Loss 1.0582 
[2025-05-11 13:38:59,338 INFO evaluator.py line 167 288342] Test: [484/1505] Loss 0.5459 
[2025-05-11 13:38:59,519 INFO evaluator.py line 167 288342] Test: [485/1505] Loss 1.2293 
[2025-05-11 13:38:59,675 INFO evaluator.py line 167 288342] Test: [486/1505] Loss 0.6388 
[2025-05-11 13:38:59,840 INFO evaluator.py line 167 288342] Test: [487/1505] Loss 0.8939 
[2025-05-11 13:38:59,960 INFO evaluator.py line 167 288342] Test: [488/1505] Loss 0.5880 
[2025-05-11 13:39:00,093 INFO evaluator.py line 167 288342] Test: [489/1505] Loss 0.3666 
[2025-05-11 13:39:00,221 INFO evaluator.py line 167 288342] Test: [490/1505] Loss 0.5912 
[2025-05-11 13:39:00,379 INFO evaluator.py line 167 288342] Test: [491/1505] Loss 1.4672 
[2025-05-11 13:39:00,522 INFO evaluator.py line 167 288342] Test: [492/1505] Loss 0.5687 
[2025-05-11 13:39:00,677 INFO evaluator.py line 167 288342] Test: [493/1505] Loss 1.3753 
[2025-05-11 13:39:00,806 INFO evaluator.py line 167 288342] Test: [494/1505] Loss 0.8697 
[2025-05-11 13:39:00,974 INFO evaluator.py line 167 288342] Test: [495/1505] Loss 0.6173 
[2025-05-11 13:39:01,123 INFO evaluator.py line 167 288342] Test: [496/1505] Loss 0.8316 
[2025-05-11 13:39:01,296 INFO evaluator.py line 167 288342] Test: [497/1505] Loss 0.6895 
[2025-05-11 13:39:01,450 INFO evaluator.py line 167 288342] Test: [498/1505] Loss 0.5674 
[2025-05-11 13:39:01,592 INFO evaluator.py line 167 288342] Test: [499/1505] Loss 0.6315 
[2025-05-11 13:39:01,696 INFO evaluator.py line 167 288342] Test: [500/1505] Loss 0.8353 
[2025-05-11 13:39:01,813 INFO evaluator.py line 167 288342] Test: [501/1505] Loss 1.1755 
[2025-05-11 13:39:01,937 INFO evaluator.py line 167 288342] Test: [502/1505] Loss 1.0220 
[2025-05-11 13:39:02,086 INFO evaluator.py line 167 288342] Test: [503/1505] Loss 0.6327 
[2025-05-11 13:39:02,263 INFO evaluator.py line 167 288342] Test: [504/1505] Loss 0.6580 
[2025-05-11 13:39:02,431 INFO evaluator.py line 167 288342] Test: [505/1505] Loss 0.7863 
[2025-05-11 13:39:02,590 INFO evaluator.py line 167 288342] Test: [506/1505] Loss 0.6836 
[2025-05-11 13:39:02,803 INFO evaluator.py line 167 288342] Test: [507/1505] Loss 0.6818 
[2025-05-11 13:39:02,964 INFO evaluator.py line 167 288342] Test: [508/1505] Loss 0.7880 
[2025-05-11 13:39:03,095 INFO evaluator.py line 167 288342] Test: [509/1505] Loss 0.9861 
[2025-05-11 13:39:03,244 INFO evaluator.py line 167 288342] Test: [510/1505] Loss 0.7894 
[2025-05-11 13:39:03,418 INFO evaluator.py line 167 288342] Test: [511/1505] Loss 0.8426 
[2025-05-11 13:39:03,546 INFO evaluator.py line 167 288342] Test: [512/1505] Loss 1.1431 
[2025-05-11 13:39:03,671 INFO evaluator.py line 167 288342] Test: [513/1505] Loss 0.7048 
[2025-05-11 13:39:03,808 INFO evaluator.py line 167 288342] Test: [514/1505] Loss 0.8617 
[2025-05-11 13:39:03,980 INFO evaluator.py line 167 288342] Test: [515/1505] Loss 0.6524 
[2025-05-11 13:39:04,148 INFO evaluator.py line 167 288342] Test: [516/1505] Loss 0.3010 
[2025-05-11 13:39:04,293 INFO evaluator.py line 167 288342] Test: [517/1505] Loss 0.8194 
[2025-05-11 13:39:04,424 INFO evaluator.py line 167 288342] Test: [518/1505] Loss 0.7598 
[2025-05-11 13:39:04,560 INFO evaluator.py line 167 288342] Test: [519/1505] Loss 0.7010 
[2025-05-11 13:39:04,699 INFO evaluator.py line 167 288342] Test: [520/1505] Loss 0.6948 
[2025-05-11 13:39:04,858 INFO evaluator.py line 167 288342] Test: [521/1505] Loss 0.9513 
[2025-05-11 13:39:04,994 INFO evaluator.py line 167 288342] Test: [522/1505] Loss 0.7371 
[2025-05-11 13:39:05,147 INFO evaluator.py line 167 288342] Test: [523/1505] Loss 0.6273 
[2025-05-11 13:39:05,322 INFO evaluator.py line 167 288342] Test: [524/1505] Loss 1.0337 
[2025-05-11 13:39:05,506 INFO evaluator.py line 167 288342] Test: [525/1505] Loss 0.6827 
[2025-05-11 13:39:05,648 INFO evaluator.py line 167 288342] Test: [526/1505] Loss 0.5797 
[2025-05-11 13:39:05,767 INFO evaluator.py line 167 288342] Test: [527/1505] Loss 1.0094 
[2025-05-11 13:39:05,904 INFO evaluator.py line 167 288342] Test: [528/1505] Loss 0.8096 
[2025-05-11 13:39:06,027 INFO evaluator.py line 167 288342] Test: [529/1505] Loss 0.9535 
[2025-05-11 13:39:06,171 INFO evaluator.py line 167 288342] Test: [530/1505] Loss 0.5894 
[2025-05-11 13:39:06,311 INFO evaluator.py line 167 288342] Test: [531/1505] Loss 0.9183 
[2025-05-11 13:39:06,457 INFO evaluator.py line 167 288342] Test: [532/1505] Loss 0.7194 
[2025-05-11 13:39:06,629 INFO evaluator.py line 167 288342] Test: [533/1505] Loss 0.9330 
[2025-05-11 13:39:06,797 INFO evaluator.py line 167 288342] Test: [534/1505] Loss 0.7133 
[2025-05-11 13:39:06,961 INFO evaluator.py line 167 288342] Test: [535/1505] Loss 0.6266 
[2025-05-11 13:39:07,127 INFO evaluator.py line 167 288342] Test: [536/1505] Loss 0.7390 
[2025-05-11 13:39:07,250 INFO evaluator.py line 167 288342] Test: [537/1505] Loss 0.9285 
[2025-05-11 13:39:07,402 INFO evaluator.py line 167 288342] Test: [538/1505] Loss 1.0731 
[2025-05-11 13:39:07,596 INFO evaluator.py line 167 288342] Test: [539/1505] Loss 0.8656 
[2025-05-11 13:39:07,784 INFO evaluator.py line 167 288342] Test: [540/1505] Loss 0.8615 
[2025-05-11 13:39:07,952 INFO evaluator.py line 167 288342] Test: [541/1505] Loss 0.8273 
[2025-05-11 13:39:08,131 INFO evaluator.py line 167 288342] Test: [542/1505] Loss 0.7665 
[2025-05-11 13:39:08,317 INFO evaluator.py line 167 288342] Test: [543/1505] Loss 0.5246 
[2025-05-11 13:39:08,456 INFO evaluator.py line 167 288342] Test: [544/1505] Loss 0.9111 
[2025-05-11 13:39:08,606 INFO evaluator.py line 167 288342] Test: [545/1505] Loss 0.5014 
[2025-05-11 13:39:08,769 INFO evaluator.py line 167 288342] Test: [546/1505] Loss 0.7241 
[2025-05-11 13:39:08,946 INFO evaluator.py line 167 288342] Test: [547/1505] Loss 0.5731 
[2025-05-11 13:39:09,084 INFO evaluator.py line 167 288342] Test: [548/1505] Loss 0.8848 
[2025-05-11 13:39:09,204 INFO evaluator.py line 167 288342] Test: [549/1505] Loss 0.8608 
[2025-05-11 13:39:09,345 INFO evaluator.py line 167 288342] Test: [550/1505] Loss 0.5582 
[2025-05-11 13:39:09,502 INFO evaluator.py line 167 288342] Test: [551/1505] Loss 0.7669 
[2025-05-11 13:39:09,647 INFO evaluator.py line 167 288342] Test: [552/1505] Loss 1.0339 
[2025-05-11 13:39:09,807 INFO evaluator.py line 167 288342] Test: [553/1505] Loss 0.9366 
[2025-05-11 13:39:10,004 INFO evaluator.py line 167 288342] Test: [554/1505] Loss 0.8083 
[2025-05-11 13:39:10,181 INFO evaluator.py line 167 288342] Test: [555/1505] Loss 0.6928 
[2025-05-11 13:39:10,308 INFO evaluator.py line 167 288342] Test: [556/1505] Loss 0.7655 
[2025-05-11 13:39:10,504 INFO evaluator.py line 167 288342] Test: [557/1505] Loss 0.9290 
[2025-05-11 13:39:10,629 INFO evaluator.py line 167 288342] Test: [558/1505] Loss 0.9422 
[2025-05-11 13:39:10,790 INFO evaluator.py line 167 288342] Test: [559/1505] Loss 1.0491 
[2025-05-11 13:39:10,954 INFO evaluator.py line 167 288342] Test: [560/1505] Loss 0.8123 
[2025-05-11 13:39:11,121 INFO evaluator.py line 167 288342] Test: [561/1505] Loss 0.6341 
[2025-05-11 13:39:11,300 INFO evaluator.py line 167 288342] Test: [562/1505] Loss 0.6667 
[2025-05-11 13:39:11,458 INFO evaluator.py line 167 288342] Test: [563/1505] Loss 0.6429 
[2025-05-11 13:39:11,597 INFO evaluator.py line 167 288342] Test: [564/1505] Loss 0.7659 
[2025-05-11 13:39:11,734 INFO evaluator.py line 167 288342] Test: [565/1505] Loss 0.9079 
[2025-05-11 13:39:11,868 INFO evaluator.py line 167 288342] Test: [566/1505] Loss 0.9896 
[2025-05-11 13:39:12,037 INFO evaluator.py line 167 288342] Test: [567/1505] Loss 1.0689 
[2025-05-11 13:39:12,198 INFO evaluator.py line 167 288342] Test: [568/1505] Loss 0.7140 
[2025-05-11 13:39:12,304 INFO evaluator.py line 167 288342] Test: [569/1505] Loss 0.7026 
[2025-05-11 13:39:12,473 INFO evaluator.py line 167 288342] Test: [570/1505] Loss 0.6979 
[2025-05-11 13:39:12,657 INFO evaluator.py line 167 288342] Test: [571/1505] Loss 0.7013 
[2025-05-11 13:39:12,810 INFO evaluator.py line 167 288342] Test: [572/1505] Loss 0.6218 
[2025-05-11 13:39:12,950 INFO evaluator.py line 167 288342] Test: [573/1505] Loss 1.1097 
[2025-05-11 13:39:13,082 INFO evaluator.py line 167 288342] Test: [574/1505] Loss 0.5579 
[2025-05-11 13:39:13,235 INFO evaluator.py line 167 288342] Test: [575/1505] Loss 0.8035 
[2025-05-11 13:39:13,398 INFO evaluator.py line 167 288342] Test: [576/1505] Loss 0.6180 
[2025-05-11 13:39:13,551 INFO evaluator.py line 167 288342] Test: [577/1505] Loss 0.9824 
[2025-05-11 13:39:13,686 INFO evaluator.py line 167 288342] Test: [578/1505] Loss 0.7581 
[2025-05-11 13:39:13,860 INFO evaluator.py line 167 288342] Test: [579/1505] Loss 0.8187 
[2025-05-11 13:39:14,061 INFO evaluator.py line 167 288342] Test: [580/1505] Loss 0.7637 
[2025-05-11 13:39:14,178 INFO evaluator.py line 167 288342] Test: [581/1505] Loss 0.7821 
[2025-05-11 13:39:14,329 INFO evaluator.py line 167 288342] Test: [582/1505] Loss 0.7139 
[2025-05-11 13:39:14,460 INFO evaluator.py line 167 288342] Test: [583/1505] Loss 0.5329 
[2025-05-11 13:39:14,599 INFO evaluator.py line 167 288342] Test: [584/1505] Loss 0.6430 
[2025-05-11 13:39:14,736 INFO evaluator.py line 167 288342] Test: [585/1505] Loss 0.6963 
[2025-05-11 13:39:14,905 INFO evaluator.py line 167 288342] Test: [586/1505] Loss 0.6634 
[2025-05-11 13:39:15,032 INFO evaluator.py line 167 288342] Test: [587/1505] Loss 0.3354 
[2025-05-11 13:39:15,193 INFO evaluator.py line 167 288342] Test: [588/1505] Loss 0.9576 
[2025-05-11 13:39:15,303 INFO evaluator.py line 167 288342] Test: [589/1505] Loss 0.7910 
[2025-05-11 13:39:15,495 INFO evaluator.py line 167 288342] Test: [590/1505] Loss 0.6497 
[2025-05-11 13:39:15,659 INFO evaluator.py line 167 288342] Test: [591/1505] Loss 0.6358 
[2025-05-11 13:39:15,812 INFO evaluator.py line 167 288342] Test: [592/1505] Loss 0.6700 
[2025-05-11 13:39:15,966 INFO evaluator.py line 167 288342] Test: [593/1505] Loss 0.7521 
[2025-05-11 13:39:16,102 INFO evaluator.py line 167 288342] Test: [594/1505] Loss 1.0023 
[2025-05-11 13:39:16,213 INFO evaluator.py line 167 288342] Test: [595/1505] Loss 0.9093 
[2025-05-11 13:39:16,362 INFO evaluator.py line 167 288342] Test: [596/1505] Loss 0.7450 
[2025-05-11 13:39:16,520 INFO evaluator.py line 167 288342] Test: [597/1505] Loss 0.7206 
[2025-05-11 13:39:16,684 INFO evaluator.py line 167 288342] Test: [598/1505] Loss 0.7715 
[2025-05-11 13:39:16,832 INFO evaluator.py line 167 288342] Test: [599/1505] Loss 0.6625 
[2025-05-11 13:39:16,978 INFO evaluator.py line 167 288342] Test: [600/1505] Loss 0.9884 
[2025-05-11 13:39:17,168 INFO evaluator.py line 167 288342] Test: [601/1505] Loss 0.7488 
[2025-05-11 13:39:17,342 INFO evaluator.py line 167 288342] Test: [602/1505] Loss 0.9359 
[2025-05-11 13:39:17,485 INFO evaluator.py line 167 288342] Test: [603/1505] Loss 0.7728 
[2025-05-11 13:39:17,613 INFO evaluator.py line 167 288342] Test: [604/1505] Loss 0.4134 
[2025-05-11 13:39:17,759 INFO evaluator.py line 167 288342] Test: [605/1505] Loss 0.8244 
[2025-05-11 13:39:17,921 INFO evaluator.py line 167 288342] Test: [606/1505] Loss 0.7923 
[2025-05-11 13:39:18,088 INFO evaluator.py line 167 288342] Test: [607/1505] Loss 0.8903 
[2025-05-11 13:39:18,193 INFO evaluator.py line 167 288342] Test: [608/1505] Loss 1.2314 
[2025-05-11 13:39:18,326 INFO evaluator.py line 167 288342] Test: [609/1505] Loss 1.3706 
[2025-05-11 13:39:18,492 INFO evaluator.py line 167 288342] Test: [610/1505] Loss 0.6648 
[2025-05-11 13:39:18,632 INFO evaluator.py line 167 288342] Test: [611/1505] Loss 0.5307 
[2025-05-11 13:39:18,753 INFO evaluator.py line 167 288342] Test: [612/1505] Loss 1.0647 
[2025-05-11 13:39:18,933 INFO evaluator.py line 167 288342] Test: [613/1505] Loss 0.8454 
[2025-05-11 13:39:19,053 INFO evaluator.py line 167 288342] Test: [614/1505] Loss 0.6358 
[2025-05-11 13:39:19,233 INFO evaluator.py line 167 288342] Test: [615/1505] Loss 0.9806 
[2025-05-11 13:39:19,386 INFO evaluator.py line 167 288342] Test: [616/1505] Loss 0.9343 
[2025-05-11 13:39:19,527 INFO evaluator.py line 167 288342] Test: [617/1505] Loss 0.7504 
[2025-05-11 13:39:19,699 INFO evaluator.py line 167 288342] Test: [618/1505] Loss 0.8220 
[2025-05-11 13:39:19,863 INFO evaluator.py line 167 288342] Test: [619/1505] Loss 0.9324 
[2025-05-11 13:39:20,011 INFO evaluator.py line 167 288342] Test: [620/1505] Loss 0.6461 
[2025-05-11 13:39:20,168 INFO evaluator.py line 167 288342] Test: [621/1505] Loss 0.5687 
[2025-05-11 13:39:20,326 INFO evaluator.py line 167 288342] Test: [622/1505] Loss 0.7514 
[2025-05-11 13:39:20,464 INFO evaluator.py line 167 288342] Test: [623/1505] Loss 0.7261 
[2025-05-11 13:39:20,661 INFO evaluator.py line 167 288342] Test: [624/1505] Loss 0.8837 
[2025-05-11 13:39:20,791 INFO evaluator.py line 167 288342] Test: [625/1505] Loss 0.8993 
[2025-05-11 13:39:20,976 INFO evaluator.py line 167 288342] Test: [626/1505] Loss 0.6479 
[2025-05-11 13:39:21,122 INFO evaluator.py line 167 288342] Test: [627/1505] Loss 0.7772 
[2025-05-11 13:39:21,279 INFO evaluator.py line 167 288342] Test: [628/1505] Loss 0.7526 
[2025-05-11 13:39:21,438 INFO evaluator.py line 167 288342] Test: [629/1505] Loss 0.6288 
[2025-05-11 13:39:21,579 INFO evaluator.py line 167 288342] Test: [630/1505] Loss 0.7088 
[2025-05-11 13:39:21,729 INFO evaluator.py line 167 288342] Test: [631/1505] Loss 0.7963 
[2025-05-11 13:39:21,933 INFO evaluator.py line 167 288342] Test: [632/1505] Loss 0.9081 
[2025-05-11 13:39:22,058 INFO evaluator.py line 167 288342] Test: [633/1505] Loss 0.7827 
[2025-05-11 13:39:22,196 INFO evaluator.py line 167 288342] Test: [634/1505] Loss 0.8052 
[2025-05-11 13:39:22,339 INFO evaluator.py line 167 288342] Test: [635/1505] Loss 0.7154 
[2025-05-11 13:39:22,446 INFO evaluator.py line 167 288342] Test: [636/1505] Loss 1.0723 
[2025-05-11 13:39:22,590 INFO evaluator.py line 167 288342] Test: [637/1505] Loss 0.4877 
[2025-05-11 13:39:22,726 INFO evaluator.py line 167 288342] Test: [638/1505] Loss 0.9808 
[2025-05-11 13:39:22,849 INFO evaluator.py line 167 288342] Test: [639/1505] Loss 0.9824 
[2025-05-11 13:39:22,983 INFO evaluator.py line 167 288342] Test: [640/1505] Loss 1.0648 
[2025-05-11 13:39:23,146 INFO evaluator.py line 167 288342] Test: [641/1505] Loss 1.0078 
[2025-05-11 13:39:23,300 INFO evaluator.py line 167 288342] Test: [642/1505] Loss 0.6474 
[2025-05-11 13:39:23,478 INFO evaluator.py line 167 288342] Test: [643/1505] Loss 1.0076 
[2025-05-11 13:39:23,617 INFO evaluator.py line 167 288342] Test: [644/1505] Loss 0.9059 
[2025-05-11 13:39:23,775 INFO evaluator.py line 167 288342] Test: [645/1505] Loss 1.2785 
[2025-05-11 13:39:23,931 INFO evaluator.py line 167 288342] Test: [646/1505] Loss 0.8454 
[2025-05-11 13:39:24,131 INFO evaluator.py line 167 288342] Test: [647/1505] Loss 0.9687 
[2025-05-11 13:39:24,288 INFO evaluator.py line 167 288342] Test: [648/1505] Loss 0.6535 
[2025-05-11 13:39:24,428 INFO evaluator.py line 167 288342] Test: [649/1505] Loss 0.5872 
[2025-05-11 13:39:24,599 INFO evaluator.py line 167 288342] Test: [650/1505] Loss 0.6953 
[2025-05-11 13:39:24,750 INFO evaluator.py line 167 288342] Test: [651/1505] Loss 0.9808 
[2025-05-11 13:39:24,906 INFO evaluator.py line 167 288342] Test: [652/1505] Loss 0.8186 
[2025-05-11 13:39:25,052 INFO evaluator.py line 167 288342] Test: [653/1505] Loss 1.1690 
[2025-05-11 13:39:25,202 INFO evaluator.py line 167 288342] Test: [654/1505] Loss 0.7081 
[2025-05-11 13:39:25,414 INFO evaluator.py line 167 288342] Test: [655/1505] Loss 0.7595 
[2025-05-11 13:39:25,560 INFO evaluator.py line 167 288342] Test: [656/1505] Loss 0.7451 
[2025-05-11 13:39:25,693 INFO evaluator.py line 167 288342] Test: [657/1505] Loss 0.7956 
[2025-05-11 13:39:25,823 INFO evaluator.py line 167 288342] Test: [658/1505] Loss 0.6706 
[2025-05-11 13:39:25,971 INFO evaluator.py line 167 288342] Test: [659/1505] Loss 0.7530 
[2025-05-11 13:39:26,122 INFO evaluator.py line 167 288342] Test: [660/1505] Loss 0.8064 
[2025-05-11 13:39:26,249 INFO evaluator.py line 167 288342] Test: [661/1505] Loss 0.8427 
[2025-05-11 13:39:26,432 INFO evaluator.py line 167 288342] Test: [662/1505] Loss 1.0126 
[2025-05-11 13:39:26,625 INFO evaluator.py line 167 288342] Test: [663/1505] Loss 0.9738 
[2025-05-11 13:39:26,784 INFO evaluator.py line 167 288342] Test: [664/1505] Loss 0.4227 
[2025-05-11 13:39:26,890 INFO evaluator.py line 167 288342] Test: [665/1505] Loss 0.9285 
[2025-05-11 13:39:27,082 INFO evaluator.py line 167 288342] Test: [666/1505] Loss 0.7127 
[2025-05-11 13:39:27,228 INFO evaluator.py line 167 288342] Test: [667/1505] Loss 0.5117 
[2025-05-11 13:39:27,354 INFO evaluator.py line 167 288342] Test: [668/1505] Loss 0.5969 
[2025-05-11 13:39:27,510 INFO evaluator.py line 167 288342] Test: [669/1505] Loss 0.7516 
[2025-05-11 13:39:27,663 INFO evaluator.py line 167 288342] Test: [670/1505] Loss 0.6717 
[2025-05-11 13:39:27,799 INFO evaluator.py line 167 288342] Test: [671/1505] Loss 0.6710 
[2025-05-11 13:39:27,971 INFO evaluator.py line 167 288342] Test: [672/1505] Loss 0.6947 
[2025-05-11 13:39:28,133 INFO evaluator.py line 167 288342] Test: [673/1505] Loss 0.5325 
[2025-05-11 13:39:28,294 INFO evaluator.py line 167 288342] Test: [674/1505] Loss 1.5496 
[2025-05-11 13:39:28,483 INFO evaluator.py line 167 288342] Test: [675/1505] Loss 1.0191 
[2025-05-11 13:39:28,626 INFO evaluator.py line 167 288342] Test: [676/1505] Loss 0.4912 
[2025-05-11 13:39:28,784 INFO evaluator.py line 167 288342] Test: [677/1505] Loss 0.5320 
[2025-05-11 13:39:28,945 INFO evaluator.py line 167 288342] Test: [678/1505] Loss 1.2010 
[2025-05-11 13:39:29,082 INFO evaluator.py line 167 288342] Test: [679/1505] Loss 0.9255 
[2025-05-11 13:39:29,258 INFO evaluator.py line 167 288342] Test: [680/1505] Loss 0.9416 
[2025-05-11 13:39:29,402 INFO evaluator.py line 167 288342] Test: [681/1505] Loss 0.7690 
[2025-05-11 13:39:29,528 INFO evaluator.py line 167 288342] Test: [682/1505] Loss 0.6185 
[2025-05-11 13:39:29,670 INFO evaluator.py line 167 288342] Test: [683/1505] Loss 0.6508 
[2025-05-11 13:39:29,832 INFO evaluator.py line 167 288342] Test: [684/1505] Loss 0.6380 
[2025-05-11 13:39:29,984 INFO evaluator.py line 167 288342] Test: [685/1505] Loss 0.6830 
[2025-05-11 13:39:30,121 INFO evaluator.py line 167 288342] Test: [686/1505] Loss 0.9838 
[2025-05-11 13:39:30,308 INFO evaluator.py line 167 288342] Test: [687/1505] Loss 0.7793 
[2025-05-11 13:39:30,429 INFO evaluator.py line 167 288342] Test: [688/1505] Loss 0.7632 
[2025-05-11 13:39:30,596 INFO evaluator.py line 167 288342] Test: [689/1505] Loss 0.8976 
[2025-05-11 13:39:30,752 INFO evaluator.py line 167 288342] Test: [690/1505] Loss 0.6690 
[2025-05-11 13:39:30,936 INFO evaluator.py line 167 288342] Test: [691/1505] Loss 0.6888 
[2025-05-11 13:39:31,100 INFO evaluator.py line 167 288342] Test: [692/1505] Loss 0.7552 
[2025-05-11 13:39:31,244 INFO evaluator.py line 167 288342] Test: [693/1505] Loss 0.9830 
[2025-05-11 13:39:31,377 INFO evaluator.py line 167 288342] Test: [694/1505] Loss 0.6157 
[2025-05-11 13:39:31,538 INFO evaluator.py line 167 288342] Test: [695/1505] Loss 0.6960 
[2025-05-11 13:39:31,704 INFO evaluator.py line 167 288342] Test: [696/1505] Loss 0.5858 
[2025-05-11 13:39:31,883 INFO evaluator.py line 167 288342] Test: [697/1505] Loss 0.7980 
[2025-05-11 13:39:32,033 INFO evaluator.py line 167 288342] Test: [698/1505] Loss 1.1717 
[2025-05-11 13:39:32,204 INFO evaluator.py line 167 288342] Test: [699/1505] Loss 0.9320 
[2025-05-11 13:39:32,394 INFO evaluator.py line 167 288342] Test: [700/1505] Loss 0.8725 
[2025-05-11 13:39:32,528 INFO evaluator.py line 167 288342] Test: [701/1505] Loss 0.6391 
[2025-05-11 13:39:32,676 INFO evaluator.py line 167 288342] Test: [702/1505] Loss 0.5616 
[2025-05-11 13:39:32,797 INFO evaluator.py line 167 288342] Test: [703/1505] Loss 0.8590 
[2025-05-11 13:39:32,961 INFO evaluator.py line 167 288342] Test: [704/1505] Loss 0.5202 
[2025-05-11 13:39:33,115 INFO evaluator.py line 167 288342] Test: [705/1505] Loss 0.8984 
[2025-05-11 13:39:33,312 INFO evaluator.py line 167 288342] Test: [706/1505] Loss 0.9105 
[2025-05-11 13:39:33,450 INFO evaluator.py line 167 288342] Test: [707/1505] Loss 0.8387 
[2025-05-11 13:39:33,614 INFO evaluator.py line 167 288342] Test: [708/1505] Loss 0.6119 
[2025-05-11 13:39:33,756 INFO evaluator.py line 167 288342] Test: [709/1505] Loss 0.6807 
[2025-05-11 13:39:33,957 INFO evaluator.py line 167 288342] Test: [710/1505] Loss 0.4917 
[2025-05-11 13:39:34,094 INFO evaluator.py line 167 288342] Test: [711/1505] Loss 0.6820 
[2025-05-11 13:39:34,258 INFO evaluator.py line 167 288342] Test: [712/1505] Loss 0.8457 
[2025-05-11 13:39:34,409 INFO evaluator.py line 167 288342] Test: [713/1505] Loss 0.3808 
[2025-05-11 13:39:34,560 INFO evaluator.py line 167 288342] Test: [714/1505] Loss 0.9500 
[2025-05-11 13:39:34,682 INFO evaluator.py line 167 288342] Test: [715/1505] Loss 0.9704 
[2025-05-11 13:39:34,823 INFO evaluator.py line 167 288342] Test: [716/1505] Loss 1.3177 
[2025-05-11 13:39:35,038 INFO evaluator.py line 167 288342] Test: [717/1505] Loss 0.8321 
[2025-05-11 13:39:35,197 INFO evaluator.py line 167 288342] Test: [718/1505] Loss 0.9915 
[2025-05-11 13:39:35,318 INFO evaluator.py line 167 288342] Test: [719/1505] Loss 0.8045 
[2025-05-11 13:39:35,490 INFO evaluator.py line 167 288342] Test: [720/1505] Loss 1.0366 
[2025-05-11 13:39:35,683 INFO evaluator.py line 167 288342] Test: [721/1505] Loss 0.8053 
[2025-05-11 13:39:35,813 INFO evaluator.py line 167 288342] Test: [722/1505] Loss 0.6683 
[2025-05-11 13:39:35,955 INFO evaluator.py line 167 288342] Test: [723/1505] Loss 0.9275 
[2025-05-11 13:39:36,100 INFO evaluator.py line 167 288342] Test: [724/1505] Loss 0.8166 
[2025-05-11 13:39:36,237 INFO evaluator.py line 167 288342] Test: [725/1505] Loss 0.7872 
[2025-05-11 13:39:36,419 INFO evaluator.py line 167 288342] Test: [726/1505] Loss 0.8776 
[2025-05-11 13:39:36,546 INFO evaluator.py line 167 288342] Test: [727/1505] Loss 1.1078 
[2025-05-11 13:39:36,677 INFO evaluator.py line 167 288342] Test: [728/1505] Loss 0.9446 
[2025-05-11 13:39:36,800 INFO evaluator.py line 167 288342] Test: [729/1505] Loss 0.7158 
[2025-05-11 13:39:36,962 INFO evaluator.py line 167 288342] Test: [730/1505] Loss 0.6588 
[2025-05-11 13:39:37,092 INFO evaluator.py line 167 288342] Test: [731/1505] Loss 0.8063 
[2025-05-11 13:39:37,210 INFO evaluator.py line 167 288342] Test: [732/1505] Loss 1.3057 
[2025-05-11 13:39:37,381 INFO evaluator.py line 167 288342] Test: [733/1505] Loss 0.6766 
[2025-05-11 13:39:37,557 INFO evaluator.py line 167 288342] Test: [734/1505] Loss 1.1267 
[2025-05-11 13:39:37,710 INFO evaluator.py line 167 288342] Test: [735/1505] Loss 0.6877 
[2025-05-11 13:39:37,836 INFO evaluator.py line 167 288342] Test: [736/1505] Loss 0.7066 
[2025-05-11 13:39:38,004 INFO evaluator.py line 167 288342] Test: [737/1505] Loss 0.6426 
[2025-05-11 13:39:38,159 INFO evaluator.py line 167 288342] Test: [738/1505] Loss 0.6906 
[2025-05-11 13:39:38,333 INFO evaluator.py line 167 288342] Test: [739/1505] Loss 0.8112 
[2025-05-11 13:39:38,514 INFO evaluator.py line 167 288342] Test: [740/1505] Loss 0.9504 
[2025-05-11 13:39:38,684 INFO evaluator.py line 167 288342] Test: [741/1505] Loss 0.6385 
[2025-05-11 13:39:38,856 INFO evaluator.py line 167 288342] Test: [742/1505] Loss 0.6565 
[2025-05-11 13:39:38,994 INFO evaluator.py line 167 288342] Test: [743/1505] Loss 1.0719 
[2025-05-11 13:39:39,148 INFO evaluator.py line 167 288342] Test: [744/1505] Loss 0.5942 
[2025-05-11 13:39:39,262 INFO evaluator.py line 167 288342] Test: [745/1505] Loss 0.7210 
[2025-05-11 13:39:39,450 INFO evaluator.py line 167 288342] Test: [746/1505] Loss 0.8542 
[2025-05-11 13:39:39,593 INFO evaluator.py line 167 288342] Test: [747/1505] Loss 0.7758 
[2025-05-11 13:39:39,741 INFO evaluator.py line 167 288342] Test: [748/1505] Loss 1.1015 
[2025-05-11 13:39:39,862 INFO evaluator.py line 167 288342] Test: [749/1505] Loss 1.0645 
[2025-05-11 13:39:40,035 INFO evaluator.py line 167 288342] Test: [750/1505] Loss 0.9536 
[2025-05-11 13:39:40,209 INFO evaluator.py line 167 288342] Test: [751/1505] Loss 0.8637 
[2025-05-11 13:39:40,396 INFO evaluator.py line 167 288342] Test: [752/1505] Loss 0.5799 
[2025-05-11 13:39:40,541 INFO evaluator.py line 167 288342] Test: [753/1505] Loss 0.6673 
[2025-05-11 13:39:40,743 INFO evaluator.py line 167 288342] Test: [754/1505] Loss 0.7586 
[2025-05-11 13:39:40,908 INFO evaluator.py line 167 288342] Test: [755/1505] Loss 0.7333 
[2025-05-11 13:39:41,061 INFO evaluator.py line 167 288342] Test: [756/1505] Loss 0.7032 
[2025-05-11 13:39:41,216 INFO evaluator.py line 167 288342] Test: [757/1505] Loss 0.8368 
[2025-05-11 13:39:41,394 INFO evaluator.py line 167 288342] Test: [758/1505] Loss 0.8518 
[2025-05-11 13:39:41,516 INFO evaluator.py line 167 288342] Test: [759/1505] Loss 0.5867 
[2025-05-11 13:39:41,674 INFO evaluator.py line 167 288342] Test: [760/1505] Loss 0.9370 
[2025-05-11 13:39:41,848 INFO evaluator.py line 167 288342] Test: [761/1505] Loss 0.5358 
[2025-05-11 13:39:42,018 INFO evaluator.py line 167 288342] Test: [762/1505] Loss 1.0453 
[2025-05-11 13:39:42,160 INFO evaluator.py line 167 288342] Test: [763/1505] Loss 0.8492 
[2025-05-11 13:39:42,307 INFO evaluator.py line 167 288342] Test: [764/1505] Loss 0.8076 
[2025-05-11 13:39:42,483 INFO evaluator.py line 167 288342] Test: [765/1505] Loss 0.7285 
[2025-05-11 13:39:42,628 INFO evaluator.py line 167 288342] Test: [766/1505] Loss 0.8179 
[2025-05-11 13:39:42,777 INFO evaluator.py line 167 288342] Test: [767/1505] Loss 1.3486 
[2025-05-11 13:39:42,924 INFO evaluator.py line 167 288342] Test: [768/1505] Loss 0.7632 
[2025-05-11 13:39:43,057 INFO evaluator.py line 167 288342] Test: [769/1505] Loss 1.3295 
[2025-05-11 13:39:43,210 INFO evaluator.py line 167 288342] Test: [770/1505] Loss 0.7651 
[2025-05-11 13:39:43,362 INFO evaluator.py line 167 288342] Test: [771/1505] Loss 0.8461 
[2025-05-11 13:39:43,509 INFO evaluator.py line 167 288342] Test: [772/1505] Loss 1.0279 
[2025-05-11 13:39:43,684 INFO evaluator.py line 167 288342] Test: [773/1505] Loss 1.0785 
[2025-05-11 13:39:43,850 INFO evaluator.py line 167 288342] Test: [774/1505] Loss 0.5366 
[2025-05-11 13:39:44,013 INFO evaluator.py line 167 288342] Test: [775/1505] Loss 0.7585 
[2025-05-11 13:39:44,168 INFO evaluator.py line 167 288342] Test: [776/1505] Loss 0.6278 
[2025-05-11 13:39:44,323 INFO evaluator.py line 167 288342] Test: [777/1505] Loss 0.6441 
[2025-05-11 13:39:44,452 INFO evaluator.py line 167 288342] Test: [778/1505] Loss 0.6054 
[2025-05-11 13:39:44,578 INFO evaluator.py line 167 288342] Test: [779/1505] Loss 0.9097 
[2025-05-11 13:39:44,740 INFO evaluator.py line 167 288342] Test: [780/1505] Loss 0.6088 
[2025-05-11 13:39:44,909 INFO evaluator.py line 167 288342] Test: [781/1505] Loss 1.2065 
[2025-05-11 13:39:45,053 INFO evaluator.py line 167 288342] Test: [782/1505] Loss 0.7844 
[2025-05-11 13:39:45,243 INFO evaluator.py line 167 288342] Test: [783/1505] Loss 1.1824 
[2025-05-11 13:39:45,384 INFO evaluator.py line 167 288342] Test: [784/1505] Loss 1.4705 
[2025-05-11 13:39:45,543 INFO evaluator.py line 167 288342] Test: [785/1505] Loss 0.7553 
[2025-05-11 13:39:45,669 INFO evaluator.py line 167 288342] Test: [786/1505] Loss 0.6049 
[2025-05-11 13:39:45,808 INFO evaluator.py line 167 288342] Test: [787/1505] Loss 0.8877 
[2025-05-11 13:39:45,882 INFO evaluator.py line 167 288342] Test: [788/1505] Loss 0.6180 
[2025-05-11 13:39:46,053 INFO evaluator.py line 167 288342] Test: [789/1505] Loss 0.7635 
[2025-05-11 13:39:46,209 INFO evaluator.py line 167 288342] Test: [790/1505] Loss 1.2186 
[2025-05-11 13:39:46,383 INFO evaluator.py line 167 288342] Test: [791/1505] Loss 0.6581 
[2025-05-11 13:39:46,526 INFO evaluator.py line 167 288342] Test: [792/1505] Loss 0.8498 
[2025-05-11 13:39:46,665 INFO evaluator.py line 167 288342] Test: [793/1505] Loss 0.7039 
[2025-05-11 13:39:46,784 INFO evaluator.py line 167 288342] Test: [794/1505] Loss 0.8765 
[2025-05-11 13:39:46,935 INFO evaluator.py line 167 288342] Test: [795/1505] Loss 0.5538 
[2025-05-11 13:39:47,072 INFO evaluator.py line 167 288342] Test: [796/1505] Loss 0.7729 
[2025-05-11 13:39:47,192 INFO evaluator.py line 167 288342] Test: [797/1505] Loss 0.6942 
[2025-05-11 13:39:47,356 INFO evaluator.py line 167 288342] Test: [798/1505] Loss 0.6858 
[2025-05-11 13:39:47,575 INFO evaluator.py line 167 288342] Test: [799/1505] Loss 0.5300 
[2025-05-11 13:39:47,739 INFO evaluator.py line 167 288342] Test: [800/1505] Loss 1.0447 
[2025-05-11 13:39:47,907 INFO evaluator.py line 167 288342] Test: [801/1505] Loss 0.9435 
[2025-05-11 13:39:48,030 INFO evaluator.py line 167 288342] Test: [802/1505] Loss 0.8200 
[2025-05-11 13:39:48,196 INFO evaluator.py line 167 288342] Test: [803/1505] Loss 1.2763 
[2025-05-11 13:39:48,345 INFO evaluator.py line 167 288342] Test: [804/1505] Loss 0.7214 
[2025-05-11 13:39:48,521 INFO evaluator.py line 167 288342] Test: [805/1505] Loss 1.0677 
[2025-05-11 13:39:48,681 INFO evaluator.py line 167 288342] Test: [806/1505] Loss 1.1330 
[2025-05-11 13:39:48,828 INFO evaluator.py line 167 288342] Test: [807/1505] Loss 0.8479 
[2025-05-11 13:39:48,963 INFO evaluator.py line 167 288342] Test: [808/1505] Loss 0.7626 
[2025-05-11 13:39:49,130 INFO evaluator.py line 167 288342] Test: [809/1505] Loss 0.6961 
[2025-05-11 13:39:49,271 INFO evaluator.py line 167 288342] Test: [810/1505] Loss 0.6965 
[2025-05-11 13:39:49,412 INFO evaluator.py line 167 288342] Test: [811/1505] Loss 0.9710 
[2025-05-11 13:39:49,558 INFO evaluator.py line 167 288342] Test: [812/1505] Loss 0.8286 
[2025-05-11 13:39:49,712 INFO evaluator.py line 167 288342] Test: [813/1505] Loss 0.6929 
[2025-05-11 13:39:49,876 INFO evaluator.py line 167 288342] Test: [814/1505] Loss 0.9128 
[2025-05-11 13:39:50,013 INFO evaluator.py line 167 288342] Test: [815/1505] Loss 0.6345 
[2025-05-11 13:39:50,186 INFO evaluator.py line 167 288342] Test: [816/1505] Loss 0.9356 
[2025-05-11 13:39:50,361 INFO evaluator.py line 167 288342] Test: [817/1505] Loss 0.6212 
[2025-05-11 13:39:50,536 INFO evaluator.py line 167 288342] Test: [818/1505] Loss 0.7002 
[2025-05-11 13:39:50,750 INFO evaluator.py line 167 288342] Test: [819/1505] Loss 0.9975 
[2025-05-11 13:39:50,886 INFO evaluator.py line 167 288342] Test: [820/1505] Loss 0.6483 
[2025-05-11 13:39:51,004 INFO evaluator.py line 167 288342] Test: [821/1505] Loss 0.6651 
[2025-05-11 13:39:51,165 INFO evaluator.py line 167 288342] Test: [822/1505] Loss 0.8825 
[2025-05-11 13:39:51,316 INFO evaluator.py line 167 288342] Test: [823/1505] Loss 1.1077 
[2025-05-11 13:39:51,464 INFO evaluator.py line 167 288342] Test: [824/1505] Loss 0.8795 
[2025-05-11 13:39:51,622 INFO evaluator.py line 167 288342] Test: [825/1505] Loss 0.7511 
[2025-05-11 13:39:51,766 INFO evaluator.py line 167 288342] Test: [826/1505] Loss 0.7406 
[2025-05-11 13:39:51,896 INFO evaluator.py line 167 288342] Test: [827/1505] Loss 0.8562 
[2025-05-11 13:39:52,082 INFO evaluator.py line 167 288342] Test: [828/1505] Loss 0.9086 
[2025-05-11 13:39:52,211 INFO evaluator.py line 167 288342] Test: [829/1505] Loss 1.0229 
[2025-05-11 13:39:52,377 INFO evaluator.py line 167 288342] Test: [830/1505] Loss 0.9625 
[2025-05-11 13:39:52,530 INFO evaluator.py line 167 288342] Test: [831/1505] Loss 0.4702 
[2025-05-11 13:39:52,645 INFO evaluator.py line 167 288342] Test: [832/1505] Loss 0.9729 
[2025-05-11 13:39:52,801 INFO evaluator.py line 167 288342] Test: [833/1505] Loss 1.1283 
[2025-05-11 13:39:52,930 INFO evaluator.py line 167 288342] Test: [834/1505] Loss 0.6771 
[2025-05-11 13:39:53,072 INFO evaluator.py line 167 288342] Test: [835/1505] Loss 0.3697 
[2025-05-11 13:39:53,231 INFO evaluator.py line 167 288342] Test: [836/1505] Loss 0.5090 
[2025-05-11 13:39:53,379 INFO evaluator.py line 167 288342] Test: [837/1505] Loss 0.7980 
[2025-05-11 13:39:53,561 INFO evaluator.py line 167 288342] Test: [838/1505] Loss 0.5820 
[2025-05-11 13:39:53,694 INFO evaluator.py line 167 288342] Test: [839/1505] Loss 0.7495 
[2025-05-11 13:39:53,863 INFO evaluator.py line 167 288342] Test: [840/1505] Loss 0.5522 
[2025-05-11 13:39:54,024 INFO evaluator.py line 167 288342] Test: [841/1505] Loss 0.5726 
[2025-05-11 13:39:54,160 INFO evaluator.py line 167 288342] Test: [842/1505] Loss 0.7628 
[2025-05-11 13:39:54,312 INFO evaluator.py line 167 288342] Test: [843/1505] Loss 0.6300 
[2025-05-11 13:39:54,487 INFO evaluator.py line 167 288342] Test: [844/1505] Loss 1.3198 
[2025-05-11 13:39:54,608 INFO evaluator.py line 167 288342] Test: [845/1505] Loss 0.6497 
[2025-05-11 13:39:54,779 INFO evaluator.py line 167 288342] Test: [846/1505] Loss 0.7966 
[2025-05-11 13:39:54,934 INFO evaluator.py line 167 288342] Test: [847/1505] Loss 0.8613 
[2025-05-11 13:39:55,101 INFO evaluator.py line 167 288342] Test: [848/1505] Loss 0.9516 
[2025-05-11 13:39:55,279 INFO evaluator.py line 167 288342] Test: [849/1505] Loss 0.7111 
[2025-05-11 13:39:55,440 INFO evaluator.py line 167 288342] Test: [850/1505] Loss 0.7443 
[2025-05-11 13:39:55,551 INFO evaluator.py line 167 288342] Test: [851/1505] Loss 1.0575 
[2025-05-11 13:39:55,692 INFO evaluator.py line 167 288342] Test: [852/1505] Loss 0.8296 
[2025-05-11 13:39:55,831 INFO evaluator.py line 167 288342] Test: [853/1505] Loss 0.7259 
[2025-05-11 13:39:55,959 INFO evaluator.py line 167 288342] Test: [854/1505] Loss 1.0768 
[2025-05-11 13:39:56,106 INFO evaluator.py line 167 288342] Test: [855/1505] Loss 0.8365 
[2025-05-11 13:39:56,222 INFO evaluator.py line 167 288342] Test: [856/1505] Loss 1.3424 
[2025-05-11 13:39:56,349 INFO evaluator.py line 167 288342] Test: [857/1505] Loss 0.7835 
[2025-05-11 13:39:56,526 INFO evaluator.py line 167 288342] Test: [858/1505] Loss 0.7351 
[2025-05-11 13:39:56,698 INFO evaluator.py line 167 288342] Test: [859/1505] Loss 0.6139 
[2025-05-11 13:39:56,883 INFO evaluator.py line 167 288342] Test: [860/1505] Loss 1.1062 
[2025-05-11 13:39:57,081 INFO evaluator.py line 167 288342] Test: [861/1505] Loss 0.5755 
[2025-05-11 13:39:57,195 INFO evaluator.py line 167 288342] Test: [862/1505] Loss 0.7362 
[2025-05-11 13:39:57,344 INFO evaluator.py line 167 288342] Test: [863/1505] Loss 1.3781 
[2025-05-11 13:39:57,487 INFO evaluator.py line 167 288342] Test: [864/1505] Loss 0.9122 
[2025-05-11 13:39:57,635 INFO evaluator.py line 167 288342] Test: [865/1505] Loss 0.5017 
[2025-05-11 13:39:57,762 INFO evaluator.py line 167 288342] Test: [866/1505] Loss 0.5907 
[2025-05-11 13:39:57,896 INFO evaluator.py line 167 288342] Test: [867/1505] Loss 0.6843 
[2025-05-11 13:39:58,060 INFO evaluator.py line 167 288342] Test: [868/1505] Loss 0.7425 
[2025-05-11 13:39:58,188 INFO evaluator.py line 167 288342] Test: [869/1505] Loss 1.2795 
[2025-05-11 13:39:58,366 INFO evaluator.py line 167 288342] Test: [870/1505] Loss 0.6758 
[2025-05-11 13:39:58,504 INFO evaluator.py line 167 288342] Test: [871/1505] Loss 0.9025 
[2025-05-11 13:39:58,678 INFO evaluator.py line 167 288342] Test: [872/1505] Loss 0.7523 
[2025-05-11 13:39:58,825 INFO evaluator.py line 167 288342] Test: [873/1505] Loss 0.9689 
[2025-05-11 13:39:58,980 INFO evaluator.py line 167 288342] Test: [874/1505] Loss 0.8825 
[2025-05-11 13:39:59,137 INFO evaluator.py line 167 288342] Test: [875/1505] Loss 1.1278 
[2025-05-11 13:39:59,277 INFO evaluator.py line 167 288342] Test: [876/1505] Loss 0.9241 
[2025-05-11 13:39:59,423 INFO evaluator.py line 167 288342] Test: [877/1505] Loss 1.3977 
[2025-05-11 13:39:59,559 INFO evaluator.py line 167 288342] Test: [878/1505] Loss 0.5501 
[2025-05-11 13:39:59,709 INFO evaluator.py line 167 288342] Test: [879/1505] Loss 0.4647 
[2025-05-11 13:39:59,904 INFO evaluator.py line 167 288342] Test: [880/1505] Loss 0.6748 
[2025-05-11 13:40:00,060 INFO evaluator.py line 167 288342] Test: [881/1505] Loss 0.7480 
[2025-05-11 13:40:00,198 INFO evaluator.py line 167 288342] Test: [882/1505] Loss 1.7668 
[2025-05-11 13:40:00,334 INFO evaluator.py line 167 288342] Test: [883/1505] Loss 1.1843 
[2025-05-11 13:40:00,481 INFO evaluator.py line 167 288342] Test: [884/1505] Loss 0.9048 
[2025-05-11 13:40:00,615 INFO evaluator.py line 167 288342] Test: [885/1505] Loss 0.8390 
[2025-05-11 13:40:00,775 INFO evaluator.py line 167 288342] Test: [886/1505] Loss 1.1535 
[2025-05-11 13:40:00,899 INFO evaluator.py line 167 288342] Test: [887/1505] Loss 0.6045 
[2025-05-11 13:40:01,096 INFO evaluator.py line 167 288342] Test: [888/1505] Loss 0.8366 
[2025-05-11 13:40:01,238 INFO evaluator.py line 167 288342] Test: [889/1505] Loss 0.4210 
[2025-05-11 13:40:01,368 INFO evaluator.py line 167 288342] Test: [890/1505] Loss 0.9567 
[2025-05-11 13:40:01,515 INFO evaluator.py line 167 288342] Test: [891/1505] Loss 0.7089 
[2025-05-11 13:40:01,634 INFO evaluator.py line 167 288342] Test: [892/1505] Loss 1.1322 
[2025-05-11 13:40:01,793 INFO evaluator.py line 167 288342] Test: [893/1505] Loss 0.9831 
[2025-05-11 13:40:01,900 INFO evaluator.py line 167 288342] Test: [894/1505] Loss 0.8398 
[2025-05-11 13:40:02,037 INFO evaluator.py line 167 288342] Test: [895/1505] Loss 0.7882 
[2025-05-11 13:40:02,183 INFO evaluator.py line 167 288342] Test: [896/1505] Loss 0.7622 
[2025-05-11 13:40:02,328 INFO evaluator.py line 167 288342] Test: [897/1505] Loss 1.4941 
[2025-05-11 13:40:02,488 INFO evaluator.py line 167 288342] Test: [898/1505] Loss 0.7153 
[2025-05-11 13:40:02,663 INFO evaluator.py line 167 288342] Test: [899/1505] Loss 0.6017 
[2025-05-11 13:40:02,850 INFO evaluator.py line 167 288342] Test: [900/1505] Loss 0.8972 
[2025-05-11 13:40:03,004 INFO evaluator.py line 167 288342] Test: [901/1505] Loss 0.8441 
[2025-05-11 13:40:03,135 INFO evaluator.py line 167 288342] Test: [902/1505] Loss 0.8789 
[2025-05-11 13:40:03,315 INFO evaluator.py line 167 288342] Test: [903/1505] Loss 0.5851 
[2025-05-11 13:40:03,471 INFO evaluator.py line 167 288342] Test: [904/1505] Loss 0.7365 
[2025-05-11 13:40:03,622 INFO evaluator.py line 167 288342] Test: [905/1505] Loss 1.5676 
[2025-05-11 13:40:03,759 INFO evaluator.py line 167 288342] Test: [906/1505] Loss 0.5080 
[2025-05-11 13:40:03,936 INFO evaluator.py line 167 288342] Test: [907/1505] Loss 0.7419 
[2025-05-11 13:40:04,066 INFO evaluator.py line 167 288342] Test: [908/1505] Loss 0.9073 
[2025-05-11 13:40:04,188 INFO evaluator.py line 167 288342] Test: [909/1505] Loss 0.6411 
[2025-05-11 13:40:04,364 INFO evaluator.py line 167 288342] Test: [910/1505] Loss 0.7980 
[2025-05-11 13:40:04,502 INFO evaluator.py line 167 288342] Test: [911/1505] Loss 0.4901 
[2025-05-11 13:40:04,643 INFO evaluator.py line 167 288342] Test: [912/1505] Loss 0.7325 
[2025-05-11 13:40:04,825 INFO evaluator.py line 167 288342] Test: [913/1505] Loss 1.0578 
[2025-05-11 13:40:04,995 INFO evaluator.py line 167 288342] Test: [914/1505] Loss 1.1245 
[2025-05-11 13:40:05,150 INFO evaluator.py line 167 288342] Test: [915/1505] Loss 0.8228 
[2025-05-11 13:40:05,290 INFO evaluator.py line 167 288342] Test: [916/1505] Loss 0.9152 
[2025-05-11 13:40:05,425 INFO evaluator.py line 167 288342] Test: [917/1505] Loss 1.0927 
[2025-05-11 13:40:05,578 INFO evaluator.py line 167 288342] Test: [918/1505] Loss 0.7203 
[2025-05-11 13:40:05,739 INFO evaluator.py line 167 288342] Test: [919/1505] Loss 0.8094 
[2025-05-11 13:40:05,864 INFO evaluator.py line 167 288342] Test: [920/1505] Loss 0.8844 
[2025-05-11 13:40:06,033 INFO evaluator.py line 167 288342] Test: [921/1505] Loss 0.5640 
[2025-05-11 13:40:06,201 INFO evaluator.py line 167 288342] Test: [922/1505] Loss 0.7243 
[2025-05-11 13:40:06,330 INFO evaluator.py line 167 288342] Test: [923/1505] Loss 0.6826 
[2025-05-11 13:40:06,490 INFO evaluator.py line 167 288342] Test: [924/1505] Loss 1.4365 
[2025-05-11 13:40:06,618 INFO evaluator.py line 167 288342] Test: [925/1505] Loss 0.6508 
[2025-05-11 13:40:06,782 INFO evaluator.py line 167 288342] Test: [926/1505] Loss 0.6199 
[2025-05-11 13:40:06,910 INFO evaluator.py line 167 288342] Test: [927/1505] Loss 0.7404 
[2025-05-11 13:40:07,055 INFO evaluator.py line 167 288342] Test: [928/1505] Loss 0.6521 
[2025-05-11 13:40:07,210 INFO evaluator.py line 167 288342] Test: [929/1505] Loss 0.6692 
[2025-05-11 13:40:07,354 INFO evaluator.py line 167 288342] Test: [930/1505] Loss 0.6545 
[2025-05-11 13:40:07,495 INFO evaluator.py line 167 288342] Test: [931/1505] Loss 1.1484 
[2025-05-11 13:40:07,636 INFO evaluator.py line 167 288342] Test: [932/1505] Loss 0.9702 
[2025-05-11 13:40:07,798 INFO evaluator.py line 167 288342] Test: [933/1505] Loss 1.2841 
[2025-05-11 13:40:07,948 INFO evaluator.py line 167 288342] Test: [934/1505] Loss 0.5562 
[2025-05-11 13:40:08,117 INFO evaluator.py line 167 288342] Test: [935/1505] Loss 0.6723 
[2025-05-11 13:40:08,250 INFO evaluator.py line 167 288342] Test: [936/1505] Loss 0.8983 
[2025-05-11 13:40:08,371 INFO evaluator.py line 167 288342] Test: [937/1505] Loss 0.8330 
[2025-05-11 13:40:08,522 INFO evaluator.py line 167 288342] Test: [938/1505] Loss 1.0578 
[2025-05-11 13:40:08,650 INFO evaluator.py line 167 288342] Test: [939/1505] Loss 0.7227 
[2025-05-11 13:40:08,826 INFO evaluator.py line 167 288342] Test: [940/1505] Loss 0.8239 
[2025-05-11 13:40:08,988 INFO evaluator.py line 167 288342] Test: [941/1505] Loss 0.6258 
[2025-05-11 13:40:09,127 INFO evaluator.py line 167 288342] Test: [942/1505] Loss 1.0227 
[2025-05-11 13:40:09,226 INFO evaluator.py line 167 288342] Test: [943/1505] Loss 0.6417 
[2025-05-11 13:40:09,395 INFO evaluator.py line 167 288342] Test: [944/1505] Loss 0.7698 
[2025-05-11 13:40:09,531 INFO evaluator.py line 167 288342] Test: [945/1505] Loss 0.8855 
[2025-05-11 13:40:09,670 INFO evaluator.py line 167 288342] Test: [946/1505] Loss 0.7549 
[2025-05-11 13:40:09,839 INFO evaluator.py line 167 288342] Test: [947/1505] Loss 1.0458 
[2025-05-11 13:40:10,012 INFO evaluator.py line 167 288342] Test: [948/1505] Loss 0.6955 
[2025-05-11 13:40:10,150 INFO evaluator.py line 167 288342] Test: [949/1505] Loss 0.6700 
[2025-05-11 13:40:10,309 INFO evaluator.py line 167 288342] Test: [950/1505] Loss 0.7228 
[2025-05-11 13:40:10,477 INFO evaluator.py line 167 288342] Test: [951/1505] Loss 0.7627 
[2025-05-11 13:40:10,647 INFO evaluator.py line 167 288342] Test: [952/1505] Loss 0.6528 
[2025-05-11 13:40:10,786 INFO evaluator.py line 167 288342] Test: [953/1505] Loss 0.6112 
[2025-05-11 13:40:10,954 INFO evaluator.py line 167 288342] Test: [954/1505] Loss 1.1323 
[2025-05-11 13:40:11,025 INFO evaluator.py line 167 288342] Test: [955/1505] Loss 1.2471 
[2025-05-11 13:40:11,168 INFO evaluator.py line 167 288342] Test: [956/1505] Loss 0.9304 
[2025-05-11 13:40:11,283 INFO evaluator.py line 167 288342] Test: [957/1505] Loss 0.6141 
[2025-05-11 13:40:11,420 INFO evaluator.py line 167 288342] Test: [958/1505] Loss 0.5386 
[2025-05-11 13:40:11,605 INFO evaluator.py line 167 288342] Test: [959/1505] Loss 0.5817 
[2025-05-11 13:40:11,783 INFO evaluator.py line 167 288342] Test: [960/1505] Loss 0.5249 
[2025-05-11 13:40:11,905 INFO evaluator.py line 167 288342] Test: [961/1505] Loss 0.7681 
[2025-05-11 13:40:12,040 INFO evaluator.py line 167 288342] Test: [962/1505] Loss 0.8466 
[2025-05-11 13:40:12,180 INFO evaluator.py line 167 288342] Test: [963/1505] Loss 0.8713 
[2025-05-11 13:40:12,321 INFO evaluator.py line 167 288342] Test: [964/1505] Loss 0.5917 
[2025-05-11 13:40:12,468 INFO evaluator.py line 167 288342] Test: [965/1505] Loss 0.5455 
[2025-05-11 13:40:12,650 INFO evaluator.py line 167 288342] Test: [966/1505] Loss 0.4608 
[2025-05-11 13:40:12,768 INFO evaluator.py line 167 288342] Test: [967/1505] Loss 0.8033 
[2025-05-11 13:40:12,904 INFO evaluator.py line 167 288342] Test: [968/1505] Loss 0.7736 
[2025-05-11 13:40:13,032 INFO evaluator.py line 167 288342] Test: [969/1505] Loss 0.9024 
[2025-05-11 13:40:13,207 INFO evaluator.py line 167 288342] Test: [970/1505] Loss 0.6405 
[2025-05-11 13:40:13,382 INFO evaluator.py line 167 288342] Test: [971/1505] Loss 0.6315 
[2025-05-11 13:40:13,530 INFO evaluator.py line 167 288342] Test: [972/1505] Loss 0.9727 
[2025-05-11 13:40:13,649 INFO evaluator.py line 167 288342] Test: [973/1505] Loss 0.6678 
[2025-05-11 13:40:13,795 INFO evaluator.py line 167 288342] Test: [974/1505] Loss 0.5112 
[2025-05-11 13:40:13,969 INFO evaluator.py line 167 288342] Test: [975/1505] Loss 0.8455 
[2025-05-11 13:40:14,117 INFO evaluator.py line 167 288342] Test: [976/1505] Loss 0.9137 
[2025-05-11 13:40:14,286 INFO evaluator.py line 167 288342] Test: [977/1505] Loss 0.5481 
[2025-05-11 13:40:14,451 INFO evaluator.py line 167 288342] Test: [978/1505] Loss 0.8052 
[2025-05-11 13:40:14,620 INFO evaluator.py line 167 288342] Test: [979/1505] Loss 0.8070 
[2025-05-11 13:40:14,797 INFO evaluator.py line 167 288342] Test: [980/1505] Loss 0.5557 
[2025-05-11 13:40:14,881 INFO evaluator.py line 167 288342] Test: [981/1505] Loss 1.0156 
[2025-05-11 13:40:15,008 INFO evaluator.py line 167 288342] Test: [982/1505] Loss 0.6586 
[2025-05-11 13:40:15,141 INFO evaluator.py line 167 288342] Test: [983/1505] Loss 0.7946 
[2025-05-11 13:40:15,294 INFO evaluator.py line 167 288342] Test: [984/1505] Loss 0.7592 
[2025-05-11 13:40:15,427 INFO evaluator.py line 167 288342] Test: [985/1505] Loss 0.6931 
[2025-05-11 13:40:15,616 INFO evaluator.py line 167 288342] Test: [986/1505] Loss 0.5642 
[2025-05-11 13:40:15,800 INFO evaluator.py line 167 288342] Test: [987/1505] Loss 0.5848 
[2025-05-11 13:40:15,946 INFO evaluator.py line 167 288342] Test: [988/1505] Loss 0.6710 
[2025-05-11 13:40:16,097 INFO evaluator.py line 167 288342] Test: [989/1505] Loss 1.0458 
[2025-05-11 13:40:16,237 INFO evaluator.py line 167 288342] Test: [990/1505] Loss 0.5052 
[2025-05-11 13:40:16,387 INFO evaluator.py line 167 288342] Test: [991/1505] Loss 0.7649 
[2025-05-11 13:40:16,554 INFO evaluator.py line 167 288342] Test: [992/1505] Loss 0.8337 
[2025-05-11 13:40:16,707 INFO evaluator.py line 167 288342] Test: [993/1505] Loss 0.4701 
[2025-05-11 13:40:16,857 INFO evaluator.py line 167 288342] Test: [994/1505] Loss 1.0188 
[2025-05-11 13:40:17,000 INFO evaluator.py line 167 288342] Test: [995/1505] Loss 0.7179 
[2025-05-11 13:40:17,187 INFO evaluator.py line 167 288342] Test: [996/1505] Loss 0.8102 
[2025-05-11 13:40:17,309 INFO evaluator.py line 167 288342] Test: [997/1505] Loss 0.6614 
[2025-05-11 13:40:17,485 INFO evaluator.py line 167 288342] Test: [998/1505] Loss 0.9066 
[2025-05-11 13:40:17,624 INFO evaluator.py line 167 288342] Test: [999/1505] Loss 0.6116 
[2025-05-11 13:40:17,781 INFO evaluator.py line 167 288342] Test: [1000/1505] Loss 0.8950 
[2025-05-11 13:40:17,907 INFO evaluator.py line 167 288342] Test: [1001/1505] Loss 0.6039 
[2025-05-11 13:40:18,013 INFO evaluator.py line 167 288342] Test: [1002/1505] Loss 0.5746 
[2025-05-11 13:40:18,142 INFO evaluator.py line 167 288342] Test: [1003/1505] Loss 0.7390 
[2025-05-11 13:40:18,334 INFO evaluator.py line 167 288342] Test: [1004/1505] Loss 0.9825 
[2025-05-11 13:40:18,496 INFO evaluator.py line 167 288342] Test: [1005/1505] Loss 0.7610 
[2025-05-11 13:40:18,654 INFO evaluator.py line 167 288342] Test: [1006/1505] Loss 0.7659 
[2025-05-11 13:40:18,812 INFO evaluator.py line 167 288342] Test: [1007/1505] Loss 0.7537 
[2025-05-11 13:40:18,962 INFO evaluator.py line 167 288342] Test: [1008/1505] Loss 1.0239 
[2025-05-11 13:40:19,088 INFO evaluator.py line 167 288342] Test: [1009/1505] Loss 0.9339 
[2025-05-11 13:40:19,274 INFO evaluator.py line 167 288342] Test: [1010/1505] Loss 0.9113 
[2025-05-11 13:40:19,459 INFO evaluator.py line 167 288342] Test: [1011/1505] Loss 0.6506 
[2025-05-11 13:40:19,612 INFO evaluator.py line 167 288342] Test: [1012/1505] Loss 0.9624 
[2025-05-11 13:40:19,747 INFO evaluator.py line 167 288342] Test: [1013/1505] Loss 0.8481 
[2025-05-11 13:40:19,899 INFO evaluator.py line 167 288342] Test: [1014/1505] Loss 0.7991 
[2025-05-11 13:40:20,030 INFO evaluator.py line 167 288342] Test: [1015/1505] Loss 0.6635 
[2025-05-11 13:40:20,198 INFO evaluator.py line 167 288342] Test: [1016/1505] Loss 0.5362 
[2025-05-11 13:40:20,346 INFO evaluator.py line 167 288342] Test: [1017/1505] Loss 0.7874 
[2025-05-11 13:40:20,537 INFO evaluator.py line 167 288342] Test: [1018/1505] Loss 0.6222 
[2025-05-11 13:40:20,711 INFO evaluator.py line 167 288342] Test: [1019/1505] Loss 0.7213 
[2025-05-11 13:40:20,842 INFO evaluator.py line 167 288342] Test: [1020/1505] Loss 1.0690 
[2025-05-11 13:40:20,962 INFO evaluator.py line 167 288342] Test: [1021/1505] Loss 0.5872 
[2025-05-11 13:40:21,077 INFO evaluator.py line 167 288342] Test: [1022/1505] Loss 0.7480 
[2025-05-11 13:40:21,204 INFO evaluator.py line 167 288342] Test: [1023/1505] Loss 0.7295 
[2025-05-11 13:40:21,317 INFO evaluator.py line 167 288342] Test: [1024/1505] Loss 0.8439 
[2025-05-11 13:40:21,474 INFO evaluator.py line 167 288342] Test: [1025/1505] Loss 0.8407 
[2025-05-11 13:40:21,618 INFO evaluator.py line 167 288342] Test: [1026/1505] Loss 0.8213 
[2025-05-11 13:40:21,800 INFO evaluator.py line 167 288342] Test: [1027/1505] Loss 0.6888 
[2025-05-11 13:40:21,933 INFO evaluator.py line 167 288342] Test: [1028/1505] Loss 0.8014 
[2025-05-11 13:40:22,061 INFO evaluator.py line 167 288342] Test: [1029/1505] Loss 0.5531 
[2025-05-11 13:40:22,216 INFO evaluator.py line 167 288342] Test: [1030/1505] Loss 0.7834 
[2025-05-11 13:40:22,369 INFO evaluator.py line 167 288342] Test: [1031/1505] Loss 0.8106 
[2025-05-11 13:40:22,494 INFO evaluator.py line 167 288342] Test: [1032/1505] Loss 0.6202 
[2025-05-11 13:40:22,661 INFO evaluator.py line 167 288342] Test: [1033/1505] Loss 1.6214 
[2025-05-11 13:40:22,809 INFO evaluator.py line 167 288342] Test: [1034/1505] Loss 1.0629 
[2025-05-11 13:40:22,953 INFO evaluator.py line 167 288342] Test: [1035/1505] Loss 0.6389 
[2025-05-11 13:40:23,113 INFO evaluator.py line 167 288342] Test: [1036/1505] Loss 0.8167 
[2025-05-11 13:40:23,253 INFO evaluator.py line 167 288342] Test: [1037/1505] Loss 0.5163 
[2025-05-11 13:40:23,397 INFO evaluator.py line 167 288342] Test: [1038/1505] Loss 0.6189 
[2025-05-11 13:40:23,579 INFO evaluator.py line 167 288342] Test: [1039/1505] Loss 0.8186 
[2025-05-11 13:40:23,738 INFO evaluator.py line 167 288342] Test: [1040/1505] Loss 0.6182 
[2025-05-11 13:40:23,864 INFO evaluator.py line 167 288342] Test: [1041/1505] Loss 0.8273 
[2025-05-11 13:40:24,030 INFO evaluator.py line 167 288342] Test: [1042/1505] Loss 0.7664 
[2025-05-11 13:40:24,188 INFO evaluator.py line 167 288342] Test: [1043/1505] Loss 1.1061 
[2025-05-11 13:40:24,344 INFO evaluator.py line 167 288342] Test: [1044/1505] Loss 0.5020 
[2025-05-11 13:40:24,512 INFO evaluator.py line 167 288342] Test: [1045/1505] Loss 0.6183 
[2025-05-11 13:40:24,631 INFO evaluator.py line 167 288342] Test: [1046/1505] Loss 0.9069 
[2025-05-11 13:40:24,818 INFO evaluator.py line 167 288342] Test: [1047/1505] Loss 0.7996 
[2025-05-11 13:40:24,936 INFO evaluator.py line 167 288342] Test: [1048/1505] Loss 0.5871 
[2025-05-11 13:40:25,067 INFO evaluator.py line 167 288342] Test: [1049/1505] Loss 0.8525 
[2025-05-11 13:40:25,207 INFO evaluator.py line 167 288342] Test: [1050/1505] Loss 0.9021 
[2025-05-11 13:40:25,390 INFO evaluator.py line 167 288342] Test: [1051/1505] Loss 0.6139 
[2025-05-11 13:40:25,578 INFO evaluator.py line 167 288342] Test: [1052/1505] Loss 0.4888 
[2025-05-11 13:40:25,742 INFO evaluator.py line 167 288342] Test: [1053/1505] Loss 0.7705 
[2025-05-11 13:40:25,910 INFO evaluator.py line 167 288342] Test: [1054/1505] Loss 0.7796 
[2025-05-11 13:40:26,078 INFO evaluator.py line 167 288342] Test: [1055/1505] Loss 1.0985 
[2025-05-11 13:40:26,252 INFO evaluator.py line 167 288342] Test: [1056/1505] Loss 0.6698 
[2025-05-11 13:40:26,380 INFO evaluator.py line 167 288342] Test: [1057/1505] Loss 1.0972 
[2025-05-11 13:40:26,536 INFO evaluator.py line 167 288342] Test: [1058/1505] Loss 0.7624 
[2025-05-11 13:40:26,682 INFO evaluator.py line 167 288342] Test: [1059/1505] Loss 0.6501 
[2025-05-11 13:40:26,848 INFO evaluator.py line 167 288342] Test: [1060/1505] Loss 0.6059 
[2025-05-11 13:40:26,993 INFO evaluator.py line 167 288342] Test: [1061/1505] Loss 0.6371 
[2025-05-11 13:40:27,138 INFO evaluator.py line 167 288342] Test: [1062/1505] Loss 0.7778 
[2025-05-11 13:40:27,312 INFO evaluator.py line 167 288342] Test: [1063/1505] Loss 0.9312 
[2025-05-11 13:40:27,457 INFO evaluator.py line 167 288342] Test: [1064/1505] Loss 0.8527 
[2025-05-11 13:40:27,592 INFO evaluator.py line 167 288342] Test: [1065/1505] Loss 0.8266 
[2025-05-11 13:40:27,758 INFO evaluator.py line 167 288342] Test: [1066/1505] Loss 1.1595 
[2025-05-11 13:40:27,926 INFO evaluator.py line 167 288342] Test: [1067/1505] Loss 1.2571 
[2025-05-11 13:40:28,065 INFO evaluator.py line 167 288342] Test: [1068/1505] Loss 0.5593 
[2025-05-11 13:40:28,231 INFO evaluator.py line 167 288342] Test: [1069/1505] Loss 0.9769 
[2025-05-11 13:40:28,360 INFO evaluator.py line 167 288342] Test: [1070/1505] Loss 0.7804 
[2025-05-11 13:40:28,510 INFO evaluator.py line 167 288342] Test: [1071/1505] Loss 0.8352 
[2025-05-11 13:40:28,681 INFO evaluator.py line 167 288342] Test: [1072/1505] Loss 1.0460 
[2025-05-11 13:40:28,869 INFO evaluator.py line 167 288342] Test: [1073/1505] Loss 0.6106 
[2025-05-11 13:40:28,991 INFO evaluator.py line 167 288342] Test: [1074/1505] Loss 0.8043 
[2025-05-11 13:40:29,099 INFO evaluator.py line 167 288342] Test: [1075/1505] Loss 0.9009 
[2025-05-11 13:40:29,242 INFO evaluator.py line 167 288342] Test: [1076/1505] Loss 0.6061 
[2025-05-11 13:40:29,381 INFO evaluator.py line 167 288342] Test: [1077/1505] Loss 0.6788 
[2025-05-11 13:40:29,539 INFO evaluator.py line 167 288342] Test: [1078/1505] Loss 0.8671 
[2025-05-11 13:40:29,734 INFO evaluator.py line 167 288342] Test: [1079/1505] Loss 1.2030 
[2025-05-11 13:40:29,901 INFO evaluator.py line 167 288342] Test: [1080/1505] Loss 0.7944 
[2025-05-11 13:40:30,031 INFO evaluator.py line 167 288342] Test: [1081/1505] Loss 0.5872 
[2025-05-11 13:40:30,171 INFO evaluator.py line 167 288342] Test: [1082/1505] Loss 1.6063 
[2025-05-11 13:40:30,333 INFO evaluator.py line 167 288342] Test: [1083/1505] Loss 1.1384 
[2025-05-11 13:40:30,453 INFO evaluator.py line 167 288342] Test: [1084/1505] Loss 0.7747 
[2025-05-11 13:40:30,565 INFO evaluator.py line 167 288342] Test: [1085/1505] Loss 0.5846 
[2025-05-11 13:40:30,675 INFO evaluator.py line 167 288342] Test: [1086/1505] Loss 0.8560 
[2025-05-11 13:40:30,838 INFO evaluator.py line 167 288342] Test: [1087/1505] Loss 0.7154 
[2025-05-11 13:40:30,989 INFO evaluator.py line 167 288342] Test: [1088/1505] Loss 0.7195 
[2025-05-11 13:40:31,157 INFO evaluator.py line 167 288342] Test: [1089/1505] Loss 0.7998 
[2025-05-11 13:40:31,271 INFO evaluator.py line 167 288342] Test: [1090/1505] Loss 0.7839 
[2025-05-11 13:40:31,426 INFO evaluator.py line 167 288342] Test: [1091/1505] Loss 0.9192 
[2025-05-11 13:40:31,582 INFO evaluator.py line 167 288342] Test: [1092/1505] Loss 1.1601 
[2025-05-11 13:40:31,777 INFO evaluator.py line 167 288342] Test: [1093/1505] Loss 0.8071 
[2025-05-11 13:40:31,914 INFO evaluator.py line 167 288342] Test: [1094/1505] Loss 0.5368 
[2025-05-11 13:40:32,110 INFO evaluator.py line 167 288342] Test: [1095/1505] Loss 1.1420 
[2025-05-11 13:40:32,286 INFO evaluator.py line 167 288342] Test: [1096/1505] Loss 1.2070 
[2025-05-11 13:40:32,456 INFO evaluator.py line 167 288342] Test: [1097/1505] Loss 0.5850 
[2025-05-11 13:40:32,596 INFO evaluator.py line 167 288342] Test: [1098/1505] Loss 0.7892 
[2025-05-11 13:40:32,733 INFO evaluator.py line 167 288342] Test: [1099/1505] Loss 0.9962 
[2025-05-11 13:40:32,882 INFO evaluator.py line 167 288342] Test: [1100/1505] Loss 0.6857 
[2025-05-11 13:40:33,036 INFO evaluator.py line 167 288342] Test: [1101/1505] Loss 0.7587 
[2025-05-11 13:40:33,213 INFO evaluator.py line 167 288342] Test: [1102/1505] Loss 1.0100 
[2025-05-11 13:40:33,374 INFO evaluator.py line 167 288342] Test: [1103/1505] Loss 0.8758 
[2025-05-11 13:40:33,547 INFO evaluator.py line 167 288342] Test: [1104/1505] Loss 0.8204 
[2025-05-11 13:40:33,674 INFO evaluator.py line 167 288342] Test: [1105/1505] Loss 0.6641 
[2025-05-11 13:40:33,815 INFO evaluator.py line 167 288342] Test: [1106/1505] Loss 0.8627 
[2025-05-11 13:40:33,932 INFO evaluator.py line 167 288342] Test: [1107/1505] Loss 0.8241 
[2025-05-11 13:40:34,059 INFO evaluator.py line 167 288342] Test: [1108/1505] Loss 0.8808 
[2025-05-11 13:40:34,208 INFO evaluator.py line 167 288342] Test: [1109/1505] Loss 0.7277 
[2025-05-11 13:40:34,368 INFO evaluator.py line 167 288342] Test: [1110/1505] Loss 0.9019 
[2025-05-11 13:40:34,506 INFO evaluator.py line 167 288342] Test: [1111/1505] Loss 0.7602 
[2025-05-11 13:40:34,665 INFO evaluator.py line 167 288342] Test: [1112/1505] Loss 0.4814 
[2025-05-11 13:40:34,778 INFO evaluator.py line 167 288342] Test: [1113/1505] Loss 1.6384 
[2025-05-11 13:40:34,940 INFO evaluator.py line 167 288342] Test: [1114/1505] Loss 0.7987 
[2025-05-11 13:40:35,080 INFO evaluator.py line 167 288342] Test: [1115/1505] Loss 0.5703 
[2025-05-11 13:40:35,221 INFO evaluator.py line 167 288342] Test: [1116/1505] Loss 0.8305 
[2025-05-11 13:40:35,328 INFO evaluator.py line 167 288342] Test: [1117/1505] Loss 1.0024 
[2025-05-11 13:40:35,459 INFO evaluator.py line 167 288342] Test: [1118/1505] Loss 0.6028 
[2025-05-11 13:40:35,627 INFO evaluator.py line 167 288342] Test: [1119/1505] Loss 0.8026 
[2025-05-11 13:40:35,779 INFO evaluator.py line 167 288342] Test: [1120/1505] Loss 0.6760 
[2025-05-11 13:40:35,946 INFO evaluator.py line 167 288342] Test: [1121/1505] Loss 0.5255 
[2025-05-11 13:40:36,071 INFO evaluator.py line 167 288342] Test: [1122/1505] Loss 0.7604 
[2025-05-11 13:40:36,208 INFO evaluator.py line 167 288342] Test: [1123/1505] Loss 0.3999 
[2025-05-11 13:40:36,322 INFO evaluator.py line 167 288342] Test: [1124/1505] Loss 1.0514 
[2025-05-11 13:40:36,491 INFO evaluator.py line 167 288342] Test: [1125/1505] Loss 0.7760 
[2025-05-11 13:40:36,653 INFO evaluator.py line 167 288342] Test: [1126/1505] Loss 1.0120 
[2025-05-11 13:40:36,778 INFO evaluator.py line 167 288342] Test: [1127/1505] Loss 0.7160 
[2025-05-11 13:40:36,936 INFO evaluator.py line 167 288342] Test: [1128/1505] Loss 0.6860 
[2025-05-11 13:40:37,018 INFO evaluator.py line 167 288342] Test: [1129/1505] Loss 0.9741 
[2025-05-11 13:40:37,155 INFO evaluator.py line 167 288342] Test: [1130/1505] Loss 0.8920 
[2025-05-11 13:40:37,282 INFO evaluator.py line 167 288342] Test: [1131/1505] Loss 0.8887 
[2025-05-11 13:40:37,444 INFO evaluator.py line 167 288342] Test: [1132/1505] Loss 0.8537 
[2025-05-11 13:40:37,585 INFO evaluator.py line 167 288342] Test: [1133/1505] Loss 0.7253 
[2025-05-11 13:40:37,740 INFO evaluator.py line 167 288342] Test: [1134/1505] Loss 0.7905 
[2025-05-11 13:40:37,865 INFO evaluator.py line 167 288342] Test: [1135/1505] Loss 0.3578 
[2025-05-11 13:40:38,008 INFO evaluator.py line 167 288342] Test: [1136/1505] Loss 0.7495 
[2025-05-11 13:40:38,135 INFO evaluator.py line 167 288342] Test: [1137/1505] Loss 0.9478 
[2025-05-11 13:40:38,273 INFO evaluator.py line 167 288342] Test: [1138/1505] Loss 0.6134 
[2025-05-11 13:40:38,439 INFO evaluator.py line 167 288342] Test: [1139/1505] Loss 0.7539 
[2025-05-11 13:40:38,593 INFO evaluator.py line 167 288342] Test: [1140/1505] Loss 0.6339 
[2025-05-11 13:40:38,754 INFO evaluator.py line 167 288342] Test: [1141/1505] Loss 0.6542 
[2025-05-11 13:40:38,926 INFO evaluator.py line 167 288342] Test: [1142/1505] Loss 0.9856 
[2025-05-11 13:40:39,064 INFO evaluator.py line 167 288342] Test: [1143/1505] Loss 0.5378 
[2025-05-11 13:40:39,219 INFO evaluator.py line 167 288342] Test: [1144/1505] Loss 0.5600 
[2025-05-11 13:40:39,396 INFO evaluator.py line 167 288342] Test: [1145/1505] Loss 1.1337 
[2025-05-11 13:40:39,586 INFO evaluator.py line 167 288342] Test: [1146/1505] Loss 0.7432 
[2025-05-11 13:40:39,721 INFO evaluator.py line 167 288342] Test: [1147/1505] Loss 0.8774 
[2025-05-11 13:40:39,865 INFO evaluator.py line 167 288342] Test: [1148/1505] Loss 0.5304 
[2025-05-11 13:40:39,987 INFO evaluator.py line 167 288342] Test: [1149/1505] Loss 0.7322 
[2025-05-11 13:40:40,125 INFO evaluator.py line 167 288342] Test: [1150/1505] Loss 1.2961 
[2025-05-11 13:40:40,274 INFO evaluator.py line 167 288342] Test: [1151/1505] Loss 0.6672 
[2025-05-11 13:40:40,411 INFO evaluator.py line 167 288342] Test: [1152/1505] Loss 0.7591 
[2025-05-11 13:40:40,561 INFO evaluator.py line 167 288342] Test: [1153/1505] Loss 0.8491 
[2025-05-11 13:40:40,719 INFO evaluator.py line 167 288342] Test: [1154/1505] Loss 0.6775 
[2025-05-11 13:40:40,836 INFO evaluator.py line 167 288342] Test: [1155/1505] Loss 0.8360 
[2025-05-11 13:40:40,947 INFO evaluator.py line 167 288342] Test: [1156/1505] Loss 0.9428 
[2025-05-11 13:40:41,131 INFO evaluator.py line 167 288342] Test: [1157/1505] Loss 0.5976 
[2025-05-11 13:40:41,223 INFO evaluator.py line 167 288342] Test: [1158/1505] Loss 0.7395 
[2025-05-11 13:40:41,370 INFO evaluator.py line 167 288342] Test: [1159/1505] Loss 0.8322 
[2025-05-11 13:40:41,507 INFO evaluator.py line 167 288342] Test: [1160/1505] Loss 0.5245 
[2025-05-11 13:40:41,681 INFO evaluator.py line 167 288342] Test: [1161/1505] Loss 0.7877 
[2025-05-11 13:40:41,818 INFO evaluator.py line 167 288342] Test: [1162/1505] Loss 0.6894 
[2025-05-11 13:40:42,024 INFO evaluator.py line 167 288342] Test: [1163/1505] Loss 1.0360 
[2025-05-11 13:40:42,191 INFO evaluator.py line 167 288342] Test: [1164/1505] Loss 0.9898 
[2025-05-11 13:40:42,351 INFO evaluator.py line 167 288342] Test: [1165/1505] Loss 1.1520 
[2025-05-11 13:40:42,472 INFO evaluator.py line 167 288342] Test: [1166/1505] Loss 0.7532 
[2025-05-11 13:40:42,633 INFO evaluator.py line 167 288342] Test: [1167/1505] Loss 0.7119 
[2025-05-11 13:40:42,795 INFO evaluator.py line 167 288342] Test: [1168/1505] Loss 0.5838 
[2025-05-11 13:40:43,006 INFO evaluator.py line 167 288342] Test: [1169/1505] Loss 0.6308 
[2025-05-11 13:40:43,159 INFO evaluator.py line 167 288342] Test: [1170/1505] Loss 0.8349 
[2025-05-11 13:40:43,325 INFO evaluator.py line 167 288342] Test: [1171/1505] Loss 0.7480 
[2025-05-11 13:40:43,452 INFO evaluator.py line 167 288342] Test: [1172/1505] Loss 0.9226 
[2025-05-11 13:40:43,588 INFO evaluator.py line 167 288342] Test: [1173/1505] Loss 1.0176 
[2025-05-11 13:40:43,755 INFO evaluator.py line 167 288342] Test: [1174/1505] Loss 0.7731 
[2025-05-11 13:40:43,878 INFO evaluator.py line 167 288342] Test: [1175/1505] Loss 0.6947 
[2025-05-11 13:40:44,029 INFO evaluator.py line 167 288342] Test: [1176/1505] Loss 0.7054 
[2025-05-11 13:40:44,199 INFO evaluator.py line 167 288342] Test: [1177/1505] Loss 0.8045 
[2025-05-11 13:40:44,352 INFO evaluator.py line 167 288342] Test: [1178/1505] Loss 0.9060 
[2025-05-11 13:40:44,436 INFO evaluator.py line 167 288342] Test: [1179/1505] Loss 0.6265 
[2025-05-11 13:40:44,585 INFO evaluator.py line 167 288342] Test: [1180/1505] Loss 0.5247 
[2025-05-11 13:40:44,775 INFO evaluator.py line 167 288342] Test: [1181/1505] Loss 0.7246 
[2025-05-11 13:40:44,944 INFO evaluator.py line 167 288342] Test: [1182/1505] Loss 0.6134 
[2025-05-11 13:40:45,072 INFO evaluator.py line 167 288342] Test: [1183/1505] Loss 0.8510 
[2025-05-11 13:40:45,245 INFO evaluator.py line 167 288342] Test: [1184/1505] Loss 1.1049 
[2025-05-11 13:40:45,441 INFO evaluator.py line 167 288342] Test: [1185/1505] Loss 0.7862 
[2025-05-11 13:40:45,638 INFO evaluator.py line 167 288342] Test: [1186/1505] Loss 0.8947 
[2025-05-11 13:40:45,776 INFO evaluator.py line 167 288342] Test: [1187/1505] Loss 0.7807 
[2025-05-11 13:40:45,934 INFO evaluator.py line 167 288342] Test: [1188/1505] Loss 0.7061 
[2025-05-11 13:40:46,075 INFO evaluator.py line 167 288342] Test: [1189/1505] Loss 0.6031 
[2025-05-11 13:40:46,206 INFO evaluator.py line 167 288342] Test: [1190/1505] Loss 0.9389 
[2025-05-11 13:40:46,330 INFO evaluator.py line 167 288342] Test: [1191/1505] Loss 0.6401 
[2025-05-11 13:40:46,504 INFO evaluator.py line 167 288342] Test: [1192/1505] Loss 0.7296 
[2025-05-11 13:40:46,682 INFO evaluator.py line 167 288342] Test: [1193/1505] Loss 0.7328 
[2025-05-11 13:40:46,809 INFO evaluator.py line 167 288342] Test: [1194/1505] Loss 0.6867 
[2025-05-11 13:40:46,972 INFO evaluator.py line 167 288342] Test: [1195/1505] Loss 1.0411 
[2025-05-11 13:40:47,103 INFO evaluator.py line 167 288342] Test: [1196/1505] Loss 0.8700 
[2025-05-11 13:40:47,302 INFO evaluator.py line 167 288342] Test: [1197/1505] Loss 0.6025 
[2025-05-11 13:40:47,457 INFO evaluator.py line 167 288342] Test: [1198/1505] Loss 0.7947 
[2025-05-11 13:40:47,599 INFO evaluator.py line 167 288342] Test: [1199/1505] Loss 0.8347 
[2025-05-11 13:40:47,734 INFO evaluator.py line 167 288342] Test: [1200/1505] Loss 0.6224 
[2025-05-11 13:40:47,885 INFO evaluator.py line 167 288342] Test: [1201/1505] Loss 0.6963 
[2025-05-11 13:40:48,046 INFO evaluator.py line 167 288342] Test: [1202/1505] Loss 0.9764 
[2025-05-11 13:40:48,197 INFO evaluator.py line 167 288342] Test: [1203/1505] Loss 0.6231 
[2025-05-11 13:40:48,345 INFO evaluator.py line 167 288342] Test: [1204/1505] Loss 1.2320 
[2025-05-11 13:40:48,458 INFO evaluator.py line 167 288342] Test: [1205/1505] Loss 0.9090 
[2025-05-11 13:40:48,614 INFO evaluator.py line 167 288342] Test: [1206/1505] Loss 0.5393 
[2025-05-11 13:40:48,752 INFO evaluator.py line 167 288342] Test: [1207/1505] Loss 1.1186 
[2025-05-11 13:40:48,925 INFO evaluator.py line 167 288342] Test: [1208/1505] Loss 0.7073 
[2025-05-11 13:40:49,071 INFO evaluator.py line 167 288342] Test: [1209/1505] Loss 0.6825 
[2025-05-11 13:40:49,235 INFO evaluator.py line 167 288342] Test: [1210/1505] Loss 0.8693 
[2025-05-11 13:40:49,370 INFO evaluator.py line 167 288342] Test: [1211/1505] Loss 0.7053 
[2025-05-11 13:40:49,528 INFO evaluator.py line 167 288342] Test: [1212/1505] Loss 0.7367 
[2025-05-11 13:40:49,656 INFO evaluator.py line 167 288342] Test: [1213/1505] Loss 0.9107 
[2025-05-11 13:40:49,828 INFO evaluator.py line 167 288342] Test: [1214/1505] Loss 0.9882 
[2025-05-11 13:40:49,988 INFO evaluator.py line 167 288342] Test: [1215/1505] Loss 1.0122 
[2025-05-11 13:40:50,157 INFO evaluator.py line 167 288342] Test: [1216/1505] Loss 0.6525 
[2025-05-11 13:40:50,330 INFO evaluator.py line 167 288342] Test: [1217/1505] Loss 0.5757 
[2025-05-11 13:40:50,486 INFO evaluator.py line 167 288342] Test: [1218/1505] Loss 0.4400 
[2025-05-11 13:40:50,631 INFO evaluator.py line 167 288342] Test: [1219/1505] Loss 0.8230 
[2025-05-11 13:40:50,812 INFO evaluator.py line 167 288342] Test: [1220/1505] Loss 0.7121 
[2025-05-11 13:40:50,946 INFO evaluator.py line 167 288342] Test: [1221/1505] Loss 0.4866 
[2025-05-11 13:40:51,087 INFO evaluator.py line 167 288342] Test: [1222/1505] Loss 0.8645 
[2025-05-11 13:40:51,234 INFO evaluator.py line 167 288342] Test: [1223/1505] Loss 1.0532 
[2025-05-11 13:40:51,354 INFO evaluator.py line 167 288342] Test: [1224/1505] Loss 0.4097 
[2025-05-11 13:40:51,528 INFO evaluator.py line 167 288342] Test: [1225/1505] Loss 0.9172 
[2025-05-11 13:40:51,657 INFO evaluator.py line 167 288342] Test: [1226/1505] Loss 0.6415 
[2025-05-11 13:40:51,778 INFO evaluator.py line 167 288342] Test: [1227/1505] Loss 0.6744 
[2025-05-11 13:40:51,940 INFO evaluator.py line 167 288342] Test: [1228/1505] Loss 0.6694 
[2025-05-11 13:40:52,093 INFO evaluator.py line 167 288342] Test: [1229/1505] Loss 0.9090 
[2025-05-11 13:40:52,267 INFO evaluator.py line 167 288342] Test: [1230/1505] Loss 0.9897 
[2025-05-11 13:40:52,435 INFO evaluator.py line 167 288342] Test: [1231/1505] Loss 0.8785 
[2025-05-11 13:40:52,586 INFO evaluator.py line 167 288342] Test: [1232/1505] Loss 0.8877 
[2025-05-11 13:40:52,702 INFO evaluator.py line 167 288342] Test: [1233/1505] Loss 0.9849 
[2025-05-11 13:40:52,855 INFO evaluator.py line 167 288342] Test: [1234/1505] Loss 0.8298 
[2025-05-11 13:40:52,986 INFO evaluator.py line 167 288342] Test: [1235/1505] Loss 0.7924 
[2025-05-11 13:40:53,125 INFO evaluator.py line 167 288342] Test: [1236/1505] Loss 1.1819 
[2025-05-11 13:40:53,301 INFO evaluator.py line 167 288342] Test: [1237/1505] Loss 0.9575 
[2025-05-11 13:40:53,431 INFO evaluator.py line 167 288342] Test: [1238/1505] Loss 0.6243 
[2025-05-11 13:40:53,593 INFO evaluator.py line 167 288342] Test: [1239/1505] Loss 0.5623 
[2025-05-11 13:40:53,748 INFO evaluator.py line 167 288342] Test: [1240/1505] Loss 0.7650 
[2025-05-11 13:40:53,874 INFO evaluator.py line 167 288342] Test: [1241/1505] Loss 0.7939 
[2025-05-11 13:40:54,024 INFO evaluator.py line 167 288342] Test: [1242/1505] Loss 1.1527 
[2025-05-11 13:40:54,171 INFO evaluator.py line 167 288342] Test: [1243/1505] Loss 0.6607 
[2025-05-11 13:40:54,299 INFO evaluator.py line 167 288342] Test: [1244/1505] Loss 0.7189 
[2025-05-11 13:40:54,496 INFO evaluator.py line 167 288342] Test: [1245/1505] Loss 0.7336 
[2025-05-11 13:40:54,655 INFO evaluator.py line 167 288342] Test: [1246/1505] Loss 1.5404 
[2025-05-11 13:40:54,810 INFO evaluator.py line 167 288342] Test: [1247/1505] Loss 0.5804 
[2025-05-11 13:40:54,932 INFO evaluator.py line 167 288342] Test: [1248/1505] Loss 0.9123 
[2025-05-11 13:40:55,078 INFO evaluator.py line 167 288342] Test: [1249/1505] Loss 0.5865 
[2025-05-11 13:40:55,218 INFO evaluator.py line 167 288342] Test: [1250/1505] Loss 0.6728 
[2025-05-11 13:40:55,327 INFO evaluator.py line 167 288342] Test: [1251/1505] Loss 0.5670 
[2025-05-11 13:40:55,466 INFO evaluator.py line 167 288342] Test: [1252/1505] Loss 0.6683 
[2025-05-11 13:40:55,600 INFO evaluator.py line 167 288342] Test: [1253/1505] Loss 0.9602 
[2025-05-11 13:40:55,776 INFO evaluator.py line 167 288342] Test: [1254/1505] Loss 0.7296 
[2025-05-11 13:40:55,909 INFO evaluator.py line 167 288342] Test: [1255/1505] Loss 0.7458 
[2025-05-11 13:40:56,028 INFO evaluator.py line 167 288342] Test: [1256/1505] Loss 0.8455 
[2025-05-11 13:40:56,167 INFO evaluator.py line 167 288342] Test: [1257/1505] Loss 0.6148 
[2025-05-11 13:40:56,326 INFO evaluator.py line 167 288342] Test: [1258/1505] Loss 0.6635 
[2025-05-11 13:40:56,498 INFO evaluator.py line 167 288342] Test: [1259/1505] Loss 0.9245 
[2025-05-11 13:40:56,662 INFO evaluator.py line 167 288342] Test: [1260/1505] Loss 0.7761 
[2025-05-11 13:40:56,784 INFO evaluator.py line 167 288342] Test: [1261/1505] Loss 0.8560 
[2025-05-11 13:40:56,923 INFO evaluator.py line 167 288342] Test: [1262/1505] Loss 0.8260 
[2025-05-11 13:40:57,055 INFO evaluator.py line 167 288342] Test: [1263/1505] Loss 0.7244 
[2025-05-11 13:40:57,218 INFO evaluator.py line 167 288342] Test: [1264/1505] Loss 0.7227 
[2025-05-11 13:40:57,371 INFO evaluator.py line 167 288342] Test: [1265/1505] Loss 1.5016 
[2025-05-11 13:40:57,531 INFO evaluator.py line 167 288342] Test: [1266/1505] Loss 0.9109 
[2025-05-11 13:40:57,675 INFO evaluator.py line 167 288342] Test: [1267/1505] Loss 0.8025 
[2025-05-11 13:40:57,824 INFO evaluator.py line 167 288342] Test: [1268/1505] Loss 0.7440 
[2025-05-11 13:40:57,983 INFO evaluator.py line 167 288342] Test: [1269/1505] Loss 0.7553 
[2025-05-11 13:40:58,146 INFO evaluator.py line 167 288342] Test: [1270/1505] Loss 0.6006 
[2025-05-11 13:40:58,281 INFO evaluator.py line 167 288342] Test: [1271/1505] Loss 1.0453 
[2025-05-11 13:40:58,436 INFO evaluator.py line 167 288342] Test: [1272/1505] Loss 0.6826 
[2025-05-11 13:40:58,603 INFO evaluator.py line 167 288342] Test: [1273/1505] Loss 1.4238 
[2025-05-11 13:40:58,782 INFO evaluator.py line 167 288342] Test: [1274/1505] Loss 0.7631 
[2025-05-11 13:40:58,933 INFO evaluator.py line 167 288342] Test: [1275/1505] Loss 0.7174 
[2025-05-11 13:40:59,096 INFO evaluator.py line 167 288342] Test: [1276/1505] Loss 0.7925 
[2025-05-11 13:40:59,229 INFO evaluator.py line 167 288342] Test: [1277/1505] Loss 0.6490 
[2025-05-11 13:40:59,362 INFO evaluator.py line 167 288342] Test: [1278/1505] Loss 0.7417 
[2025-05-11 13:40:59,500 INFO evaluator.py line 167 288342] Test: [1279/1505] Loss 0.7372 
[2025-05-11 13:40:59,642 INFO evaluator.py line 167 288342] Test: [1280/1505] Loss 0.6039 
[2025-05-11 13:40:59,831 INFO evaluator.py line 167 288342] Test: [1281/1505] Loss 0.7774 
[2025-05-11 13:41:00,004 INFO evaluator.py line 167 288342] Test: [1282/1505] Loss 0.5748 
[2025-05-11 13:41:00,159 INFO evaluator.py line 167 288342] Test: [1283/1505] Loss 0.5721 
[2025-05-11 13:41:00,372 INFO evaluator.py line 167 288342] Test: [1284/1505] Loss 0.5262 
[2025-05-11 13:41:00,515 INFO evaluator.py line 167 288342] Test: [1285/1505] Loss 0.9049 
[2025-05-11 13:41:00,689 INFO evaluator.py line 167 288342] Test: [1286/1505] Loss 0.8490 
[2025-05-11 13:41:00,860 INFO evaluator.py line 167 288342] Test: [1287/1505] Loss 0.8559 
[2025-05-11 13:41:01,025 INFO evaluator.py line 167 288342] Test: [1288/1505] Loss 0.7664 
[2025-05-11 13:41:01,176 INFO evaluator.py line 167 288342] Test: [1289/1505] Loss 0.7221 
[2025-05-11 13:41:01,361 INFO evaluator.py line 167 288342] Test: [1290/1505] Loss 0.8885 
[2025-05-11 13:41:01,514 INFO evaluator.py line 167 288342] Test: [1291/1505] Loss 0.7394 
[2025-05-11 13:41:01,640 INFO evaluator.py line 167 288342] Test: [1292/1505] Loss 0.8181 
[2025-05-11 13:41:01,794 INFO evaluator.py line 167 288342] Test: [1293/1505] Loss 0.9518 
[2025-05-11 13:41:01,986 INFO evaluator.py line 167 288342] Test: [1294/1505] Loss 0.9378 
[2025-05-11 13:41:02,139 INFO evaluator.py line 167 288342] Test: [1295/1505] Loss 0.5293 
[2025-05-11 13:41:02,275 INFO evaluator.py line 167 288342] Test: [1296/1505] Loss 0.6832 
[2025-05-11 13:41:02,446 INFO evaluator.py line 167 288342] Test: [1297/1505] Loss 0.7882 
[2025-05-11 13:41:02,624 INFO evaluator.py line 167 288342] Test: [1298/1505] Loss 0.8698 
[2025-05-11 13:41:02,774 INFO evaluator.py line 167 288342] Test: [1299/1505] Loss 0.9713 
[2025-05-11 13:41:02,927 INFO evaluator.py line 167 288342] Test: [1300/1505] Loss 0.3680 
[2025-05-11 13:41:03,046 INFO evaluator.py line 167 288342] Test: [1301/1505] Loss 0.8220 
[2025-05-11 13:41:03,215 INFO evaluator.py line 167 288342] Test: [1302/1505] Loss 0.9975 
[2025-05-11 13:41:03,382 INFO evaluator.py line 167 288342] Test: [1303/1505] Loss 0.6716 
[2025-05-11 13:41:03,526 INFO evaluator.py line 167 288342] Test: [1304/1505] Loss 1.3136 
[2025-05-11 13:41:03,659 INFO evaluator.py line 167 288342] Test: [1305/1505] Loss 0.6534 
[2025-05-11 13:41:03,831 INFO evaluator.py line 167 288342] Test: [1306/1505] Loss 0.5074 
[2025-05-11 13:41:03,957 INFO evaluator.py line 167 288342] Test: [1307/1505] Loss 0.6335 
[2025-05-11 13:41:04,098 INFO evaluator.py line 167 288342] Test: [1308/1505] Loss 0.6774 
[2025-05-11 13:41:04,247 INFO evaluator.py line 167 288342] Test: [1309/1505] Loss 0.9218 
[2025-05-11 13:41:04,376 INFO evaluator.py line 167 288342] Test: [1310/1505] Loss 0.5977 
[2025-05-11 13:41:04,505 INFO evaluator.py line 167 288342] Test: [1311/1505] Loss 0.4619 
[2025-05-11 13:41:04,646 INFO evaluator.py line 167 288342] Test: [1312/1505] Loss 0.6775 
[2025-05-11 13:41:04,779 INFO evaluator.py line 167 288342] Test: [1313/1505] Loss 1.2018 
[2025-05-11 13:41:04,950 INFO evaluator.py line 167 288342] Test: [1314/1505] Loss 0.9311 
[2025-05-11 13:41:05,102 INFO evaluator.py line 167 288342] Test: [1315/1505] Loss 0.5476 
[2025-05-11 13:41:05,256 INFO evaluator.py line 167 288342] Test: [1316/1505] Loss 0.9414 
[2025-05-11 13:41:05,382 INFO evaluator.py line 167 288342] Test: [1317/1505] Loss 0.7411 
[2025-05-11 13:41:05,537 INFO evaluator.py line 167 288342] Test: [1318/1505] Loss 0.6342 
[2025-05-11 13:41:05,682 INFO evaluator.py line 167 288342] Test: [1319/1505] Loss 1.1681 
[2025-05-11 13:41:05,823 INFO evaluator.py line 167 288342] Test: [1320/1505] Loss 0.7086 
[2025-05-11 13:41:05,984 INFO evaluator.py line 167 288342] Test: [1321/1505] Loss 0.7268 
[2025-05-11 13:41:06,137 INFO evaluator.py line 167 288342] Test: [1322/1505] Loss 0.7907 
[2025-05-11 13:41:06,263 INFO evaluator.py line 167 288342] Test: [1323/1505] Loss 0.5999 
[2025-05-11 13:41:06,454 INFO evaluator.py line 167 288342] Test: [1324/1505] Loss 0.8588 
[2025-05-11 13:41:06,590 INFO evaluator.py line 167 288342] Test: [1325/1505] Loss 0.7091 
[2025-05-11 13:41:06,743 INFO evaluator.py line 167 288342] Test: [1326/1505] Loss 1.2285 
[2025-05-11 13:41:06,892 INFO evaluator.py line 167 288342] Test: [1327/1505] Loss 0.8921 
[2025-05-11 13:41:07,061 INFO evaluator.py line 167 288342] Test: [1328/1505] Loss 0.7266 
[2025-05-11 13:41:07,250 INFO evaluator.py line 167 288342] Test: [1329/1505] Loss 0.7230 
[2025-05-11 13:41:07,379 INFO evaluator.py line 167 288342] Test: [1330/1505] Loss 0.4590 
[2025-05-11 13:41:07,466 INFO evaluator.py line 167 288342] Test: [1331/1505] Loss 0.6845 
[2025-05-11 13:41:07,672 INFO evaluator.py line 167 288342] Test: [1332/1505] Loss 0.8425 
[2025-05-11 13:41:07,883 INFO evaluator.py line 167 288342] Test: [1333/1505] Loss 0.7348 
[2025-05-11 13:41:08,029 INFO evaluator.py line 167 288342] Test: [1334/1505] Loss 0.9970 
[2025-05-11 13:41:08,194 INFO evaluator.py line 167 288342] Test: [1335/1505] Loss 0.7182 
[2025-05-11 13:41:08,312 INFO evaluator.py line 167 288342] Test: [1336/1505] Loss 0.7271 
[2025-05-11 13:41:08,439 INFO evaluator.py line 167 288342] Test: [1337/1505] Loss 1.0237 
[2025-05-11 13:41:08,587 INFO evaluator.py line 167 288342] Test: [1338/1505] Loss 1.0133 
[2025-05-11 13:41:08,750 INFO evaluator.py line 167 288342] Test: [1339/1505] Loss 1.0661 
[2025-05-11 13:41:08,900 INFO evaluator.py line 167 288342] Test: [1340/1505] Loss 0.8284 
[2025-05-11 13:41:09,055 INFO evaluator.py line 167 288342] Test: [1341/1505] Loss 0.8906 
[2025-05-11 13:41:09,203 INFO evaluator.py line 167 288342] Test: [1342/1505] Loss 0.8747 
[2025-05-11 13:41:09,334 INFO evaluator.py line 167 288342] Test: [1343/1505] Loss 0.6140 
[2025-05-11 13:41:09,452 INFO evaluator.py line 167 288342] Test: [1344/1505] Loss 0.7476 
[2025-05-11 13:41:09,602 INFO evaluator.py line 167 288342] Test: [1345/1505] Loss 0.8247 
[2025-05-11 13:41:09,758 INFO evaluator.py line 167 288342] Test: [1346/1505] Loss 0.7338 
[2025-05-11 13:41:09,927 INFO evaluator.py line 167 288342] Test: [1347/1505] Loss 0.6008 
[2025-05-11 13:41:10,103 INFO evaluator.py line 167 288342] Test: [1348/1505] Loss 0.5916 
[2025-05-11 13:41:10,271 INFO evaluator.py line 167 288342] Test: [1349/1505] Loss 1.0809 
[2025-05-11 13:41:10,413 INFO evaluator.py line 167 288342] Test: [1350/1505] Loss 0.9133 
[2025-05-11 13:41:10,550 INFO evaluator.py line 167 288342] Test: [1351/1505] Loss 1.0238 
[2025-05-11 13:41:10,674 INFO evaluator.py line 167 288342] Test: [1352/1505] Loss 0.6770 
[2025-05-11 13:41:10,838 INFO evaluator.py line 167 288342] Test: [1353/1505] Loss 0.7811 
[2025-05-11 13:41:10,975 INFO evaluator.py line 167 288342] Test: [1354/1505] Loss 0.7870 
[2025-05-11 13:41:11,116 INFO evaluator.py line 167 288342] Test: [1355/1505] Loss 0.9578 
[2025-05-11 13:41:11,271 INFO evaluator.py line 167 288342] Test: [1356/1505] Loss 0.5412 
[2025-05-11 13:41:11,429 INFO evaluator.py line 167 288342] Test: [1357/1505] Loss 1.1632 
[2025-05-11 13:41:11,558 INFO evaluator.py line 167 288342] Test: [1358/1505] Loss 0.6748 
[2025-05-11 13:41:11,689 INFO evaluator.py line 167 288342] Test: [1359/1505] Loss 1.1547 
[2025-05-11 13:41:11,861 INFO evaluator.py line 167 288342] Test: [1360/1505] Loss 1.0040 
[2025-05-11 13:41:12,025 INFO evaluator.py line 167 288342] Test: [1361/1505] Loss 0.4944 
[2025-05-11 13:41:12,189 INFO evaluator.py line 167 288342] Test: [1362/1505] Loss 0.4815 
[2025-05-11 13:41:12,313 INFO evaluator.py line 167 288342] Test: [1363/1505] Loss 0.9692 
[2025-05-11 13:41:12,449 INFO evaluator.py line 167 288342] Test: [1364/1505] Loss 0.6846 
[2025-05-11 13:41:12,603 INFO evaluator.py line 167 288342] Test: [1365/1505] Loss 0.7364 
[2025-05-11 13:41:12,767 INFO evaluator.py line 167 288342] Test: [1366/1505] Loss 0.9510 
[2025-05-11 13:41:12,946 INFO evaluator.py line 167 288342] Test: [1367/1505] Loss 0.4417 
[2025-05-11 13:41:13,083 INFO evaluator.py line 167 288342] Test: [1368/1505] Loss 0.9826 
[2025-05-11 13:41:13,225 INFO evaluator.py line 167 288342] Test: [1369/1505] Loss 0.4823 
[2025-05-11 13:41:13,416 INFO evaluator.py line 167 288342] Test: [1370/1505] Loss 0.6348 
[2025-05-11 13:41:13,524 INFO evaluator.py line 167 288342] Test: [1371/1505] Loss 0.6006 
[2025-05-11 13:41:13,660 INFO evaluator.py line 167 288342] Test: [1372/1505] Loss 1.2838 
[2025-05-11 13:41:13,831 INFO evaluator.py line 167 288342] Test: [1373/1505] Loss 0.4595 
[2025-05-11 13:41:13,995 INFO evaluator.py line 167 288342] Test: [1374/1505] Loss 1.1628 
[2025-05-11 13:41:14,146 INFO evaluator.py line 167 288342] Test: [1375/1505] Loss 0.6455 
[2025-05-11 13:41:14,294 INFO evaluator.py line 167 288342] Test: [1376/1505] Loss 1.0396 
[2025-05-11 13:41:14,429 INFO evaluator.py line 167 288342] Test: [1377/1505] Loss 0.4859 
[2025-05-11 13:41:14,566 INFO evaluator.py line 167 288342] Test: [1378/1505] Loss 0.7585 
[2025-05-11 13:41:14,717 INFO evaluator.py line 167 288342] Test: [1379/1505] Loss 1.7881 
[2025-05-11 13:41:14,883 INFO evaluator.py line 167 288342] Test: [1380/1505] Loss 0.9563 
[2025-05-11 13:41:15,016 INFO evaluator.py line 167 288342] Test: [1381/1505] Loss 1.1428 
[2025-05-11 13:41:15,152 INFO evaluator.py line 167 288342] Test: [1382/1505] Loss 0.6899 
[2025-05-11 13:41:15,297 INFO evaluator.py line 167 288342] Test: [1383/1505] Loss 0.6261 
[2025-05-11 13:41:15,440 INFO evaluator.py line 167 288342] Test: [1384/1505] Loss 1.0491 
[2025-05-11 13:41:15,591 INFO evaluator.py line 167 288342] Test: [1385/1505] Loss 0.8014 
[2025-05-11 13:41:15,729 INFO evaluator.py line 167 288342] Test: [1386/1505] Loss 0.6640 
[2025-05-11 13:41:15,929 INFO evaluator.py line 167 288342] Test: [1387/1505] Loss 0.5311 
[2025-05-11 13:41:16,085 INFO evaluator.py line 167 288342] Test: [1388/1505] Loss 0.7577 
[2025-05-11 13:41:16,248 INFO evaluator.py line 167 288342] Test: [1389/1505] Loss 0.6130 
[2025-05-11 13:41:16,406 INFO evaluator.py line 167 288342] Test: [1390/1505] Loss 0.7888 
[2025-05-11 13:41:16,554 INFO evaluator.py line 167 288342] Test: [1391/1505] Loss 0.5740 
[2025-05-11 13:41:16,718 INFO evaluator.py line 167 288342] Test: [1392/1505] Loss 0.8745 
[2025-05-11 13:41:16,839 INFO evaluator.py line 167 288342] Test: [1393/1505] Loss 0.9503 
[2025-05-11 13:41:16,984 INFO evaluator.py line 167 288342] Test: [1394/1505] Loss 0.5574 
[2025-05-11 13:41:17,141 INFO evaluator.py line 167 288342] Test: [1395/1505] Loss 0.8010 
[2025-05-11 13:41:17,294 INFO evaluator.py line 167 288342] Test: [1396/1505] Loss 0.5135 
[2025-05-11 13:41:17,409 INFO evaluator.py line 167 288342] Test: [1397/1505] Loss 0.9505 
[2025-05-11 13:41:17,557 INFO evaluator.py line 167 288342] Test: [1398/1505] Loss 0.9666 
[2025-05-11 13:41:17,725 INFO evaluator.py line 167 288342] Test: [1399/1505] Loss 0.9633 
[2025-05-11 13:41:17,888 INFO evaluator.py line 167 288342] Test: [1400/1505] Loss 0.6576 
[2025-05-11 13:41:18,036 INFO evaluator.py line 167 288342] Test: [1401/1505] Loss 0.9524 
[2025-05-11 13:41:18,163 INFO evaluator.py line 167 288342] Test: [1402/1505] Loss 0.9388 
[2025-05-11 13:41:18,319 INFO evaluator.py line 167 288342] Test: [1403/1505] Loss 0.6763 
[2025-05-11 13:41:18,449 INFO evaluator.py line 167 288342] Test: [1404/1505] Loss 0.7635 
[2025-05-11 13:41:18,594 INFO evaluator.py line 167 288342] Test: [1405/1505] Loss 0.7067 
[2025-05-11 13:41:18,730 INFO evaluator.py line 167 288342] Test: [1406/1505] Loss 1.2905 
[2025-05-11 13:41:18,886 INFO evaluator.py line 167 288342] Test: [1407/1505] Loss 0.6901 
[2025-05-11 13:41:19,016 INFO evaluator.py line 167 288342] Test: [1408/1505] Loss 0.7071 
[2025-05-11 13:41:19,180 INFO evaluator.py line 167 288342] Test: [1409/1505] Loss 0.7716 
[2025-05-11 13:41:19,334 INFO evaluator.py line 167 288342] Test: [1410/1505] Loss 0.6281 
[2025-05-11 13:41:19,503 INFO evaluator.py line 167 288342] Test: [1411/1505] Loss 0.8615 
[2025-05-11 13:41:19,618 INFO evaluator.py line 167 288342] Test: [1412/1505] Loss 0.7864 
[2025-05-11 13:41:19,737 INFO evaluator.py line 167 288342] Test: [1413/1505] Loss 0.9090 
[2025-05-11 13:41:19,907 INFO evaluator.py line 167 288342] Test: [1414/1505] Loss 0.9551 
[2025-05-11 13:41:20,046 INFO evaluator.py line 167 288342] Test: [1415/1505] Loss 0.6117 
[2025-05-11 13:41:20,232 INFO evaluator.py line 167 288342] Test: [1416/1505] Loss 0.7518 
[2025-05-11 13:41:20,364 INFO evaluator.py line 167 288342] Test: [1417/1505] Loss 0.6641 
[2025-05-11 13:41:20,521 INFO evaluator.py line 167 288342] Test: [1418/1505] Loss 0.6538 
[2025-05-11 13:41:20,665 INFO evaluator.py line 167 288342] Test: [1419/1505] Loss 0.8980 
[2025-05-11 13:41:20,815 INFO evaluator.py line 167 288342] Test: [1420/1505] Loss 0.9586 
[2025-05-11 13:41:20,965 INFO evaluator.py line 167 288342] Test: [1421/1505] Loss 0.7891 
[2025-05-11 13:41:21,105 INFO evaluator.py line 167 288342] Test: [1422/1505] Loss 0.6537 
[2025-05-11 13:41:21,276 INFO evaluator.py line 167 288342] Test: [1423/1505] Loss 0.7047 
[2025-05-11 13:41:21,438 INFO evaluator.py line 167 288342] Test: [1424/1505] Loss 0.7175 
[2025-05-11 13:41:21,577 INFO evaluator.py line 167 288342] Test: [1425/1505] Loss 1.0397 
[2025-05-11 13:41:21,719 INFO evaluator.py line 167 288342] Test: [1426/1505] Loss 0.7609 
[2025-05-11 13:41:21,903 INFO evaluator.py line 167 288342] Test: [1427/1505] Loss 1.0970 
[2025-05-11 13:41:22,051 INFO evaluator.py line 167 288342] Test: [1428/1505] Loss 0.5565 
[2025-05-11 13:41:22,195 INFO evaluator.py line 167 288342] Test: [1429/1505] Loss 0.7909 
[2025-05-11 13:41:22,333 INFO evaluator.py line 167 288342] Test: [1430/1505] Loss 0.7611 
[2025-05-11 13:41:22,476 INFO evaluator.py line 167 288342] Test: [1431/1505] Loss 0.7456 
[2025-05-11 13:41:22,598 INFO evaluator.py line 167 288342] Test: [1432/1505] Loss 0.5371 
[2025-05-11 13:41:22,726 INFO evaluator.py line 167 288342] Test: [1433/1505] Loss 0.4839 
[2025-05-11 13:41:22,879 INFO evaluator.py line 167 288342] Test: [1434/1505] Loss 0.8177 
[2025-05-11 13:41:23,110 INFO evaluator.py line 167 288342] Test: [1435/1505] Loss 1.0194 
[2025-05-11 13:41:23,284 INFO evaluator.py line 167 288342] Test: [1436/1505] Loss 0.7877 
[2025-05-11 13:41:23,406 INFO evaluator.py line 167 288342] Test: [1437/1505] Loss 0.7109 
[2025-05-11 13:41:23,529 INFO evaluator.py line 167 288342] Test: [1438/1505] Loss 0.7195 
[2025-05-11 13:41:23,698 INFO evaluator.py line 167 288342] Test: [1439/1505] Loss 0.9337 
[2025-05-11 13:41:23,848 INFO evaluator.py line 167 288342] Test: [1440/1505] Loss 0.7122 
[2025-05-11 13:41:24,016 INFO evaluator.py line 167 288342] Test: [1441/1505] Loss 0.7926 
[2025-05-11 13:41:24,143 INFO evaluator.py line 167 288342] Test: [1442/1505] Loss 1.3761 
[2025-05-11 13:41:24,329 INFO evaluator.py line 167 288342] Test: [1443/1505] Loss 0.7803 
[2025-05-11 13:41:24,485 INFO evaluator.py line 167 288342] Test: [1444/1505] Loss 0.5168 
[2025-05-11 13:41:24,640 INFO evaluator.py line 167 288342] Test: [1445/1505] Loss 0.6759 
[2025-05-11 13:41:24,770 INFO evaluator.py line 167 288342] Test: [1446/1505] Loss 0.8940 
[2025-05-11 13:41:24,882 INFO evaluator.py line 167 288342] Test: [1447/1505] Loss 0.9516 
[2025-05-11 13:41:25,034 INFO evaluator.py line 167 288342] Test: [1448/1505] Loss 0.8257 
[2025-05-11 13:41:25,169 INFO evaluator.py line 167 288342] Test: [1449/1505] Loss 0.7200 
[2025-05-11 13:41:25,323 INFO evaluator.py line 167 288342] Test: [1450/1505] Loss 0.6805 
[2025-05-11 13:41:25,502 INFO evaluator.py line 167 288342] Test: [1451/1505] Loss 0.5496 
[2025-05-11 13:41:25,644 INFO evaluator.py line 167 288342] Test: [1452/1505] Loss 0.7908 
[2025-05-11 13:41:25,814 INFO evaluator.py line 167 288342] Test: [1453/1505] Loss 1.3229 
[2025-05-11 13:41:25,906 INFO evaluator.py line 167 288342] Test: [1454/1505] Loss 0.5245 
[2025-05-11 13:41:26,063 INFO evaluator.py line 167 288342] Test: [1455/1505] Loss 0.6827 
[2025-05-11 13:41:26,232 INFO evaluator.py line 167 288342] Test: [1456/1505] Loss 0.7738 
[2025-05-11 13:41:26,381 INFO evaluator.py line 167 288342] Test: [1457/1505] Loss 0.9924 
[2025-05-11 13:41:26,531 INFO evaluator.py line 167 288342] Test: [1458/1505] Loss 0.8224 
[2025-05-11 13:41:26,710 INFO evaluator.py line 167 288342] Test: [1459/1505] Loss 0.4883 
[2025-05-11 13:41:26,824 INFO evaluator.py line 167 288342] Test: [1460/1505] Loss 0.6943 
[2025-05-11 13:41:26,970 INFO evaluator.py line 167 288342] Test: [1461/1505] Loss 0.5440 
[2025-05-11 13:41:27,129 INFO evaluator.py line 167 288342] Test: [1462/1505] Loss 0.6672 
[2025-05-11 13:41:27,250 INFO evaluator.py line 167 288342] Test: [1463/1505] Loss 0.6023 
[2025-05-11 13:41:27,438 INFO evaluator.py line 167 288342] Test: [1464/1505] Loss 0.7318 
[2025-05-11 13:41:27,573 INFO evaluator.py line 167 288342] Test: [1465/1505] Loss 0.6039 
[2025-05-11 13:41:27,728 INFO evaluator.py line 167 288342] Test: [1466/1505] Loss 1.0432 
[2025-05-11 13:41:27,858 INFO evaluator.py line 167 288342] Test: [1467/1505] Loss 0.9232 
[2025-05-11 13:41:28,021 INFO evaluator.py line 167 288342] Test: [1468/1505] Loss 0.8903 
[2025-05-11 13:41:28,134 INFO evaluator.py line 167 288342] Test: [1469/1505] Loss 0.9020 
[2025-05-11 13:41:28,254 INFO evaluator.py line 167 288342] Test: [1470/1505] Loss 0.8807 
[2025-05-11 13:41:28,409 INFO evaluator.py line 167 288342] Test: [1471/1505] Loss 0.9985 
[2025-05-11 13:41:28,558 INFO evaluator.py line 167 288342] Test: [1472/1505] Loss 0.7795 
[2025-05-11 13:41:28,743 INFO evaluator.py line 167 288342] Test: [1473/1505] Loss 0.7207 
[2025-05-11 13:41:28,848 INFO evaluator.py line 167 288342] Test: [1474/1505] Loss 1.1817 
[2025-05-11 13:41:29,003 INFO evaluator.py line 167 288342] Test: [1475/1505] Loss 0.8025 
[2025-05-11 13:41:29,167 INFO evaluator.py line 167 288342] Test: [1476/1505] Loss 1.0512 
[2025-05-11 13:41:29,360 INFO evaluator.py line 167 288342] Test: [1477/1505] Loss 0.7258 
[2025-05-11 13:41:29,556 INFO evaluator.py line 167 288342] Test: [1478/1505] Loss 0.6054 
[2025-05-11 13:41:29,748 INFO evaluator.py line 167 288342] Test: [1479/1505] Loss 0.5264 
[2025-05-11 13:41:29,916 INFO evaluator.py line 167 288342] Test: [1480/1505] Loss 0.8110 
[2025-05-11 13:41:30,050 INFO evaluator.py line 167 288342] Test: [1481/1505] Loss 1.0921 
[2025-05-11 13:41:30,182 INFO evaluator.py line 167 288342] Test: [1482/1505] Loss 1.0618 
[2025-05-11 13:41:30,328 INFO evaluator.py line 167 288342] Test: [1483/1505] Loss 0.6583 
[2025-05-11 13:41:30,484 INFO evaluator.py line 167 288342] Test: [1484/1505] Loss 0.7903 
[2025-05-11 13:41:30,656 INFO evaluator.py line 167 288342] Test: [1485/1505] Loss 1.1290 
[2025-05-11 13:41:30,808 INFO evaluator.py line 167 288342] Test: [1486/1505] Loss 0.8747 
[2025-05-11 13:41:30,935 INFO evaluator.py line 167 288342] Test: [1487/1505] Loss 0.9124 
[2025-05-11 13:41:31,114 INFO evaluator.py line 167 288342] Test: [1488/1505] Loss 0.8699 
[2025-05-11 13:41:31,277 INFO evaluator.py line 167 288342] Test: [1489/1505] Loss 0.7923 
[2025-05-11 13:41:31,435 INFO evaluator.py line 167 288342] Test: [1490/1505] Loss 0.8345 
[2025-05-11 13:41:31,560 INFO evaluator.py line 167 288342] Test: [1491/1505] Loss 0.9125 
[2025-05-11 13:41:31,695 INFO evaluator.py line 167 288342] Test: [1492/1505] Loss 0.8974 
[2025-05-11 13:41:31,836 INFO evaluator.py line 167 288342] Test: [1493/1505] Loss 0.7493 
[2025-05-11 13:41:32,022 INFO evaluator.py line 167 288342] Test: [1494/1505] Loss 0.6381 
[2025-05-11 13:41:32,186 INFO evaluator.py line 167 288342] Test: [1495/1505] Loss 0.8612 
[2025-05-11 13:41:32,336 INFO evaluator.py line 167 288342] Test: [1496/1505] Loss 0.9324 
[2025-05-11 13:41:32,489 INFO evaluator.py line 167 288342] Test: [1497/1505] Loss 0.6638 
[2025-05-11 13:41:32,684 INFO evaluator.py line 167 288342] Test: [1498/1505] Loss 0.6446 
[2025-05-11 13:41:32,815 INFO evaluator.py line 167 288342] Test: [1499/1505] Loss 0.8820 
[2025-05-11 13:41:32,973 INFO evaluator.py line 167 288342] Test: [1500/1505] Loss 0.4298 
[2025-05-11 13:41:33,142 INFO evaluator.py line 167 288342] Test: [1501/1505] Loss 0.5472 
[2025-05-11 13:41:33,283 INFO evaluator.py line 167 288342] Test: [1502/1505] Loss 0.8322 
[2025-05-11 13:41:33,458 INFO evaluator.py line 167 288342] Test: [1503/1505] Loss 0.8092 
[2025-05-11 13:41:33,586 INFO evaluator.py line 167 288342] Test: [1504/1505] Loss 0.7864 
[2025-05-11 13:41:33,756 INFO evaluator.py line 167 288342] Test: [1505/1505] Loss 0.8948 
[2025-05-11 13:41:40,243 INFO evaluator.py line 182 288342] Val result: mIoU/mAcc/allAcc 0.5307/0.6758/0.8923.
[2025-05-11 13:41:40,243 INFO evaluator.py line 188 288342] Class_0-barrier Result: iou/accuracy 0.5926/0.7370
[2025-05-11 13:41:40,243 INFO evaluator.py line 188 288342] Class_1-bicycle Result: iou/accuracy 0.0796/0.1949
[2025-05-11 13:41:40,244 INFO evaluator.py line 188 288342] Class_2-bus Result: iou/accuracy 0.5676/0.6351
[2025-05-11 13:41:40,244 INFO evaluator.py line 188 288342] Class_3-car Result: iou/accuracy 0.7837/0.8725
[2025-05-11 13:41:40,244 INFO evaluator.py line 188 288342] Class_4-construction_vehicle Result: iou/accuracy 0.1207/0.3010
[2025-05-11 13:41:40,244 INFO evaluator.py line 188 288342] Class_5-motorcycle Result: iou/accuracy 0.3767/0.7387
[2025-05-11 13:41:40,244 INFO evaluator.py line 188 288342] Class_6-pedestrian Result: iou/accuracy 0.6645/0.7249
[2025-05-11 13:41:40,244 INFO evaluator.py line 188 288342] Class_7-traffic_cone Result: iou/accuracy 0.3013/0.5871
[2025-05-11 13:41:40,244 INFO evaluator.py line 188 288342] Class_8-trailer Result: iou/accuracy 0.2238/0.2960
[2025-05-11 13:41:40,244 INFO evaluator.py line 188 288342] Class_9-truck Result: iou/accuracy 0.4498/0.7287
[2025-05-11 13:41:40,244 INFO evaluator.py line 188 288342] Class_10-driveable_surface Result: iou/accuracy 0.9154/0.9682
[2025-05-11 13:41:40,244 INFO evaluator.py line 188 288342] Class_11-other_flat Result: iou/accuracy 0.4738/0.7160
[2025-05-11 13:41:40,244 INFO evaluator.py line 188 288342] Class_12-sidewalk Result: iou/accuracy 0.5527/0.6784
[2025-05-11 13:41:40,245 INFO evaluator.py line 188 288342] Class_13-terrain Result: iou/accuracy 0.6773/0.7971
[2025-05-11 13:41:40,245 INFO evaluator.py line 188 288342] Class_14-manmade Result: iou/accuracy 0.8507/0.9057
[2025-05-11 13:41:40,245 INFO evaluator.py line 188 288342] Class_15-vegetation Result: iou/accuracy 0.8611/0.9317
[2025-05-11 13:41:40,246 INFO evaluator.py line 231 288342] <<<<<<<<<<<<<<<<< End Evaluation <<<<<<<<<<<<<<<<<
[2025-05-11 13:41:40,246 INFO misc.py line 182 288342] Best validation mIoU updated to: 0.5307
[2025-05-11 13:41:40,246 INFO misc.py line 187 288342] Currently Best mIoU: 0.5307
[2025-05-11 13:41:40,246 INFO misc.py line 196 288342] Saving checkpoint to: exp/ptv3/nuscenes_norm-semseg-pt-v3m1-0-nxnynzr_168597/model/model_last.pth
[2025-05-11 13:41:43,647 INFO misc.py line 117 288342] Train: [2/50][1/2344] Data 1.636 (1.636) Batch 2.067 (2.067) Remain 65:56:42 loss: 0.7869 Lr: 0.00110
[2025-05-11 13:41:44,274 INFO misc.py line 117 288342] Train: [2/50][2/2344] Data 0.002 (0.002) Batch 0.627 (0.627) Remain 20:00:45 loss: 0.8916 Lr: 0.00110
[2025-05-11 13:41:44,903 INFO misc.py line 117 288342] Train: [2/50][3/2344] Data 0.002 (0.002) Batch 0.628 (0.628) Remain 20:02:59 loss: 0.6341 Lr: 0.00110
[2025-05-11 13:41:46,286 INFO misc.py line 117 288342] Train: [2/50][4/2344] Data 0.003 (0.003) Batch 1.383 (1.383) Remain 44:07:00 loss: 1.1753 Lr: 0.00110
[2025-05-11 13:41:46,902 INFO misc.py line 117 288342] Train: [2/50][5/2344] Data 0.003 (0.003) Batch 0.617 (1.000) Remain 31:53:49 loss: 0.9050 Lr: 0.00110
[2025-05-11 13:41:47,644 INFO misc.py line 117 288342] Train: [2/50][6/2344] Data 0.002 (0.002) Batch 0.742 (0.914) Remain 29:09:10 loss: 0.8222 Lr: 0.00110
[2025-05-11 13:41:48,252 INFO misc.py line 117 288342] Train: [2/50][7/2344] Data 0.003 (0.003) Batch 0.608 (0.837) Remain 26:42:51 loss: 0.8951 Lr: 0.00110
[2025-05-11 13:41:48,832 INFO misc.py line 117 288342] Train: [2/50][8/2344] Data 0.002 (0.003) Batch 0.579 (0.786) Remain 25:04:05 loss: 0.8247 Lr: 0.00110
[2025-05-11 13:41:49,324 INFO misc.py line 117 288342] Train: [2/50][9/2344] Data 0.002 (0.002) Batch 0.493 (0.737) Remain 23:30:33 loss: 0.9664 Lr: 0.00110
[2025-05-11 13:41:50,039 INFO misc.py line 117 288342] Train: [2/50][10/2344] Data 0.003 (0.003) Batch 0.715 (0.734) Remain 23:24:26 loss: 0.8253 Lr: 0.00111
[2025-05-11 13:41:50,663 INFO misc.py line 117 288342] Train: [2/50][11/2344] Data 0.002 (0.002) Batch 0.624 (0.720) Remain 22:58:07 loss: 0.8670 Lr: 0.00111
[2025-05-11 13:41:51,360 INFO misc.py line 117 288342] Train: [2/50][12/2344] Data 0.002 (0.002) Batch 0.697 (0.717) Remain 22:53:15 loss: 0.7376 Lr: 0.00111
[2025-05-11 13:41:52,017 INFO misc.py line 117 288342] Train: [2/50][13/2344] Data 0.002 (0.002) Batch 0.657 (0.711) Remain 22:41:44 loss: 0.9731 Lr: 0.00111
[2025-05-11 13:41:52,635 INFO misc.py line 117 288342] Train: [2/50][14/2344] Data 0.003 (0.002) Batch 0.618 (0.703) Remain 22:25:24 loss: 0.7694 Lr: 0.00111
[2025-05-11 13:41:53,090 INFO misc.py line 117 288342] Train: [2/50][15/2344] Data 0.002 (0.002) Batch 0.455 (0.682) Remain 21:45:49 loss: 0.7227 Lr: 0.00111
[2025-05-11 13:41:53,623 INFO misc.py line 117 288342] Train: [2/50][16/2344] Data 0.003 (0.003) Batch 0.533 (0.671) Remain 21:23:53 loss: 0.8694 Lr: 0.00111
[2025-05-11 13:41:54,245 INFO misc.py line 117 288342] Train: [2/50][17/2344] Data 0.003 (0.003) Batch 0.621 (0.667) Remain 21:17:07 loss: 0.7628 Lr: 0.00111
[2025-05-11 13:41:54,868 INFO misc.py line 117 288342] Train: [2/50][18/2344] Data 0.003 (0.003) Batch 0.623 (0.664) Remain 21:11:27 loss: 1.1066 Lr: 0.00111
[2025-05-11 13:41:55,418 INFO misc.py line 117 288342] Train: [2/50][19/2344] Data 0.003 (0.003) Batch 0.551 (0.657) Remain 20:57:53 loss: 0.8557 Lr: 0.00111
[2025-05-11 13:41:56,086 INFO misc.py line 117 288342] Train: [2/50][20/2344] Data 0.002 (0.003) Batch 0.668 (0.658) Remain 20:59:05 loss: 0.7814 Lr: 0.00111
[2025-05-11 13:41:56,719 INFO misc.py line 117 288342] Train: [2/50][21/2344] Data 0.002 (0.003) Batch 0.633 (0.656) Remain 20:56:24 loss: 0.8419 Lr: 0.00111
[2025-05-11 13:41:57,288 INFO misc.py line 117 288342] Train: [2/50][22/2344] Data 0.002 (0.003) Batch 0.569 (0.652) Remain 20:47:36 loss: 0.8339 Lr: 0.00111
[2025-05-11 13:41:57,933 INFO misc.py line 117 288342] Train: [2/50][23/2344] Data 0.003 (0.003) Batch 0.644 (0.651) Remain 20:46:53 loss: 0.8367 Lr: 0.00111
[2025-05-11 13:41:58,594 INFO misc.py line 117 288342] Train: [2/50][24/2344] Data 0.003 (0.003) Batch 0.661 (0.652) Remain 20:47:43 loss: 0.8132 Lr: 0.00111
[2025-05-11 13:41:59,165 INFO misc.py line 117 288342] Train: [2/50][25/2344] Data 0.003 (0.003) Batch 0.572 (0.648) Remain 20:40:43 loss: 0.7306 Lr: 0.00111
[2025-05-11 13:41:59,645 INFO misc.py line 117 288342] Train: [2/50][26/2344] Data 0.003 (0.003) Batch 0.480 (0.641) Remain 20:26:41 loss: 0.8842 Lr: 0.00111
[2025-05-11 13:42:00,248 INFO misc.py line 117 288342] Train: [2/50][27/2344] Data 0.003 (0.003) Batch 0.603 (0.639) Remain 20:23:40 loss: 0.7142 Lr: 0.00112
[2025-05-11 13:42:00,790 INFO misc.py line 117 288342] Train: [2/50][28/2344] Data 0.003 (0.003) Batch 0.541 (0.635) Remain 20:16:09 loss: 0.9114 Lr: 0.00112
[2025-05-11 13:42:01,269 INFO misc.py line 117 288342] Train: [2/50][29/2344] Data 0.003 (0.003) Batch 0.479 (0.629) Remain 20:04:39 loss: 0.8382 Lr: 0.00112
[2025-05-11 13:42:01,981 INFO misc.py line 117 288342] Train: [2/50][30/2344] Data 0.002 (0.003) Batch 0.712 (0.633) Remain 20:10:30 loss: 0.9005 Lr: 0.00112
[2025-05-11 13:42:02,577 INFO misc.py line 117 288342] Train: [2/50][31/2344] Data 0.003 (0.003) Batch 0.596 (0.631) Remain 20:07:58 loss: 0.9054 Lr: 0.00112
[2025-05-11 13:42:03,339 INFO misc.py line 117 288342] Train: [2/50][32/2344] Data 0.002 (0.003) Batch 0.762 (0.636) Remain 20:16:34 loss: 1.0379 Lr: 0.00112
[2025-05-11 13:42:04,001 INFO misc.py line 117 288342] Train: [2/50][33/2344] Data 0.003 (0.003) Batch 0.663 (0.637) Remain 20:18:16 loss: 0.7568 Lr: 0.00112
[2025-05-11 13:42:04,534 INFO misc.py line 117 288342] Train: [2/50][34/2344] Data 0.003 (0.003) Batch 0.533 (0.633) Remain 20:11:53 loss: 0.7988 Lr: 0.00112
[2025-05-11 13:42:05,150 INFO misc.py line 117 288342] Train: [2/50][35/2344] Data 0.003 (0.003) Batch 0.615 (0.633) Remain 20:10:48 loss: 1.0195 Lr: 0.00112
[2025-05-11 13:42:05,683 INFO misc.py line 117 288342] Train: [2/50][36/2344] Data 0.002 (0.003) Batch 0.533 (0.630) Remain 20:05:02 loss: 0.9387 Lr: 0.00112
[2025-05-11 13:42:06,285 INFO misc.py line 117 288342] Train: [2/50][37/2344] Data 0.003 (0.003) Batch 0.602 (0.629) Remain 20:03:27 loss: 0.7681 Lr: 0.00112
[2025-05-11 13:42:06,844 INFO misc.py line 117 288342] Train: [2/50][38/2344] Data 0.003 (0.003) Batch 0.559 (0.627) Remain 19:59:38 loss: 0.7230 Lr: 0.00112
[2025-05-11 13:42:07,555 INFO misc.py line 117 288342] Train: [2/50][39/2344] Data 0.002 (0.003) Batch 0.711 (0.629) Remain 20:04:04 loss: 0.9286 Lr: 0.00112
[2025-05-11 13:42:08,284 INFO misc.py line 117 288342] Train: [2/50][40/2344] Data 0.002 (0.003) Batch 0.730 (0.632) Remain 20:09:16 loss: 0.8796 Lr: 0.00112
[2025-05-11 13:42:08,900 INFO misc.py line 117 288342] Train: [2/50][41/2344] Data 0.003 (0.003) Batch 0.616 (0.632) Remain 20:08:26 loss: 0.9109 Lr: 0.00112
[2025-05-11 13:42:09,486 INFO misc.py line 117 288342] Train: [2/50][42/2344] Data 0.002 (0.003) Batch 0.586 (0.630) Remain 20:06:11 loss: 0.8520 Lr: 0.00112
[2025-05-11 13:42:10,193 INFO misc.py line 117 288342] Train: [2/50][43/2344] Data 0.002 (0.003) Batch 0.707 (0.632) Remain 20:09:50 loss: 1.0146 Lr: 0.00113
[2025-05-11 13:42:10,832 INFO misc.py line 117 288342] Train: [2/50][44/2344] Data 0.002 (0.003) Batch 0.639 (0.632) Remain 20:10:10 loss: 0.7710 Lr: 0.00113
[2025-05-11 13:42:11,486 INFO misc.py line 117 288342] Train: [2/50][45/2344] Data 0.002 (0.003) Batch 0.654 (0.633) Remain 20:11:07 loss: 1.1287 Lr: 0.00113
[2025-05-11 13:42:11,981 INFO misc.py line 117 288342] Train: [2/50][46/2344] Data 0.002 (0.003) Batch 0.495 (0.630) Remain 20:04:58 loss: 0.8744 Lr: 0.00113
[2025-05-11 13:42:12,632 INFO misc.py line 117 288342] Train: [2/50][47/2344] Data 0.003 (0.003) Batch 0.651 (0.630) Remain 20:05:53 loss: 0.8893 Lr: 0.00113
[2025-05-11 13:42:13,127 INFO misc.py line 117 288342] Train: [2/50][48/2344] Data 0.003 (0.003) Batch 0.495 (0.627) Remain 20:00:06 loss: 0.8967 Lr: 0.00113
[2025-05-11 13:42:13,640 INFO misc.py line 117 288342] Train: [2/50][49/2344] Data 0.003 (0.003) Batch 0.514 (0.625) Remain 19:55:22 loss: 0.8773 Lr: 0.00113
[2025-05-11 13:42:14,218 INFO misc.py line 117 288342] Train: [2/50][50/2344] Data 0.003 (0.003) Batch 0.578 (0.624) Remain 19:53:28 loss: 0.8002 Lr: 0.00113
[2025-05-11 13:42:14,843 INFO misc.py line 117 288342] Train: [2/50][51/2344] Data 0.003 (0.003) Batch 0.625 (0.624) Remain 19:53:30 loss: 0.7457 Lr: 0.00113
[2025-05-11 13:42:15,440 INFO misc.py line 117 288342] Train: [2/50][52/2344] Data 0.002 (0.003) Batch 0.597 (0.623) Remain 19:52:26 loss: 0.8343 Lr: 0.00113
[2025-05-11 13:42:15,977 INFO misc.py line 117 288342] Train: [2/50][53/2344] Data 0.002 (0.003) Batch 0.538 (0.621) Remain 19:49:09 loss: 0.8998 Lr: 0.00113
[2025-05-11 13:42:16,459 INFO misc.py line 117 288342] Train: [2/50][54/2344] Data 0.002 (0.003) Batch 0.481 (0.619) Remain 19:43:53 loss: 0.8523 Lr: 0.00113
[2025-05-11 13:42:17,132 INFO misc.py line 117 288342] Train: [2/50][55/2344] Data 0.003 (0.003) Batch 0.673 (0.620) Remain 19:45:53 loss: 0.8527 Lr: 0.00113
[2025-05-11 13:42:17,617 INFO misc.py line 117 288342] Train: [2/50][56/2344] Data 0.003 (0.003) Batch 0.485 (0.617) Remain 19:40:59 loss: 0.7622 Lr: 0.00113
[2025-05-11 13:42:18,126 INFO misc.py line 117 288342] Train: [2/50][57/2344] Data 0.003 (0.003) Batch 0.509 (0.615) Remain 19:37:09 loss: 0.9391 Lr: 0.00113
[2025-05-11 13:42:18,725 INFO misc.py line 117 288342] Train: [2/50][58/2344] Data 0.003 (0.003) Batch 0.599 (0.615) Remain 19:36:35 loss: 0.6677 Lr: 0.00113
[2025-05-11 13:42:19,271 INFO misc.py line 117 288342] Train: [2/50][59/2344] Data 0.003 (0.003) Batch 0.545 (0.614) Remain 19:34:12 loss: 0.7657 Lr: 0.00113
[2025-05-11 13:42:19,904 INFO misc.py line 117 288342] Train: [2/50][60/2344] Data 0.003 (0.003) Batch 0.633 (0.614) Remain 19:34:50 loss: 0.9928 Lr: 0.00114
[2025-05-11 13:42:20,696 INFO misc.py line 117 288342] Train: [2/50][61/2344] Data 0.002 (0.003) Batch 0.792 (0.617) Remain 19:40:41 loss: 1.0524 Lr: 0.00114
[2025-05-11 13:42:21,428 INFO misc.py line 117 288342] Train: [2/50][62/2344] Data 0.003 (0.003) Batch 0.733 (0.619) Remain 19:44:25 loss: 0.9046 Lr: 0.00114
[2025-05-11 13:42:22,093 INFO misc.py line 117 288342] Train: [2/50][63/2344] Data 0.003 (0.003) Batch 0.665 (0.620) Remain 19:45:52 loss: 1.0653 Lr: 0.00114
[2025-05-11 13:42:22,669 INFO misc.py line 117 288342] Train: [2/50][64/2344] Data 0.003 (0.003) Batch 0.576 (0.619) Remain 19:44:29 loss: 0.8299 Lr: 0.00114
[2025-05-11 13:42:23,158 INFO misc.py line 117 288342] Train: [2/50][65/2344] Data 0.003 (0.003) Batch 0.489 (0.617) Remain 19:40:28 loss: 0.7778 Lr: 0.00114
[2025-05-11 13:42:23,792 INFO misc.py line 117 288342] Train: [2/50][66/2344] Data 0.003 (0.003) Batch 0.634 (0.617) Remain 19:40:58 loss: 0.8332 Lr: 0.00114
[2025-05-11 13:42:24,467 INFO misc.py line 117 288342] Train: [2/50][67/2344] Data 0.003 (0.003) Batch 0.675 (0.618) Remain 19:42:41 loss: 0.8528 Lr: 0.00114
[2025-05-11 13:42:25,196 INFO misc.py line 117 288342] Train: [2/50][68/2344] Data 0.002 (0.003) Batch 0.730 (0.620) Remain 19:45:57 loss: 0.7549 Lr: 0.00114
[2025-05-11 13:42:25,790 INFO misc.py line 117 288342] Train: [2/50][69/2344] Data 0.002 (0.003) Batch 0.594 (0.620) Remain 19:45:11 loss: 0.6950 Lr: 0.00114
[2025-05-11 13:42:26,432 INFO misc.py line 117 288342] Train: [2/50][70/2344] Data 0.002 (0.003) Batch 0.641 (0.620) Remain 19:45:48 loss: 1.0527 Lr: 0.00114
[2025-05-11 13:42:27,012 INFO misc.py line 117 288342] Train: [2/50][71/2344] Data 0.002 (0.003) Batch 0.580 (0.619) Remain 19:44:40 loss: 0.6355 Lr: 0.00114
[2025-05-11 13:42:27,772 INFO misc.py line 117 288342] Train: [2/50][72/2344] Data 0.002 (0.003) Batch 0.761 (0.621) Remain 19:48:34 loss: 0.9830 Lr: 0.00114
[2025-05-11 13:42:28,324 INFO misc.py line 117 288342] Train: [2/50][73/2344] Data 0.003 (0.003) Batch 0.552 (0.620) Remain 19:46:40 loss: 0.8788 Lr: 0.00114
[2025-05-11 13:42:29,033 INFO misc.py line 117 288342] Train: [2/50][74/2344] Data 0.002 (0.003) Batch 0.709 (0.622) Remain 19:49:03 loss: 0.8319 Lr: 0.00114
[2025-05-11 13:42:29,653 INFO misc.py line 117 288342] Train: [2/50][75/2344] Data 0.002 (0.003) Batch 0.620 (0.622) Remain 19:49:00 loss: 0.7661 Lr: 0.00114
[2025-05-11 13:42:30,314 INFO misc.py line 117 288342] Train: [2/50][76/2344] Data 0.003 (0.003) Batch 0.661 (0.622) Remain 19:50:01 loss: 0.8094 Lr: 0.00114
[2025-05-11 13:42:30,825 INFO misc.py line 117 288342] Train: [2/50][77/2344] Data 0.002 (0.003) Batch 0.510 (0.621) Remain 19:47:07 loss: 0.8255 Lr: 0.00115
[2025-05-11 13:42:31,514 INFO misc.py line 117 288342] Train: [2/50][78/2344] Data 0.003 (0.003) Batch 0.690 (0.621) Remain 19:48:53 loss: 0.7887 Lr: 0.00115
[2025-05-11 13:42:32,219 INFO misc.py line 117 288342] Train: [2/50][79/2344] Data 0.002 (0.003) Batch 0.705 (0.623) Remain 19:50:58 loss: 0.8610 Lr: 0.00115
[2025-05-11 13:42:32,921 INFO misc.py line 117 288342] Train: [2/50][80/2344] Data 0.003 (0.003) Batch 0.701 (0.624) Remain 19:52:55 loss: 0.7920 Lr: 0.00115
[2025-05-11 13:42:33,556 INFO misc.py line 117 288342] Train: [2/50][81/2344] Data 0.002 (0.003) Batch 0.636 (0.624) Remain 19:53:12 loss: 0.5827 Lr: 0.00115
[2025-05-11 13:42:34,132 INFO misc.py line 117 288342] Train: [2/50][82/2344] Data 0.002 (0.003) Batch 0.576 (0.623) Remain 19:52:02 loss: 0.9350 Lr: 0.00115
[2025-05-11 13:42:34,748 INFO misc.py line 117 288342] Train: [2/50][83/2344] Data 0.002 (0.003) Batch 0.616 (0.623) Remain 19:51:51 loss: 0.8149 Lr: 0.00115
[2025-05-11 13:42:35,304 INFO misc.py line 117 288342] Train: [2/50][84/2344] Data 0.003 (0.003) Batch 0.556 (0.622) Remain 19:50:15 loss: 0.9315 Lr: 0.00115
[2025-05-11 13:42:35,893 INFO misc.py line 117 288342] Train: [2/50][85/2344] Data 0.003 (0.003) Batch 0.589 (0.622) Remain 19:49:28 loss: 0.9619 Lr: 0.00115
[2025-05-11 13:42:36,509 INFO misc.py line 117 288342] Train: [2/50][86/2344] Data 0.003 (0.003) Batch 0.616 (0.622) Remain 19:49:19 loss: 0.7377 Lr: 0.00115
[2025-05-11 13:42:37,203 INFO misc.py line 117 288342] Train: [2/50][87/2344] Data 0.003 (0.003) Batch 0.694 (0.623) Remain 19:50:57 loss: 0.9004 Lr: 0.00115
[2025-05-11 13:42:37,795 INFO misc.py line 117 288342] Train: [2/50][88/2344] Data 0.003 (0.003) Batch 0.592 (0.622) Remain 19:50:15 loss: 0.7490 Lr: 0.00115
[2025-05-11 13:42:38,398 INFO misc.py line 117 288342] Train: [2/50][89/2344] Data 0.003 (0.003) Batch 0.603 (0.622) Remain 19:49:48 loss: 0.9175 Lr: 0.00115
[2025-05-11 13:42:39,051 INFO misc.py line 117 288342] Train: [2/50][90/2344] Data 0.003 (0.003) Batch 0.653 (0.622) Remain 19:50:28 loss: 0.9144 Lr: 0.00115
[2025-05-11 13:42:39,658 INFO misc.py line 117 288342] Train: [2/50][91/2344] Data 0.003 (0.003) Batch 0.607 (0.622) Remain 19:50:08 loss: 0.9216 Lr: 0.00115
[2025-05-11 13:42:40,224 INFO misc.py line 117 288342] Train: [2/50][92/2344] Data 0.002 (0.003) Batch 0.566 (0.622) Remain 19:48:55 loss: 0.9298 Lr: 0.00115
[2025-05-11 13:42:40,846 INFO misc.py line 117 288342] Train: [2/50][93/2344] Data 0.002 (0.003) Batch 0.622 (0.622) Remain 19:48:55 loss: 0.8548 Lr: 0.00116
[2025-05-11 13:42:41,417 INFO misc.py line 117 288342] Train: [2/50][94/2344] Data 0.003 (0.003) Batch 0.571 (0.621) Remain 19:47:50 loss: 1.1503 Lr: 0.00116
[2025-05-11 13:42:41,957 INFO misc.py line 117 288342] Train: [2/50][95/2344] Data 0.002 (0.003) Batch 0.540 (0.620) Remain 19:46:09 loss: 0.7353 Lr: 0.00116
[2025-05-11 13:42:42,538 INFO misc.py line 117 288342] Train: [2/50][96/2344] Data 0.003 (0.003) Batch 0.581 (0.620) Remain 19:45:20 loss: 1.0278 Lr: 0.00116
[2025-05-11 13:42:43,225 INFO misc.py line 117 288342] Train: [2/50][97/2344] Data 0.003 (0.003) Batch 0.688 (0.620) Remain 19:46:42 loss: 0.8609 Lr: 0.00116
[2025-05-11 13:42:43,845 INFO misc.py line 117 288342] Train: [2/50][98/2344] Data 0.003 (0.003) Batch 0.619 (0.620) Remain 19:46:40 loss: 0.8240 Lr: 0.00116
[2025-05-11 13:42:44,402 INFO misc.py line 117 288342] Train: [2/50][99/2344] Data 0.002 (0.003) Batch 0.557 (0.620) Remain 19:45:24 loss: 0.9441 Lr: 0.00116
[2025-05-11 13:42:45,078 INFO misc.py line 117 288342] Train: [2/50][100/2344] Data 0.003 (0.003) Batch 0.676 (0.620) Remain 19:46:29 loss: 0.8589 Lr: 0.00116
[2025-05-11 13:42:45,789 INFO misc.py line 117 288342] Train: [2/50][101/2344] Data 0.003 (0.003) Batch 0.712 (0.621) Remain 19:48:16 loss: 0.8688 Lr: 0.00116
[2025-05-11 13:42:46,431 INFO misc.py line 117 288342] Train: [2/50][102/2344] Data 0.003 (0.003) Batch 0.642 (0.621) Remain 19:48:39 loss: 0.7088 Lr: 0.00116
[2025-05-11 13:42:47,029 INFO misc.py line 117 288342] Train: [2/50][103/2344] Data 0.003 (0.003) Batch 0.598 (0.621) Remain 19:48:11 loss: 0.8533 Lr: 0.00116
[2025-05-11 13:42:47,626 INFO misc.py line 117 288342] Train: [2/50][104/2344] Data 0.003 (0.003) Batch 0.596 (0.621) Remain 19:47:42 loss: 0.6525 Lr: 0.00116
[2025-05-11 13:42:48,223 INFO misc.py line 117 288342] Train: [2/50][105/2344] Data 0.003 (0.003) Batch 0.597 (0.621) Remain 19:47:15 loss: 0.9865 Lr: 0.00116
[2025-05-11 13:42:48,745 INFO misc.py line 117 288342] Train: [2/50][106/2344] Data 0.003 (0.003) Batch 0.523 (0.620) Remain 19:45:25 loss: 0.7303 Lr: 0.00116
[2025-05-11 13:42:49,327 INFO misc.py line 117 288342] Train: [2/50][107/2344] Data 0.003 (0.003) Batch 0.582 (0.619) Remain 19:44:42 loss: 1.2942 Lr: 0.00116
[2025-05-11 13:42:49,871 INFO misc.py line 117 288342] Train: [2/50][108/2344] Data 0.003 (0.003) Batch 0.544 (0.619) Remain 19:43:19 loss: 0.8599 Lr: 0.00116
[2025-05-11 13:42:50,540 INFO misc.py line 117 288342] Train: [2/50][109/2344] Data 0.002 (0.003) Batch 0.669 (0.619) Remain 19:44:13 loss: 1.0726 Lr: 0.00116
[2025-05-11 13:42:51,240 INFO misc.py line 117 288342] Train: [2/50][110/2344] Data 0.002 (0.003) Batch 0.700 (0.620) Remain 19:45:39 loss: 0.8668 Lr: 0.00117
[2025-05-11 13:42:51,850 INFO misc.py line 117 288342] Train: [2/50][111/2344] Data 0.003 (0.003) Batch 0.610 (0.620) Remain 19:45:27 loss: 0.8796 Lr: 0.00117
[2025-05-11 13:42:52,520 INFO misc.py line 117 288342] Train: [2/50][112/2344] Data 0.002 (0.003) Batch 0.670 (0.620) Remain 19:46:19 loss: 0.8504 Lr: 0.00117
[2025-05-11 13:42:53,061 INFO misc.py line 117 288342] Train: [2/50][113/2344] Data 0.002 (0.003) Batch 0.541 (0.620) Remain 19:44:56 loss: 0.6612 Lr: 0.00117
[2025-05-11 13:42:53,660 INFO misc.py line 117 288342] Train: [2/50][114/2344] Data 0.002 (0.003) Batch 0.599 (0.619) Remain 19:44:34 loss: 1.4180 Lr: 0.00117
[2025-05-11 13:42:54,306 INFO misc.py line 117 288342] Train: [2/50][115/2344] Data 0.003 (0.003) Batch 0.646 (0.620) Remain 19:45:01 loss: 1.2076 Lr: 0.00117
[2025-05-11 13:42:54,772 INFO misc.py line 117 288342] Train: [2/50][116/2344] Data 0.003 (0.003) Batch 0.465 (0.618) Remain 19:42:24 loss: 0.8409 Lr: 0.00117
[2025-05-11 13:42:55,331 INFO misc.py line 117 288342] Train: [2/50][117/2344] Data 0.003 (0.003) Batch 0.559 (0.618) Remain 19:41:24 loss: 1.0062 Lr: 0.00117
[2025-05-11 13:42:55,959 INFO misc.py line 117 288342] Train: [2/50][118/2344] Data 0.003 (0.003) Batch 0.628 (0.618) Remain 19:41:34 loss: 0.7305 Lr: 0.00117
[2025-05-11 13:42:56,623 INFO misc.py line 117 288342] Train: [2/50][119/2344] Data 0.003 (0.003) Batch 0.664 (0.618) Remain 19:42:19 loss: 0.8038 Lr: 0.00117
[2025-05-11 13:42:57,241 INFO misc.py line 117 288342] Train: [2/50][120/2344] Data 0.003 (0.003) Batch 0.618 (0.618) Remain 19:42:18 loss: 0.8613 Lr: 0.00117
[2025-05-11 13:42:57,955 INFO misc.py line 117 288342] Train: [2/50][121/2344] Data 0.002 (0.003) Batch 0.714 (0.619) Remain 19:43:50 loss: 0.7736 Lr: 0.00117
[2025-05-11 13:42:58,414 INFO misc.py line 117 288342] Train: [2/50][122/2344] Data 0.003 (0.003) Batch 0.459 (0.618) Remain 19:41:15 loss: 0.9018 Lr: 0.00117
[2025-05-11 13:42:58,990 INFO misc.py line 117 288342] Train: [2/50][123/2344] Data 0.005 (0.003) Batch 0.577 (0.617) Remain 19:40:35 loss: 0.8429 Lr: 0.00117
[2025-05-11 13:42:59,618 INFO misc.py line 117 288342] Train: [2/50][124/2344] Data 0.002 (0.003) Batch 0.628 (0.617) Remain 19:40:45 loss: 0.7020 Lr: 0.00117
[2025-05-11 13:43:00,215 INFO misc.py line 117 288342] Train: [2/50][125/2344] Data 0.002 (0.003) Batch 0.597 (0.617) Remain 19:40:25 loss: 0.8174 Lr: 0.00117
[2025-05-11 13:43:00,714 INFO misc.py line 117 288342] Train: [2/50][126/2344] Data 0.002 (0.003) Batch 0.499 (0.616) Remain 19:38:33 loss: 0.9492 Lr: 0.00118
[2025-05-11 13:43:01,252 INFO misc.py line 117 288342] Train: [2/50][127/2344] Data 0.003 (0.003) Batch 0.538 (0.616) Remain 19:37:20 loss: 0.7819 Lr: 0.00118
[2025-05-11 13:43:01,859 INFO misc.py line 117 288342] Train: [2/50][128/2344] Data 0.003 (0.003) Batch 0.607 (0.616) Remain 19:37:12 loss: 0.7515 Lr: 0.00118
[2025-05-11 13:43:03,190 INFO misc.py line 117 288342] Train: [2/50][129/2344] Data 0.002 (0.003) Batch 1.331 (0.621) Remain 19:48:02 loss: 0.6484 Lr: 0.00118
[2025-05-11 13:43:03,861 INFO misc.py line 117 288342] Train: [2/50][130/2344] Data 0.003 (0.003) Batch 0.671 (0.622) Remain 19:48:46 loss: 0.8920 Lr: 0.00118
[2025-05-11 13:43:04,520 INFO misc.py line 117 288342] Train: [2/50][131/2344] Data 0.003 (0.003) Batch 0.659 (0.622) Remain 19:49:19 loss: 0.9482 Lr: 0.00118
[2025-05-11 13:43:05,256 INFO misc.py line 117 288342] Train: [2/50][132/2344] Data 0.003 (0.003) Batch 0.736 (0.623) Remain 19:51:00 loss: 0.8196 Lr: 0.00118
[2025-05-11 13:43:05,754 INFO misc.py line 117 288342] Train: [2/50][133/2344] Data 0.003 (0.003) Batch 0.498 (0.622) Remain 19:49:09 loss: 0.7892 Lr: 0.00118
[2025-05-11 13:43:06,305 INFO misc.py line 117 288342] Train: [2/50][134/2344] Data 0.003 (0.003) Batch 0.551 (0.621) Remain 19:48:07 loss: 0.9009 Lr: 0.00118
[2025-05-11 13:43:06,963 INFO misc.py line 117 288342] Train: [2/50][135/2344] Data 0.003 (0.003) Batch 0.658 (0.622) Remain 19:48:38 loss: 0.8065 Lr: 0.00118
[2025-05-11 13:43:07,467 INFO misc.py line 117 288342] Train: [2/50][136/2344] Data 0.003 (0.003) Batch 0.504 (0.621) Remain 19:46:56 loss: 0.8184 Lr: 0.00118
[2025-05-11 13:43:08,116 INFO misc.py line 117 288342] Train: [2/50][137/2344] Data 0.002 (0.003) Batch 0.649 (0.621) Remain 19:47:19 loss: 0.7639 Lr: 0.00118
[2025-05-11 13:43:08,770 INFO misc.py line 117 288342] Train: [2/50][138/2344] Data 0.003 (0.003) Batch 0.654 (0.621) Remain 19:47:47 loss: 0.6021 Lr: 0.00118
[2025-05-11 13:43:09,379 INFO misc.py line 117 288342] Train: [2/50][139/2344] Data 0.002 (0.003) Batch 0.609 (0.621) Remain 19:47:36 loss: 0.7297 Lr: 0.00118
[2025-05-11 13:43:10,032 INFO misc.py line 117 288342] Train: [2/50][140/2344] Data 0.002 (0.003) Batch 0.653 (0.621) Remain 19:48:02 loss: 0.9778 Lr: 0.00118
[2025-05-11 13:43:10,587 INFO misc.py line 117 288342] Train: [2/50][141/2344] Data 0.002 (0.003) Batch 0.554 (0.621) Remain 19:47:06 loss: 0.8970 Lr: 0.00118
[2025-05-11 13:43:11,395 INFO misc.py line 117 288342] Train: [2/50][142/2344] Data 0.003 (0.003) Batch 0.809 (0.622) Remain 19:49:40 loss: 0.8493 Lr: 0.00118
[2025-05-11 13:43:12,018 INFO misc.py line 117 288342] Train: [2/50][143/2344] Data 0.002 (0.003) Batch 0.622 (0.622) Remain 19:49:39 loss: 0.8552 Lr: 0.00119
[2025-05-11 13:43:12,661 INFO misc.py line 117 288342] Train: [2/50][144/2344] Data 0.003 (0.003) Batch 0.643 (0.622) Remain 19:49:56 loss: 0.7006 Lr: 0.00119
[2025-05-11 13:43:13,279 INFO misc.py line 117 288342] Train: [2/50][145/2344] Data 0.002 (0.003) Batch 0.619 (0.622) Remain 19:49:52 loss: 1.1595 Lr: 0.00119
[2025-05-11 13:43:13,829 INFO misc.py line 117 288342] Train: [2/50][146/2344] Data 0.002 (0.003) Batch 0.549 (0.622) Remain 19:48:53 loss: 0.6545 Lr: 0.00119
[2025-05-11 13:43:14,556 INFO misc.py line 117 288342] Train: [2/50][147/2344] Data 0.003 (0.003) Batch 0.727 (0.623) Remain 19:50:16 loss: 0.8086 Lr: 0.00119
[2025-05-11 13:43:15,217 INFO misc.py line 117 288342] Train: [2/50][148/2344] Data 0.003 (0.003) Batch 0.661 (0.623) Remain 19:50:46 loss: 0.8359 Lr: 0.00119
[2025-05-11 13:43:15,852 INFO misc.py line 117 288342] Train: [2/50][149/2344] Data 0.003 (0.003) Batch 0.635 (0.623) Remain 19:50:55 loss: 0.9926 Lr: 0.00119
[2025-05-11 13:43:16,417 INFO misc.py line 117 288342] Train: [2/50][150/2344] Data 0.003 (0.003) Batch 0.565 (0.623) Remain 19:50:09 loss: 0.6425 Lr: 0.00119
[2025-05-11 13:43:17,111 INFO misc.py line 117 288342] Train: [2/50][151/2344] Data 0.003 (0.003) Batch 0.694 (0.623) Remain 19:51:04 loss: 0.6867 Lr: 0.00119
[2025-05-11 13:43:17,605 INFO misc.py line 117 288342] Train: [2/50][152/2344] Data 0.003 (0.003) Batch 0.494 (0.622) Remain 19:49:24 loss: 0.8724 Lr: 0.00119
[2025-05-11 13:43:18,320 INFO misc.py line 117 288342] Train: [2/50][153/2344] Data 0.003 (0.003) Batch 0.715 (0.623) Remain 19:50:35 loss: 0.7649 Lr: 0.00119
[2025-05-11 13:43:18,916 INFO misc.py line 117 288342] Train: [2/50][154/2344] Data 0.003 (0.003) Batch 0.596 (0.623) Remain 19:50:13 loss: 0.7798 Lr: 0.00119
[2025-05-11 13:43:19,468 INFO misc.py line 117 288342] Train: [2/50][155/2344] Data 0.003 (0.003) Batch 0.552 (0.622) Remain 19:49:20 loss: 0.8598 Lr: 0.00119
[2025-05-11 13:43:19,989 INFO misc.py line 117 288342] Train: [2/50][156/2344] Data 0.003 (0.003) Batch 0.521 (0.621) Remain 19:48:03 loss: 0.7058 Lr: 0.00119
[2025-05-11 13:43:20,636 INFO misc.py line 117 288342] Train: [2/50][157/2344] Data 0.003 (0.003) Batch 0.647 (0.622) Remain 19:48:22 loss: 0.8338 Lr: 0.00119
[2025-05-11 13:43:21,300 INFO misc.py line 117 288342] Train: [2/50][158/2344] Data 0.003 (0.003) Batch 0.663 (0.622) Remain 19:48:52 loss: 0.8438 Lr: 0.00119
[2025-05-11 13:43:21,902 INFO misc.py line 117 288342] Train: [2/50][159/2344] Data 0.003 (0.003) Batch 0.602 (0.622) Remain 19:48:37 loss: 0.8117 Lr: 0.00119
[2025-05-11 13:43:22,452 INFO misc.py line 117 288342] Train: [2/50][160/2344] Data 0.002 (0.003) Batch 0.550 (0.621) Remain 19:47:44 loss: 0.8606 Lr: 0.00120
[2025-05-11 13:43:23,023 INFO misc.py line 117 288342] Train: [2/50][161/2344] Data 0.002 (0.003) Batch 0.571 (0.621) Remain 19:47:06 loss: 0.7293 Lr: 0.00120
[2025-05-11 13:43:23,582 INFO misc.py line 117 288342] Train: [2/50][162/2344] Data 0.003 (0.003) Batch 0.559 (0.621) Remain 19:46:21 loss: 0.6967 Lr: 0.00120
[2025-05-11 13:43:24,141 INFO misc.py line 117 288342] Train: [2/50][163/2344] Data 0.003 (0.003) Batch 0.559 (0.620) Remain 19:45:36 loss: 0.7687 Lr: 0.00120
[2025-05-11 13:43:24,779 INFO misc.py line 117 288342] Train: [2/50][164/2344] Data 0.003 (0.003) Batch 0.638 (0.620) Remain 19:45:49 loss: 0.8632 Lr: 0.00120
[2025-05-11 13:43:25,505 INFO misc.py line 117 288342] Train: [2/50][165/2344] Data 0.003 (0.003) Batch 0.726 (0.621) Remain 19:47:03 loss: 1.3238 Lr: 0.00120
[2025-05-11 13:43:26,132 INFO misc.py line 117 288342] Train: [2/50][166/2344] Data 0.003 (0.003) Batch 0.627 (0.621) Remain 19:47:06 loss: 0.9853 Lr: 0.00120
[2025-05-11 13:43:26,674 INFO misc.py line 117 288342] Train: [2/50][167/2344] Data 0.003 (0.003) Batch 0.543 (0.621) Remain 19:46:10 loss: 0.8005 Lr: 0.00120
[2025-05-11 13:43:27,238 INFO misc.py line 117 288342] Train: [2/50][168/2344] Data 0.003 (0.003) Batch 0.564 (0.620) Remain 19:45:30 loss: 0.8164 Lr: 0.00120
[2025-05-11 13:43:27,818 INFO misc.py line 117 288342] Train: [2/50][169/2344] Data 0.002 (0.003) Batch 0.580 (0.620) Remain 19:45:02 loss: 0.8419 Lr: 0.00120
[2025-05-11 13:43:28,468 INFO misc.py line 117 288342] Train: [2/50][170/2344] Data 0.002 (0.003) Batch 0.650 (0.620) Remain 19:45:22 loss: 0.8010 Lr: 0.00120
[2025-05-11 13:43:29,143 INFO misc.py line 117 288342] Train: [2/50][171/2344] Data 0.003 (0.003) Batch 0.675 (0.620) Remain 19:45:59 loss: 0.8462 Lr: 0.00120
[2025-05-11 13:43:29,763 INFO misc.py line 117 288342] Train: [2/50][172/2344] Data 0.002 (0.003) Batch 0.620 (0.620) Remain 19:45:58 loss: 0.8563 Lr: 0.00120
[2025-05-11 13:43:30,486 INFO misc.py line 117 288342] Train: [2/50][173/2344] Data 0.002 (0.003) Batch 0.723 (0.621) Remain 19:47:07 loss: 0.8791 Lr: 0.00120
[2025-05-11 13:43:30,972 INFO misc.py line 117 288342] Train: [2/50][174/2344] Data 0.003 (0.003) Batch 0.486 (0.620) Remain 19:45:35 loss: 1.2030 Lr: 0.00120
[2025-05-11 13:43:31,543 INFO misc.py line 117 288342] Train: [2/50][175/2344] Data 0.003 (0.003) Batch 0.571 (0.620) Remain 19:45:02 loss: 0.9261 Lr: 0.00120
[2025-05-11 13:43:32,179 INFO misc.py line 117 288342] Train: [2/50][176/2344] Data 0.003 (0.003) Batch 0.635 (0.620) Remain 19:45:11 loss: 0.9440 Lr: 0.00121
[2025-05-11 13:43:32,880 INFO misc.py line 117 288342] Train: [2/50][177/2344] Data 0.003 (0.003) Batch 0.701 (0.621) Remain 19:46:04 loss: 0.8272 Lr: 0.00121
[2025-05-11 13:43:33,432 INFO misc.py line 117 288342] Train: [2/50][178/2344] Data 0.003 (0.003) Batch 0.552 (0.620) Remain 19:45:19 loss: 0.8038 Lr: 0.00121
[2025-05-11 13:43:33,911 INFO misc.py line 117 288342] Train: [2/50][179/2344] Data 0.003 (0.003) Batch 0.479 (0.619) Remain 19:43:46 loss: 0.8488 Lr: 0.00121
[2025-05-11 13:43:34,564 INFO misc.py line 117 288342] Train: [2/50][180/2344] Data 0.002 (0.003) Batch 0.653 (0.620) Remain 19:44:08 loss: 1.0713 Lr: 0.00121
[2025-05-11 13:43:35,139 INFO misc.py line 117 288342] Train: [2/50][181/2344] Data 0.002 (0.003) Batch 0.575 (0.619) Remain 19:43:38 loss: 0.8141 Lr: 0.00121
[2025-05-11 13:43:36,363 INFO misc.py line 117 288342] Train: [2/50][182/2344] Data 0.002 (0.003) Batch 1.224 (0.623) Remain 19:50:05 loss: 0.8369 Lr: 0.00121
[2025-05-11 13:43:36,988 INFO misc.py line 117 288342] Train: [2/50][183/2344] Data 0.002 (0.003) Batch 0.625 (0.623) Remain 19:50:05 loss: 0.9037 Lr: 0.00121
[2025-05-11 13:43:37,607 INFO misc.py line 117 288342] Train: [2/50][184/2344] Data 0.002 (0.003) Batch 0.619 (0.623) Remain 19:50:03 loss: 0.8651 Lr: 0.00121
[2025-05-11 13:43:38,080 INFO misc.py line 117 288342] Train: [2/50][185/2344] Data 0.002 (0.003) Batch 0.473 (0.622) Remain 19:48:28 loss: 0.8651 Lr: 0.00121
[2025-05-11 13:43:38,665 INFO misc.py line 117 288342] Train: [2/50][186/2344] Data 0.003 (0.003) Batch 0.585 (0.622) Remain 19:48:04 loss: 0.8244 Lr: 0.00121
[2025-05-11 13:43:39,283 INFO misc.py line 117 288342] Train: [2/50][187/2344] Data 0.003 (0.003) Batch 0.618 (0.622) Remain 19:48:01 loss: 0.9012 Lr: 0.00121
[2025-05-11 13:43:39,863 INFO misc.py line 117 288342] Train: [2/50][188/2344] Data 0.003 (0.003) Batch 0.580 (0.621) Remain 19:47:35 loss: 1.0813 Lr: 0.00121
[2025-05-11 13:43:41,138 INFO misc.py line 117 288342] Train: [2/50][189/2344] Data 0.003 (0.003) Batch 1.275 (0.625) Remain 19:54:17 loss: 0.7572 Lr: 0.00121
[2025-05-11 13:43:41,925 INFO misc.py line 117 288342] Train: [2/50][190/2344] Data 0.003 (0.003) Batch 0.788 (0.626) Remain 19:55:56 loss: 0.9413 Lr: 0.00121
[2025-05-11 13:43:42,497 INFO misc.py line 117 288342] Train: [2/50][191/2344] Data 0.003 (0.003) Batch 0.572 (0.625) Remain 19:55:22 loss: 0.9122 Lr: 0.00121
[2025-05-11 13:43:43,248 INFO misc.py line 117 288342] Train: [2/50][192/2344] Data 0.003 (0.003) Batch 0.751 (0.626) Remain 19:56:38 loss: 0.9794 Lr: 0.00121
[2025-05-11 13:43:43,977 INFO misc.py line 117 288342] Train: [2/50][193/2344] Data 0.006 (0.003) Batch 0.729 (0.627) Remain 19:57:39 loss: 0.8482 Lr: 0.00122
[2025-05-11 13:43:44,628 INFO misc.py line 117 288342] Train: [2/50][194/2344] Data 0.003 (0.003) Batch 0.651 (0.627) Remain 19:57:54 loss: 0.8778 Lr: 0.00122
[2025-05-11 13:43:45,198 INFO misc.py line 117 288342] Train: [2/50][195/2344] Data 0.003 (0.003) Batch 0.570 (0.627) Remain 19:57:19 loss: 0.5591 Lr: 0.00122
[2025-05-11 13:43:45,771 INFO misc.py line 117 288342] Train: [2/50][196/2344] Data 0.003 (0.003) Batch 0.573 (0.626) Remain 19:56:46 loss: 0.8321 Lr: 0.00122
[2025-05-11 13:43:46,229 INFO misc.py line 117 288342] Train: [2/50][197/2344] Data 0.003 (0.003) Batch 0.458 (0.625) Remain 19:55:07 loss: 0.6853 Lr: 0.00122
[2025-05-11 13:43:46,880 INFO misc.py line 117 288342] Train: [2/50][198/2344] Data 0.003 (0.003) Batch 0.651 (0.626) Remain 19:55:21 loss: 1.0175 Lr: 0.00122
[2025-05-11 13:43:47,383 INFO misc.py line 117 288342] Train: [2/50][199/2344] Data 0.003 (0.003) Batch 0.503 (0.625) Remain 19:54:08 loss: 1.0385 Lr: 0.00122
[2025-05-11 13:43:47,860 INFO misc.py line 117 288342] Train: [2/50][200/2344] Data 0.003 (0.003) Batch 0.477 (0.624) Remain 19:52:42 loss: 0.7926 Lr: 0.00122
[2025-05-11 13:43:48,421 INFO misc.py line 117 288342] Train: [2/50][201/2344] Data 0.003 (0.003) Batch 0.561 (0.624) Remain 19:52:05 loss: 0.8026 Lr: 0.00122
[2025-05-11 13:43:49,130 INFO misc.py line 117 288342] Train: [2/50][202/2344] Data 0.003 (0.003) Batch 0.708 (0.624) Remain 19:52:53 loss: 0.8023 Lr: 0.00122
[2025-05-11 13:43:49,752 INFO misc.py line 117 288342] Train: [2/50][203/2344] Data 0.003 (0.003) Batch 0.623 (0.624) Remain 19:52:51 loss: 0.7805 Lr: 0.00122
[2025-05-11 13:43:50,327 INFO misc.py line 117 288342] Train: [2/50][204/2344] Data 0.003 (0.003) Batch 0.574 (0.624) Remain 19:52:22 loss: 0.7374 Lr: 0.00122
[2025-05-11 13:43:50,951 INFO misc.py line 117 288342] Train: [2/50][205/2344] Data 0.003 (0.003) Batch 0.625 (0.624) Remain 19:52:22 loss: 0.8435 Lr: 0.00122
[2025-05-11 13:43:51,502 INFO misc.py line 117 288342] Train: [2/50][206/2344] Data 0.003 (0.003) Batch 0.551 (0.624) Remain 19:51:40 loss: 0.9139 Lr: 0.00122
[2025-05-11 13:43:52,067 INFO misc.py line 117 288342] Train: [2/50][207/2344] Data 0.002 (0.003) Batch 0.565 (0.623) Remain 19:51:06 loss: 0.6904 Lr: 0.00122
[2025-05-11 13:43:52,760 INFO misc.py line 117 288342] Train: [2/50][208/2344] Data 0.002 (0.003) Batch 0.693 (0.624) Remain 19:51:44 loss: 0.6963 Lr: 0.00122
[2025-05-11 13:43:53,374 INFO misc.py line 117 288342] Train: [2/50][209/2344] Data 0.003 (0.003) Batch 0.614 (0.624) Remain 19:51:38 loss: 0.8529 Lr: 0.00122
[2025-05-11 13:43:53,954 INFO misc.py line 117 288342] Train: [2/50][210/2344] Data 0.002 (0.003) Batch 0.580 (0.623) Remain 19:51:14 loss: 0.7619 Lr: 0.00123
[2025-05-11 13:43:54,639 INFO misc.py line 117 288342] Train: [2/50][211/2344] Data 0.002 (0.003) Batch 0.686 (0.624) Remain 19:51:47 loss: 0.6228 Lr: 0.00123
[2025-05-11 13:43:55,224 INFO misc.py line 117 288342] Train: [2/50][212/2344] Data 0.002 (0.003) Batch 0.585 (0.624) Remain 19:51:25 loss: 0.8114 Lr: 0.00123
[2025-05-11 13:43:55,761 INFO misc.py line 117 288342] Train: [2/50][213/2344] Data 0.002 (0.003) Batch 0.536 (0.623) Remain 19:50:37 loss: 0.9052 Lr: 0.00123
[2025-05-11 13:43:56,336 INFO misc.py line 117 288342] Train: [2/50][214/2344] Data 0.003 (0.003) Batch 0.575 (0.623) Remain 19:50:11 loss: 0.6909 Lr: 0.00123
[2025-05-11 13:43:56,986 INFO misc.py line 117 288342] Train: [2/50][215/2344] Data 0.003 (0.003) Batch 0.650 (0.623) Remain 19:50:25 loss: 0.8229 Lr: 0.00123
[2025-05-11 13:43:57,705 INFO misc.py line 117 288342] Train: [2/50][216/2344] Data 0.003 (0.003) Batch 0.719 (0.623) Remain 19:51:16 loss: 0.5762 Lr: 0.00123
[2025-05-11 13:43:58,302 INFO misc.py line 117 288342] Train: [2/50][217/2344] Data 0.002 (0.003) Batch 0.597 (0.623) Remain 19:51:01 loss: 0.8395 Lr: 0.00123
[2025-05-11 13:43:58,954 INFO misc.py line 117 288342] Train: [2/50][218/2344] Data 0.003 (0.003) Batch 0.652 (0.623) Remain 19:51:16 loss: 0.6796 Lr: 0.00123
[2025-05-11 13:43:59,611 INFO misc.py line 117 288342] Train: [2/50][219/2344] Data 0.003 (0.003) Batch 0.656 (0.624) Remain 19:51:33 loss: 0.7959 Lr: 0.00123
[2025-05-11 13:44:00,301 INFO misc.py line 117 288342] Train: [2/50][220/2344] Data 0.003 (0.003) Batch 0.690 (0.624) Remain 19:52:07 loss: 0.8086 Lr: 0.00123
[2025-05-11 13:44:00,854 INFO misc.py line 117 288342] Train: [2/50][221/2344] Data 0.003 (0.003) Batch 0.553 (0.624) Remain 19:51:29 loss: 0.8002 Lr: 0.00123
[2025-05-11 13:44:01,379 INFO misc.py line 117 288342] Train: [2/50][222/2344] Data 0.003 (0.003) Batch 0.525 (0.623) Remain 19:50:37 loss: 0.8330 Lr: 0.00123
[2025-05-11 13:44:01,915 INFO misc.py line 117 288342] Train: [2/50][223/2344] Data 0.003 (0.003) Batch 0.535 (0.623) Remain 19:49:51 loss: 1.0635 Lr: 0.00123
[2025-05-11 13:44:02,360 INFO misc.py line 117 288342] Train: [2/50][224/2344] Data 0.003 (0.003) Batch 0.445 (0.622) Remain 19:48:18 loss: 0.8360 Lr: 0.00123
[2025-05-11 13:44:03,043 INFO misc.py line 117 288342] Train: [2/50][225/2344] Data 0.003 (0.003) Batch 0.683 (0.622) Remain 19:48:49 loss: 0.6883 Lr: 0.00123
[2025-05-11 13:44:03,677 INFO misc.py line 117 288342] Train: [2/50][226/2344] Data 0.003 (0.003) Batch 0.634 (0.622) Remain 19:48:54 loss: 1.0142 Lr: 0.00123
[2025-05-11 13:44:04,321 INFO misc.py line 117 288342] Train: [2/50][227/2344] Data 0.003 (0.003) Batch 0.644 (0.622) Remain 19:49:05 loss: 0.8547 Lr: 0.00124
[2025-05-11 13:44:05,025 INFO misc.py line 117 288342] Train: [2/50][228/2344] Data 0.003 (0.003) Batch 0.704 (0.623) Remain 19:49:46 loss: 0.7953 Lr: 0.00124
[2025-05-11 13:44:05,631 INFO misc.py line 117 288342] Train: [2/50][229/2344] Data 0.003 (0.003) Batch 0.606 (0.623) Remain 19:49:37 loss: 0.7653 Lr: 0.00124
[2025-05-11 13:44:06,242 INFO misc.py line 117 288342] Train: [2/50][230/2344] Data 0.003 (0.003) Batch 0.611 (0.623) Remain 19:49:30 loss: 0.8670 Lr: 0.00124
[2025-05-11 13:44:06,885 INFO misc.py line 117 288342] Train: [2/50][231/2344] Data 0.003 (0.003) Batch 0.643 (0.623) Remain 19:49:40 loss: 0.7719 Lr: 0.00124
[2025-05-11 13:44:07,491 INFO misc.py line 117 288342] Train: [2/50][232/2344] Data 0.003 (0.003) Batch 0.605 (0.623) Remain 19:49:30 loss: 0.9459 Lr: 0.00124
[2025-05-11 13:44:08,141 INFO misc.py line 117 288342] Train: [2/50][233/2344] Data 0.003 (0.003) Batch 0.651 (0.623) Remain 19:49:44 loss: 0.7723 Lr: 0.00124
[2025-05-11 13:44:08,830 INFO misc.py line 117 288342] Train: [2/50][234/2344] Data 0.003 (0.003) Batch 0.689 (0.623) Remain 19:50:16 loss: 0.7305 Lr: 0.00124
[2025-05-11 13:44:09,393 INFO misc.py line 117 288342] Train: [2/50][235/2344] Data 0.002 (0.003) Batch 0.563 (0.623) Remain 19:49:46 loss: 0.6449 Lr: 0.00124
[2025-05-11 13:44:09,978 INFO misc.py line 117 288342] Train: [2/50][236/2344] Data 0.003 (0.003) Batch 0.585 (0.623) Remain 19:49:26 loss: 0.8966 Lr: 0.00124
[2025-05-11 13:44:10,695 INFO misc.py line 117 288342] Train: [2/50][237/2344] Data 0.003 (0.003) Batch 0.718 (0.623) Remain 19:50:12 loss: 0.8979 Lr: 0.00124
[2025-05-11 13:44:11,347 INFO misc.py line 117 288342] Train: [2/50][238/2344] Data 0.003 (0.003) Batch 0.651 (0.623) Remain 19:50:25 loss: 1.0589 Lr: 0.00124
[2025-05-11 13:44:11,896 INFO misc.py line 117 288342] Train: [2/50][239/2344] Data 0.003 (0.003) Batch 0.549 (0.623) Remain 19:49:49 loss: 0.8226 Lr: 0.00124
[2025-05-11 13:44:12,512 INFO misc.py line 117 288342] Train: [2/50][240/2344] Data 0.003 (0.003) Batch 0.616 (0.623) Remain 19:49:45 loss: 0.8241 Lr: 0.00124
[2025-05-11 13:44:13,040 INFO misc.py line 117 288342] Train: [2/50][241/2344] Data 0.003 (0.003) Batch 0.528 (0.622) Remain 19:48:58 loss: 1.0681 Lr: 0.00124
[2025-05-11 13:44:13,581 INFO misc.py line 117 288342] Train: [2/50][242/2344] Data 0.003 (0.003) Batch 0.542 (0.622) Remain 19:48:19 loss: 0.7846 Lr: 0.00124
[2025-05-11 13:44:14,179 INFO misc.py line 117 288342] Train: [2/50][243/2344] Data 0.003 (0.003) Batch 0.598 (0.622) Remain 19:48:07 loss: 0.9837 Lr: 0.00125
[2025-05-11 13:44:14,762 INFO misc.py line 117 288342] Train: [2/50][244/2344] Data 0.002 (0.003) Batch 0.582 (0.622) Remain 19:47:48 loss: 0.8929 Lr: 0.00125
[2025-05-11 13:44:15,265 INFO misc.py line 117 288342] Train: [2/50][245/2344] Data 0.003 (0.003) Batch 0.503 (0.621) Remain 19:46:51 loss: 0.8203 Lr: 0.00125
[2025-05-11 13:44:15,830 INFO misc.py line 117 288342] Train: [2/50][246/2344] Data 0.003 (0.003) Batch 0.565 (0.621) Remain 19:46:24 loss: 0.8203 Lr: 0.00125
[2025-05-11 13:44:16,483 INFO misc.py line 117 288342] Train: [2/50][247/2344] Data 0.002 (0.003) Batch 0.653 (0.621) Remain 19:46:38 loss: 0.6783 Lr: 0.00125
[2025-05-11 13:44:17,046 INFO misc.py line 117 288342] Train: [2/50][248/2344] Data 0.003 (0.003) Batch 0.564 (0.621) Remain 19:46:10 loss: 0.7298 Lr: 0.00125
[2025-05-11 13:44:17,496 INFO misc.py line 117 288342] Train: [2/50][249/2344] Data 0.002 (0.003) Batch 0.449 (0.620) Remain 19:44:50 loss: 0.7807 Lr: 0.00125
[2025-05-11 13:44:17,980 INFO misc.py line 117 288342] Train: [2/50][250/2344] Data 0.003 (0.003) Batch 0.484 (0.620) Remain 19:43:46 loss: 0.9505 Lr: 0.00125
[2025-05-11 13:44:18,624 INFO misc.py line 117 288342] Train: [2/50][251/2344] Data 0.003 (0.003) Batch 0.644 (0.620) Remain 19:43:57 loss: 1.0031 Lr: 0.00125
[2025-05-11 13:44:19,181 INFO misc.py line 117 288342] Train: [2/50][252/2344] Data 0.003 (0.003) Batch 0.557 (0.620) Remain 19:43:27 loss: 0.8998 Lr: 0.00125
[2025-05-11 13:44:19,821 INFO misc.py line 117 288342] Train: [2/50][253/2344] Data 0.003 (0.003) Batch 0.640 (0.620) Remain 19:43:36 loss: 0.7424 Lr: 0.00125
[2025-05-11 13:44:20,398 INFO misc.py line 117 288342] Train: [2/50][254/2344] Data 0.003 (0.003) Batch 0.577 (0.620) Remain 19:43:16 loss: 0.9055 Lr: 0.00125
[2025-05-11 13:44:20,930 INFO misc.py line 117 288342] Train: [2/50][255/2344] Data 0.003 (0.003) Batch 0.532 (0.619) Remain 19:42:35 loss: 0.7435 Lr: 0.00125
[2025-05-11 13:44:21,537 INFO misc.py line 117 288342] Train: [2/50][256/2344] Data 0.003 (0.003) Batch 0.607 (0.619) Remain 19:42:29 loss: 0.8141 Lr: 0.00125
[2025-05-11 13:44:22,210 INFO misc.py line 117 288342] Train: [2/50][257/2344] Data 0.002 (0.003) Batch 0.673 (0.619) Remain 19:42:53 loss: 0.9901 Lr: 0.00125
[2025-05-11 13:44:22,882 INFO misc.py line 117 288342] Train: [2/50][258/2344] Data 0.003 (0.003) Batch 0.672 (0.620) Remain 19:43:16 loss: 0.7596 Lr: 0.00125
[2025-05-11 13:44:23,548 INFO misc.py line 117 288342] Train: [2/50][259/2344] Data 0.002 (0.003) Batch 0.666 (0.620) Remain 19:43:36 loss: 0.9440 Lr: 0.00125
[2025-05-11 13:44:24,265 INFO misc.py line 117 288342] Train: [2/50][260/2344] Data 0.002 (0.003) Batch 0.717 (0.620) Remain 19:44:19 loss: 0.7229 Lr: 0.00126
[2025-05-11 13:44:24,779 INFO misc.py line 117 288342] Train: [2/50][261/2344] Data 0.002 (0.003) Batch 0.514 (0.620) Remain 19:43:31 loss: 0.8755 Lr: 0.00126
[2025-05-11 13:44:25,471 INFO misc.py line 117 288342] Train: [2/50][262/2344] Data 0.003 (0.003) Batch 0.691 (0.620) Remain 19:44:02 loss: 0.7736 Lr: 0.00126
[2025-05-11 13:44:25,965 INFO misc.py line 117 288342] Train: [2/50][263/2344] Data 0.002 (0.003) Batch 0.494 (0.619) Remain 19:43:06 loss: 0.8316 Lr: 0.00126
[2025-05-11 13:44:26,544 INFO misc.py line 117 288342] Train: [2/50][264/2344] Data 0.003 (0.003) Batch 0.579 (0.619) Remain 19:42:48 loss: 0.9269 Lr: 0.00126
[2025-05-11 13:44:27,173 INFO misc.py line 117 288342] Train: [2/50][265/2344] Data 0.003 (0.003) Batch 0.628 (0.619) Remain 19:42:51 loss: 0.8642 Lr: 0.00126
[2025-05-11 13:44:27,799 INFO misc.py line 117 288342] Train: [2/50][266/2344] Data 0.003 (0.003) Batch 0.626 (0.619) Remain 19:42:54 loss: 0.7505 Lr: 0.00126
[2025-05-11 13:44:28,281 INFO misc.py line 117 288342] Train: [2/50][267/2344] Data 0.003 (0.003) Batch 0.482 (0.619) Remain 19:41:54 loss: 0.9470 Lr: 0.00126
[2025-05-11 13:44:29,024 INFO misc.py line 117 288342] Train: [2/50][268/2344] Data 0.002 (0.003) Batch 0.743 (0.619) Remain 19:42:47 loss: 1.0069 Lr: 0.00126
[2025-05-11 13:44:29,587 INFO misc.py line 117 288342] Train: [2/50][269/2344] Data 0.003 (0.003) Batch 0.563 (0.619) Remain 19:42:22 loss: 0.8793 Lr: 0.00126
[2025-05-11 13:44:30,379 INFO misc.py line 117 288342] Train: [2/50][270/2344] Data 0.002 (0.003) Batch 0.791 (0.620) Remain 19:43:35 loss: 1.0972 Lr: 0.00126
[2025-05-11 13:44:30,930 INFO misc.py line 117 288342] Train: [2/50][271/2344] Data 0.003 (0.003) Batch 0.551 (0.620) Remain 19:43:05 loss: 0.8508 Lr: 0.00126
[2025-05-11 13:44:31,461 INFO misc.py line 117 288342] Train: [2/50][272/2344] Data 0.003 (0.003) Batch 0.532 (0.619) Remain 19:42:27 loss: 0.7477 Lr: 0.00126
[2025-05-11 13:44:32,148 INFO misc.py line 117 288342] Train: [2/50][273/2344] Data 0.002 (0.003) Batch 0.687 (0.619) Remain 19:42:55 loss: 0.7303 Lr: 0.00126
[2025-05-11 13:44:32,639 INFO misc.py line 117 288342] Train: [2/50][274/2344] Data 0.002 (0.003) Batch 0.491 (0.619) Remain 19:42:00 loss: 0.6662 Lr: 0.00126
[2025-05-11 13:44:33,382 INFO misc.py line 117 288342] Train: [2/50][275/2344] Data 0.002 (0.003) Batch 0.743 (0.619) Remain 19:42:52 loss: 0.9238 Lr: 0.00126
[2025-05-11 13:44:34,083 INFO misc.py line 117 288342] Train: [2/50][276/2344] Data 0.003 (0.003) Batch 0.701 (0.620) Remain 19:43:25 loss: 0.7278 Lr: 0.00126
[2025-05-11 13:44:34,632 INFO misc.py line 117 288342] Train: [2/50][277/2344] Data 0.003 (0.003) Batch 0.549 (0.619) Remain 19:42:55 loss: 1.1287 Lr: 0.00127
[2025-05-11 13:44:35,253 INFO misc.py line 117 288342] Train: [2/50][278/2344] Data 0.002 (0.003) Batch 0.620 (0.619) Remain 19:42:55 loss: 0.9695 Lr: 0.00127
[2025-05-11 13:44:35,877 INFO misc.py line 117 288342] Train: [2/50][279/2344] Data 0.003 (0.003) Batch 0.625 (0.619) Remain 19:42:57 loss: 0.7593 Lr: 0.00127
[2025-05-11 13:44:36,608 INFO misc.py line 117 288342] Train: [2/50][280/2344] Data 0.002 (0.003) Batch 0.731 (0.620) Remain 19:43:42 loss: 0.8349 Lr: 0.00127
[2025-05-11 13:44:37,223 INFO misc.py line 117 288342] Train: [2/50][281/2344] Data 0.002 (0.003) Batch 0.615 (0.620) Remain 19:43:39 loss: 0.6817 Lr: 0.00127
[2025-05-11 13:44:37,959 INFO misc.py line 117 288342] Train: [2/50][282/2344] Data 0.002 (0.003) Batch 0.736 (0.620) Remain 19:44:26 loss: 0.7231 Lr: 0.00127
[2025-05-11 13:44:38,576 INFO misc.py line 117 288342] Train: [2/50][283/2344] Data 0.003 (0.003) Batch 0.618 (0.620) Remain 19:44:25 loss: 1.1113 Lr: 0.00127
[2025-05-11 13:44:39,152 INFO misc.py line 117 288342] Train: [2/50][284/2344] Data 0.002 (0.003) Batch 0.576 (0.620) Remain 19:44:06 loss: 0.6988 Lr: 0.00127
[2025-05-11 13:44:39,683 INFO misc.py line 117 288342] Train: [2/50][285/2344] Data 0.003 (0.003) Batch 0.531 (0.620) Remain 19:43:29 loss: 0.9650 Lr: 0.00127
[2025-05-11 13:44:40,306 INFO misc.py line 117 288342] Train: [2/50][286/2344] Data 0.003 (0.003) Batch 0.623 (0.620) Remain 19:43:30 loss: 0.9746 Lr: 0.00127
[2025-05-11 13:44:41,029 INFO misc.py line 117 288342] Train: [2/50][287/2344] Data 0.003 (0.003) Batch 0.722 (0.620) Remain 19:44:11 loss: 0.7421 Lr: 0.00127
[2025-05-11 13:44:41,731 INFO misc.py line 117 288342] Train: [2/50][288/2344] Data 0.003 (0.003) Batch 0.702 (0.620) Remain 19:44:43 loss: 0.7998 Lr: 0.00127
[2025-05-11 13:44:42,142 INFO misc.py line 117 288342] Train: [2/50][289/2344] Data 0.003 (0.003) Batch 0.411 (0.620) Remain 19:43:19 loss: 1.1248 Lr: 0.00127
[2025-05-11 13:44:42,841 INFO misc.py line 117 288342] Train: [2/50][290/2344] Data 0.003 (0.003) Batch 0.699 (0.620) Remain 19:43:50 loss: 0.9719 Lr: 0.00127
[2025-05-11 13:44:43,476 INFO misc.py line 117 288342] Train: [2/50][291/2344] Data 0.003 (0.003) Batch 0.635 (0.620) Remain 19:43:55 loss: 1.2350 Lr: 0.00127
[2025-05-11 13:44:44,323 INFO misc.py line 117 288342] Train: [2/50][292/2344] Data 0.003 (0.003) Batch 0.847 (0.621) Remain 19:45:24 loss: 0.8968 Lr: 0.00127
[2025-05-11 13:44:44,909 INFO misc.py line 117 288342] Train: [2/50][293/2344] Data 0.003 (0.003) Batch 0.587 (0.621) Remain 19:45:10 loss: 0.6897 Lr: 0.00127
[2025-05-11 13:44:45,422 INFO misc.py line 117 288342] Train: [2/50][294/2344] Data 0.003 (0.003) Batch 0.513 (0.620) Remain 19:44:27 loss: 0.9906 Lr: 0.00128
[2025-05-11 13:44:46,059 INFO misc.py line 117 288342] Train: [2/50][295/2344] Data 0.003 (0.003) Batch 0.637 (0.620) Remain 19:44:33 loss: 1.2026 Lr: 0.00128
[2025-05-11 13:44:46,583 INFO misc.py line 117 288342] Train: [2/50][296/2344] Data 0.004 (0.003) Batch 0.524 (0.620) Remain 19:43:54 loss: 0.8032 Lr: 0.00128
[2025-05-11 13:44:47,147 INFO misc.py line 117 288342] Train: [2/50][297/2344] Data 0.002 (0.003) Batch 0.565 (0.620) Remain 19:43:32 loss: 0.7969 Lr: 0.00128
[2025-05-11 13:44:47,721 INFO misc.py line 117 288342] Train: [2/50][298/2344] Data 0.003 (0.003) Batch 0.574 (0.620) Remain 19:43:14 loss: 0.7423 Lr: 0.00128
[2025-05-11 13:44:48,473 INFO misc.py line 117 288342] Train: [2/50][299/2344] Data 0.002 (0.003) Batch 0.752 (0.620) Remain 19:44:04 loss: 0.8302 Lr: 0.00128
[2025-05-11 13:44:49,102 INFO misc.py line 117 288342] Train: [2/50][300/2344] Data 0.002 (0.003) Batch 0.629 (0.620) Remain 19:44:07 loss: 0.9006 Lr: 0.00128
[2025-05-11 13:44:49,793 INFO misc.py line 117 288342] Train: [2/50][301/2344] Data 0.002 (0.003) Batch 0.692 (0.620) Remain 19:44:34 loss: 0.7919 Lr: 0.00128
[2025-05-11 13:44:50,275 INFO misc.py line 117 288342] Train: [2/50][302/2344] Data 0.003 (0.003) Batch 0.482 (0.620) Remain 19:43:40 loss: 0.8091 Lr: 0.00128
[2025-05-11 13:44:50,886 INFO misc.py line 117 288342] Train: [2/50][303/2344] Data 0.002 (0.003) Batch 0.611 (0.620) Remain 19:43:36 loss: 0.9904 Lr: 0.00128
[2025-05-11 13:44:51,458 INFO misc.py line 117 288342] Train: [2/50][304/2344] Data 0.003 (0.003) Batch 0.572 (0.620) Remain 19:43:17 loss: 0.8498 Lr: 0.00128
[2025-05-11 13:44:52,048 INFO misc.py line 117 288342] Train: [2/50][305/2344] Data 0.003 (0.003) Batch 0.590 (0.620) Remain 19:43:05 loss: 0.8772 Lr: 0.00128
[2025-05-11 13:44:52,612 INFO misc.py line 117 288342] Train: [2/50][306/2344] Data 0.003 (0.003) Batch 0.564 (0.620) Remain 19:42:43 loss: 0.6185 Lr: 0.00128
[2025-05-11 13:44:53,277 INFO misc.py line 117 288342] Train: [2/50][307/2344] Data 0.003 (0.003) Batch 0.665 (0.620) Remain 19:43:00 loss: 0.7249 Lr: 0.00128
[2025-05-11 13:44:53,887 INFO misc.py line 117 288342] Train: [2/50][308/2344] Data 0.003 (0.003) Batch 0.610 (0.620) Remain 19:42:56 loss: 0.7416 Lr: 0.00128
[2025-05-11 13:44:54,464 INFO misc.py line 117 288342] Train: [2/50][309/2344] Data 0.002 (0.003) Batch 0.577 (0.619) Remain 19:42:39 loss: 0.7448 Lr: 0.00128
[2025-05-11 13:44:55,044 INFO misc.py line 117 288342] Train: [2/50][310/2344] Data 0.003 (0.003) Batch 0.580 (0.619) Remain 19:42:24 loss: 0.8560 Lr: 0.00128
[2025-05-11 13:44:55,631 INFO misc.py line 117 288342] Train: [2/50][311/2344] Data 0.002 (0.003) Batch 0.587 (0.619) Remain 19:42:11 loss: 1.0507 Lr: 0.00129
[2025-05-11 13:44:56,370 INFO misc.py line 117 288342] Train: [2/50][312/2344] Data 0.002 (0.003) Batch 0.739 (0.620) Remain 19:42:55 loss: 0.7699 Lr: 0.00129
[2025-05-11 13:44:57,082 INFO misc.py line 117 288342] Train: [2/50][313/2344] Data 0.002 (0.003) Batch 0.712 (0.620) Remain 19:43:28 loss: 0.6848 Lr: 0.00129
[2025-05-11 13:44:57,561 INFO misc.py line 117 288342] Train: [2/50][314/2344] Data 0.003 (0.003) Batch 0.479 (0.619) Remain 19:42:36 loss: 0.7915 Lr: 0.00129
[2025-05-11 13:44:58,085 INFO misc.py line 117 288342] Train: [2/50][315/2344] Data 0.003 (0.003) Batch 0.524 (0.619) Remain 19:42:00 loss: 0.6452 Lr: 0.00129
[2025-05-11 13:44:58,729 INFO misc.py line 117 288342] Train: [2/50][316/2344] Data 0.003 (0.003) Batch 0.643 (0.619) Remain 19:42:09 loss: 0.6343 Lr: 0.00129
[2025-05-11 13:44:59,371 INFO misc.py line 117 288342] Train: [2/50][317/2344] Data 0.002 (0.003) Batch 0.643 (0.619) Remain 19:42:16 loss: 0.9556 Lr: 0.00129
[2025-05-11 13:45:00,093 INFO misc.py line 117 288342] Train: [2/50][318/2344] Data 0.002 (0.003) Batch 0.721 (0.620) Remain 19:42:53 loss: 0.7415 Lr: 0.00129
[2025-05-11 13:45:00,696 INFO misc.py line 117 288342] Train: [2/50][319/2344] Data 0.002 (0.003) Batch 0.603 (0.620) Remain 19:42:46 loss: 0.8261 Lr: 0.00129
[2025-05-11 13:45:01,342 INFO misc.py line 117 288342] Train: [2/50][320/2344] Data 0.003 (0.003) Batch 0.646 (0.620) Remain 19:42:55 loss: 0.9084 Lr: 0.00129
[2025-05-11 13:45:02,022 INFO misc.py line 117 288342] Train: [2/50][321/2344] Data 0.002 (0.003) Batch 0.681 (0.620) Remain 19:43:17 loss: 0.7296 Lr: 0.00129
[2025-05-11 13:45:02,794 INFO misc.py line 117 288342] Train: [2/50][322/2344] Data 0.002 (0.003) Batch 0.771 (0.620) Remain 19:44:10 loss: 1.0552 Lr: 0.00129
[2025-05-11 13:45:03,424 INFO misc.py line 117 288342] Train: [2/50][323/2344] Data 0.003 (0.003) Batch 0.630 (0.620) Remain 19:44:13 loss: 0.7413 Lr: 0.00129
[2025-05-11 13:45:04,078 INFO misc.py line 117 288342] Train: [2/50][324/2344] Data 0.002 (0.003) Batch 0.654 (0.620) Remain 19:44:24 loss: 0.7560 Lr: 0.00129
[2025-05-11 13:45:04,693 INFO misc.py line 117 288342] Train: [2/50][325/2344] Data 0.002 (0.003) Batch 0.615 (0.620) Remain 19:44:22 loss: 0.7041 Lr: 0.00129
[2025-05-11 13:45:05,292 INFO misc.py line 117 288342] Train: [2/50][326/2344] Data 0.002 (0.003) Batch 0.600 (0.620) Remain 19:44:14 loss: 0.8748 Lr: 0.00129
[2025-05-11 13:45:06,031 INFO misc.py line 117 288342] Train: [2/50][327/2344] Data 0.002 (0.003) Batch 0.739 (0.621) Remain 19:44:55 loss: 0.6663 Lr: 0.00129
[2025-05-11 13:45:06,572 INFO misc.py line 117 288342] Train: [2/50][328/2344] Data 0.002 (0.003) Batch 0.541 (0.621) Remain 19:44:26 loss: 0.6321 Lr: 0.00130
[2025-05-11 13:45:07,102 INFO misc.py line 117 288342] Train: [2/50][329/2344] Data 0.003 (0.003) Batch 0.530 (0.620) Remain 19:43:54 loss: 0.6560 Lr: 0.00130
[2025-05-11 13:45:07,705 INFO misc.py line 117 288342] Train: [2/50][330/2344] Data 0.003 (0.003) Batch 0.603 (0.620) Remain 19:43:47 loss: 0.8542 Lr: 0.00130
[2025-05-11 13:45:08,252 INFO misc.py line 117 288342] Train: [2/50][331/2344] Data 0.003 (0.003) Batch 0.547 (0.620) Remain 19:43:21 loss: 0.8283 Lr: 0.00130
[2025-05-11 13:45:08,906 INFO misc.py line 117 288342] Train: [2/50][332/2344] Data 0.003 (0.003) Batch 0.655 (0.620) Remain 19:43:32 loss: 0.6885 Lr: 0.00130
[2025-05-11 13:45:09,601 INFO misc.py line 117 288342] Train: [2/50][333/2344] Data 0.003 (0.003) Batch 0.695 (0.620) Remain 19:43:58 loss: 0.7835 Lr: 0.00130
[2025-05-11 13:45:10,282 INFO misc.py line 117 288342] Train: [2/50][334/2344] Data 0.003 (0.003) Batch 0.680 (0.620) Remain 19:44:18 loss: 0.7927 Lr: 0.00130
[2025-05-11 13:45:10,768 INFO misc.py line 117 288342] Train: [2/50][335/2344] Data 0.003 (0.003) Batch 0.486 (0.620) Remain 19:43:31 loss: 0.8366 Lr: 0.00130
[2025-05-11 13:45:11,272 INFO misc.py line 117 288342] Train: [2/50][336/2344] Data 0.002 (0.003) Batch 0.504 (0.620) Remain 19:42:50 loss: 0.8081 Lr: 0.00130
[2025-05-11 13:45:11,981 INFO misc.py line 117 288342] Train: [2/50][337/2344] Data 0.002 (0.003) Batch 0.710 (0.620) Remain 19:43:21 loss: 0.7152 Lr: 0.00130
[2025-05-11 13:45:12,689 INFO misc.py line 117 288342] Train: [2/50][338/2344] Data 0.002 (0.003) Batch 0.707 (0.620) Remain 19:43:50 loss: 0.7612 Lr: 0.00130
[2025-05-11 13:45:13,382 INFO misc.py line 117 288342] Train: [2/50][339/2344] Data 0.002 (0.003) Batch 0.694 (0.620) Remain 19:44:14 loss: 0.7442 Lr: 0.00130
[2025-05-11 13:45:14,026 INFO misc.py line 117 288342] Train: [2/50][340/2344] Data 0.002 (0.003) Batch 0.644 (0.621) Remain 19:44:22 loss: 0.9234 Lr: 0.00130
[2025-05-11 13:45:14,589 INFO misc.py line 117 288342] Train: [2/50][341/2344] Data 0.002 (0.003) Batch 0.563 (0.620) Remain 19:44:02 loss: 0.8918 Lr: 0.00130
[2025-05-11 13:45:15,327 INFO misc.py line 117 288342] Train: [2/50][342/2344] Data 0.002 (0.003) Batch 0.737 (0.621) Remain 19:44:40 loss: 0.8377 Lr: 0.00130
[2025-05-11 13:45:16,057 INFO misc.py line 117 288342] Train: [2/50][343/2344] Data 0.002 (0.003) Batch 0.730 (0.621) Remain 19:45:17 loss: 0.7319 Lr: 0.00130
[2025-05-11 13:45:16,620 INFO misc.py line 117 288342] Train: [2/50][344/2344] Data 0.002 (0.003) Batch 0.563 (0.621) Remain 19:44:57 loss: 0.8484 Lr: 0.00130
[2025-05-11 13:45:17,389 INFO misc.py line 117 288342] Train: [2/50][345/2344] Data 0.002 (0.003) Batch 0.769 (0.621) Remain 19:45:46 loss: 1.2030 Lr: 0.00131
[2025-05-11 13:45:18,004 INFO misc.py line 117 288342] Train: [2/50][346/2344] Data 0.003 (0.003) Batch 0.615 (0.621) Remain 19:45:43 loss: 0.8663 Lr: 0.00131
[2025-05-11 13:45:18,648 INFO misc.py line 117 288342] Train: [2/50][347/2344] Data 0.002 (0.003) Batch 0.643 (0.621) Remain 19:45:50 loss: 0.7323 Lr: 0.00131
[2025-05-11 13:45:19,279 INFO misc.py line 117 288342] Train: [2/50][348/2344] Data 0.002 (0.003) Batch 0.631 (0.621) Remain 19:45:52 loss: 0.8992 Lr: 0.00131
[2025-05-11 13:45:19,928 INFO misc.py line 117 288342] Train: [2/50][349/2344] Data 0.003 (0.003) Batch 0.650 (0.621) Remain 19:46:01 loss: 0.6080 Lr: 0.00131
[2025-05-11 13:45:20,438 INFO misc.py line 117 288342] Train: [2/50][350/2344] Data 0.002 (0.003) Batch 0.509 (0.621) Remain 19:45:23 loss: 0.9205 Lr: 0.00131
[2025-05-11 13:45:21,145 INFO misc.py line 117 288342] Train: [2/50][351/2344] Data 0.002 (0.003) Batch 0.707 (0.621) Remain 19:45:51 loss: 0.6826 Lr: 0.00131
[2025-05-11 13:45:21,663 INFO misc.py line 117 288342] Train: [2/50][352/2344] Data 0.002 (0.003) Batch 0.518 (0.621) Remain 19:45:16 loss: 0.8448 Lr: 0.00131
[2025-05-11 13:45:22,217 INFO misc.py line 117 288342] Train: [2/50][353/2344] Data 0.003 (0.003) Batch 0.554 (0.621) Remain 19:44:54 loss: 0.8135 Lr: 0.00131
[2025-05-11 13:45:22,924 INFO misc.py line 117 288342] Train: [2/50][354/2344] Data 0.003 (0.003) Batch 0.707 (0.621) Remain 19:45:22 loss: 0.7649 Lr: 0.00131
[2025-05-11 13:45:23,512 INFO misc.py line 117 288342] Train: [2/50][355/2344] Data 0.003 (0.003) Batch 0.588 (0.621) Remain 19:45:10 loss: 1.1104 Lr: 0.00131
[2025-05-11 13:45:24,174 INFO misc.py line 117 288342] Train: [2/50][356/2344] Data 0.003 (0.003) Batch 0.662 (0.621) Remain 19:45:23 loss: 0.7396 Lr: 0.00131
[2025-05-11 13:45:24,788 INFO misc.py line 117 288342] Train: [2/50][357/2344] Data 0.003 (0.003) Batch 0.613 (0.621) Remain 19:45:20 loss: 1.0306 Lr: 0.00131
[2025-05-11 13:45:25,471 INFO misc.py line 117 288342] Train: [2/50][358/2344] Data 0.003 (0.003) Batch 0.683 (0.621) Remain 19:45:39 loss: 0.7260 Lr: 0.00131
[2025-05-11 13:45:26,197 INFO misc.py line 117 288342] Train: [2/50][359/2344] Data 0.003 (0.003) Batch 0.727 (0.622) Remain 19:46:12 loss: 0.8030 Lr: 0.00131
[2025-05-11 13:45:26,781 INFO misc.py line 117 288342] Train: [2/50][360/2344] Data 0.003 (0.003) Batch 0.584 (0.622) Remain 19:46:00 loss: 0.9265 Lr: 0.00131
[2025-05-11 13:45:27,256 INFO misc.py line 117 288342] Train: [2/50][361/2344] Data 0.002 (0.003) Batch 0.474 (0.621) Remain 19:45:12 loss: 1.0250 Lr: 0.00131
[2025-05-11 13:45:27,950 INFO misc.py line 117 288342] Train: [2/50][362/2344] Data 0.003 (0.003) Batch 0.694 (0.621) Remain 19:45:35 loss: 0.8499 Lr: 0.00132
[2025-05-11 13:45:28,499 INFO misc.py line 117 288342] Train: [2/50][363/2344] Data 0.002 (0.003) Batch 0.549 (0.621) Remain 19:45:11 loss: 0.6889 Lr: 0.00132
[2025-05-11 13:45:29,088 INFO misc.py line 117 288342] Train: [2/50][364/2344] Data 0.002 (0.003) Batch 0.589 (0.621) Remain 19:45:00 loss: 0.8078 Lr: 0.00132
[2025-05-11 13:45:29,655 INFO misc.py line 117 288342] Train: [2/50][365/2344] Data 0.003 (0.003) Batch 0.567 (0.621) Remain 19:44:43 loss: 0.8906 Lr: 0.00132
[2025-05-11 13:45:30,296 INFO misc.py line 117 288342] Train: [2/50][366/2344] Data 0.003 (0.003) Batch 0.641 (0.621) Remain 19:44:48 loss: 0.9070 Lr: 0.00132
[2025-05-11 13:45:30,901 INFO misc.py line 117 288342] Train: [2/50][367/2344] Data 0.003 (0.003) Batch 0.605 (0.621) Remain 19:44:43 loss: 0.8113 Lr: 0.00132
[2025-05-11 13:45:31,468 INFO misc.py line 117 288342] Train: [2/50][368/2344] Data 0.003 (0.003) Batch 0.567 (0.621) Remain 19:44:25 loss: 0.6972 Lr: 0.00132
[2025-05-11 13:45:32,176 INFO misc.py line 117 288342] Train: [2/50][369/2344] Data 0.002 (0.003) Batch 0.708 (0.621) Remain 19:44:52 loss: 0.6088 Lr: 0.00132
[2025-05-11 13:45:32,811 INFO misc.py line 117 288342] Train: [2/50][370/2344] Data 0.003 (0.003) Batch 0.636 (0.621) Remain 19:44:56 loss: 1.1413 Lr: 0.00132
[2025-05-11 13:45:33,531 INFO misc.py line 117 288342] Train: [2/50][371/2344] Data 0.003 (0.003) Batch 0.720 (0.621) Remain 19:45:26 loss: 0.8812 Lr: 0.00132
[2025-05-11 13:45:34,075 INFO misc.py line 117 288342] Train: [2/50][372/2344] Data 0.003 (0.003) Batch 0.543 (0.621) Remain 19:45:01 loss: 0.6854 Lr: 0.00132
[2025-05-11 13:45:34,743 INFO misc.py line 117 288342] Train: [2/50][373/2344] Data 0.003 (0.003) Batch 0.669 (0.621) Remain 19:45:15 loss: 0.8859 Lr: 0.00132
[2025-05-11 13:45:35,281 INFO misc.py line 117 288342] Train: [2/50][374/2344] Data 0.003 (0.003) Batch 0.538 (0.621) Remain 19:44:49 loss: 0.9026 Lr: 0.00132
[2025-05-11 13:45:35,960 INFO misc.py line 117 288342] Train: [2/50][375/2344] Data 0.003 (0.003) Batch 0.679 (0.621) Remain 19:45:06 loss: 0.9527 Lr: 0.00132
[2025-05-11 13:45:36,612 INFO misc.py line 117 288342] Train: [2/50][376/2344] Data 0.002 (0.003) Batch 0.651 (0.621) Remain 19:45:15 loss: 0.8587 Lr: 0.00132
[2025-05-11 13:45:37,144 INFO misc.py line 117 288342] Train: [2/50][377/2344] Data 0.002 (0.003) Batch 0.532 (0.621) Remain 19:44:47 loss: 0.6568 Lr: 0.00132
[2025-05-11 13:45:37,858 INFO misc.py line 117 288342] Train: [2/50][378/2344] Data 0.002 (0.003) Batch 0.715 (0.621) Remain 19:45:15 loss: 0.7737 Lr: 0.00132
[2025-05-11 13:45:38,606 INFO misc.py line 117 288342] Train: [2/50][379/2344] Data 0.003 (0.003) Batch 0.748 (0.622) Remain 19:45:53 loss: 0.6864 Lr: 0.00133
[2025-05-11 13:45:39,225 INFO misc.py line 117 288342] Train: [2/50][380/2344] Data 0.003 (0.003) Batch 0.619 (0.622) Remain 19:45:51 loss: 0.7647 Lr: 0.00133
[2025-05-11 13:45:39,881 INFO misc.py line 117 288342] Train: [2/50][381/2344] Data 0.002 (0.003) Batch 0.656 (0.622) Remain 19:46:01 loss: 1.0038 Lr: 0.00133
[2025-05-11 13:45:40,376 INFO misc.py line 117 288342] Train: [2/50][382/2344] Data 0.002 (0.003) Batch 0.495 (0.621) Remain 19:45:22 loss: 0.7805 Lr: 0.00133
[2025-05-11 13:45:41,041 INFO misc.py line 117 288342] Train: [2/50][383/2344] Data 0.003 (0.003) Batch 0.665 (0.621) Remain 19:45:35 loss: 0.8205 Lr: 0.00133
[2025-05-11 13:45:41,579 INFO misc.py line 117 288342] Train: [2/50][384/2344] Data 0.003 (0.003) Batch 0.538 (0.621) Remain 19:45:09 loss: 0.8149 Lr: 0.00133
[2025-05-11 13:45:42,155 INFO misc.py line 117 288342] Train: [2/50][385/2344] Data 0.003 (0.003) Batch 0.576 (0.621) Remain 19:44:55 loss: 0.7000 Lr: 0.00133
[2025-05-11 13:45:42,695 INFO misc.py line 117 288342] Train: [2/50][386/2344] Data 0.003 (0.003) Batch 0.540 (0.621) Remain 19:44:30 loss: 0.6854 Lr: 0.00133
[2025-05-11 13:45:43,394 INFO misc.py line 117 288342] Train: [2/50][387/2344] Data 0.003 (0.003) Batch 0.699 (0.621) Remain 19:44:53 loss: 1.0655 Lr: 0.00133
[2025-05-11 13:45:44,061 INFO misc.py line 117 288342] Train: [2/50][388/2344] Data 0.003 (0.003) Batch 0.668 (0.621) Remain 19:45:06 loss: 0.7881 Lr: 0.00133
[2025-05-11 13:45:44,846 INFO misc.py line 117 288342] Train: [2/50][389/2344] Data 0.003 (0.003) Batch 0.784 (0.622) Remain 19:45:54 loss: 0.8587 Lr: 0.00133
[2025-05-11 13:45:45,517 INFO misc.py line 117 288342] Train: [2/50][390/2344] Data 0.002 (0.003) Batch 0.671 (0.622) Remain 19:46:08 loss: 0.7588 Lr: 0.00133
[2025-05-11 13:45:46,178 INFO misc.py line 117 288342] Train: [2/50][391/2344] Data 0.002 (0.003) Batch 0.662 (0.622) Remain 19:46:19 loss: 0.8236 Lr: 0.00133
[2025-05-11 13:45:46,819 INFO misc.py line 117 288342] Train: [2/50][392/2344] Data 0.003 (0.003) Batch 0.640 (0.622) Remain 19:46:24 loss: 0.8272 Lr: 0.00133
[2025-05-11 13:45:47,504 INFO misc.py line 117 288342] Train: [2/50][393/2344] Data 0.003 (0.003) Batch 0.685 (0.622) Remain 19:46:42 loss: 0.9379 Lr: 0.00133
[2025-05-11 13:45:48,072 INFO misc.py line 117 288342] Train: [2/50][394/2344] Data 0.003 (0.003) Batch 0.568 (0.622) Remain 19:46:25 loss: 0.7505 Lr: 0.00133
[2025-05-11 13:45:48,554 INFO misc.py line 117 288342] Train: [2/50][395/2344] Data 0.003 (0.003) Batch 0.482 (0.622) Remain 19:45:44 loss: 0.9307 Lr: 0.00133
[2025-05-11 13:45:49,294 INFO misc.py line 117 288342] Train: [2/50][396/2344] Data 0.003 (0.003) Batch 0.741 (0.622) Remain 19:46:18 loss: 0.6967 Lr: 0.00134
[2025-05-11 13:45:49,910 INFO misc.py line 117 288342] Train: [2/50][397/2344] Data 0.003 (0.003) Batch 0.616 (0.622) Remain 19:46:15 loss: 0.8133 Lr: 0.00134
[2025-05-11 13:45:50,520 INFO misc.py line 117 288342] Train: [2/50][398/2344] Data 0.003 (0.003) Batch 0.610 (0.622) Remain 19:46:11 loss: 0.7820 Lr: 0.00134
[2025-05-11 13:45:51,174 INFO misc.py line 117 288342] Train: [2/50][399/2344] Data 0.003 (0.003) Batch 0.654 (0.622) Remain 19:46:20 loss: 0.8601 Lr: 0.00134
[2025-05-11 13:45:51,745 INFO misc.py line 117 288342] Train: [2/50][400/2344] Data 0.003 (0.003) Batch 0.571 (0.622) Remain 19:46:04 loss: 0.8027 Lr: 0.00134
[2025-05-11 13:45:52,352 INFO misc.py line 117 288342] Train: [2/50][401/2344] Data 0.002 (0.003) Batch 0.607 (0.622) Remain 19:46:00 loss: 0.7837 Lr: 0.00134
[2025-05-11 13:45:53,157 INFO misc.py line 117 288342] Train: [2/50][402/2344] Data 0.003 (0.003) Batch 0.805 (0.622) Remain 19:46:52 loss: 0.9517 Lr: 0.00134
[2025-05-11 13:45:53,766 INFO misc.py line 117 288342] Train: [2/50][403/2344] Data 0.003 (0.003) Batch 0.609 (0.622) Remain 19:46:47 loss: 0.9991 Lr: 0.00134
[2025-05-11 13:45:54,407 INFO misc.py line 117 288342] Train: [2/50][404/2344] Data 0.003 (0.003) Batch 0.640 (0.622) Remain 19:46:52 loss: 0.9166 Lr: 0.00134
[2025-05-11 13:45:54,956 INFO misc.py line 117 288342] Train: [2/50][405/2344] Data 0.003 (0.003) Batch 0.550 (0.622) Remain 19:46:31 loss: 0.7579 Lr: 0.00134
[2025-05-11 13:45:55,504 INFO misc.py line 117 288342] Train: [2/50][406/2344] Data 0.003 (0.003) Batch 0.548 (0.622) Remain 19:46:09 loss: 0.9529 Lr: 0.00134
[2025-05-11 13:45:56,142 INFO misc.py line 117 288342] Train: [2/50][407/2344] Data 0.002 (0.003) Batch 0.638 (0.622) Remain 19:46:13 loss: 0.8530 Lr: 0.00134
[2025-05-11 13:45:56,682 INFO misc.py line 117 288342] Train: [2/50][408/2344] Data 0.002 (0.003) Batch 0.540 (0.622) Remain 19:45:49 loss: 0.7848 Lr: 0.00134
[2025-05-11 13:45:57,305 INFO misc.py line 117 288342] Train: [2/50][409/2344] Data 0.002 (0.003) Batch 0.623 (0.622) Remain 19:45:49 loss: 0.7563 Lr: 0.00134
[2025-05-11 13:45:57,880 INFO misc.py line 117 288342] Train: [2/50][410/2344] Data 0.003 (0.003) Batch 0.575 (0.622) Remain 19:45:35 loss: 0.7225 Lr: 0.00134
[2025-05-11 13:45:58,564 INFO misc.py line 117 288342] Train: [2/50][411/2344] Data 0.003 (0.003) Batch 0.684 (0.622) Remain 19:45:52 loss: 0.9276 Lr: 0.00134
[2025-05-11 13:45:59,165 INFO misc.py line 117 288342] Train: [2/50][412/2344] Data 0.002 (0.003) Batch 0.601 (0.622) Remain 19:45:45 loss: 0.5839 Lr: 0.00134
[2025-05-11 13:45:59,767 INFO misc.py line 117 288342] Train: [2/50][413/2344] Data 0.002 (0.003) Batch 0.602 (0.622) Remain 19:45:39 loss: 0.9073 Lr: 0.00135
[2025-05-11 13:46:00,559 INFO misc.py line 117 288342] Train: [2/50][414/2344] Data 0.002 (0.003) Batch 0.792 (0.622) Remain 19:46:26 loss: 0.8388 Lr: 0.00135
[2025-05-11 13:46:01,090 INFO misc.py line 117 288342] Train: [2/50][415/2344] Data 0.002 (0.003) Batch 0.530 (0.622) Remain 19:46:00 loss: 0.8196 Lr: 0.00135
[2025-05-11 13:46:01,732 INFO misc.py line 117 288342] Train: [2/50][416/2344] Data 0.002 (0.003) Batch 0.642 (0.622) Remain 19:46:05 loss: 0.8570 Lr: 0.00135
[2025-05-11 13:46:02,296 INFO misc.py line 117 288342] Train: [2/50][417/2344] Data 0.002 (0.003) Batch 0.564 (0.622) Remain 19:45:49 loss: 0.7795 Lr: 0.00135
[2025-05-11 13:46:03,029 INFO misc.py line 117 288342] Train: [2/50][418/2344] Data 0.003 (0.003) Batch 0.733 (0.622) Remain 19:46:19 loss: 0.8098 Lr: 0.00135
[2025-05-11 13:46:03,592 INFO misc.py line 117 288342] Train: [2/50][419/2344] Data 0.002 (0.003) Batch 0.563 (0.622) Remain 19:46:02 loss: 0.9711 Lr: 0.00135
[2025-05-11 13:46:04,092 INFO misc.py line 117 288342] Train: [2/50][420/2344] Data 0.003 (0.003) Batch 0.500 (0.622) Remain 19:45:28 loss: 0.8929 Lr: 0.00135
[2025-05-11 13:46:04,703 INFO misc.py line 117 288342] Train: [2/50][421/2344] Data 0.003 (0.003) Batch 0.612 (0.622) Remain 19:45:24 loss: 0.7849 Lr: 0.00135
[2025-05-11 13:46:05,259 INFO misc.py line 117 288342] Train: [2/50][422/2344] Data 0.003 (0.003) Batch 0.555 (0.621) Remain 19:45:06 loss: 0.8579 Lr: 0.00135
[2025-05-11 13:46:05,961 INFO misc.py line 117 288342] Train: [2/50][423/2344] Data 0.003 (0.003) Batch 0.702 (0.622) Remain 19:45:27 loss: 0.7643 Lr: 0.00135
[2025-05-11 13:46:06,451 INFO misc.py line 117 288342] Train: [2/50][424/2344] Data 0.003 (0.003) Batch 0.490 (0.621) Remain 19:44:51 loss: 0.9657 Lr: 0.00135
[2025-05-11 13:46:07,063 INFO misc.py line 117 288342] Train: [2/50][425/2344] Data 0.002 (0.003) Batch 0.611 (0.621) Remain 19:44:48 loss: 0.7781 Lr: 0.00135
[2025-05-11 13:46:07,672 INFO misc.py line 117 288342] Train: [2/50][426/2344] Data 0.003 (0.003) Batch 0.609 (0.621) Remain 19:44:44 loss: 0.9649 Lr: 0.00135
[2025-05-11 13:46:08,355 INFO misc.py line 117 288342] Train: [2/50][427/2344] Data 0.003 (0.003) Batch 0.683 (0.621) Remain 19:45:00 loss: 1.0371 Lr: 0.00135
[2025-05-11 13:46:08,778 INFO misc.py line 117 288342] Train: [2/50][428/2344] Data 0.003 (0.003) Batch 0.423 (0.621) Remain 19:44:06 loss: 1.0076 Lr: 0.00135
[2025-05-11 13:46:09,369 INFO misc.py line 117 288342] Train: [2/50][429/2344] Data 0.002 (0.003) Batch 0.591 (0.621) Remain 19:43:57 loss: 0.7490 Lr: 0.00135
[2025-05-11 13:46:10,015 INFO misc.py line 117 288342] Train: [2/50][430/2344] Data 0.003 (0.003) Batch 0.646 (0.621) Remain 19:44:03 loss: 1.0313 Lr: 0.00135
[2025-05-11 13:46:10,670 INFO misc.py line 117 288342] Train: [2/50][431/2344] Data 0.002 (0.003) Batch 0.656 (0.621) Remain 19:44:12 loss: 0.8224 Lr: 0.00136
[2025-05-11 13:46:11,286 INFO misc.py line 117 288342] Train: [2/50][432/2344] Data 0.003 (0.003) Batch 0.616 (0.621) Remain 19:44:10 loss: 0.8455 Lr: 0.00136
[2025-05-11 13:46:11,843 INFO misc.py line 117 288342] Train: [2/50][433/2344] Data 0.002 (0.003) Batch 0.557 (0.621) Remain 19:43:52 loss: 0.7781 Lr: 0.00136
[2025-05-11 13:46:12,567 INFO misc.py line 117 288342] Train: [2/50][434/2344] Data 0.003 (0.003) Batch 0.724 (0.621) Remain 19:44:19 loss: 1.1068 Lr: 0.00136
[2025-05-11 13:46:13,106 INFO misc.py line 117 288342] Train: [2/50][435/2344] Data 0.002 (0.003) Batch 0.539 (0.621) Remain 19:43:57 loss: 0.8834 Lr: 0.00136
[2025-05-11 13:46:13,678 INFO misc.py line 117 288342] Train: [2/50][436/2344] Data 0.003 (0.003) Batch 0.572 (0.621) Remain 19:43:43 loss: 0.8030 Lr: 0.00136
[2025-05-11 13:46:14,311 INFO misc.py line 117 288342] Train: [2/50][437/2344] Data 0.003 (0.003) Batch 0.632 (0.621) Remain 19:43:46 loss: 0.8028 Lr: 0.00136
[2025-05-11 13:46:14,773 INFO misc.py line 117 288342] Train: [2/50][438/2344] Data 0.003 (0.003) Batch 0.462 (0.620) Remain 19:43:03 loss: 1.1266 Lr: 0.00136
[2025-05-11 13:46:15,421 INFO misc.py line 117 288342] Train: [2/50][439/2344] Data 0.003 (0.003) Batch 0.648 (0.620) Remain 19:43:10 loss: 0.6482 Lr: 0.00136
[2025-05-11 13:46:15,995 INFO misc.py line 117 288342] Train: [2/50][440/2344] Data 0.002 (0.003) Batch 0.573 (0.620) Remain 19:42:57 loss: 1.0305 Lr: 0.00136
[2025-05-11 13:46:16,532 INFO misc.py line 117 288342] Train: [2/50][441/2344] Data 0.002 (0.003) Batch 0.538 (0.620) Remain 19:42:35 loss: 0.8517 Lr: 0.00136
[2025-05-11 13:46:17,218 INFO misc.py line 117 288342] Train: [2/50][442/2344] Data 0.002 (0.003) Batch 0.686 (0.620) Remain 19:42:51 loss: 0.8637 Lr: 0.00136
[2025-05-11 13:46:17,777 INFO misc.py line 117 288342] Train: [2/50][443/2344] Data 0.002 (0.003) Batch 0.559 (0.620) Remain 19:42:35 loss: 0.6608 Lr: 0.00136
[2025-05-11 13:46:18,199 INFO misc.py line 117 288342] Train: [2/50][444/2344] Data 0.003 (0.003) Batch 0.422 (0.620) Remain 19:41:43 loss: 0.9227 Lr: 0.00136
[2025-05-11 13:46:18,719 INFO misc.py line 117 288342] Train: [2/50][445/2344] Data 0.003 (0.003) Batch 0.520 (0.619) Remain 19:41:16 loss: 0.9727 Lr: 0.00136
[2025-05-11 13:46:19,389 INFO misc.py line 117 288342] Train: [2/50][446/2344] Data 0.003 (0.003) Batch 0.670 (0.620) Remain 19:41:29 loss: 0.7363 Lr: 0.00136
[2025-05-11 13:46:19,933 INFO misc.py line 117 288342] Train: [2/50][447/2344] Data 0.003 (0.003) Batch 0.544 (0.619) Remain 19:41:09 loss: 1.0226 Lr: 0.00136
[2025-05-11 13:46:20,580 INFO misc.py line 117 288342] Train: [2/50][448/2344] Data 0.003 (0.003) Batch 0.647 (0.619) Remain 19:41:15 loss: 0.6864 Lr: 0.00137
[2025-05-11 13:46:21,189 INFO misc.py line 117 288342] Train: [2/50][449/2344] Data 0.003 (0.003) Batch 0.608 (0.619) Remain 19:41:12 loss: 0.7517 Lr: 0.00137
[2025-05-11 13:46:21,910 INFO misc.py line 117 288342] Train: [2/50][450/2344] Data 0.003 (0.003) Batch 0.721 (0.620) Remain 19:41:37 loss: 0.6944 Lr: 0.00137
[2025-05-11 13:46:22,523 INFO misc.py line 117 288342] Train: [2/50][451/2344] Data 0.003 (0.003) Batch 0.613 (0.620) Remain 19:41:35 loss: 0.8091 Lr: 0.00137
[2025-05-11 13:46:23,273 INFO misc.py line 117 288342] Train: [2/50][452/2344] Data 0.003 (0.003) Batch 0.750 (0.620) Remain 19:42:07 loss: 1.0074 Lr: 0.00137
[2025-05-11 13:46:23,830 INFO misc.py line 117 288342] Train: [2/50][453/2344] Data 0.003 (0.003) Batch 0.557 (0.620) Remain 19:41:51 loss: 1.0125 Lr: 0.00137
[2025-05-11 13:46:24,488 INFO misc.py line 117 288342] Train: [2/50][454/2344] Data 0.003 (0.003) Batch 0.658 (0.620) Remain 19:42:00 loss: 0.7392 Lr: 0.00137
[2025-05-11 13:46:25,069 INFO misc.py line 117 288342] Train: [2/50][455/2344] Data 0.003 (0.003) Batch 0.582 (0.620) Remain 19:41:49 loss: 0.8874 Lr: 0.00137
[2025-05-11 13:46:25,688 INFO misc.py line 117 288342] Train: [2/50][456/2344] Data 0.003 (0.003) Batch 0.619 (0.620) Remain 19:41:48 loss: 1.2126 Lr: 0.00137
[2025-05-11 13:46:26,241 INFO misc.py line 117 288342] Train: [2/50][457/2344] Data 0.003 (0.003) Batch 0.553 (0.620) Remain 19:41:31 loss: 0.8500 Lr: 0.00137
[2025-05-11 13:46:26,696 INFO misc.py line 117 288342] Train: [2/50][458/2344] Data 0.003 (0.003) Batch 0.455 (0.619) Remain 19:40:49 loss: 0.8938 Lr: 0.00137
[2025-05-11 13:46:27,275 INFO misc.py line 117 288342] Train: [2/50][459/2344] Data 0.003 (0.003) Batch 0.579 (0.619) Remain 19:40:38 loss: 0.9911 Lr: 0.00137
[2025-05-11 13:46:27,811 INFO misc.py line 117 288342] Train: [2/50][460/2344] Data 0.003 (0.003) Batch 0.537 (0.619) Remain 19:40:17 loss: 0.8815 Lr: 0.00137
[2025-05-11 13:46:28,354 INFO misc.py line 117 288342] Train: [2/50][461/2344] Data 0.003 (0.003) Batch 0.543 (0.619) Remain 19:39:57 loss: 0.9837 Lr: 0.00137
[2025-05-11 13:46:28,877 INFO misc.py line 117 288342] Train: [2/50][462/2344] Data 0.002 (0.003) Batch 0.523 (0.619) Remain 19:39:33 loss: 0.9267 Lr: 0.00137
[2025-05-11 13:46:29,455 INFO misc.py line 117 288342] Train: [2/50][463/2344] Data 0.003 (0.003) Batch 0.578 (0.619) Remain 19:39:22 loss: 0.9704 Lr: 0.00137
[2025-05-11 13:46:30,140 INFO misc.py line 117 288342] Train: [2/50][464/2344] Data 0.003 (0.003) Batch 0.685 (0.619) Remain 19:39:38 loss: 0.7176 Lr: 0.00137
[2025-05-11 13:46:30,850 INFO misc.py line 117 288342] Train: [2/50][465/2344] Data 0.003 (0.003) Batch 0.710 (0.619) Remain 19:40:00 loss: 0.8722 Lr: 0.00138
[2025-05-11 13:46:31,481 INFO misc.py line 117 288342] Train: [2/50][466/2344] Data 0.003 (0.003) Batch 0.631 (0.619) Remain 19:40:02 loss: 0.7044 Lr: 0.00138
[2025-05-11 13:46:31,948 INFO misc.py line 117 288342] Train: [2/50][467/2344] Data 0.003 (0.003) Batch 0.467 (0.619) Remain 19:39:24 loss: 0.8146 Lr: 0.00138
[2025-05-11 13:46:32,615 INFO misc.py line 117 288342] Train: [2/50][468/2344] Data 0.003 (0.003) Batch 0.666 (0.619) Remain 19:39:35 loss: 0.7645 Lr: 0.00138
[2025-05-11 13:46:33,100 INFO misc.py line 117 288342] Train: [2/50][469/2344] Data 0.002 (0.003) Batch 0.486 (0.618) Remain 19:39:02 loss: 0.7751 Lr: 0.00138
[2025-05-11 13:46:33,753 INFO misc.py line 117 288342] Train: [2/50][470/2344] Data 0.003 (0.003) Batch 0.652 (0.619) Remain 19:39:10 loss: 0.8531 Lr: 0.00138
[2025-05-11 13:46:34,316 INFO misc.py line 117 288342] Train: [2/50][471/2344] Data 0.002 (0.003) Batch 0.563 (0.618) Remain 19:38:56 loss: 0.7967 Lr: 0.00138
[2025-05-11 13:46:34,891 INFO misc.py line 117 288342] Train: [2/50][472/2344] Data 0.003 (0.003) Batch 0.575 (0.618) Remain 19:38:44 loss: 0.8073 Lr: 0.00138
[2025-05-11 13:46:35,493 INFO misc.py line 117 288342] Train: [2/50][473/2344] Data 0.003 (0.003) Batch 0.602 (0.618) Remain 19:38:40 loss: 0.8833 Lr: 0.00138
[2025-05-11 13:46:35,995 INFO misc.py line 117 288342] Train: [2/50][474/2344] Data 0.003 (0.003) Batch 0.502 (0.618) Remain 19:38:11 loss: 0.7714 Lr: 0.00138
[2025-05-11 13:46:36,690 INFO misc.py line 117 288342] Train: [2/50][475/2344] Data 0.003 (0.003) Batch 0.695 (0.618) Remain 19:38:29 loss: 0.7628 Lr: 0.00138
[2025-05-11 13:46:37,258 INFO misc.py line 117 288342] Train: [2/50][476/2344] Data 0.003 (0.003) Batch 0.568 (0.618) Remain 19:38:16 loss: 0.8953 Lr: 0.00138
[2025-05-11 13:46:37,859 INFO misc.py line 117 288342] Train: [2/50][477/2344] Data 0.003 (0.003) Batch 0.601 (0.618) Remain 19:38:11 loss: 0.6219 Lr: 0.00138
[2025-05-11 13:46:38,516 INFO misc.py line 117 288342] Train: [2/50][478/2344] Data 0.003 (0.003) Batch 0.657 (0.618) Remain 19:38:20 loss: 0.7871 Lr: 0.00138
[2025-05-11 13:46:39,098 INFO misc.py line 117 288342] Train: [2/50][479/2344] Data 0.003 (0.003) Batch 0.582 (0.618) Remain 19:38:11 loss: 0.8085 Lr: 0.00138
[2025-05-11 13:46:39,617 INFO misc.py line 117 288342] Train: [2/50][480/2344] Data 0.003 (0.003) Batch 0.519 (0.618) Remain 19:37:46 loss: 0.7757 Lr: 0.00138
[2025-05-11 13:46:40,372 INFO misc.py line 117 288342] Train: [2/50][481/2344] Data 0.003 (0.003) Batch 0.756 (0.618) Remain 19:38:19 loss: 0.9008 Lr: 0.00138
[2025-05-11 13:46:41,054 INFO misc.py line 117 288342] Train: [2/50][482/2344] Data 0.003 (0.003) Batch 0.681 (0.618) Remain 19:38:33 loss: 0.9024 Lr: 0.00138
[2025-05-11 13:46:41,670 INFO misc.py line 117 288342] Train: [2/50][483/2344] Data 0.003 (0.003) Batch 0.616 (0.618) Remain 19:38:32 loss: 0.7120 Lr: 0.00139
[2025-05-11 13:46:42,222 INFO misc.py line 117 288342] Train: [2/50][484/2344] Data 0.003 (0.003) Batch 0.553 (0.618) Remain 19:38:16 loss: 0.9443 Lr: 0.00139
[2025-05-11 13:46:42,910 INFO misc.py line 117 288342] Train: [2/50][485/2344] Data 0.002 (0.003) Batch 0.687 (0.618) Remain 19:38:32 loss: 1.2590 Lr: 0.00139
[2025-05-11 13:46:43,444 INFO misc.py line 117 288342] Train: [2/50][486/2344] Data 0.003 (0.003) Batch 0.534 (0.618) Remain 19:38:11 loss: 0.9188 Lr: 0.00139
[2025-05-11 13:46:43,968 INFO misc.py line 117 288342] Train: [2/50][487/2344] Data 0.003 (0.003) Batch 0.524 (0.618) Remain 19:37:48 loss: 0.9485 Lr: 0.00139
[2025-05-11 13:46:44,528 INFO misc.py line 117 288342] Train: [2/50][488/2344] Data 0.003 (0.003) Batch 0.560 (0.618) Remain 19:37:34 loss: 0.7970 Lr: 0.00139
[2025-05-11 13:46:45,017 INFO misc.py line 117 288342] Train: [2/50][489/2344] Data 0.003 (0.003) Batch 0.489 (0.618) Remain 19:37:03 loss: 0.8185 Lr: 0.00139
[2025-05-11 13:46:45,662 INFO misc.py line 117 288342] Train: [2/50][490/2344] Data 0.003 (0.003) Batch 0.645 (0.618) Remain 19:37:09 loss: 0.8237 Lr: 0.00139
[2025-05-11 13:46:46,406 INFO misc.py line 117 288342] Train: [2/50][491/2344] Data 0.003 (0.003) Batch 0.745 (0.618) Remain 19:37:38 loss: 1.0015 Lr: 0.00139
[2025-05-11 13:46:47,049 INFO misc.py line 117 288342] Train: [2/50][492/2344] Data 0.003 (0.003) Batch 0.643 (0.618) Remain 19:37:43 loss: 1.0288 Lr: 0.00139
[2025-05-11 13:46:47,767 INFO misc.py line 117 288342] Train: [2/50][493/2344] Data 0.003 (0.003) Batch 0.717 (0.618) Remain 19:38:06 loss: 0.6513 Lr: 0.00139
[2025-05-11 13:46:48,440 INFO misc.py line 117 288342] Train: [2/50][494/2344] Data 0.002 (0.003) Batch 0.673 (0.618) Remain 19:38:18 loss: 0.7588 Lr: 0.00139
[2025-05-11 13:46:48,967 INFO misc.py line 117 288342] Train: [2/50][495/2344] Data 0.002 (0.003) Batch 0.527 (0.618) Remain 19:37:56 loss: 0.8011 Lr: 0.00139
[2025-05-11 13:46:49,625 INFO misc.py line 117 288342] Train: [2/50][496/2344] Data 0.003 (0.003) Batch 0.658 (0.618) Remain 19:38:05 loss: 0.7870 Lr: 0.00139
[2025-05-11 13:46:50,404 INFO misc.py line 117 288342] Train: [2/50][497/2344] Data 0.002 (0.003) Batch 0.780 (0.618) Remain 19:38:42 loss: 0.8976 Lr: 0.00139
[2025-05-11 13:46:50,996 INFO misc.py line 117 288342] Train: [2/50][498/2344] Data 0.002 (0.003) Batch 0.591 (0.618) Remain 19:38:35 loss: 0.7190 Lr: 0.00139
[2025-05-11 13:46:51,609 INFO misc.py line 117 288342] Train: [2/50][499/2344] Data 0.003 (0.003) Batch 0.613 (0.618) Remain 19:38:33 loss: 0.7499 Lr: 0.00139
[2025-05-11 13:46:52,308 INFO misc.py line 117 288342] Train: [2/50][500/2344] Data 0.002 (0.003) Batch 0.699 (0.619) Remain 19:38:51 loss: 0.5655 Lr: 0.00140
[2025-05-11 13:46:52,965 INFO misc.py line 117 288342] Train: [2/50][501/2344] Data 0.002 (0.003) Batch 0.656 (0.619) Remain 19:38:59 loss: 0.6724 Lr: 0.00140
[2025-05-11 13:46:53,585 INFO misc.py line 117 288342] Train: [2/50][502/2344] Data 0.002 (0.003) Batch 0.620 (0.619) Remain 19:38:59 loss: 0.8141 Lr: 0.00140
[2025-05-11 13:46:54,301 INFO misc.py line 117 288342] Train: [2/50][503/2344] Data 0.002 (0.003) Batch 0.716 (0.619) Remain 19:39:21 loss: 0.6464 Lr: 0.00140
[2025-05-11 13:46:54,901 INFO misc.py line 117 288342] Train: [2/50][504/2344] Data 0.003 (0.003) Batch 0.600 (0.619) Remain 19:39:16 loss: 0.8227 Lr: 0.00140
[2025-05-11 13:46:55,491 INFO misc.py line 117 288342] Train: [2/50][505/2344] Data 0.003 (0.003) Batch 0.590 (0.619) Remain 19:39:09 loss: 0.7365 Lr: 0.00140
[2025-05-11 13:46:56,148 INFO misc.py line 117 288342] Train: [2/50][506/2344] Data 0.002 (0.003) Batch 0.657 (0.619) Remain 19:39:17 loss: 0.8500 Lr: 0.00140
[2025-05-11 13:46:56,679 INFO misc.py line 117 288342] Train: [2/50][507/2344] Data 0.002 (0.003) Batch 0.531 (0.619) Remain 19:38:56 loss: 0.9839 Lr: 0.00140
[2025-05-11 13:46:57,323 INFO misc.py line 117 288342] Train: [2/50][508/2344] Data 0.003 (0.003) Batch 0.644 (0.619) Remain 19:39:01 loss: 0.8231 Lr: 0.00140
[2025-05-11 13:46:58,042 INFO misc.py line 117 288342] Train: [2/50][509/2344] Data 0.002 (0.003) Batch 0.719 (0.619) Remain 19:39:23 loss: 0.8844 Lr: 0.00140
[2025-05-11 13:46:58,710 INFO misc.py line 117 288342] Train: [2/50][510/2344] Data 0.003 (0.003) Batch 0.667 (0.619) Remain 19:39:34 loss: 0.7813 Lr: 0.00140
[2025-05-11 13:46:59,387 INFO misc.py line 117 288342] Train: [2/50][511/2344] Data 0.002 (0.003) Batch 0.678 (0.619) Remain 19:39:46 loss: 0.8611 Lr: 0.00140
[2025-05-11 13:47:00,006 INFO misc.py line 117 288342] Train: [2/50][512/2344] Data 0.003 (0.003) Batch 0.619 (0.619) Remain 19:39:46 loss: 0.6690 Lr: 0.00140
[2025-05-11 13:47:00,555 INFO misc.py line 117 288342] Train: [2/50][513/2344] Data 0.003 (0.003) Batch 0.549 (0.619) Remain 19:39:29 loss: 0.7800 Lr: 0.00140
[2025-05-11 13:47:01,186 INFO misc.py line 117 288342] Train: [2/50][514/2344] Data 0.003 (0.003) Batch 0.631 (0.619) Remain 19:39:31 loss: 0.9747 Lr: 0.00140
[2025-05-11 13:47:01,899 INFO misc.py line 117 288342] Train: [2/50][515/2344] Data 0.002 (0.003) Batch 0.713 (0.619) Remain 19:39:52 loss: 0.5617 Lr: 0.00140
[2025-05-11 13:47:02,431 INFO misc.py line 117 288342] Train: [2/50][516/2344] Data 0.003 (0.003) Batch 0.532 (0.619) Remain 19:39:32 loss: 0.9502 Lr: 0.00140
[2025-05-11 13:47:03,120 INFO misc.py line 117 288342] Train: [2/50][517/2344] Data 0.002 (0.003) Batch 0.689 (0.619) Remain 19:39:47 loss: 0.7785 Lr: 0.00140
[2025-05-11 13:47:03,666 INFO misc.py line 117 288342] Train: [2/50][518/2344] Data 0.002 (0.003) Batch 0.546 (0.619) Remain 19:39:30 loss: 0.8033 Lr: 0.00141
[2025-05-11 13:47:04,281 INFO misc.py line 117 288342] Train: [2/50][519/2344] Data 0.003 (0.003) Batch 0.614 (0.619) Remain 19:39:28 loss: 0.8888 Lr: 0.00141
[2025-05-11 13:47:04,890 INFO misc.py line 117 288342] Train: [2/50][520/2344] Data 0.003 (0.003) Batch 0.609 (0.619) Remain 19:39:25 loss: 0.9474 Lr: 0.00141
[2025-05-11 13:47:05,571 INFO misc.py line 117 288342] Train: [2/50][521/2344] Data 0.003 (0.003) Batch 0.681 (0.619) Remain 19:39:38 loss: 0.9451 Lr: 0.00141
[2025-05-11 13:47:06,166 INFO misc.py line 117 288342] Train: [2/50][522/2344] Data 0.003 (0.003) Batch 0.595 (0.619) Remain 19:39:33 loss: 0.9214 Lr: 0.00141
[2025-05-11 13:47:06,624 INFO misc.py line 117 288342] Train: [2/50][523/2344] Data 0.003 (0.003) Batch 0.458 (0.619) Remain 19:38:57 loss: 0.8991 Lr: 0.00141
[2025-05-11 13:47:07,226 INFO misc.py line 117 288342] Train: [2/50][524/2344] Data 0.003 (0.003) Batch 0.602 (0.619) Remain 19:38:52 loss: 0.6431 Lr: 0.00141
[2025-05-11 13:47:07,910 INFO misc.py line 117 288342] Train: [2/50][525/2344] Data 0.003 (0.003) Batch 0.685 (0.619) Remain 19:39:06 loss: 1.0604 Lr: 0.00141
[2025-05-11 13:47:08,557 INFO misc.py line 117 288342] Train: [2/50][526/2344] Data 0.003 (0.003) Batch 0.646 (0.619) Remain 19:39:11 loss: 0.6665 Lr: 0.00141
[2025-05-11 13:47:09,249 INFO misc.py line 117 288342] Train: [2/50][527/2344] Data 0.003 (0.003) Batch 0.693 (0.619) Remain 19:39:27 loss: 0.5534 Lr: 0.00141
[2025-05-11 13:47:09,948 INFO misc.py line 117 288342] Train: [2/50][528/2344] Data 0.003 (0.003) Batch 0.699 (0.619) Remain 19:39:44 loss: 0.6907 Lr: 0.00141
[2025-05-11 13:47:10,464 INFO misc.py line 117 288342] Train: [2/50][529/2344] Data 0.003 (0.003) Batch 0.516 (0.619) Remain 19:39:21 loss: 0.8758 Lr: 0.00141
[2025-05-11 13:47:11,227 INFO misc.py line 117 288342] Train: [2/50][530/2344] Data 0.003 (0.003) Batch 0.764 (0.619) Remain 19:39:51 loss: 0.7461 Lr: 0.00141
[2025-05-11 13:47:11,916 INFO misc.py line 117 288342] Train: [2/50][531/2344] Data 0.002 (0.003) Batch 0.689 (0.619) Remain 19:40:06 loss: 0.9621 Lr: 0.00141
[2025-05-11 13:47:12,530 INFO misc.py line 117 288342] Train: [2/50][532/2344] Data 0.003 (0.003) Batch 0.614 (0.619) Remain 19:40:04 loss: 0.8805 Lr: 0.00141
[2025-05-11 13:47:13,070 INFO misc.py line 117 288342] Train: [2/50][533/2344] Data 0.003 (0.003) Batch 0.540 (0.619) Remain 19:39:46 loss: 0.5881 Lr: 0.00141
[2025-05-11 13:47:13,609 INFO misc.py line 117 288342] Train: [2/50][534/2344] Data 0.003 (0.003) Batch 0.539 (0.619) Remain 19:39:28 loss: 0.8348 Lr: 0.00141
[2025-05-11 13:47:14,244 INFO misc.py line 117 288342] Train: [2/50][535/2344] Data 0.002 (0.003) Batch 0.635 (0.619) Remain 19:39:31 loss: 0.7312 Lr: 0.00142
[2025-05-11 13:47:14,761 INFO misc.py line 117 288342] Train: [2/50][536/2344] Data 0.002 (0.003) Batch 0.518 (0.619) Remain 19:39:09 loss: 1.1139 Lr: 0.00142
[2025-05-11 13:47:15,389 INFO misc.py line 117 288342] Train: [2/50][537/2344] Data 0.002 (0.003) Batch 0.627 (0.619) Remain 19:39:10 loss: 0.8903 Lr: 0.00142
[2025-05-11 13:47:15,987 INFO misc.py line 117 288342] Train: [2/50][538/2344] Data 0.002 (0.003) Batch 0.598 (0.619) Remain 19:39:05 loss: 0.6760 Lr: 0.00142
[2025-05-11 13:47:16,598 INFO misc.py line 117 288342] Train: [2/50][539/2344] Data 0.002 (0.003) Batch 0.611 (0.619) Remain 19:39:03 loss: 0.8153 Lr: 0.00142
[2025-05-11 13:47:17,169 INFO misc.py line 117 288342] Train: [2/50][540/2344] Data 0.002 (0.003) Batch 0.571 (0.619) Remain 19:38:52 loss: 0.8813 Lr: 0.00142
[2025-05-11 13:47:17,727 INFO misc.py line 117 288342] Train: [2/50][541/2344] Data 0.002 (0.003) Batch 0.558 (0.619) Remain 19:38:38 loss: 0.8466 Lr: 0.00142
[2025-05-11 13:47:18,324 INFO misc.py line 117 288342] Train: [2/50][542/2344] Data 0.003 (0.003) Batch 0.597 (0.619) Remain 19:38:33 loss: 0.8906 Lr: 0.00142
[2025-05-11 13:47:18,866 INFO misc.py line 117 288342] Train: [2/50][543/2344] Data 0.003 (0.003) Batch 0.542 (0.618) Remain 19:38:16 loss: 0.7292 Lr: 0.00142
[2025-05-11 13:47:19,534 INFO misc.py line 117 288342] Train: [2/50][544/2344] Data 0.003 (0.003) Batch 0.668 (0.619) Remain 19:38:26 loss: 0.7008 Lr: 0.00142
[2025-05-11 13:47:20,087 INFO misc.py line 117 288342] Train: [2/50][545/2344] Data 0.003 (0.003) Batch 0.553 (0.618) Remain 19:38:12 loss: 0.6863 Lr: 0.00142
[2025-05-11 13:47:20,605 INFO misc.py line 117 288342] Train: [2/50][546/2344] Data 0.003 (0.003) Batch 0.518 (0.618) Remain 19:37:50 loss: 0.7525 Lr: 0.00142
[2025-05-11 13:47:21,202 INFO misc.py line 117 288342] Train: [2/50][547/2344] Data 0.002 (0.003) Batch 0.596 (0.618) Remain 19:37:45 loss: 0.8483 Lr: 0.00142
[2025-05-11 13:47:21,702 INFO misc.py line 117 288342] Train: [2/50][548/2344] Data 0.002 (0.003) Batch 0.500 (0.618) Remain 19:37:19 loss: 0.6818 Lr: 0.00142
[2025-05-11 13:47:22,486 INFO misc.py line 117 288342] Train: [2/50][549/2344] Data 0.002 (0.003) Batch 0.784 (0.618) Remain 19:37:54 loss: 0.6500 Lr: 0.00142
[2025-05-11 13:47:23,123 INFO misc.py line 117 288342] Train: [2/50][550/2344] Data 0.002 (0.003) Batch 0.637 (0.618) Remain 19:37:57 loss: 0.6804 Lr: 0.00142
[2025-05-11 13:47:23,682 INFO misc.py line 117 288342] Train: [2/50][551/2344] Data 0.003 (0.003) Batch 0.558 (0.618) Remain 19:37:44 loss: 0.7021 Lr: 0.00142
[2025-05-11 13:47:24,342 INFO misc.py line 117 288342] Train: [2/50][552/2344] Data 0.003 (0.003) Batch 0.660 (0.618) Remain 19:37:52 loss: 0.9358 Lr: 0.00142
[2025-05-11 13:47:25,116 INFO misc.py line 117 288342] Train: [2/50][553/2344] Data 0.002 (0.003) Batch 0.774 (0.619) Remain 19:38:24 loss: 0.8413 Lr: 0.00143
[2025-05-11 13:47:25,791 INFO misc.py line 117 288342] Train: [2/50][554/2344] Data 0.002 (0.003) Batch 0.675 (0.619) Remain 19:38:35 loss: 0.8520 Lr: 0.00143
[2025-05-11 13:47:26,535 INFO misc.py line 117 288342] Train: [2/50][555/2344] Data 0.003 (0.003) Batch 0.743 (0.619) Remain 19:39:00 loss: 0.7814 Lr: 0.00143
[2025-05-11 13:47:27,191 INFO misc.py line 117 288342] Train: [2/50][556/2344] Data 0.003 (0.003) Batch 0.657 (0.619) Remain 19:39:07 loss: 0.5658 Lr: 0.00143
[2025-05-11 13:47:27,769 INFO misc.py line 117 288342] Train: [2/50][557/2344] Data 0.003 (0.003) Batch 0.578 (0.619) Remain 19:38:58 loss: 1.2551 Lr: 0.00143
[2025-05-11 13:47:28,357 INFO misc.py line 117 288342] Train: [2/50][558/2344] Data 0.003 (0.003) Batch 0.588 (0.619) Remain 19:38:51 loss: 0.8859 Lr: 0.00143
[2025-05-11 13:47:28,823 INFO misc.py line 117 288342] Train: [2/50][559/2344] Data 0.002 (0.003) Batch 0.465 (0.619) Remain 19:38:19 loss: 0.8475 Lr: 0.00143
[2025-05-11 13:47:29,505 INFO misc.py line 117 288342] Train: [2/50][560/2344] Data 0.003 (0.003) Batch 0.683 (0.619) Remain 19:38:32 loss: 0.9702 Lr: 0.00143
[2025-05-11 13:47:30,176 INFO misc.py line 117 288342] Train: [2/50][561/2344] Data 0.002 (0.003) Batch 0.670 (0.619) Remain 19:38:42 loss: 1.0212 Lr: 0.00143
[2025-05-11 13:47:31,040 INFO misc.py line 117 288342] Train: [2/50][562/2344] Data 0.002 (0.003) Batch 0.864 (0.619) Remain 19:39:31 loss: 1.1189 Lr: 0.00143
[2025-05-11 13:47:31,604 INFO misc.py line 117 288342] Train: [2/50][563/2344] Data 0.003 (0.003) Batch 0.564 (0.619) Remain 19:39:19 loss: 1.0198 Lr: 0.00143
[2025-05-11 13:47:32,238 INFO misc.py line 117 288342] Train: [2/50][564/2344] Data 0.002 (0.003) Batch 0.634 (0.619) Remain 19:39:22 loss: 0.7595 Lr: 0.00143
[2025-05-11 13:47:32,816 INFO misc.py line 117 288342] Train: [2/50][565/2344] Data 0.003 (0.003) Batch 0.579 (0.619) Remain 19:39:13 loss: 0.8124 Lr: 0.00143
[2025-05-11 13:47:33,385 INFO misc.py line 117 288342] Train: [2/50][566/2344] Data 0.003 (0.003) Batch 0.569 (0.619) Remain 19:39:02 loss: 0.8546 Lr: 0.00143
[2025-05-11 13:47:34,178 INFO misc.py line 117 288342] Train: [2/50][567/2344] Data 0.002 (0.003) Batch 0.793 (0.619) Remain 19:39:36 loss: 0.6878 Lr: 0.00143
[2025-05-11 13:47:34,882 INFO misc.py line 117 288342] Train: [2/50][568/2344] Data 0.003 (0.003) Batch 0.704 (0.619) Remain 19:39:53 loss: 0.6730 Lr: 0.00143
[2025-05-11 13:47:35,441 INFO misc.py line 117 288342] Train: [2/50][569/2344] Data 0.003 (0.003) Batch 0.559 (0.619) Remain 19:39:40 loss: 0.8525 Lr: 0.00143
[2025-05-11 13:47:35,955 INFO misc.py line 117 288342] Train: [2/50][570/2344] Data 0.003 (0.003) Batch 0.514 (0.619) Remain 19:39:18 loss: 0.6278 Lr: 0.00143
[2025-05-11 13:47:36,590 INFO misc.py line 117 288342] Train: [2/50][571/2344] Data 0.003 (0.003) Batch 0.635 (0.619) Remain 19:39:21 loss: 0.9473 Lr: 0.00144
[2025-05-11 13:47:37,381 INFO misc.py line 117 288342] Train: [2/50][572/2344] Data 0.002 (0.003) Batch 0.790 (0.619) Remain 19:39:55 loss: 0.9010 Lr: 0.00144
[2025-05-11 13:47:37,886 INFO misc.py line 117 288342] Train: [2/50][573/2344] Data 0.003 (0.003) Batch 0.505 (0.619) Remain 19:39:31 loss: 0.6457 Lr: 0.00144
[2025-05-11 13:47:38,468 INFO misc.py line 117 288342] Train: [2/50][574/2344] Data 0.003 (0.003) Batch 0.582 (0.619) Remain 19:39:23 loss: 0.9412 Lr: 0.00144
[2025-05-11 13:47:39,062 INFO misc.py line 117 288342] Train: [2/50][575/2344] Data 0.002 (0.003) Batch 0.594 (0.619) Remain 19:39:18 loss: 0.7939 Lr: 0.00144
[2025-05-11 13:47:39,609 INFO misc.py line 117 288342] Train: [2/50][576/2344] Data 0.002 (0.003) Batch 0.546 (0.619) Remain 19:39:02 loss: 0.9045 Lr: 0.00144
[2025-05-11 13:47:40,266 INFO misc.py line 117 288342] Train: [2/50][577/2344] Data 0.003 (0.003) Batch 0.658 (0.619) Remain 19:39:09 loss: 0.6829 Lr: 0.00144
[2025-05-11 13:47:40,767 INFO misc.py line 117 288342] Train: [2/50][578/2344] Data 0.003 (0.003) Batch 0.501 (0.619) Remain 19:38:45 loss: 0.9236 Lr: 0.00144
[2025-05-11 13:47:41,495 INFO misc.py line 117 288342] Train: [2/50][579/2344] Data 0.003 (0.003) Batch 0.728 (0.619) Remain 19:39:06 loss: 0.7145 Lr: 0.00144
[2025-05-11 13:47:42,064 INFO misc.py line 117 288342] Train: [2/50][580/2344] Data 0.003 (0.003) Batch 0.570 (0.619) Remain 19:38:56 loss: 0.7560 Lr: 0.00144
[2025-05-11 13:47:42,845 INFO misc.py line 117 288342] Train: [2/50][581/2344] Data 0.003 (0.003) Batch 0.780 (0.619) Remain 19:39:27 loss: 0.7567 Lr: 0.00144
[2025-05-11 13:47:43,547 INFO misc.py line 117 288342] Train: [2/50][582/2344] Data 0.002 (0.003) Batch 0.702 (0.619) Remain 19:39:43 loss: 0.8466 Lr: 0.00144
[2025-05-11 13:47:44,184 INFO misc.py line 117 288342] Train: [2/50][583/2344] Data 0.003 (0.003) Batch 0.637 (0.619) Remain 19:39:46 loss: 0.7327 Lr: 0.00144
[2025-05-11 13:47:44,710 INFO misc.py line 117 288342] Train: [2/50][584/2344] Data 0.003 (0.003) Batch 0.526 (0.619) Remain 19:39:27 loss: 0.9001 Lr: 0.00144
[2025-05-11 13:47:45,240 INFO misc.py line 117 288342] Train: [2/50][585/2344] Data 0.003 (0.003) Batch 0.529 (0.619) Remain 19:39:09 loss: 0.8089 Lr: 0.00144
[2025-05-11 13:47:45,929 INFO misc.py line 117 288342] Train: [2/50][586/2344] Data 0.003 (0.003) Batch 0.689 (0.619) Remain 19:39:22 loss: 1.0021 Lr: 0.00144
[2025-05-11 13:47:46,456 INFO misc.py line 117 288342] Train: [2/50][587/2344] Data 0.003 (0.003) Batch 0.528 (0.619) Remain 19:39:03 loss: 0.6651 Lr: 0.00144
[2025-05-11 13:47:47,134 INFO misc.py line 117 288342] Train: [2/50][588/2344] Data 0.003 (0.003) Batch 0.677 (0.619) Remain 19:39:14 loss: 0.9093 Lr: 0.00144
[2025-05-11 13:47:47,713 INFO misc.py line 117 288342] Train: [2/50][589/2344] Data 0.002 (0.003) Batch 0.579 (0.619) Remain 19:39:05 loss: 0.7457 Lr: 0.00145
[2025-05-11 13:47:48,220 INFO misc.py line 117 288342] Train: [2/50][590/2344] Data 0.003 (0.003) Batch 0.508 (0.619) Remain 19:38:43 loss: 0.8283 Lr: 0.00145
[2025-05-11 13:47:48,932 INFO misc.py line 117 288342] Train: [2/50][591/2344] Data 0.002 (0.003) Batch 0.711 (0.619) Remain 19:39:00 loss: 0.7148 Lr: 0.00145
[2025-05-11 13:47:49,564 INFO misc.py line 117 288342] Train: [2/50][592/2344] Data 0.003 (0.003) Batch 0.632 (0.619) Remain 19:39:02 loss: 0.6868 Lr: 0.00145
[2025-05-11 13:47:50,092 INFO misc.py line 117 288342] Train: [2/50][593/2344] Data 0.003 (0.003) Batch 0.528 (0.619) Remain 19:38:44 loss: 0.6959 Lr: 0.00145
[2025-05-11 13:47:50,731 INFO misc.py line 117 288342] Train: [2/50][594/2344] Data 0.003 (0.003) Batch 0.640 (0.619) Remain 19:38:47 loss: 0.7517 Lr: 0.00145
[2025-05-11 13:47:51,292 INFO misc.py line 117 288342] Train: [2/50][595/2344] Data 0.002 (0.003) Batch 0.561 (0.619) Remain 19:38:36 loss: 0.6769 Lr: 0.00145
[2025-05-11 13:47:52,096 INFO misc.py line 117 288342] Train: [2/50][596/2344] Data 0.002 (0.003) Batch 0.804 (0.619) Remain 19:39:11 loss: 0.6797 Lr: 0.00145
[2025-05-11 13:47:52,629 INFO misc.py line 117 288342] Train: [2/50][597/2344] Data 0.003 (0.003) Batch 0.533 (0.619) Remain 19:38:53 loss: 0.7970 Lr: 0.00145
[2025-05-11 13:47:53,274 INFO misc.py line 117 288342] Train: [2/50][598/2344] Data 0.002 (0.003) Batch 0.645 (0.619) Remain 19:38:58 loss: 0.9331 Lr: 0.00145
[2025-05-11 13:47:53,843 INFO misc.py line 117 288342] Train: [2/50][599/2344] Data 0.002 (0.003) Batch 0.569 (0.619) Remain 19:38:48 loss: 0.9835 Lr: 0.00145
[2025-05-11 13:47:54,271 INFO misc.py line 117 288342] Train: [2/50][600/2344] Data 0.003 (0.003) Batch 0.428 (0.619) Remain 19:38:10 loss: 0.8470 Lr: 0.00145
[2025-05-11 13:47:54,798 INFO misc.py line 117 288342] Train: [2/50][601/2344] Data 0.003 (0.003) Batch 0.527 (0.619) Remain 19:37:52 loss: 0.8088 Lr: 0.00145
[2025-05-11 13:47:55,377 INFO misc.py line 117 288342] Train: [2/50][602/2344] Data 0.002 (0.003) Batch 0.578 (0.618) Remain 19:37:44 loss: 0.6383 Lr: 0.00145
[2025-05-11 13:47:55,995 INFO misc.py line 117 288342] Train: [2/50][603/2344] Data 0.003 (0.003) Batch 0.618 (0.618) Remain 19:37:43 loss: 0.8728 Lr: 0.00145
[2025-05-11 13:47:56,652 INFO misc.py line 117 288342] Train: [2/50][604/2344] Data 0.003 (0.003) Batch 0.657 (0.619) Remain 19:37:50 loss: 0.8150 Lr: 0.00145
[2025-05-11 13:47:57,230 INFO misc.py line 117 288342] Train: [2/50][605/2344] Data 0.003 (0.003) Batch 0.578 (0.618) Remain 19:37:42 loss: 0.7687 Lr: 0.00145
[2025-05-11 13:47:57,788 INFO misc.py line 117 288342] Train: [2/50][606/2344] Data 0.003 (0.003) Batch 0.558 (0.618) Remain 19:37:30 loss: 0.7744 Lr: 0.00145
[2025-05-11 13:47:58,374 INFO misc.py line 117 288342] Train: [2/50][607/2344] Data 0.003 (0.003) Batch 0.586 (0.618) Remain 19:37:23 loss: 0.9845 Lr: 0.00146
[2025-05-11 13:47:58,997 INFO misc.py line 117 288342] Train: [2/50][608/2344] Data 0.003 (0.003) Batch 0.623 (0.618) Remain 19:37:23 loss: 0.7110 Lr: 0.00146
[2025-05-11 13:47:59,588 INFO misc.py line 117 288342] Train: [2/50][609/2344] Data 0.002 (0.003) Batch 0.591 (0.618) Remain 19:37:17 loss: 0.8783 Lr: 0.00146
[2025-05-11 13:48:00,219 INFO misc.py line 117 288342] Train: [2/50][610/2344] Data 0.002 (0.003) Batch 0.631 (0.618) Remain 19:37:19 loss: 0.7439 Lr: 0.00146
[2025-05-11 13:48:00,703 INFO misc.py line 117 288342] Train: [2/50][611/2344] Data 0.002 (0.003) Batch 0.484 (0.618) Remain 19:36:53 loss: 0.6990 Lr: 0.00146
[2025-05-11 13:48:01,283 INFO misc.py line 117 288342] Train: [2/50][612/2344] Data 0.003 (0.003) Batch 0.580 (0.618) Remain 19:36:46 loss: 1.1503 Lr: 0.00146
[2025-05-11 13:48:01,976 INFO misc.py line 117 288342] Train: [2/50][613/2344] Data 0.003 (0.003) Batch 0.692 (0.618) Remain 19:36:59 loss: 0.9561 Lr: 0.00146
[2025-05-11 13:48:02,527 INFO misc.py line 117 288342] Train: [2/50][614/2344] Data 0.002 (0.003) Batch 0.552 (0.618) Remain 19:36:46 loss: 0.6862 Lr: 0.00146
[2025-05-11 13:48:03,073 INFO misc.py line 117 288342] Train: [2/50][615/2344] Data 0.003 (0.003) Batch 0.545 (0.618) Remain 19:36:32 loss: 1.0409 Lr: 0.00146
[2025-05-11 13:48:03,546 INFO misc.py line 117 288342] Train: [2/50][616/2344] Data 0.003 (0.003) Batch 0.473 (0.618) Remain 19:36:04 loss: 0.6729 Lr: 0.00146
[2025-05-11 13:48:04,203 INFO misc.py line 117 288342] Train: [2/50][617/2344] Data 0.003 (0.003) Batch 0.657 (0.618) Remain 19:36:11 loss: 0.7001 Lr: 0.00146
[2025-05-11 13:48:04,795 INFO misc.py line 117 288342] Train: [2/50][618/2344] Data 0.003 (0.003) Batch 0.593 (0.618) Remain 19:36:05 loss: 0.6868 Lr: 0.00146
[2025-05-11 13:48:05,490 INFO misc.py line 117 288342] Train: [2/50][619/2344] Data 0.002 (0.003) Batch 0.695 (0.618) Remain 19:36:19 loss: 0.6938 Lr: 0.00146
[2025-05-11 13:48:06,037 INFO misc.py line 117 288342] Train: [2/50][620/2344] Data 0.002 (0.003) Batch 0.547 (0.618) Remain 19:36:05 loss: 0.8314 Lr: 0.00146
[2025-05-11 13:48:06,829 INFO misc.py line 117 288342] Train: [2/50][621/2344] Data 0.002 (0.003) Batch 0.792 (0.618) Remain 19:36:37 loss: 0.8100 Lr: 0.00146
[2025-05-11 13:48:07,526 INFO misc.py line 117 288342] Train: [2/50][622/2344] Data 0.003 (0.003) Batch 0.697 (0.618) Remain 19:36:51 loss: 0.8357 Lr: 0.00146
[2025-05-11 13:48:08,115 INFO misc.py line 117 288342] Train: [2/50][623/2344] Data 0.003 (0.003) Batch 0.589 (0.618) Remain 19:36:45 loss: 1.0285 Lr: 0.00146
[2025-05-11 13:48:08,815 INFO misc.py line 117 288342] Train: [2/50][624/2344] Data 0.003 (0.003) Batch 0.701 (0.618) Remain 19:37:00 loss: 0.6117 Lr: 0.00146
[2025-05-11 13:48:09,400 INFO misc.py line 117 288342] Train: [2/50][625/2344] Data 0.002 (0.003) Batch 0.585 (0.618) Remain 19:36:53 loss: 0.7689 Lr: 0.00147
[2025-05-11 13:48:09,981 INFO misc.py line 117 288342] Train: [2/50][626/2344] Data 0.003 (0.003) Batch 0.581 (0.618) Remain 19:36:45 loss: 0.7950 Lr: 0.00147
[2025-05-11 13:48:10,535 INFO misc.py line 117 288342] Train: [2/50][627/2344] Data 0.003 (0.003) Batch 0.554 (0.618) Remain 19:36:33 loss: 0.6690 Lr: 0.00147
[2025-05-11 13:48:11,068 INFO misc.py line 117 288342] Train: [2/50][628/2344] Data 0.003 (0.003) Batch 0.533 (0.618) Remain 19:36:17 loss: 0.7917 Lr: 0.00147
[2025-05-11 13:48:11,630 INFO misc.py line 117 288342] Train: [2/50][629/2344] Data 0.003 (0.003) Batch 0.562 (0.618) Remain 19:36:06 loss: 0.8500 Lr: 0.00147
[2025-05-11 13:48:12,269 INFO misc.py line 117 288342] Train: [2/50][630/2344] Data 0.002 (0.003) Batch 0.639 (0.618) Remain 19:36:09 loss: 0.6432 Lr: 0.00147
[2025-05-11 13:48:12,707 INFO misc.py line 117 288342] Train: [2/50][631/2344] Data 0.002 (0.003) Batch 0.438 (0.618) Remain 19:35:36 loss: 0.9116 Lr: 0.00147
[2025-05-11 13:48:13,418 INFO misc.py line 117 288342] Train: [2/50][632/2344] Data 0.003 (0.003) Batch 0.711 (0.618) Remain 19:35:52 loss: 0.6987 Lr: 0.00147
[2025-05-11 13:48:14,002 INFO misc.py line 117 288342] Train: [2/50][633/2344] Data 0.003 (0.003) Batch 0.584 (0.618) Remain 19:35:45 loss: 0.6516 Lr: 0.00147
[2025-05-11 13:48:14,661 INFO misc.py line 117 288342] Train: [2/50][634/2344] Data 0.003 (0.003) Batch 0.659 (0.618) Remain 19:35:52 loss: 1.0160 Lr: 0.00147
[2025-05-11 13:48:15,276 INFO misc.py line 117 288342] Train: [2/50][635/2344] Data 0.003 (0.003) Batch 0.616 (0.618) Remain 19:35:51 loss: 0.7514 Lr: 0.00147
[2025-05-11 13:48:15,914 INFO misc.py line 117 288342] Train: [2/50][636/2344] Data 0.003 (0.003) Batch 0.638 (0.618) Remain 19:35:54 loss: 0.8351 Lr: 0.00147
[2025-05-11 13:48:16,549 INFO misc.py line 117 288342] Train: [2/50][637/2344] Data 0.003 (0.003) Batch 0.635 (0.618) Remain 19:35:57 loss: 0.7577 Lr: 0.00147
[2025-05-11 13:48:17,066 INFO misc.py line 117 288342] Train: [2/50][638/2344] Data 0.003 (0.003) Batch 0.517 (0.618) Remain 19:35:38 loss: 0.7908 Lr: 0.00147
[2025-05-11 13:48:17,735 INFO misc.py line 117 288342] Train: [2/50][639/2344] Data 0.003 (0.003) Batch 0.669 (0.618) Remain 19:35:47 loss: 0.5448 Lr: 0.00147
[2025-05-11 13:48:18,228 INFO misc.py line 117 288342] Train: [2/50][640/2344] Data 0.002 (0.003) Batch 0.492 (0.617) Remain 19:35:24 loss: 0.8060 Lr: 0.00147
[2025-05-11 13:48:18,879 INFO misc.py line 117 288342] Train: [2/50][641/2344] Data 0.003 (0.003) Batch 0.652 (0.618) Remain 19:35:29 loss: 0.6254 Lr: 0.00147
[2025-05-11 13:48:19,526 INFO misc.py line 117 288342] Train: [2/50][642/2344] Data 0.003 (0.003) Batch 0.647 (0.618) Remain 19:35:34 loss: 0.8948 Lr: 0.00147
[2025-05-11 13:48:20,192 INFO misc.py line 117 288342] Train: [2/50][643/2344] Data 0.003 (0.003) Batch 0.667 (0.618) Remain 19:35:42 loss: 0.9243 Lr: 0.00148
[2025-05-11 13:48:20,840 INFO misc.py line 117 288342] Train: [2/50][644/2344] Data 0.002 (0.003) Batch 0.647 (0.618) Remain 19:35:47 loss: 0.8633 Lr: 0.00148
[2025-05-11 13:48:21,466 INFO misc.py line 117 288342] Train: [2/50][645/2344] Data 0.003 (0.003) Batch 0.626 (0.618) Remain 19:35:47 loss: 0.9531 Lr: 0.00148
[2025-05-11 13:48:22,089 INFO misc.py line 117 288342] Train: [2/50][646/2344] Data 0.003 (0.003) Batch 0.624 (0.618) Remain 19:35:48 loss: 0.8199 Lr: 0.00148
[2025-05-11 13:48:22,738 INFO misc.py line 117 288342] Train: [2/50][647/2344] Data 0.002 (0.003) Batch 0.649 (0.618) Remain 19:35:53 loss: 0.8592 Lr: 0.00148
[2025-05-11 13:48:23,365 INFO misc.py line 117 288342] Train: [2/50][648/2344] Data 0.002 (0.003) Batch 0.627 (0.618) Remain 19:35:54 loss: 0.7529 Lr: 0.00148
[2025-05-11 13:48:23,920 INFO misc.py line 117 288342] Train: [2/50][649/2344] Data 0.002 (0.003) Batch 0.555 (0.618) Remain 19:35:42 loss: 0.8835 Lr: 0.00148
[2025-05-11 13:48:24,595 INFO misc.py line 117 288342] Train: [2/50][650/2344] Data 0.002 (0.003) Batch 0.675 (0.618) Remain 19:35:52 loss: 0.7294 Lr: 0.00148
[2025-05-11 13:48:25,292 INFO misc.py line 117 288342] Train: [2/50][651/2344] Data 0.002 (0.003) Batch 0.697 (0.618) Remain 19:36:05 loss: 0.7934 Lr: 0.00148
[2025-05-11 13:48:25,967 INFO misc.py line 117 288342] Train: [2/50][652/2344] Data 0.003 (0.003) Batch 0.675 (0.618) Remain 19:36:14 loss: 0.8295 Lr: 0.00148
[2025-05-11 13:48:26,541 INFO misc.py line 117 288342] Train: [2/50][653/2344] Data 0.003 (0.003) Batch 0.574 (0.618) Remain 19:36:06 loss: 0.6063 Lr: 0.00148
[2025-05-11 13:48:26,903 INFO misc.py line 117 288342] Train: [2/50][654/2344] Data 0.002 (0.003) Batch 0.362 (0.618) Remain 19:35:20 loss: 0.8370 Lr: 0.00148
[2025-05-11 13:48:27,568 INFO misc.py line 117 288342] Train: [2/50][655/2344] Data 0.003 (0.003) Batch 0.665 (0.618) Remain 19:35:28 loss: 1.1066 Lr: 0.00148
[2025-05-11 13:48:28,244 INFO misc.py line 117 288342] Train: [2/50][656/2344] Data 0.003 (0.003) Batch 0.676 (0.618) Remain 19:35:38 loss: 0.9594 Lr: 0.00148
[2025-05-11 13:48:28,830 INFO misc.py line 117 288342] Train: [2/50][657/2344] Data 0.003 (0.003) Batch 0.586 (0.618) Remain 19:35:32 loss: 0.6379 Lr: 0.00148
[2025-05-11 13:48:29,384 INFO misc.py line 117 288342] Train: [2/50][658/2344] Data 0.003 (0.003) Batch 0.554 (0.618) Remain 19:35:20 loss: 0.9466 Lr: 0.00148
[2025-05-11 13:48:30,067 INFO misc.py line 117 288342] Train: [2/50][659/2344] Data 0.003 (0.003) Batch 0.682 (0.618) Remain 19:35:31 loss: 0.7932 Lr: 0.00148
[2025-05-11 13:48:30,615 INFO misc.py line 117 288342] Train: [2/50][660/2344] Data 0.003 (0.003) Batch 0.548 (0.618) Remain 19:35:18 loss: 0.8943 Lr: 0.00148
[2025-05-11 13:48:31,289 INFO misc.py line 117 288342] Train: [2/50][661/2344] Data 0.003 (0.003) Batch 0.675 (0.618) Remain 19:35:27 loss: 0.7492 Lr: 0.00149
[2025-05-11 13:48:31,942 INFO misc.py line 117 288342] Train: [2/50][662/2344] Data 0.003 (0.003) Batch 0.653 (0.618) Remain 19:35:33 loss: 0.7540 Lr: 0.00149
[2025-05-11 13:48:32,700 INFO misc.py line 117 288342] Train: [2/50][663/2344] Data 0.003 (0.003) Batch 0.757 (0.618) Remain 19:35:56 loss: 0.8094 Lr: 0.00149
[2025-05-11 13:48:33,280 INFO misc.py line 117 288342] Train: [2/50][664/2344] Data 0.002 (0.003) Batch 0.580 (0.618) Remain 19:35:49 loss: 0.6794 Lr: 0.00149
[2025-05-11 13:48:33,909 INFO misc.py line 117 288342] Train: [2/50][665/2344] Data 0.003 (0.003) Batch 0.629 (0.618) Remain 19:35:50 loss: 0.8591 Lr: 0.00149
[2025-05-11 13:48:34,499 INFO misc.py line 117 288342] Train: [2/50][666/2344] Data 0.003 (0.003) Batch 0.590 (0.618) Remain 19:35:45 loss: 0.7034 Lr: 0.00149
[2025-05-11 13:48:35,080 INFO misc.py line 117 288342] Train: [2/50][667/2344] Data 0.003 (0.003) Batch 0.581 (0.618) Remain 19:35:38 loss: 0.9606 Lr: 0.00149
[2025-05-11 13:48:35,800 INFO misc.py line 117 288342] Train: [2/50][668/2344] Data 0.003 (0.003) Batch 0.720 (0.618) Remain 19:35:55 loss: 0.7138 Lr: 0.00149
[2025-05-11 13:48:36,419 INFO misc.py line 117 288342] Train: [2/50][669/2344] Data 0.003 (0.003) Batch 0.620 (0.618) Remain 19:35:55 loss: 0.9252 Lr: 0.00149
[2025-05-11 13:48:37,089 INFO misc.py line 117 288342] Train: [2/50][670/2344] Data 0.003 (0.003) Batch 0.670 (0.618) Remain 19:36:03 loss: 1.0724 Lr: 0.00149
[2025-05-11 13:48:37,789 INFO misc.py line 117 288342] Train: [2/50][671/2344] Data 0.003 (0.003) Batch 0.699 (0.618) Remain 19:36:16 loss: 0.6189 Lr: 0.00149
[2025-05-11 13:48:38,416 INFO misc.py line 117 288342] Train: [2/50][672/2344] Data 0.003 (0.003) Batch 0.628 (0.618) Remain 19:36:17 loss: 0.7663 Lr: 0.00149
[2025-05-11 13:48:39,071 INFO misc.py line 117 288342] Train: [2/50][673/2344] Data 0.003 (0.003) Batch 0.655 (0.618) Remain 19:36:23 loss: 0.8171 Lr: 0.00149
[2025-05-11 13:48:39,558 INFO misc.py line 117 288342] Train: [2/50][674/2344] Data 0.003 (0.003) Batch 0.486 (0.618) Remain 19:36:00 loss: 0.8692 Lr: 0.00149
[2025-05-11 13:48:40,218 INFO misc.py line 117 288342] Train: [2/50][675/2344] Data 0.003 (0.003) Batch 0.660 (0.618) Remain 19:36:06 loss: 1.0061 Lr: 0.00149
[2025-05-11 13:48:40,915 INFO misc.py line 117 288342] Train: [2/50][676/2344] Data 0.002 (0.003) Batch 0.698 (0.618) Remain 19:36:19 loss: 0.7308 Lr: 0.00149
[2025-05-11 13:48:41,584 INFO misc.py line 117 288342] Train: [2/50][677/2344] Data 0.002 (0.003) Batch 0.668 (0.618) Remain 19:36:27 loss: 0.6263 Lr: 0.00149
[2025-05-11 13:48:42,332 INFO misc.py line 117 288342] Train: [2/50][678/2344] Data 0.003 (0.003) Batch 0.749 (0.618) Remain 19:36:49 loss: 0.8188 Lr: 0.00149
[2025-05-11 13:48:43,020 INFO misc.py line 117 288342] Train: [2/50][679/2344] Data 0.002 (0.003) Batch 0.688 (0.619) Remain 19:37:00 loss: 0.7578 Lr: 0.00149
[2025-05-11 13:48:43,675 INFO misc.py line 117 288342] Train: [2/50][680/2344] Data 0.002 (0.003) Batch 0.655 (0.619) Remain 19:37:05 loss: 0.8034 Lr: 0.00150
[2025-05-11 13:48:44,292 INFO misc.py line 117 288342] Train: [2/50][681/2344] Data 0.002 (0.003) Batch 0.617 (0.619) Remain 19:37:04 loss: 0.9464 Lr: 0.00150
[2025-05-11 13:48:44,969 INFO misc.py line 117 288342] Train: [2/50][682/2344] Data 0.002 (0.003) Batch 0.677 (0.619) Remain 19:37:14 loss: 0.7725 Lr: 0.00150
[2025-05-11 13:48:45,614 INFO misc.py line 117 288342] Train: [2/50][683/2344] Data 0.002 (0.003) Batch 0.646 (0.619) Remain 19:37:17 loss: 0.8795 Lr: 0.00150
[2025-05-11 13:48:46,157 INFO misc.py line 117 288342] Train: [2/50][684/2344] Data 0.002 (0.003) Batch 0.543 (0.619) Remain 19:37:04 loss: 0.8694 Lr: 0.00150
[2025-05-11 13:48:46,730 INFO misc.py line 117 288342] Train: [2/50][685/2344] Data 0.003 (0.003) Batch 0.573 (0.619) Remain 19:36:56 loss: 0.6781 Lr: 0.00150
[2025-05-11 13:48:47,171 INFO misc.py line 117 288342] Train: [2/50][686/2344] Data 0.003 (0.003) Batch 0.441 (0.618) Remain 19:36:26 loss: 0.8024 Lr: 0.00150
[2025-05-11 13:48:47,858 INFO misc.py line 117 288342] Train: [2/50][687/2344] Data 0.003 (0.003) Batch 0.687 (0.618) Remain 19:36:36 loss: 0.8549 Lr: 0.00150
[2025-05-11 13:48:48,432 INFO misc.py line 117 288342] Train: [2/50][688/2344] Data 0.003 (0.003) Batch 0.575 (0.618) Remain 19:36:28 loss: 0.7416 Lr: 0.00150
[2025-05-11 13:48:49,020 INFO misc.py line 117 288342] Train: [2/50][689/2344] Data 0.003 (0.003) Batch 0.587 (0.618) Remain 19:36:23 loss: 0.9068 Lr: 0.00150
[2025-05-11 13:48:49,589 INFO misc.py line 117 288342] Train: [2/50][690/2344] Data 0.003 (0.003) Batch 0.569 (0.618) Remain 19:36:14 loss: 0.8253 Lr: 0.00150
[2025-05-11 13:48:50,113 INFO misc.py line 117 288342] Train: [2/50][691/2344] Data 0.003 (0.003) Batch 0.524 (0.618) Remain 19:35:58 loss: 1.0075 Lr: 0.00150
[2025-05-11 13:48:50,920 INFO misc.py line 117 288342] Train: [2/50][692/2344] Data 0.002 (0.003) Batch 0.807 (0.618) Remain 19:36:28 loss: 0.7206 Lr: 0.00150
[2025-05-11 13:48:51,528 INFO misc.py line 117 288342] Train: [2/50][693/2344] Data 0.003 (0.003) Batch 0.608 (0.618) Remain 19:36:26 loss: 0.7491 Lr: 0.00150
[2025-05-11 13:48:52,086 INFO misc.py line 117 288342] Train: [2/50][694/2344] Data 0.003 (0.003) Batch 0.558 (0.618) Remain 19:36:15 loss: 0.7524 Lr: 0.00150
[2025-05-11 13:48:52,611 INFO misc.py line 117 288342] Train: [2/50][695/2344] Data 0.002 (0.003) Batch 0.525 (0.618) Remain 19:35:59 loss: 0.6221 Lr: 0.00150
[2025-05-11 13:48:53,253 INFO misc.py line 117 288342] Train: [2/50][696/2344] Data 0.002 (0.003) Batch 0.643 (0.618) Remain 19:36:03 loss: 0.8050 Lr: 0.00150
[2025-05-11 13:48:53,751 INFO misc.py line 117 288342] Train: [2/50][697/2344] Data 0.002 (0.003) Batch 0.497 (0.618) Remain 19:35:42 loss: 0.8284 Lr: 0.00150
[2025-05-11 13:48:54,283 INFO misc.py line 117 288342] Train: [2/50][698/2344] Data 0.003 (0.003) Batch 0.533 (0.618) Remain 19:35:28 loss: 1.1381 Lr: 0.00151
[2025-05-11 13:48:54,911 INFO misc.py line 117 288342] Train: [2/50][699/2344] Data 0.003 (0.003) Batch 0.628 (0.618) Remain 19:35:29 loss: 0.7888 Lr: 0.00151
[2025-05-11 13:48:55,536 INFO misc.py line 117 288342] Train: [2/50][700/2344] Data 0.003 (0.003) Batch 0.625 (0.618) Remain 19:35:29 loss: 0.7009 Lr: 0.00151
[2025-05-11 13:48:56,081 INFO misc.py line 117 288342] Train: [2/50][701/2344] Data 0.003 (0.003) Batch 0.545 (0.618) Remain 19:35:17 loss: 0.7545 Lr: 0.00151
[2025-05-11 13:48:56,795 INFO misc.py line 117 288342] Train: [2/50][702/2344] Data 0.003 (0.003) Batch 0.714 (0.618) Remain 19:35:32 loss: 0.6829 Lr: 0.00151
[2025-05-11 13:48:57,522 INFO misc.py line 117 288342] Train: [2/50][703/2344] Data 0.003 (0.003) Batch 0.727 (0.618) Remain 19:35:49 loss: 0.8678 Lr: 0.00151
[2025-05-11 13:48:58,111 INFO misc.py line 117 288342] Train: [2/50][704/2344] Data 0.003 (0.003) Batch 0.589 (0.618) Remain 19:35:44 loss: 0.8996 Lr: 0.00151
[2025-05-11 13:48:58,767 INFO misc.py line 117 288342] Train: [2/50][705/2344] Data 0.003 (0.003) Batch 0.656 (0.618) Remain 19:35:49 loss: 0.7717 Lr: 0.00151
[2025-05-11 13:48:59,462 INFO misc.py line 117 288342] Train: [2/50][706/2344] Data 0.003 (0.003) Batch 0.695 (0.618) Remain 19:36:01 loss: 0.7000 Lr: 0.00151
[2025-05-11 13:49:00,111 INFO misc.py line 117 288342] Train: [2/50][707/2344] Data 0.003 (0.003) Batch 0.649 (0.618) Remain 19:36:05 loss: 0.7344 Lr: 0.00151
[2025-05-11 13:49:00,679 INFO misc.py line 117 288342] Train: [2/50][708/2344] Data 0.003 (0.003) Batch 0.568 (0.618) Remain 19:35:57 loss: 0.8536 Lr: 0.00151
[2025-05-11 13:49:01,126 INFO misc.py line 117 288342] Train: [2/50][709/2344] Data 0.003 (0.003) Batch 0.447 (0.618) Remain 19:35:28 loss: 0.7664 Lr: 0.00151
[2025-05-11 13:49:01,843 INFO misc.py line 117 288342] Train: [2/50][710/2344] Data 0.003 (0.003) Batch 0.718 (0.618) Remain 19:35:44 loss: 0.8183 Lr: 0.00151
[2025-05-11 13:49:02,498 INFO misc.py line 117 288342] Train: [2/50][711/2344] Data 0.025 (0.003) Batch 0.655 (0.618) Remain 19:35:49 loss: 0.8682 Lr: 0.00151
[2025-05-11 13:49:03,053 INFO misc.py line 117 288342] Train: [2/50][712/2344] Data 0.003 (0.003) Batch 0.555 (0.618) Remain 19:35:38 loss: 0.7907 Lr: 0.00151
[2025-05-11 13:49:03,665 INFO misc.py line 117 288342] Train: [2/50][713/2344] Data 0.003 (0.003) Batch 0.612 (0.618) Remain 19:35:37 loss: 1.0227 Lr: 0.00151
[2025-05-11 13:49:04,233 INFO misc.py line 117 288342] Train: [2/50][714/2344] Data 0.002 (0.003) Batch 0.568 (0.618) Remain 19:35:28 loss: 0.8498 Lr: 0.00151
[2025-05-11 13:49:04,781 INFO misc.py line 117 288342] Train: [2/50][715/2344] Data 0.002 (0.003) Batch 0.549 (0.618) Remain 19:35:16 loss: 0.8004 Lr: 0.00151
[2025-05-11 13:49:05,514 INFO misc.py line 117 288342] Train: [2/50][716/2344] Data 0.002 (0.003) Batch 0.732 (0.618) Remain 19:35:34 loss: 0.6867 Lr: 0.00151
[2025-05-11 13:49:06,052 INFO misc.py line 117 288342] Train: [2/50][717/2344] Data 0.003 (0.003) Batch 0.538 (0.618) Remain 19:35:21 loss: 0.6905 Lr: 0.00152
[2025-05-11 13:49:06,651 INFO misc.py line 117 288342] Train: [2/50][718/2344] Data 0.003 (0.003) Batch 0.599 (0.618) Remain 19:35:17 loss: 0.7786 Lr: 0.00152
[2025-05-11 13:49:07,311 INFO misc.py line 117 288342] Train: [2/50][719/2344] Data 0.003 (0.003) Batch 0.660 (0.618) Remain 19:35:23 loss: 0.7704 Lr: 0.00152
[2025-05-11 13:49:07,933 INFO misc.py line 117 288342] Train: [2/50][720/2344] Data 0.003 (0.003) Batch 0.623 (0.618) Remain 19:35:23 loss: 0.7544 Lr: 0.00152
[2025-05-11 13:49:08,635 INFO misc.py line 117 288342] Train: [2/50][721/2344] Data 0.002 (0.003) Batch 0.701 (0.618) Remain 19:35:36 loss: 0.9708 Lr: 0.00152
[2025-05-11 13:49:09,349 INFO misc.py line 117 288342] Train: [2/50][722/2344] Data 0.003 (0.003) Batch 0.714 (0.618) Remain 19:35:51 loss: 0.8161 Lr: 0.00152
[2025-05-11 13:49:09,923 INFO misc.py line 117 288342] Train: [2/50][723/2344] Data 0.003 (0.003) Batch 0.574 (0.618) Remain 19:35:43 loss: 0.6829 Lr: 0.00152
[2025-05-11 13:49:10,562 INFO misc.py line 117 288342] Train: [2/50][724/2344] Data 0.002 (0.003) Batch 0.639 (0.618) Remain 19:35:46 loss: 1.0227 Lr: 0.00152
[2025-05-11 13:49:11,152 INFO misc.py line 117 288342] Train: [2/50][725/2344] Data 0.002 (0.003) Batch 0.590 (0.618) Remain 19:35:41 loss: 0.8177 Lr: 0.00152
[2025-05-11 13:49:11,864 INFO misc.py line 117 288342] Train: [2/50][726/2344] Data 0.003 (0.003) Batch 0.712 (0.618) Remain 19:35:55 loss: 0.8720 Lr: 0.00152
[2025-05-11 13:49:12,377 INFO misc.py line 117 288342] Train: [2/50][727/2344] Data 0.002 (0.003) Batch 0.513 (0.618) Remain 19:35:38 loss: 0.6646 Lr: 0.00152
[2025-05-11 13:49:12,981 INFO misc.py line 117 288342] Train: [2/50][728/2344] Data 0.003 (0.003) Batch 0.603 (0.618) Remain 19:35:35 loss: 0.8692 Lr: 0.00152
[2025-05-11 13:49:13,550 INFO misc.py line 117 288342] Train: [2/50][729/2344] Data 0.003 (0.003) Batch 0.570 (0.618) Remain 19:35:27 loss: 1.0713 Lr: 0.00152
[2025-05-11 13:49:14,193 INFO misc.py line 117 288342] Train: [2/50][730/2344] Data 0.003 (0.003) Batch 0.643 (0.618) Remain 19:35:30 loss: 0.7220 Lr: 0.00152
[2025-05-11 13:49:14,798 INFO misc.py line 117 288342] Train: [2/50][731/2344] Data 0.003 (0.003) Batch 0.605 (0.618) Remain 19:35:27 loss: 0.9669 Lr: 0.00152
[2025-05-11 13:49:15,385 INFO misc.py line 117 288342] Train: [2/50][732/2344] Data 0.003 (0.003) Batch 0.587 (0.618) Remain 19:35:22 loss: 0.6565 Lr: 0.00152
[2025-05-11 13:49:16,072 INFO misc.py line 117 288342] Train: [2/50][733/2344] Data 0.003 (0.003) Batch 0.687 (0.618) Remain 19:35:32 loss: 0.6677 Lr: 0.00152
[2025-05-11 13:49:16,793 INFO misc.py line 117 288342] Train: [2/50][734/2344] Data 0.003 (0.003) Batch 0.720 (0.618) Remain 19:35:47 loss: 0.9109 Lr: 0.00152
[2025-05-11 13:49:17,443 INFO misc.py line 117 288342] Train: [2/50][735/2344] Data 0.003 (0.003) Batch 0.650 (0.618) Remain 19:35:52 loss: 0.7908 Lr: 0.00152
[2025-05-11 13:49:18,059 INFO misc.py line 117 288342] Train: [2/50][736/2344] Data 0.003 (0.003) Batch 0.617 (0.618) Remain 19:35:51 loss: 0.7945 Lr: 0.00153
[2025-05-11 13:49:18,681 INFO misc.py line 117 288342] Train: [2/50][737/2344] Data 0.003 (0.003) Batch 0.621 (0.618) Remain 19:35:51 loss: 0.8973 Lr: 0.00153
[2025-05-11 13:49:19,365 INFO misc.py line 117 288342] Train: [2/50][738/2344] Data 0.003 (0.003) Batch 0.685 (0.618) Remain 19:36:00 loss: 0.9343 Lr: 0.00153
[2025-05-11 13:49:19,874 INFO misc.py line 117 288342] Train: [2/50][739/2344] Data 0.023 (0.003) Batch 0.509 (0.618) Remain 19:35:43 loss: 0.8696 Lr: 0.00153
[2025-05-11 13:49:20,483 INFO misc.py line 117 288342] Train: [2/50][740/2344] Data 0.003 (0.003) Batch 0.609 (0.618) Remain 19:35:41 loss: 1.0206 Lr: 0.00153
[2025-05-11 13:49:21,214 INFO misc.py line 117 288342] Train: [2/50][741/2344] Data 0.003 (0.003) Batch 0.731 (0.618) Remain 19:35:58 loss: 0.6810 Lr: 0.00153
[2025-05-11 13:49:21,863 INFO misc.py line 117 288342] Train: [2/50][742/2344] Data 0.003 (0.003) Batch 0.649 (0.618) Remain 19:36:02 loss: 0.5996 Lr: 0.00153
[2025-05-11 13:49:22,537 INFO misc.py line 117 288342] Train: [2/50][743/2344] Data 0.002 (0.003) Batch 0.674 (0.618) Remain 19:36:10 loss: 0.7738 Lr: 0.00153
[2025-05-11 13:49:23,114 INFO misc.py line 117 288342] Train: [2/50][744/2344] Data 0.003 (0.003) Batch 0.577 (0.618) Remain 19:36:03 loss: 0.6489 Lr: 0.00153
[2025-05-11 13:49:23,743 INFO misc.py line 117 288342] Train: [2/50][745/2344] Data 0.003 (0.003) Batch 0.629 (0.618) Remain 19:36:04 loss: 0.7705 Lr: 0.00153
[2025-05-11 13:49:24,294 INFO misc.py line 117 288342] Train: [2/50][746/2344] Data 0.002 (0.003) Batch 0.551 (0.618) Remain 19:35:53 loss: 0.7885 Lr: 0.00153
[2025-05-11 13:49:24,856 INFO misc.py line 117 288342] Train: [2/50][747/2344] Data 0.003 (0.003) Batch 0.562 (0.618) Remain 19:35:43 loss: 1.2405 Lr: 0.00153
[2025-05-11 13:49:25,394 INFO misc.py line 117 288342] Train: [2/50][748/2344] Data 0.003 (0.003) Batch 0.538 (0.618) Remain 19:35:31 loss: 0.8387 Lr: 0.00153
[2025-05-11 13:49:26,014 INFO misc.py line 117 288342] Train: [2/50][749/2344] Data 0.002 (0.003) Batch 0.621 (0.618) Remain 19:35:30 loss: 0.9440 Lr: 0.00153
[2025-05-11 13:49:26,474 INFO misc.py line 117 288342] Train: [2/50][750/2344] Data 0.002 (0.003) Batch 0.460 (0.618) Remain 19:35:05 loss: 0.9839 Lr: 0.00153
[2025-05-11 13:49:27,306 INFO misc.py line 117 288342] Train: [2/50][751/2344] Data 0.003 (0.003) Batch 0.832 (0.618) Remain 19:35:37 loss: 0.5297 Lr: 0.00153
[2025-05-11 13:49:27,916 INFO misc.py line 117 288342] Train: [2/50][752/2344] Data 0.002 (0.003) Batch 0.610 (0.618) Remain 19:35:36 loss: 0.8439 Lr: 0.00153
[2025-05-11 13:49:28,610 INFO misc.py line 117 288342] Train: [2/50][753/2344] Data 0.002 (0.003) Batch 0.694 (0.618) Remain 19:35:47 loss: 0.8265 Lr: 0.00153
[2025-05-11 13:49:29,414 INFO misc.py line 117 288342] Train: [2/50][754/2344] Data 0.002 (0.003) Batch 0.781 (0.618) Remain 19:36:11 loss: 0.7592 Lr: 0.00153
[2025-05-11 13:49:30,098 INFO misc.py line 117 288342] Train: [2/50][755/2344] Data 0.026 (0.003) Batch 0.707 (0.619) Remain 19:36:23 loss: 0.8738 Lr: 0.00154
[2025-05-11 13:49:30,944 INFO misc.py line 117 288342] Train: [2/50][756/2344] Data 0.003 (0.003) Batch 0.845 (0.619) Remain 19:36:57 loss: 0.7069 Lr: 0.00154
[2025-05-11 13:49:31,413 INFO misc.py line 117 288342] Train: [2/50][757/2344] Data 0.003 (0.003) Batch 0.470 (0.619) Remain 19:36:34 loss: 0.7683 Lr: 0.00154
[2025-05-11 13:49:31,915 INFO misc.py line 117 288342] Train: [2/50][758/2344] Data 0.003 (0.003) Batch 0.501 (0.619) Remain 19:36:16 loss: 0.8913 Lr: 0.00154
[2025-05-11 13:49:32,479 INFO misc.py line 117 288342] Train: [2/50][759/2344] Data 0.003 (0.003) Batch 0.564 (0.618) Remain 19:36:07 loss: 0.7921 Lr: 0.00154
[2025-05-11 13:49:33,123 INFO misc.py line 117 288342] Train: [2/50][760/2344] Data 0.002 (0.003) Batch 0.644 (0.619) Remain 19:36:10 loss: 0.9908 Lr: 0.00154
[2025-05-11 13:49:33,671 INFO misc.py line 117 288342] Train: [2/50][761/2344] Data 0.003 (0.003) Batch 0.548 (0.618) Remain 19:35:59 loss: 0.9580 Lr: 0.00154
[2025-05-11 13:49:34,332 INFO misc.py line 117 288342] Train: [2/50][762/2344] Data 0.003 (0.003) Batch 0.661 (0.618) Remain 19:36:05 loss: 0.7574 Lr: 0.00154
[2025-05-11 13:49:34,922 INFO misc.py line 117 288342] Train: [2/50][763/2344] Data 0.002 (0.003) Batch 0.590 (0.618) Remain 19:36:00 loss: 0.6279 Lr: 0.00154
[2025-05-11 13:49:35,619 INFO misc.py line 117 288342] Train: [2/50][764/2344] Data 0.002 (0.003) Batch 0.697 (0.619) Remain 19:36:11 loss: 0.8680 Lr: 0.00154
[2025-05-11 13:49:36,126 INFO misc.py line 117 288342] Train: [2/50][765/2344] Data 0.002 (0.003) Batch 0.507 (0.618) Remain 19:35:54 loss: 1.4081 Lr: 0.00154
[2025-05-11 13:49:36,723 INFO misc.py line 117 288342] Train: [2/50][766/2344] Data 0.003 (0.003) Batch 0.597 (0.618) Remain 19:35:50 loss: 0.9320 Lr: 0.00154
[2025-05-11 13:49:37,241 INFO misc.py line 117 288342] Train: [2/50][767/2344] Data 0.002 (0.003) Batch 0.518 (0.618) Remain 19:35:34 loss: 0.9578 Lr: 0.00154
[2025-05-11 13:49:37,905 INFO misc.py line 117 288342] Train: [2/50][768/2344] Data 0.003 (0.003) Batch 0.664 (0.618) Remain 19:35:40 loss: 1.0313 Lr: 0.00154
[2025-05-11 13:49:38,495 INFO misc.py line 117 288342] Train: [2/50][769/2344] Data 0.003 (0.003) Batch 0.590 (0.618) Remain 19:35:36 loss: 0.7511 Lr: 0.00154
[2025-05-11 13:49:39,080 INFO misc.py line 117 288342] Train: [2/50][770/2344] Data 0.003 (0.003) Batch 0.585 (0.618) Remain 19:35:30 loss: 0.9332 Lr: 0.00154
[2025-05-11 13:49:39,626 INFO misc.py line 117 288342] Train: [2/50][771/2344] Data 0.003 (0.003) Batch 0.546 (0.618) Remain 19:35:19 loss: 0.7651 Lr: 0.00154
[2025-05-11 13:49:40,338 INFO misc.py line 117 288342] Train: [2/50][772/2344] Data 0.003 (0.003) Batch 0.712 (0.618) Remain 19:35:32 loss: 0.9423 Lr: 0.00154
[2025-05-11 13:49:40,966 INFO misc.py line 117 288342] Train: [2/50][773/2344] Data 0.003 (0.003) Batch 0.628 (0.618) Remain 19:35:33 loss: 0.7438 Lr: 0.00154
[2025-05-11 13:49:41,484 INFO misc.py line 117 288342] Train: [2/50][774/2344] Data 0.003 (0.003) Batch 0.517 (0.618) Remain 19:35:17 loss: 0.9548 Lr: 0.00155
[2025-05-11 13:49:42,050 INFO misc.py line 117 288342] Train: [2/50][775/2344] Data 0.003 (0.003) Batch 0.566 (0.618) Remain 19:35:09 loss: 1.1641 Lr: 0.00155
[2025-05-11 13:49:42,681 INFO misc.py line 117 288342] Train: [2/50][776/2344] Data 0.003 (0.003) Batch 0.631 (0.618) Remain 19:35:10 loss: 0.7569 Lr: 0.00155
[2025-05-11 13:49:43,174 INFO misc.py line 117 288342] Train: [2/50][777/2344] Data 0.003 (0.003) Batch 0.494 (0.618) Remain 19:34:51 loss: 0.9475 Lr: 0.00155
[2025-05-11 13:49:43,763 INFO misc.py line 117 288342] Train: [2/50][778/2344] Data 0.002 (0.003) Batch 0.588 (0.618) Remain 19:34:46 loss: 0.7295 Lr: 0.00155
[2025-05-11 13:49:44,475 INFO misc.py line 117 288342] Train: [2/50][779/2344] Data 0.003 (0.003) Batch 0.712 (0.618) Remain 19:35:00 loss: 0.7024 Lr: 0.00155
[2025-05-11 13:49:45,059 INFO misc.py line 117 288342] Train: [2/50][780/2344] Data 0.003 (0.003) Batch 0.584 (0.618) Remain 19:34:54 loss: 0.7866 Lr: 0.00155
[2025-05-11 13:49:45,669 INFO misc.py line 117 288342] Train: [2/50][781/2344] Data 0.003 (0.003) Batch 0.610 (0.618) Remain 19:34:52 loss: 0.7125 Lr: 0.00155
[2025-05-11 13:49:46,218 INFO misc.py line 117 288342] Train: [2/50][782/2344] Data 0.003 (0.003) Batch 0.549 (0.618) Remain 19:34:41 loss: 0.8454 Lr: 0.00155
[2025-05-11 13:49:46,916 INFO misc.py line 117 288342] Train: [2/50][783/2344] Data 0.003 (0.003) Batch 0.698 (0.618) Remain 19:34:53 loss: 0.9257 Lr: 0.00155
[2025-05-11 13:49:47,527 INFO misc.py line 117 288342] Train: [2/50][784/2344] Data 0.003 (0.003) Batch 0.611 (0.618) Remain 19:34:51 loss: 0.7270 Lr: 0.00155
[2025-05-11 13:49:48,228 INFO misc.py line 117 288342] Train: [2/50][785/2344] Data 0.003 (0.003) Batch 0.701 (0.618) Remain 19:35:02 loss: 0.7462 Lr: 0.00155
[2025-05-11 13:49:48,725 INFO misc.py line 117 288342] Train: [2/50][786/2344] Data 0.003 (0.003) Batch 0.497 (0.618) Remain 19:34:44 loss: 0.7892 Lr: 0.00155
[2025-05-11 13:49:49,311 INFO misc.py line 117 288342] Train: [2/50][787/2344] Data 0.003 (0.003) Batch 0.586 (0.618) Remain 19:34:39 loss: 0.8767 Lr: 0.00155
[2025-05-11 13:49:49,931 INFO misc.py line 117 288342] Train: [2/50][788/2344] Data 0.003 (0.003) Batch 0.619 (0.618) Remain 19:34:39 loss: 0.9517 Lr: 0.00155
[2025-05-11 13:49:50,648 INFO misc.py line 117 288342] Train: [2/50][789/2344] Data 0.003 (0.003) Batch 0.717 (0.618) Remain 19:34:52 loss: 0.6365 Lr: 0.00155
[2025-05-11 13:49:51,136 INFO misc.py line 117 288342] Train: [2/50][790/2344] Data 0.003 (0.003) Batch 0.488 (0.618) Remain 19:34:33 loss: 0.6555 Lr: 0.00155
[2025-05-11 13:49:51,770 INFO misc.py line 117 288342] Train: [2/50][791/2344] Data 0.003 (0.003) Batch 0.634 (0.618) Remain 19:34:35 loss: 0.9054 Lr: 0.00155
[2025-05-11 13:49:52,474 INFO misc.py line 117 288342] Train: [2/50][792/2344] Data 0.002 (0.003) Batch 0.705 (0.618) Remain 19:34:47 loss: 0.7352 Lr: 0.00155
[2025-05-11 13:49:53,125 INFO misc.py line 117 288342] Train: [2/50][793/2344] Data 0.002 (0.003) Batch 0.651 (0.618) Remain 19:34:51 loss: 0.7150 Lr: 0.00156
[2025-05-11 13:49:53,856 INFO misc.py line 117 288342] Train: [2/50][794/2344] Data 0.003 (0.003) Batch 0.730 (0.618) Remain 19:35:06 loss: 0.7839 Lr: 0.00156
[2025-05-11 13:49:54,374 INFO misc.py line 117 288342] Train: [2/50][795/2344] Data 0.003 (0.003) Batch 0.518 (0.618) Remain 19:34:51 loss: 0.5832 Lr: 0.00156
[2025-05-11 13:49:54,960 INFO misc.py line 117 288342] Train: [2/50][796/2344] Data 0.003 (0.003) Batch 0.586 (0.618) Remain 19:34:46 loss: 0.7474 Lr: 0.00156
[2025-05-11 13:49:55,527 INFO misc.py line 117 288342] Train: [2/50][797/2344] Data 0.003 (0.003) Batch 0.567 (0.618) Remain 19:34:38 loss: 0.8171 Lr: 0.00156
[2025-05-11 13:49:56,194 INFO misc.py line 117 288342] Train: [2/50][798/2344] Data 0.003 (0.003) Batch 0.667 (0.618) Remain 19:34:45 loss: 0.7151 Lr: 0.00156
[2025-05-11 13:49:56,756 INFO misc.py line 117 288342] Train: [2/50][799/2344] Data 0.002 (0.003) Batch 0.562 (0.618) Remain 19:34:36 loss: 0.7632 Lr: 0.00156
[2025-05-11 13:49:57,413 INFO misc.py line 117 288342] Train: [2/50][800/2344] Data 0.003 (0.003) Batch 0.657 (0.618) Remain 19:34:41 loss: 0.8426 Lr: 0.00156
[2025-05-11 13:49:58,167 INFO misc.py line 117 288342] Train: [2/50][801/2344] Data 0.003 (0.003) Batch 0.754 (0.618) Remain 19:35:00 loss: 0.6848 Lr: 0.00156
[2025-05-11 13:49:58,710 INFO misc.py line 117 288342] Train: [2/50][802/2344] Data 0.003 (0.003) Batch 0.543 (0.618) Remain 19:34:48 loss: 0.8245 Lr: 0.00156
[2025-05-11 13:49:59,144 INFO misc.py line 117 288342] Train: [2/50][803/2344] Data 0.002 (0.003) Batch 0.434 (0.618) Remain 19:34:21 loss: 0.7372 Lr: 0.00156
[2025-05-11 13:49:59,869 INFO misc.py line 117 288342] Train: [2/50][804/2344] Data 0.003 (0.003) Batch 0.725 (0.618) Remain 19:34:36 loss: 1.0567 Lr: 0.00156
[2025-05-11 13:50:00,608 INFO misc.py line 117 288342] Train: [2/50][805/2344] Data 0.002 (0.003) Batch 0.738 (0.618) Remain 19:34:53 loss: 0.9895 Lr: 0.00156
[2025-05-11 13:50:01,352 INFO misc.py line 117 288342] Train: [2/50][806/2344] Data 0.003 (0.003) Batch 0.744 (0.618) Remain 19:35:10 loss: 0.7631 Lr: 0.00156
[2025-05-11 13:50:02,017 INFO misc.py line 117 288342] Train: [2/50][807/2344] Data 0.002 (0.003) Batch 0.666 (0.618) Remain 19:35:16 loss: 0.7467 Lr: 0.00156
[2025-05-11 13:50:02,637 INFO misc.py line 117 288342] Train: [2/50][808/2344] Data 0.002 (0.003) Batch 0.620 (0.618) Remain 19:35:16 loss: 0.7569 Lr: 0.00156
[2025-05-11 13:50:03,247 INFO misc.py line 117 288342] Train: [2/50][809/2344] Data 0.002 (0.003) Batch 0.610 (0.618) Remain 19:35:14 loss: 0.9384 Lr: 0.00156
[2025-05-11 13:50:03,759 INFO misc.py line 117 288342] Train: [2/50][810/2344] Data 0.002 (0.003) Batch 0.512 (0.618) Remain 19:34:58 loss: 0.8324 Lr: 0.00156
[2025-05-11 13:50:04,362 INFO misc.py line 117 288342] Train: [2/50][811/2344] Data 0.002 (0.003) Batch 0.603 (0.618) Remain 19:34:55 loss: 0.7287 Lr: 0.00156
[2025-05-11 13:50:04,997 INFO misc.py line 117 288342] Train: [2/50][812/2344] Data 0.003 (0.003) Batch 0.635 (0.618) Remain 19:34:57 loss: 0.8653 Lr: 0.00157
[2025-05-11 13:50:05,788 INFO misc.py line 117 288342] Train: [2/50][813/2344] Data 0.002 (0.003) Batch 0.791 (0.618) Remain 19:35:21 loss: 0.9457 Lr: 0.00157
[2025-05-11 13:50:06,379 INFO misc.py line 117 288342] Train: [2/50][814/2344] Data 0.004 (0.003) Batch 0.591 (0.618) Remain 19:35:16 loss: 0.6121 Lr: 0.00157
[2025-05-11 13:50:06,897 INFO misc.py line 117 288342] Train: [2/50][815/2344] Data 0.002 (0.003) Batch 0.518 (0.618) Remain 19:35:02 loss: 0.6657 Lr: 0.00157
[2025-05-11 13:50:07,481 INFO misc.py line 117 288342] Train: [2/50][816/2344] Data 0.002 (0.003) Batch 0.584 (0.618) Remain 19:34:56 loss: 0.9972 Lr: 0.00157
[2025-05-11 13:50:08,261 INFO misc.py line 117 288342] Train: [2/50][817/2344] Data 0.003 (0.003) Batch 0.780 (0.618) Remain 19:35:18 loss: 0.7827 Lr: 0.00157
[2025-05-11 13:50:08,780 INFO misc.py line 117 288342] Train: [2/50][818/2344] Data 0.002 (0.003) Batch 0.520 (0.618) Remain 19:35:04 loss: 0.9134 Lr: 0.00157
[2025-05-11 13:50:09,377 INFO misc.py line 117 288342] Train: [2/50][819/2344] Data 0.003 (0.003) Batch 0.597 (0.618) Remain 19:35:00 loss: 0.6694 Lr: 0.00157
[2025-05-11 13:50:09,866 INFO misc.py line 117 288342] Train: [2/50][820/2344] Data 0.003 (0.003) Batch 0.488 (0.618) Remain 19:34:42 loss: 0.9294 Lr: 0.00157
[2025-05-11 13:50:10,433 INFO misc.py line 117 288342] Train: [2/50][821/2344] Data 0.003 (0.003) Batch 0.568 (0.618) Remain 19:34:34 loss: 0.9013 Lr: 0.00157
[2025-05-11 13:50:11,088 INFO misc.py line 117 288342] Train: [2/50][822/2344] Data 0.003 (0.003) Batch 0.655 (0.618) Remain 19:34:38 loss: 0.8503 Lr: 0.00157
[2025-05-11 13:50:11,702 INFO misc.py line 117 288342] Train: [2/50][823/2344] Data 0.003 (0.003) Batch 0.614 (0.618) Remain 19:34:37 loss: 0.7423 Lr: 0.00157
[2025-05-11 13:50:12,165 INFO misc.py line 117 288342] Train: [2/50][824/2344] Data 0.004 (0.003) Batch 0.462 (0.618) Remain 19:34:15 loss: 0.8006 Lr: 0.00157
[2025-05-11 13:50:12,670 INFO misc.py line 117 288342] Train: [2/50][825/2344] Data 0.003 (0.003) Batch 0.505 (0.618) Remain 19:33:59 loss: 0.6935 Lr: 0.00157
[2025-05-11 13:50:13,189 INFO misc.py line 117 288342] Train: [2/50][826/2344] Data 0.003 (0.003) Batch 0.520 (0.618) Remain 19:33:45 loss: 0.7569 Lr: 0.00157
[2025-05-11 13:50:13,828 INFO misc.py line 117 288342] Train: [2/50][827/2344] Data 0.003 (0.003) Batch 0.638 (0.618) Remain 19:33:47 loss: 0.5559 Lr: 0.00157
[2025-05-11 13:50:14,491 INFO misc.py line 117 288342] Train: [2/50][828/2344] Data 0.003 (0.003) Batch 0.664 (0.618) Remain 19:33:52 loss: 0.7024 Lr: 0.00157
[2025-05-11 13:50:15,133 INFO misc.py line 117 288342] Train: [2/50][829/2344] Data 0.003 (0.003) Batch 0.642 (0.618) Remain 19:33:55 loss: 0.9162 Lr: 0.00157
[2025-05-11 13:50:15,721 INFO misc.py line 117 288342] Train: [2/50][830/2344] Data 0.003 (0.003) Batch 0.587 (0.618) Remain 19:33:50 loss: 0.9711 Lr: 0.00157
[2025-05-11 13:50:16,339 INFO misc.py line 117 288342] Train: [2/50][831/2344] Data 0.003 (0.003) Batch 0.618 (0.618) Remain 19:33:50 loss: 0.9161 Lr: 0.00158
[2025-05-11 13:50:16,963 INFO misc.py line 117 288342] Train: [2/50][832/2344] Data 0.002 (0.003) Batch 0.625 (0.618) Remain 19:33:50 loss: 0.8194 Lr: 0.00158
[2025-05-11 13:50:17,565 INFO misc.py line 117 288342] Train: [2/50][833/2344] Data 0.003 (0.003) Batch 0.601 (0.618) Remain 19:33:47 loss: 0.7681 Lr: 0.00158
[2025-05-11 13:50:18,168 INFO misc.py line 117 288342] Train: [2/50][834/2344] Data 0.003 (0.003) Batch 0.604 (0.618) Remain 19:33:45 loss: 0.8619 Lr: 0.00158
[2025-05-11 13:50:18,742 INFO misc.py line 117 288342] Train: [2/50][835/2344] Data 0.003 (0.003) Batch 0.574 (0.618) Remain 19:33:38 loss: 0.7866 Lr: 0.00158
[2025-05-11 13:50:19,392 INFO misc.py line 117 288342] Train: [2/50][836/2344] Data 0.003 (0.003) Batch 0.649 (0.618) Remain 19:33:42 loss: 0.6507 Lr: 0.00158
[2025-05-11 13:50:19,989 INFO misc.py line 117 288342] Train: [2/50][837/2344] Data 0.002 (0.003) Batch 0.597 (0.618) Remain 19:33:38 loss: 1.2182 Lr: 0.00158
[2025-05-11 13:50:20,509 INFO misc.py line 117 288342] Train: [2/50][838/2344] Data 0.003 (0.003) Batch 0.521 (0.617) Remain 19:33:25 loss: 0.7425 Lr: 0.00158
[2025-05-11 13:50:21,025 INFO misc.py line 117 288342] Train: [2/50][839/2344] Data 0.003 (0.003) Batch 0.515 (0.617) Remain 19:33:10 loss: 0.9004 Lr: 0.00158
[2025-05-11 13:50:21,703 INFO misc.py line 117 288342] Train: [2/50][840/2344] Data 0.003 (0.003) Batch 0.679 (0.617) Remain 19:33:18 loss: 0.6793 Lr: 0.00158
[2025-05-11 13:50:22,306 INFO misc.py line 117 288342] Train: [2/50][841/2344] Data 0.003 (0.003) Batch 0.603 (0.617) Remain 19:33:15 loss: 0.7875 Lr: 0.00158
[2025-05-11 13:50:22,906 INFO misc.py line 117 288342] Train: [2/50][842/2344] Data 0.003 (0.003) Batch 0.600 (0.617) Remain 19:33:12 loss: 0.9115 Lr: 0.00158
[2025-05-11 13:50:23,612 INFO misc.py line 117 288342] Train: [2/50][843/2344] Data 0.003 (0.003) Batch 0.706 (0.618) Remain 19:33:24 loss: 1.2104 Lr: 0.00158
[2025-05-11 13:50:24,214 INFO misc.py line 117 288342] Train: [2/50][844/2344] Data 0.003 (0.003) Batch 0.602 (0.617) Remain 19:33:21 loss: 0.7659 Lr: 0.00158
[2025-05-11 13:50:24,864 INFO misc.py line 117 288342] Train: [2/50][845/2344] Data 0.003 (0.003) Batch 0.650 (0.618) Remain 19:33:25 loss: 0.7187 Lr: 0.00158
[2025-05-11 13:50:25,447 INFO misc.py line 117 288342] Train: [2/50][846/2344] Data 0.003 (0.003) Batch 0.583 (0.617) Remain 19:33:19 loss: 0.8164 Lr: 0.00158
[2025-05-11 13:50:26,144 INFO misc.py line 117 288342] Train: [2/50][847/2344] Data 0.003 (0.003) Batch 0.697 (0.618) Remain 19:33:29 loss: 0.7711 Lr: 0.00158
[2025-05-11 13:50:26,608 INFO misc.py line 117 288342] Train: [2/50][848/2344] Data 0.003 (0.003) Batch 0.464 (0.617) Remain 19:33:08 loss: 0.8596 Lr: 0.00158
[2025-05-11 13:50:27,273 INFO misc.py line 117 288342] Train: [2/50][849/2344] Data 0.002 (0.003) Batch 0.665 (0.617) Remain 19:33:14 loss: 0.8360 Lr: 0.00158
[2025-05-11 13:50:27,971 INFO misc.py line 117 288342] Train: [2/50][850/2344] Data 0.002 (0.003) Batch 0.697 (0.618) Remain 19:33:24 loss: 0.9709 Lr: 0.00158
[2025-05-11 13:50:28,462 INFO misc.py line 117 288342] Train: [2/50][851/2344] Data 0.003 (0.003) Batch 0.491 (0.617) Remain 19:33:07 loss: 0.8590 Lr: 0.00159
[2025-05-11 13:50:29,069 INFO misc.py line 117 288342] Train: [2/50][852/2344] Data 0.002 (0.003) Batch 0.607 (0.617) Remain 19:33:05 loss: 0.8121 Lr: 0.00159
[2025-05-11 13:50:29,698 INFO misc.py line 117 288342] Train: [2/50][853/2344] Data 0.002 (0.003) Batch 0.629 (0.617) Remain 19:33:06 loss: 0.7567 Lr: 0.00159
[2025-05-11 13:50:30,268 INFO misc.py line 117 288342] Train: [2/50][854/2344] Data 0.002 (0.003) Batch 0.569 (0.617) Remain 19:32:58 loss: 0.8615 Lr: 0.00159
[2025-05-11 13:50:31,070 INFO misc.py line 117 288342] Train: [2/50][855/2344] Data 0.003 (0.003) Batch 0.803 (0.618) Remain 19:33:23 loss: 0.7104 Lr: 0.00159
[2025-05-11 13:50:31,513 INFO misc.py line 117 288342] Train: [2/50][856/2344] Data 0.002 (0.003) Batch 0.442 (0.617) Remain 19:32:59 loss: 0.9009 Lr: 0.00159
[2025-05-11 13:50:32,149 INFO misc.py line 117 288342] Train: [2/50][857/2344] Data 0.003 (0.003) Batch 0.636 (0.617) Remain 19:33:00 loss: 0.9088 Lr: 0.00159
[2025-05-11 13:50:32,798 INFO misc.py line 117 288342] Train: [2/50][858/2344] Data 0.003 (0.003) Batch 0.649 (0.617) Remain 19:33:04 loss: 0.7636 Lr: 0.00159
[2025-05-11 13:50:33,606 INFO misc.py line 117 288342] Train: [2/50][859/2344] Data 0.003 (0.003) Batch 0.809 (0.618) Remain 19:33:29 loss: 0.9615 Lr: 0.00159
[2025-05-11 13:50:34,206 INFO misc.py line 117 288342] Train: [2/50][860/2344] Data 0.002 (0.003) Batch 0.600 (0.618) Remain 19:33:26 loss: 1.0683 Lr: 0.00159
[2025-05-11 13:50:34,779 INFO misc.py line 117 288342] Train: [2/50][861/2344] Data 0.002 (0.003) Batch 0.573 (0.618) Remain 19:33:19 loss: 0.7899 Lr: 0.00159
[2025-05-11 13:50:35,320 INFO misc.py line 117 288342] Train: [2/50][862/2344] Data 0.003 (0.003) Batch 0.541 (0.617) Remain 19:33:09 loss: 0.9007 Lr: 0.00159
[2025-05-11 13:50:36,039 INFO misc.py line 117 288342] Train: [2/50][863/2344] Data 0.003 (0.003) Batch 0.719 (0.618) Remain 19:33:21 loss: 0.8318 Lr: 0.00159
[2025-05-11 13:50:36,531 INFO misc.py line 117 288342] Train: [2/50][864/2344] Data 0.003 (0.003) Batch 0.491 (0.617) Remain 19:33:04 loss: 0.9413 Lr: 0.00159
[2025-05-11 13:50:37,173 INFO misc.py line 117 288342] Train: [2/50][865/2344] Data 0.003 (0.003) Batch 0.642 (0.617) Remain 19:33:07 loss: 0.7925 Lr: 0.00159
[2025-05-11 13:50:37,796 INFO misc.py line 117 288342] Train: [2/50][866/2344] Data 0.003 (0.003) Batch 0.623 (0.617) Remain 19:33:07 loss: 0.6928 Lr: 0.00159
[2025-05-11 13:50:38,428 INFO misc.py line 117 288342] Train: [2/50][867/2344] Data 0.002 (0.003) Batch 0.632 (0.618) Remain 19:33:08 loss: 0.7935 Lr: 0.00159
[2025-05-11 13:50:39,120 INFO misc.py line 117 288342] Train: [2/50][868/2344] Data 0.002 (0.003) Batch 0.692 (0.618) Remain 19:33:17 loss: 0.9053 Lr: 0.00159
[2025-05-11 13:50:39,687 INFO misc.py line 117 288342] Train: [2/50][869/2344] Data 0.002 (0.003) Batch 0.567 (0.618) Remain 19:33:10 loss: 0.6671 Lr: 0.00159
[2025-05-11 13:50:40,193 INFO misc.py line 117 288342] Train: [2/50][870/2344] Data 0.002 (0.003) Batch 0.506 (0.617) Remain 19:32:55 loss: 0.8074 Lr: 0.00159
[2025-05-11 13:50:40,784 INFO misc.py line 117 288342] Train: [2/50][871/2344] Data 0.002 (0.003) Batch 0.591 (0.617) Remain 19:32:51 loss: 0.6876 Lr: 0.00160
[2025-05-11 13:50:41,422 INFO misc.py line 117 288342] Train: [2/50][872/2344] Data 0.002 (0.003) Batch 0.637 (0.617) Remain 19:32:53 loss: 0.6457 Lr: 0.00160
[2025-05-11 13:50:42,064 INFO misc.py line 117 288342] Train: [2/50][873/2344] Data 0.002 (0.003) Batch 0.643 (0.617) Remain 19:32:56 loss: 0.7483 Lr: 0.00160
[2025-05-11 13:50:42,798 INFO misc.py line 117 288342] Train: [2/50][874/2344] Data 0.002 (0.003) Batch 0.733 (0.618) Remain 19:33:10 loss: 0.7579 Lr: 0.00160
[2025-05-11 13:50:43,462 INFO misc.py line 117 288342] Train: [2/50][875/2344] Data 0.003 (0.003) Batch 0.664 (0.618) Remain 19:33:16 loss: 0.6631 Lr: 0.00160
[2025-05-11 13:50:44,032 INFO misc.py line 117 288342] Train: [2/50][876/2344] Data 0.003 (0.003) Batch 0.570 (0.618) Remain 19:33:09 loss: 0.7789 Lr: 0.00160
[2025-05-11 13:50:44,562 INFO misc.py line 117 288342] Train: [2/50][877/2344] Data 0.002 (0.003) Batch 0.529 (0.617) Remain 19:32:57 loss: 0.8417 Lr: 0.00160
[2025-05-11 13:50:45,132 INFO misc.py line 117 288342] Train: [2/50][878/2344] Data 0.003 (0.003) Batch 0.571 (0.617) Remain 19:32:50 loss: 0.8159 Lr: 0.00160
[2025-05-11 13:50:45,611 INFO misc.py line 117 288342] Train: [2/50][879/2344] Data 0.003 (0.003) Batch 0.478 (0.617) Remain 19:32:31 loss: 0.9458 Lr: 0.00160
[2025-05-11 13:50:46,116 INFO misc.py line 117 288342] Train: [2/50][880/2344] Data 0.003 (0.003) Batch 0.506 (0.617) Remain 19:32:16 loss: 0.8823 Lr: 0.00160
[2025-05-11 13:50:46,744 INFO misc.py line 117 288342] Train: [2/50][881/2344] Data 0.003 (0.003) Batch 0.628 (0.617) Remain 19:32:17 loss: 0.8414 Lr: 0.00160
[2025-05-11 13:50:47,413 INFO misc.py line 117 288342] Train: [2/50][882/2344] Data 0.003 (0.003) Batch 0.669 (0.617) Remain 19:32:23 loss: 0.8425 Lr: 0.00160
[2025-05-11 13:50:48,026 INFO misc.py line 117 288342] Train: [2/50][883/2344] Data 0.002 (0.003) Batch 0.613 (0.617) Remain 19:32:22 loss: 0.7784 Lr: 0.00160
[2025-05-11 13:50:48,507 INFO misc.py line 117 288342] Train: [2/50][884/2344] Data 0.002 (0.003) Batch 0.480 (0.617) Remain 19:32:04 loss: 0.8633 Lr: 0.00160
[2025-05-11 13:50:49,023 INFO misc.py line 117 288342] Train: [2/50][885/2344] Data 0.003 (0.003) Batch 0.517 (0.617) Remain 19:31:50 loss: 0.8115 Lr: 0.00160
[2025-05-11 13:50:49,650 INFO misc.py line 117 288342] Train: [2/50][886/2344] Data 0.003 (0.003) Batch 0.626 (0.617) Remain 19:31:51 loss: 1.0107 Lr: 0.00160
[2025-05-11 13:50:50,325 INFO misc.py line 117 288342] Train: [2/50][887/2344] Data 0.003 (0.003) Batch 0.675 (0.617) Remain 19:31:57 loss: 0.8084 Lr: 0.00160
[2025-05-11 13:50:50,915 INFO misc.py line 117 288342] Train: [2/50][888/2344] Data 0.002 (0.003) Batch 0.590 (0.617) Remain 19:31:53 loss: 0.8984 Lr: 0.00160
[2025-05-11 13:50:51,563 INFO misc.py line 117 288342] Train: [2/50][889/2344] Data 0.003 (0.003) Batch 0.648 (0.617) Remain 19:31:57 loss: 0.6756 Lr: 0.00160
[2025-05-11 13:50:52,130 INFO misc.py line 117 288342] Train: [2/50][890/2344] Data 0.003 (0.003) Batch 0.567 (0.617) Remain 19:31:50 loss: 0.8956 Lr: 0.00160
[2025-05-11 13:50:52,632 INFO misc.py line 117 288342] Train: [2/50][891/2344] Data 0.003 (0.003) Batch 0.501 (0.617) Remain 19:31:34 loss: 0.6878 Lr: 0.00161
[2025-05-11 13:50:53,209 INFO misc.py line 117 288342] Train: [2/50][892/2344] Data 0.003 (0.003) Batch 0.578 (0.617) Remain 19:31:29 loss: 0.8353 Lr: 0.00161
[2025-05-11 13:50:53,685 INFO misc.py line 117 288342] Train: [2/50][893/2344] Data 0.003 (0.003) Batch 0.475 (0.617) Remain 19:31:10 loss: 1.0749 Lr: 0.00161
[2025-05-11 13:50:54,455 INFO misc.py line 117 288342] Train: [2/50][894/2344] Data 0.003 (0.003) Batch 0.770 (0.617) Remain 19:31:29 loss: 0.9214 Lr: 0.00161
[2025-05-11 13:50:54,935 INFO misc.py line 117 288342] Train: [2/50][895/2344] Data 0.002 (0.003) Batch 0.480 (0.617) Remain 19:31:11 loss: 0.8185 Lr: 0.00161
[2025-05-11 13:50:55,445 INFO misc.py line 117 288342] Train: [2/50][896/2344] Data 0.002 (0.003) Batch 0.510 (0.617) Remain 19:30:57 loss: 0.5849 Lr: 0.00161
[2025-05-11 13:50:56,127 INFO misc.py line 117 288342] Train: [2/50][897/2344] Data 0.003 (0.003) Batch 0.682 (0.617) Remain 19:31:04 loss: 0.7289 Lr: 0.00161
[2025-05-11 13:50:56,752 INFO misc.py line 117 288342] Train: [2/50][898/2344] Data 0.002 (0.003) Batch 0.625 (0.617) Remain 19:31:05 loss: 0.6701 Lr: 0.00161
[2025-05-11 13:50:57,514 INFO misc.py line 117 288342] Train: [2/50][899/2344] Data 0.002 (0.003) Batch 0.762 (0.617) Remain 19:31:23 loss: 0.8655 Lr: 0.00161
[2025-05-11 13:50:58,067 INFO misc.py line 117 288342] Train: [2/50][900/2344] Data 0.003 (0.003) Batch 0.554 (0.617) Remain 19:31:14 loss: 0.5729 Lr: 0.00161
[2025-05-11 13:50:58,721 INFO misc.py line 117 288342] Train: [2/50][901/2344] Data 0.002 (0.003) Batch 0.654 (0.617) Remain 19:31:18 loss: 0.7689 Lr: 0.00161
[2025-05-11 13:50:59,325 INFO misc.py line 117 288342] Train: [2/50][902/2344] Data 0.002 (0.003) Batch 0.603 (0.617) Remain 19:31:16 loss: 0.6604 Lr: 0.00161
[2025-05-11 13:50:59,994 INFO misc.py line 117 288342] Train: [2/50][903/2344] Data 0.003 (0.003) Batch 0.667 (0.617) Remain 19:31:22 loss: 0.8662 Lr: 0.00161
[2025-05-11 13:51:00,699 INFO misc.py line 117 288342] Train: [2/50][904/2344] Data 0.005 (0.003) Batch 0.707 (0.617) Remain 19:31:32 loss: 0.7583 Lr: 0.00161
[2025-05-11 13:51:01,459 INFO misc.py line 117 288342] Train: [2/50][905/2344] Data 0.002 (0.003) Batch 0.761 (0.617) Remain 19:31:50 loss: 0.5709 Lr: 0.00161
[2025-05-11 13:51:02,139 INFO misc.py line 117 288342] Train: [2/50][906/2344] Data 0.003 (0.003) Batch 0.680 (0.617) Remain 19:31:57 loss: 0.7347 Lr: 0.00161
[2025-05-11 13:51:02,753 INFO misc.py line 117 288342] Train: [2/50][907/2344] Data 0.003 (0.003) Batch 0.614 (0.617) Remain 19:31:56 loss: 0.7027 Lr: 0.00161
[2025-05-11 13:51:03,332 INFO misc.py line 117 288342] Train: [2/50][908/2344] Data 0.002 (0.003) Batch 0.579 (0.617) Remain 19:31:51 loss: 0.5729 Lr: 0.00161
[2025-05-11 13:51:03,976 INFO misc.py line 117 288342] Train: [2/50][909/2344] Data 0.002 (0.003) Batch 0.644 (0.617) Remain 19:31:54 loss: 0.8902 Lr: 0.00161
[2025-05-11 13:51:04,644 INFO misc.py line 117 288342] Train: [2/50][910/2344] Data 0.003 (0.003) Batch 0.668 (0.617) Remain 19:31:59 loss: 1.0304 Lr: 0.00161
[2025-05-11 13:51:05,268 INFO misc.py line 117 288342] Train: [2/50][911/2344] Data 0.003 (0.003) Batch 0.624 (0.617) Remain 19:32:00 loss: 0.8007 Lr: 0.00162
[2025-05-11 13:51:05,836 INFO misc.py line 117 288342] Train: [2/50][912/2344] Data 0.003 (0.003) Batch 0.569 (0.617) Remain 19:31:53 loss: 0.9053 Lr: 0.00162
[2025-05-11 13:51:06,521 INFO misc.py line 117 288342] Train: [2/50][913/2344] Data 0.002 (0.003) Batch 0.685 (0.617) Remain 19:32:01 loss: 0.7594 Lr: 0.00162
[2025-05-11 13:51:07,099 INFO misc.py line 117 288342] Train: [2/50][914/2344] Data 0.003 (0.003) Batch 0.578 (0.617) Remain 19:31:55 loss: 0.6729 Lr: 0.00162
[2025-05-11 13:51:07,766 INFO misc.py line 117 288342] Train: [2/50][915/2344] Data 0.003 (0.003) Batch 0.667 (0.617) Remain 19:32:01 loss: 0.7634 Lr: 0.00162
[2025-05-11 13:51:08,548 INFO misc.py line 117 288342] Train: [2/50][916/2344] Data 0.002 (0.003) Batch 0.782 (0.617) Remain 19:32:21 loss: 0.8999 Lr: 0.00162
[2025-05-11 13:51:09,142 INFO misc.py line 117 288342] Train: [2/50][917/2344] Data 0.002 (0.003) Batch 0.594 (0.617) Remain 19:32:17 loss: 0.8308 Lr: 0.00162
[2025-05-11 13:51:09,861 INFO misc.py line 117 288342] Train: [2/50][918/2344] Data 0.003 (0.003) Batch 0.718 (0.617) Remain 19:32:29 loss: 0.8461 Lr: 0.00162
[2025-05-11 13:51:10,513 INFO misc.py line 117 288342] Train: [2/50][919/2344] Data 0.003 (0.003) Batch 0.652 (0.617) Remain 19:32:33 loss: 0.7214 Lr: 0.00162
[2025-05-11 13:51:11,130 INFO misc.py line 117 288342] Train: [2/50][920/2344] Data 0.003 (0.003) Batch 0.617 (0.617) Remain 19:32:32 loss: 0.8175 Lr: 0.00162
[2025-05-11 13:51:11,837 INFO misc.py line 117 288342] Train: [2/50][921/2344] Data 0.003 (0.003) Batch 0.707 (0.618) Remain 19:32:43 loss: 0.8057 Lr: 0.00162
[2025-05-11 13:51:12,561 INFO misc.py line 117 288342] Train: [2/50][922/2344] Data 0.003 (0.003) Batch 0.724 (0.618) Remain 19:32:55 loss: 0.6395 Lr: 0.00162
[2025-05-11 13:51:13,233 INFO misc.py line 117 288342] Train: [2/50][923/2344] Data 0.003 (0.003) Batch 0.671 (0.618) Remain 19:33:01 loss: 0.6936 Lr: 0.00162
[2025-05-11 13:51:13,772 INFO misc.py line 117 288342] Train: [2/50][924/2344] Data 0.003 (0.003) Batch 0.539 (0.618) Remain 19:32:51 loss: 0.6835 Lr: 0.00162
[2025-05-11 13:51:14,258 INFO misc.py line 117 288342] Train: [2/50][925/2344] Data 0.002 (0.003) Batch 0.487 (0.618) Remain 19:32:34 loss: 0.8373 Lr: 0.00162
[2025-05-11 13:51:14,789 INFO misc.py line 117 288342] Train: [2/50][926/2344] Data 0.003 (0.003) Batch 0.531 (0.617) Remain 19:32:23 loss: 0.8266 Lr: 0.00162
[2025-05-11 13:51:15,441 INFO misc.py line 117 288342] Train: [2/50][927/2344] Data 0.003 (0.003) Batch 0.652 (0.617) Remain 19:32:27 loss: 0.7059 Lr: 0.00162
[2025-05-11 13:51:15,939 INFO misc.py line 117 288342] Train: [2/50][928/2344] Data 0.002 (0.003) Batch 0.497 (0.617) Remain 19:32:11 loss: 0.9804 Lr: 0.00162
[2025-05-11 13:51:16,457 INFO misc.py line 117 288342] Train: [2/50][929/2344] Data 0.003 (0.003) Batch 0.518 (0.617) Remain 19:31:58 loss: 0.7681 Lr: 0.00162
[2025-05-11 13:51:17,174 INFO misc.py line 117 288342] Train: [2/50][930/2344] Data 0.003 (0.003) Batch 0.717 (0.617) Remain 19:32:10 loss: 0.7222 Lr: 0.00162
[2025-05-11 13:51:17,798 INFO misc.py line 117 288342] Train: [2/50][931/2344] Data 0.003 (0.003) Batch 0.624 (0.617) Remain 19:32:10 loss: 0.7840 Lr: 0.00163
[2025-05-11 13:51:18,588 INFO misc.py line 117 288342] Train: [2/50][932/2344] Data 0.003 (0.003) Batch 0.789 (0.618) Remain 19:32:31 loss: 0.9118 Lr: 0.00163
[2025-05-11 13:51:19,195 INFO misc.py line 117 288342] Train: [2/50][933/2344] Data 0.002 (0.003) Batch 0.607 (0.618) Remain 19:32:29 loss: 0.6807 Lr: 0.00163
[2025-05-11 13:51:19,715 INFO misc.py line 117 288342] Train: [2/50][934/2344] Data 0.003 (0.003) Batch 0.520 (0.617) Remain 19:32:16 loss: 1.1779 Lr: 0.00163
[2025-05-11 13:51:20,359 INFO misc.py line 117 288342] Train: [2/50][935/2344] Data 0.003 (0.003) Batch 0.644 (0.617) Remain 19:32:19 loss: 0.8287 Lr: 0.00163
[2025-05-11 13:51:20,933 INFO misc.py line 117 288342] Train: [2/50][936/2344] Data 0.003 (0.003) Batch 0.574 (0.617) Remain 19:32:13 loss: 0.9979 Lr: 0.00163
[2025-05-11 13:51:21,581 INFO misc.py line 117 288342] Train: [2/50][937/2344] Data 0.003 (0.003) Batch 0.648 (0.617) Remain 19:32:16 loss: 0.8008 Lr: 0.00163
[2025-05-11 13:51:22,116 INFO misc.py line 117 288342] Train: [2/50][938/2344] Data 0.003 (0.003) Batch 0.535 (0.617) Remain 19:32:05 loss: 0.8360 Lr: 0.00163
[2025-05-11 13:51:22,830 INFO misc.py line 117 288342] Train: [2/50][939/2344] Data 0.003 (0.003) Batch 0.714 (0.617) Remain 19:32:17 loss: 0.9167 Lr: 0.00163
[2025-05-11 13:51:23,591 INFO misc.py line 117 288342] Train: [2/50][940/2344] Data 0.003 (0.003) Batch 0.761 (0.618) Remain 19:32:33 loss: 0.7283 Lr: 0.00163
[2025-05-11 13:51:24,153 INFO misc.py line 117 288342] Train: [2/50][941/2344] Data 0.003 (0.003) Batch 0.562 (0.618) Remain 19:32:26 loss: 0.6860 Lr: 0.00163
[2025-05-11 13:51:24,851 INFO misc.py line 117 288342] Train: [2/50][942/2344] Data 0.003 (0.003) Batch 0.697 (0.618) Remain 19:32:35 loss: 1.0079 Lr: 0.00163
[2025-05-11 13:51:25,429 INFO misc.py line 117 288342] Train: [2/50][943/2344] Data 0.003 (0.003) Batch 0.578 (0.618) Remain 19:32:30 loss: 0.8212 Lr: 0.00163
[2025-05-11 13:51:26,147 INFO misc.py line 117 288342] Train: [2/50][944/2344] Data 0.003 (0.003) Batch 0.718 (0.618) Remain 19:32:41 loss: 0.7565 Lr: 0.00163
[2025-05-11 13:51:26,706 INFO misc.py line 117 288342] Train: [2/50][945/2344] Data 0.003 (0.003) Batch 0.558 (0.618) Remain 19:32:34 loss: 0.8655 Lr: 0.00163
[2025-05-11 13:51:27,375 INFO misc.py line 117 288342] Train: [2/50][946/2344] Data 0.003 (0.003) Batch 0.669 (0.618) Remain 19:32:39 loss: 0.7828 Lr: 0.00163
[2025-05-11 13:51:28,007 INFO misc.py line 117 288342] Train: [2/50][947/2344] Data 0.003 (0.003) Batch 0.633 (0.618) Remain 19:32:40 loss: 0.7077 Lr: 0.00163
[2025-05-11 13:51:28,684 INFO misc.py line 117 288342] Train: [2/50][948/2344] Data 0.003 (0.003) Batch 0.677 (0.618) Remain 19:32:47 loss: 0.9195 Lr: 0.00163
[2025-05-11 13:51:29,303 INFO misc.py line 117 288342] Train: [2/50][949/2344] Data 0.002 (0.003) Batch 0.619 (0.618) Remain 19:32:46 loss: 0.8942 Lr: 0.00163
[2025-05-11 13:51:29,810 INFO misc.py line 117 288342] Train: [2/50][950/2344] Data 0.002 (0.003) Batch 0.507 (0.618) Remain 19:32:32 loss: 0.8382 Lr: 0.00163
[2025-05-11 13:51:30,398 INFO misc.py line 117 288342] Train: [2/50][951/2344] Data 0.003 (0.003) Batch 0.588 (0.618) Remain 19:32:28 loss: 0.7730 Lr: 0.00163
[2025-05-11 13:51:31,053 INFO misc.py line 117 288342] Train: [2/50][952/2344] Data 0.002 (0.003) Batch 0.654 (0.618) Remain 19:32:32 loss: 0.8669 Lr: 0.00164
[2025-05-11 13:51:31,633 INFO misc.py line 117 288342] Train: [2/50][953/2344] Data 0.003 (0.003) Batch 0.581 (0.618) Remain 19:32:27 loss: 0.8172 Lr: 0.00164
[2025-05-11 13:51:32,142 INFO misc.py line 117 288342] Train: [2/50][954/2344] Data 0.002 (0.003) Batch 0.509 (0.617) Remain 19:32:14 loss: 0.8859 Lr: 0.00164
[2025-05-11 13:51:32,848 INFO misc.py line 117 288342] Train: [2/50][955/2344] Data 0.002 (0.003) Batch 0.705 (0.618) Remain 19:32:23 loss: 0.5198 Lr: 0.00164
[2025-05-11 13:51:33,472 INFO misc.py line 117 288342] Train: [2/50][956/2344] Data 0.003 (0.003) Batch 0.624 (0.618) Remain 19:32:24 loss: 1.0676 Lr: 0.00164
[2025-05-11 13:51:34,128 INFO misc.py line 117 288342] Train: [2/50][957/2344] Data 0.003 (0.003) Batch 0.656 (0.618) Remain 19:32:27 loss: 0.9192 Lr: 0.00164
[2025-05-11 13:51:34,579 INFO misc.py line 117 288342] Train: [2/50][958/2344] Data 0.003 (0.003) Batch 0.451 (0.617) Remain 19:32:07 loss: 0.7107 Lr: 0.00164
[2025-05-11 13:51:35,243 INFO misc.py line 117 288342] Train: [2/50][959/2344] Data 0.003 (0.003) Batch 0.665 (0.618) Remain 19:32:12 loss: 0.7475 Lr: 0.00164
[2025-05-11 13:51:35,863 INFO misc.py line 117 288342] Train: [2/50][960/2344] Data 0.002 (0.003) Batch 0.620 (0.618) Remain 19:32:12 loss: 0.6880 Lr: 0.00164
[2025-05-11 13:51:36,612 INFO misc.py line 117 288342] Train: [2/50][961/2344] Data 0.003 (0.003) Batch 0.749 (0.618) Remain 19:32:27 loss: 0.8769 Lr: 0.00164
[2025-05-11 13:51:37,237 INFO misc.py line 117 288342] Train: [2/50][962/2344] Data 0.003 (0.003) Batch 0.625 (0.618) Remain 19:32:27 loss: 0.8449 Lr: 0.00164
[2025-05-11 13:51:37,841 INFO misc.py line 117 288342] Train: [2/50][963/2344] Data 0.003 (0.003) Batch 0.604 (0.618) Remain 19:32:25 loss: 0.7037 Lr: 0.00164
[2025-05-11 13:51:38,387 INFO misc.py line 117 288342] Train: [2/50][964/2344] Data 0.002 (0.003) Batch 0.546 (0.618) Remain 19:32:16 loss: 0.6189 Lr: 0.00164
[2025-05-11 13:51:39,080 INFO misc.py line 117 288342] Train: [2/50][965/2344] Data 0.003 (0.003) Batch 0.693 (0.618) Remain 19:32:24 loss: 0.8018 Lr: 0.00164
[2025-05-11 13:51:39,676 INFO misc.py line 117 288342] Train: [2/50][966/2344] Data 0.003 (0.003) Batch 0.597 (0.618) Remain 19:32:21 loss: 0.7208 Lr: 0.00164
[2025-05-11 13:51:40,317 INFO misc.py line 117 288342] Train: [2/50][967/2344] Data 0.003 (0.003) Batch 0.641 (0.618) Remain 19:32:23 loss: 0.7630 Lr: 0.00164
[2025-05-11 13:51:40,818 INFO misc.py line 117 288342] Train: [2/50][968/2344] Data 0.003 (0.003) Batch 0.500 (0.618) Remain 19:32:08 loss: 0.9705 Lr: 0.00164
[2025-05-11 13:51:41,533 INFO misc.py line 117 288342] Train: [2/50][969/2344] Data 0.003 (0.003) Batch 0.715 (0.618) Remain 19:32:19 loss: 0.8005 Lr: 0.00164
[2025-05-11 13:51:41,992 INFO misc.py line 117 288342] Train: [2/50][970/2344] Data 0.003 (0.003) Batch 0.460 (0.617) Remain 19:32:00 loss: 0.7854 Lr: 0.00164
[2025-05-11 13:51:42,513 INFO misc.py line 117 288342] Train: [2/50][971/2344] Data 0.003 (0.003) Batch 0.521 (0.617) Remain 19:31:48 loss: 0.7627 Lr: 0.00164
[2025-05-11 13:51:43,081 INFO misc.py line 117 288342] Train: [2/50][972/2344] Data 0.002 (0.003) Batch 0.568 (0.617) Remain 19:31:42 loss: 0.7192 Lr: 0.00165
[2025-05-11 13:51:43,588 INFO misc.py line 117 288342] Train: [2/50][973/2344] Data 0.002 (0.003) Batch 0.507 (0.617) Remain 19:31:28 loss: 1.0137 Lr: 0.00165
[2025-05-11 13:51:44,267 INFO misc.py line 117 288342] Train: [2/50][974/2344] Data 0.003 (0.003) Batch 0.679 (0.617) Remain 19:31:35 loss: 0.7870 Lr: 0.00165
[2025-05-11 13:51:44,909 INFO misc.py line 117 288342] Train: [2/50][975/2344] Data 0.003 (0.003) Batch 0.642 (0.617) Remain 19:31:37 loss: 0.6501 Lr: 0.00165
[2025-05-11 13:51:45,472 INFO misc.py line 117 288342] Train: [2/50][976/2344] Data 0.002 (0.003) Batch 0.562 (0.617) Remain 19:31:30 loss: 0.7413 Lr: 0.00165
[2025-05-11 13:51:46,162 INFO misc.py line 117 288342] Train: [2/50][977/2344] Data 0.003 (0.003) Batch 0.691 (0.617) Remain 19:31:38 loss: 0.7558 Lr: 0.00165
[2025-05-11 13:51:46,708 INFO misc.py line 117 288342] Train: [2/50][978/2344] Data 0.002 (0.003) Batch 0.546 (0.617) Remain 19:31:29 loss: 0.9194 Lr: 0.00165
[2025-05-11 13:51:47,395 INFO misc.py line 117 288342] Train: [2/50][979/2344] Data 0.003 (0.003) Batch 0.687 (0.617) Remain 19:31:36 loss: 0.9476 Lr: 0.00165
[2025-05-11 13:51:48,038 INFO misc.py line 117 288342] Train: [2/50][980/2344] Data 0.003 (0.003) Batch 0.643 (0.617) Remain 19:31:39 loss: 0.7270 Lr: 0.00165
[2025-05-11 13:51:48,540 INFO misc.py line 117 288342] Train: [2/50][981/2344] Data 0.003 (0.003) Batch 0.503 (0.617) Remain 19:31:25 loss: 0.9400 Lr: 0.00165
[2025-05-11 13:51:49,209 INFO misc.py line 117 288342] Train: [2/50][982/2344] Data 0.003 (0.003) Batch 0.668 (0.617) Remain 19:31:30 loss: 0.6431 Lr: 0.00165
[2025-05-11 13:51:49,756 INFO misc.py line 117 288342] Train: [2/50][983/2344] Data 0.003 (0.003) Batch 0.546 (0.617) Remain 19:31:21 loss: 0.9966 Lr: 0.00165
[2025-05-11 13:51:50,442 INFO misc.py line 117 288342] Train: [2/50][984/2344] Data 0.004 (0.003) Batch 0.687 (0.617) Remain 19:31:29 loss: 0.7959 Lr: 0.00165
[2025-05-11 13:51:51,101 INFO misc.py line 117 288342] Train: [2/50][985/2344] Data 0.003 (0.003) Batch 0.660 (0.617) Remain 19:31:33 loss: 0.8434 Lr: 0.00165
[2025-05-11 13:51:51,719 INFO misc.py line 117 288342] Train: [2/50][986/2344] Data 0.003 (0.003) Batch 0.618 (0.617) Remain 19:31:33 loss: 0.8729 Lr: 0.00165
[2025-05-11 13:51:52,381 INFO misc.py line 117 288342] Train: [2/50][987/2344] Data 0.003 (0.003) Batch 0.661 (0.617) Remain 19:31:37 loss: 0.7863 Lr: 0.00165
[2025-05-11 13:51:52,998 INFO misc.py line 117 288342] Train: [2/50][988/2344] Data 0.003 (0.003) Batch 0.617 (0.617) Remain 19:31:36 loss: 0.8819 Lr: 0.00165
[2025-05-11 13:51:53,583 INFO misc.py line 117 288342] Train: [2/50][989/2344] Data 0.003 (0.003) Batch 0.585 (0.617) Remain 19:31:32 loss: 0.7308 Lr: 0.00165
[2025-05-11 13:51:54,130 INFO misc.py line 117 288342] Train: [2/50][990/2344] Data 0.003 (0.003) Batch 0.547 (0.617) Remain 19:31:23 loss: 0.8957 Lr: 0.00165
[2025-05-11 13:51:54,749 INFO misc.py line 117 288342] Train: [2/50][991/2344] Data 0.003 (0.003) Batch 0.619 (0.617) Remain 19:31:23 loss: 0.9127 Lr: 0.00165
[2025-05-11 13:51:55,335 INFO misc.py line 117 288342] Train: [2/50][992/2344] Data 0.003 (0.003) Batch 0.586 (0.617) Remain 19:31:19 loss: 0.7172 Lr: 0.00165
[2025-05-11 13:51:56,014 INFO misc.py line 117 288342] Train: [2/50][993/2344] Data 0.003 (0.003) Batch 0.679 (0.617) Remain 19:31:25 loss: 0.8397 Lr: 0.00166
[2025-05-11 13:51:56,528 INFO misc.py line 117 288342] Train: [2/50][994/2344] Data 0.003 (0.003) Batch 0.515 (0.617) Remain 19:31:13 loss: 0.7022 Lr: 0.00166
[2025-05-11 13:51:57,100 INFO misc.py line 117 288342] Train: [2/50][995/2344] Data 0.003 (0.003) Batch 0.572 (0.617) Remain 19:31:07 loss: 0.8961 Lr: 0.00166
[2025-05-11 13:51:57,759 INFO misc.py line 117 288342] Train: [2/50][996/2344] Data 0.003 (0.003) Batch 0.659 (0.617) Remain 19:31:11 loss: 0.8442 Lr: 0.00166
[2025-05-11 13:51:58,445 INFO misc.py line 117 288342] Train: [2/50][997/2344] Data 0.002 (0.003) Batch 0.686 (0.617) Remain 19:31:18 loss: 0.9558 Lr: 0.00166
[2025-05-11 13:51:59,071 INFO misc.py line 117 288342] Train: [2/50][998/2344] Data 0.003 (0.003) Batch 0.626 (0.617) Remain 19:31:19 loss: 0.8273 Lr: 0.00166
[2025-05-11 13:51:59,742 INFO misc.py line 117 288342] Train: [2/50][999/2344] Data 0.002 (0.003) Batch 0.671 (0.617) Remain 19:31:24 loss: 0.8477 Lr: 0.00166
[2025-05-11 13:52:00,463 INFO misc.py line 117 288342] Train: [2/50][1000/2344] Data 0.002 (0.003) Batch 0.721 (0.617) Remain 19:31:36 loss: 0.7418 Lr: 0.00166
[2025-05-11 13:52:01,096 INFO misc.py line 117 288342] Train: [2/50][1001/2344] Data 0.002 (0.003) Batch 0.633 (0.617) Remain 19:31:37 loss: 0.8879 Lr: 0.00166
[2025-05-11 13:52:01,749 INFO misc.py line 117 288342] Train: [2/50][1002/2344] Data 0.002 (0.003) Batch 0.652 (0.617) Remain 19:31:40 loss: 0.8992 Lr: 0.00166
[2025-05-11 13:52:02,532 INFO misc.py line 117 288342] Train: [2/50][1003/2344] Data 0.002 (0.003) Batch 0.784 (0.618) Remain 19:31:58 loss: 0.6327 Lr: 0.00166
[2025-05-11 13:52:03,117 INFO misc.py line 117 288342] Train: [2/50][1004/2344] Data 0.003 (0.003) Batch 0.584 (0.618) Remain 19:31:54 loss: 0.7808 Lr: 0.00166
[2025-05-11 13:52:03,869 INFO misc.py line 117 288342] Train: [2/50][1005/2344] Data 0.003 (0.003) Batch 0.752 (0.618) Remain 19:32:09 loss: 0.8881 Lr: 0.00166
[2025-05-11 13:52:04,607 INFO misc.py line 117 288342] Train: [2/50][1006/2344] Data 0.003 (0.003) Batch 0.738 (0.618) Remain 19:32:22 loss: 0.9529 Lr: 0.00166
[2025-05-11 13:52:05,198 INFO misc.py line 117 288342] Train: [2/50][1007/2344] Data 0.003 (0.003) Batch 0.592 (0.618) Remain 19:32:18 loss: 0.7388 Lr: 0.00166
[2025-05-11 13:52:05,797 INFO misc.py line 117 288342] Train: [2/50][1008/2344] Data 0.003 (0.003) Batch 0.598 (0.618) Remain 19:32:15 loss: 0.9290 Lr: 0.00166
[2025-05-11 13:52:06,505 INFO misc.py line 117 288342] Train: [2/50][1009/2344] Data 0.003 (0.003) Batch 0.709 (0.618) Remain 19:32:25 loss: 0.6560 Lr: 0.00166
[2025-05-11 13:52:07,147 INFO misc.py line 117 288342] Train: [2/50][1010/2344] Data 0.003 (0.003) Batch 0.642 (0.618) Remain 19:32:27 loss: 0.5629 Lr: 0.00166
[2025-05-11 13:52:07,839 INFO misc.py line 117 288342] Train: [2/50][1011/2344] Data 0.003 (0.003) Batch 0.692 (0.618) Remain 19:32:35 loss: 0.7647 Lr: 0.00166
[2025-05-11 13:52:08,541 INFO misc.py line 117 288342] Train: [2/50][1012/2344] Data 0.002 (0.003) Batch 0.702 (0.618) Remain 19:32:44 loss: 0.7264 Lr: 0.00166
[2025-05-11 13:52:09,051 INFO misc.py line 117 288342] Train: [2/50][1013/2344] Data 0.002 (0.003) Batch 0.509 (0.618) Remain 19:32:31 loss: 0.7629 Lr: 0.00166
[2025-05-11 13:52:09,639 INFO misc.py line 117 288342] Train: [2/50][1014/2344] Data 0.003 (0.003) Batch 0.588 (0.618) Remain 19:32:27 loss: 0.8948 Lr: 0.00166
[2025-05-11 13:52:10,221 INFO misc.py line 117 288342] Train: [2/50][1015/2344] Data 0.002 (0.003) Batch 0.582 (0.618) Remain 19:32:22 loss: 0.6493 Lr: 0.00167
[2025-05-11 13:52:10,758 INFO misc.py line 117 288342] Train: [2/50][1016/2344] Data 0.003 (0.003) Batch 0.538 (0.618) Remain 19:32:12 loss: 0.7952 Lr: 0.00167
[2025-05-11 13:52:11,388 INFO misc.py line 117 288342] Train: [2/50][1017/2344] Data 0.002 (0.003) Batch 0.630 (0.618) Remain 19:32:13 loss: 0.7065 Lr: 0.00167
[2025-05-11 13:52:12,084 INFO misc.py line 117 288342] Train: [2/50][1018/2344] Data 0.002 (0.003) Batch 0.696 (0.618) Remain 19:32:21 loss: 0.9797 Lr: 0.00167
[2025-05-11 13:52:12,788 INFO misc.py line 117 288342] Train: [2/50][1019/2344] Data 0.003 (0.003) Batch 0.704 (0.618) Remain 19:32:30 loss: 0.6348 Lr: 0.00167
[2025-05-11 13:52:13,405 INFO misc.py line 117 288342] Train: [2/50][1020/2344] Data 0.003 (0.003) Batch 0.617 (0.618) Remain 19:32:30 loss: 0.6397 Lr: 0.00167
[2025-05-11 13:52:14,075 INFO misc.py line 117 288342] Train: [2/50][1021/2344] Data 0.002 (0.003) Batch 0.669 (0.618) Remain 19:32:35 loss: 0.6839 Lr: 0.00167
[2025-05-11 13:52:14,582 INFO misc.py line 117 288342] Train: [2/50][1022/2344] Data 0.003 (0.003) Batch 0.507 (0.618) Remain 19:32:22 loss: 0.7694 Lr: 0.00167
[2025-05-11 13:52:15,234 INFO misc.py line 117 288342] Train: [2/50][1023/2344] Data 0.002 (0.003) Batch 0.652 (0.618) Remain 19:32:25 loss: 0.8553 Lr: 0.00167
[2025-05-11 13:52:15,876 INFO misc.py line 117 288342] Train: [2/50][1024/2344] Data 0.002 (0.003) Batch 0.642 (0.618) Remain 19:32:27 loss: 0.8267 Lr: 0.00167
[2025-05-11 13:52:16,427 INFO misc.py line 117 288342] Train: [2/50][1025/2344] Data 0.002 (0.003) Batch 0.550 (0.618) Remain 19:32:19 loss: 0.8977 Lr: 0.00167
[2025-05-11 13:52:17,148 INFO misc.py line 117 288342] Train: [2/50][1026/2344] Data 0.003 (0.003) Batch 0.722 (0.618) Remain 19:32:30 loss: 0.8551 Lr: 0.00167
[2025-05-11 13:52:17,704 INFO misc.py line 117 288342] Train: [2/50][1027/2344] Data 0.002 (0.003) Batch 0.556 (0.618) Remain 19:32:22 loss: 0.7432 Lr: 0.00167
[2025-05-11 13:52:18,319 INFO misc.py line 117 288342] Train: [2/50][1028/2344] Data 0.002 (0.003) Batch 0.615 (0.618) Remain 19:32:21 loss: 0.9150 Lr: 0.00167
[2025-05-11 13:52:19,006 INFO misc.py line 117 288342] Train: [2/50][1029/2344] Data 0.002 (0.003) Batch 0.687 (0.618) Remain 19:32:28 loss: 0.6763 Lr: 0.00167
[2025-05-11 13:52:19,502 INFO misc.py line 117 288342] Train: [2/50][1030/2344] Data 0.002 (0.003) Batch 0.497 (0.618) Remain 19:32:14 loss: 0.6885 Lr: 0.00167
[2025-05-11 13:52:20,123 INFO misc.py line 117 288342] Train: [2/50][1031/2344] Data 0.002 (0.003) Batch 0.620 (0.618) Remain 19:32:14 loss: 0.7808 Lr: 0.00167
[2025-05-11 13:52:20,709 INFO misc.py line 117 288342] Train: [2/50][1032/2344] Data 0.003 (0.003) Batch 0.586 (0.618) Remain 19:32:10 loss: 0.9594 Lr: 0.00167
[2025-05-11 13:52:21,304 INFO misc.py line 117 288342] Train: [2/50][1033/2344] Data 0.003 (0.003) Batch 0.595 (0.618) Remain 19:32:07 loss: 0.6941 Lr: 0.00167
[2025-05-11 13:52:21,984 INFO misc.py line 117 288342] Train: [2/50][1034/2344] Data 0.003 (0.003) Batch 0.680 (0.618) Remain 19:32:13 loss: 0.9229 Lr: 0.00167
[2025-05-11 13:52:22,591 INFO misc.py line 117 288342] Train: [2/50][1035/2344] Data 0.003 (0.003) Batch 0.607 (0.618) Remain 19:32:11 loss: 0.7742 Lr: 0.00167
[2025-05-11 13:52:23,298 INFO misc.py line 117 288342] Train: [2/50][1036/2344] Data 0.003 (0.003) Batch 0.708 (0.618) Remain 19:32:20 loss: 0.7983 Lr: 0.00168
[2025-05-11 13:52:23,982 INFO misc.py line 117 288342] Train: [2/50][1037/2344] Data 0.003 (0.003) Batch 0.684 (0.618) Remain 19:32:27 loss: 0.6931 Lr: 0.00168
[2025-05-11 13:52:24,689 INFO misc.py line 117 288342] Train: [2/50][1038/2344] Data 0.003 (0.003) Batch 0.708 (0.618) Remain 19:32:36 loss: 0.6989 Lr: 0.00168
[2025-05-11 13:52:25,304 INFO misc.py line 117 288342] Train: [2/50][1039/2344] Data 0.002 (0.003) Batch 0.614 (0.618) Remain 19:32:35 loss: 0.7483 Lr: 0.00168
[2025-05-11 13:52:26,017 INFO misc.py line 117 288342] Train: [2/50][1040/2344] Data 0.002 (0.003) Batch 0.713 (0.618) Remain 19:32:45 loss: 0.6523 Lr: 0.00168
[2025-05-11 13:52:26,478 INFO misc.py line 117 288342] Train: [2/50][1041/2344] Data 0.003 (0.003) Batch 0.461 (0.618) Remain 19:32:27 loss: 0.8428 Lr: 0.00168
[2025-05-11 13:52:26,962 INFO misc.py line 117 288342] Train: [2/50][1042/2344] Data 0.003 (0.003) Batch 0.484 (0.618) Remain 19:32:12 loss: 0.7306 Lr: 0.00168
[2025-05-11 13:52:27,509 INFO misc.py line 117 288342] Train: [2/50][1043/2344] Data 0.003 (0.003) Batch 0.547 (0.618) Remain 19:32:03 loss: 0.7656 Lr: 0.00168
[2025-05-11 13:52:28,213 INFO misc.py line 117 288342] Train: [2/50][1044/2344] Data 0.003 (0.003) Batch 0.704 (0.618) Remain 19:32:12 loss: 0.8295 Lr: 0.00168
[2025-05-11 13:52:28,797 INFO misc.py line 117 288342] Train: [2/50][1045/2344] Data 0.003 (0.003) Batch 0.584 (0.618) Remain 19:32:08 loss: 0.8681 Lr: 0.00168
[2025-05-11 13:52:29,458 INFO misc.py line 117 288342] Train: [2/50][1046/2344] Data 0.002 (0.003) Batch 0.661 (0.618) Remain 19:32:12 loss: 0.9129 Lr: 0.00168
[2025-05-11 13:52:30,042 INFO misc.py line 117 288342] Train: [2/50][1047/2344] Data 0.003 (0.003) Batch 0.585 (0.618) Remain 19:32:08 loss: 0.7904 Lr: 0.00168
[2025-05-11 13:52:30,577 INFO misc.py line 117 288342] Train: [2/50][1048/2344] Data 0.003 (0.003) Batch 0.535 (0.618) Remain 19:31:58 loss: 0.4934 Lr: 0.00168
[2025-05-11 13:52:31,147 INFO misc.py line 117 288342] Train: [2/50][1049/2344] Data 0.003 (0.003) Batch 0.570 (0.618) Remain 19:31:52 loss: 0.8341 Lr: 0.00168
[2025-05-11 13:52:31,877 INFO misc.py line 117 288342] Train: [2/50][1050/2344] Data 0.003 (0.003) Batch 0.731 (0.618) Remain 19:32:04 loss: 1.1509 Lr: 0.00168
[2025-05-11 13:52:32,475 INFO misc.py line 117 288342] Train: [2/50][1051/2344] Data 0.002 (0.003) Batch 0.597 (0.618) Remain 19:32:01 loss: 0.8027 Lr: 0.00168
[2025-05-11 13:52:33,153 INFO misc.py line 117 288342] Train: [2/50][1052/2344] Data 0.003 (0.003) Batch 0.679 (0.618) Remain 19:32:07 loss: 0.9700 Lr: 0.00168
[2025-05-11 13:52:33,761 INFO misc.py line 117 288342] Train: [2/50][1053/2344] Data 0.003 (0.003) Batch 0.608 (0.618) Remain 19:32:05 loss: 0.6214 Lr: 0.00168
[2025-05-11 13:52:34,425 INFO misc.py line 117 288342] Train: [2/50][1054/2344] Data 0.002 (0.003) Batch 0.664 (0.618) Remain 19:32:09 loss: 0.7854 Lr: 0.00168
[2025-05-11 13:52:35,020 INFO misc.py line 117 288342] Train: [2/50][1055/2344] Data 0.003 (0.003) Batch 0.595 (0.618) Remain 19:32:06 loss: 0.8256 Lr: 0.00168
[2025-05-11 13:52:35,588 INFO misc.py line 117 288342] Train: [2/50][1056/2344] Data 0.003 (0.003) Batch 0.568 (0.618) Remain 19:32:00 loss: 0.6944 Lr: 0.00168
[2025-05-11 13:52:36,054 INFO misc.py line 117 288342] Train: [2/50][1057/2344] Data 0.002 (0.003) Batch 0.466 (0.618) Remain 19:31:43 loss: 0.7703 Lr: 0.00168
[2025-05-11 13:52:36,582 INFO misc.py line 117 288342] Train: [2/50][1058/2344] Data 0.003 (0.003) Batch 0.528 (0.618) Remain 19:31:33 loss: 0.9160 Lr: 0.00169
[2025-05-11 13:52:37,276 INFO misc.py line 117 288342] Train: [2/50][1059/2344] Data 0.003 (0.003) Batch 0.694 (0.618) Remain 19:31:41 loss: 0.7095 Lr: 0.00169
[2025-05-11 13:52:37,996 INFO misc.py line 117 288342] Train: [2/50][1060/2344] Data 0.003 (0.003) Batch 0.720 (0.618) Remain 19:31:51 loss: 0.7940 Lr: 0.00169
[2025-05-11 13:52:38,580 INFO misc.py line 117 288342] Train: [2/50][1061/2344] Data 0.003 (0.003) Batch 0.584 (0.618) Remain 19:31:47 loss: 0.7561 Lr: 0.00169
[2025-05-11 13:52:39,288 INFO misc.py line 117 288342] Train: [2/50][1062/2344] Data 0.003 (0.003) Batch 0.708 (0.618) Remain 19:31:56 loss: 0.7528 Lr: 0.00169
[2025-05-11 13:52:39,915 INFO misc.py line 117 288342] Train: [2/50][1063/2344] Data 0.003 (0.003) Batch 0.627 (0.618) Remain 19:31:56 loss: 0.8257 Lr: 0.00169
[2025-05-11 13:52:40,603 INFO misc.py line 117 288342] Train: [2/50][1064/2344] Data 0.003 (0.003) Batch 0.687 (0.618) Remain 19:32:03 loss: 0.7989 Lr: 0.00169
[2025-05-11 13:52:41,199 INFO misc.py line 117 288342] Train: [2/50][1065/2344] Data 0.003 (0.003) Batch 0.596 (0.618) Remain 19:32:00 loss: 0.8465 Lr: 0.00169
[2025-05-11 13:52:41,780 INFO misc.py line 117 288342] Train: [2/50][1066/2344] Data 0.003 (0.003) Batch 0.581 (0.618) Remain 19:31:55 loss: 0.7871 Lr: 0.00169
[2025-05-11 13:52:42,344 INFO misc.py line 117 288342] Train: [2/50][1067/2344] Data 0.003 (0.003) Batch 0.564 (0.618) Remain 19:31:49 loss: 0.4643 Lr: 0.00169
[2025-05-11 13:52:42,991 INFO misc.py line 117 288342] Train: [2/50][1068/2344] Data 0.003 (0.003) Batch 0.647 (0.618) Remain 19:31:52 loss: 0.5891 Lr: 0.00169
[2025-05-11 13:52:43,577 INFO misc.py line 117 288342] Train: [2/50][1069/2344] Data 0.003 (0.003) Batch 0.586 (0.618) Remain 19:31:48 loss: 1.1334 Lr: 0.00169
[2025-05-11 13:52:44,314 INFO misc.py line 117 288342] Train: [2/50][1070/2344] Data 0.002 (0.003) Batch 0.736 (0.618) Remain 19:32:00 loss: 0.6548 Lr: 0.00169
[2025-05-11 13:52:44,949 INFO misc.py line 117 288342] Train: [2/50][1071/2344] Data 0.003 (0.003) Batch 0.635 (0.618) Remain 19:32:01 loss: 0.8152 Lr: 0.00169
[2025-05-11 13:52:45,383 INFO misc.py line 117 288342] Train: [2/50][1072/2344] Data 0.003 (0.003) Batch 0.434 (0.618) Remain 19:31:41 loss: 0.8350 Lr: 0.00169
[2025-05-11 13:52:46,027 INFO misc.py line 117 288342] Train: [2/50][1073/2344] Data 0.002 (0.003) Batch 0.644 (0.618) Remain 19:31:43 loss: 0.8008 Lr: 0.00169
[2025-05-11 13:52:46,687 INFO misc.py line 117 288342] Train: [2/50][1074/2344] Data 0.002 (0.003) Batch 0.661 (0.618) Remain 19:31:47 loss: 0.7568 Lr: 0.00169
[2025-05-11 13:52:47,122 INFO misc.py line 117 288342] Train: [2/50][1075/2344] Data 0.002 (0.003) Batch 0.435 (0.618) Remain 19:31:27 loss: 1.1380 Lr: 0.00169
[2025-05-11 13:52:47,736 INFO misc.py line 117 288342] Train: [2/50][1076/2344] Data 0.003 (0.003) Batch 0.614 (0.618) Remain 19:31:26 loss: 0.8373 Lr: 0.00169
[2025-05-11 13:52:48,379 INFO misc.py line 117 288342] Train: [2/50][1077/2344] Data 0.002 (0.003) Batch 0.643 (0.618) Remain 19:31:28 loss: 0.6860 Lr: 0.00169
[2025-05-11 13:52:49,078 INFO misc.py line 117 288342] Train: [2/50][1078/2344] Data 0.003 (0.003) Batch 0.698 (0.618) Remain 19:31:36 loss: 1.0659 Lr: 0.00169
[2025-05-11 13:52:49,662 INFO misc.py line 117 288342] Train: [2/50][1079/2344] Data 0.002 (0.003) Batch 0.585 (0.618) Remain 19:31:32 loss: 0.8894 Lr: 0.00169
[2025-05-11 13:52:50,124 INFO misc.py line 117 288342] Train: [2/50][1080/2344] Data 0.002 (0.003) Batch 0.462 (0.618) Remain 19:31:14 loss: 0.7724 Lr: 0.00170
[2025-05-11 13:52:50,640 INFO misc.py line 117 288342] Train: [2/50][1081/2344] Data 0.003 (0.003) Batch 0.515 (0.618) Remain 19:31:03 loss: 0.7331 Lr: 0.00170
[2025-05-11 13:52:51,229 INFO misc.py line 117 288342] Train: [2/50][1082/2344] Data 0.003 (0.003) Batch 0.590 (0.618) Remain 19:30:59 loss: 0.9079 Lr: 0.00170
[2025-05-11 13:52:51,809 INFO misc.py line 117 288342] Train: [2/50][1083/2344] Data 0.003 (0.003) Batch 0.579 (0.618) Remain 19:30:55 loss: 0.5284 Lr: 0.00170
[2025-05-11 13:52:52,557 INFO misc.py line 117 288342] Train: [2/50][1084/2344] Data 0.003 (0.003) Batch 0.749 (0.618) Remain 19:31:08 loss: 0.8570 Lr: 0.00170
[2025-05-11 13:52:53,253 INFO misc.py line 117 288342] Train: [2/50][1085/2344] Data 0.003 (0.003) Batch 0.695 (0.618) Remain 19:31:16 loss: 0.9715 Lr: 0.00170
[2025-05-11 13:52:53,818 INFO misc.py line 117 288342] Train: [2/50][1086/2344] Data 0.003 (0.003) Batch 0.566 (0.618) Remain 19:31:09 loss: 0.5071 Lr: 0.00170
[2025-05-11 13:52:54,554 INFO misc.py line 117 288342] Train: [2/50][1087/2344] Data 0.003 (0.003) Batch 0.736 (0.618) Remain 19:31:21 loss: 0.9372 Lr: 0.00170
[2025-05-11 13:52:55,301 INFO misc.py line 117 288342] Train: [2/50][1088/2344] Data 0.003 (0.003) Batch 0.747 (0.618) Remain 19:31:34 loss: 0.7736 Lr: 0.00170
[2025-05-11 13:52:55,843 INFO misc.py line 117 288342] Train: [2/50][1089/2344] Data 0.003 (0.003) Batch 0.542 (0.618) Remain 19:31:26 loss: 0.9912 Lr: 0.00170
[2025-05-11 13:52:56,537 INFO misc.py line 117 288342] Train: [2/50][1090/2344] Data 0.003 (0.003) Batch 0.694 (0.618) Remain 19:31:33 loss: 0.7599 Lr: 0.00170
[2025-05-11 13:52:57,149 INFO misc.py line 117 288342] Train: [2/50][1091/2344] Data 0.003 (0.003) Batch 0.612 (0.618) Remain 19:31:32 loss: 0.9160 Lr: 0.00170
[2025-05-11 13:52:57,627 INFO misc.py line 117 288342] Train: [2/50][1092/2344] Data 0.003 (0.003) Batch 0.478 (0.618) Remain 19:31:17 loss: 0.7768 Lr: 0.00170
[2025-05-11 13:52:58,200 INFO misc.py line 117 288342] Train: [2/50][1093/2344] Data 0.003 (0.003) Batch 0.572 (0.618) Remain 19:31:11 loss: 0.8127 Lr: 0.00170
[2025-05-11 13:52:58,844 INFO misc.py line 117 288342] Train: [2/50][1094/2344] Data 0.003 (0.003) Batch 0.644 (0.618) Remain 19:31:13 loss: 0.9433 Lr: 0.00170
[2025-05-11 13:52:59,419 INFO misc.py line 117 288342] Train: [2/50][1095/2344] Data 0.002 (0.003) Batch 0.575 (0.618) Remain 19:31:08 loss: 0.9499 Lr: 0.00170
[2025-05-11 13:52:59,984 INFO misc.py line 117 288342] Train: [2/50][1096/2344] Data 0.002 (0.003) Batch 0.565 (0.618) Remain 19:31:02 loss: 0.8233 Lr: 0.00170
[2025-05-11 13:53:00,654 INFO misc.py line 117 288342] Train: [2/50][1097/2344] Data 0.002 (0.003) Batch 0.670 (0.618) Remain 19:31:07 loss: 0.9850 Lr: 0.00170
[2025-05-11 13:53:01,236 INFO misc.py line 117 288342] Train: [2/50][1098/2344] Data 0.002 (0.003) Batch 0.582 (0.618) Remain 19:31:03 loss: 0.5774 Lr: 0.00170
[2025-05-11 13:53:01,746 INFO misc.py line 117 288342] Train: [2/50][1099/2344] Data 0.002 (0.003) Batch 0.510 (0.618) Remain 19:30:51 loss: 0.6387 Lr: 0.00170
[2025-05-11 13:53:02,270 INFO misc.py line 117 288342] Train: [2/50][1100/2344] Data 0.003 (0.003) Batch 0.524 (0.617) Remain 19:30:41 loss: 0.8369 Lr: 0.00170
[2025-05-11 13:53:02,911 INFO misc.py line 117 288342] Train: [2/50][1101/2344] Data 0.003 (0.003) Batch 0.641 (0.617) Remain 19:30:42 loss: 0.7059 Lr: 0.00170
[2025-05-11 13:53:03,485 INFO misc.py line 117 288342] Train: [2/50][1102/2344] Data 0.003 (0.003) Batch 0.574 (0.617) Remain 19:30:37 loss: 0.6468 Lr: 0.00171
[2025-05-11 13:53:04,149 INFO misc.py line 117 288342] Train: [2/50][1103/2344] Data 0.003 (0.003) Batch 0.663 (0.617) Remain 19:30:41 loss: 0.5933 Lr: 0.00171
[2025-05-11 13:53:04,856 INFO misc.py line 117 288342] Train: [2/50][1104/2344] Data 0.003 (0.003) Batch 0.707 (0.618) Remain 19:30:50 loss: 0.8309 Lr: 0.00171
[2025-05-11 13:53:05,466 INFO misc.py line 117 288342] Train: [2/50][1105/2344] Data 0.003 (0.003) Batch 0.611 (0.618) Remain 19:30:49 loss: 0.6603 Lr: 0.00171
[2025-05-11 13:53:06,206 INFO misc.py line 117 288342] Train: [2/50][1106/2344] Data 0.003 (0.003) Batch 0.739 (0.618) Remain 19:31:01 loss: 0.6908 Lr: 0.00171
[2025-05-11 13:53:06,883 INFO misc.py line 117 288342] Train: [2/50][1107/2344] Data 0.002 (0.003) Batch 0.678 (0.618) Remain 19:31:06 loss: 0.8680 Lr: 0.00171
[2025-05-11 13:53:07,370 INFO misc.py line 117 288342] Train: [2/50][1108/2344] Data 0.003 (0.003) Batch 0.487 (0.618) Remain 19:30:52 loss: 0.7569 Lr: 0.00171
[2025-05-11 13:53:08,046 INFO misc.py line 117 288342] Train: [2/50][1109/2344] Data 0.003 (0.003) Batch 0.676 (0.618) Remain 19:30:58 loss: 0.7269 Lr: 0.00171
[2025-05-11 13:53:08,592 INFO misc.py line 117 288342] Train: [2/50][1110/2344] Data 0.003 (0.003) Batch 0.546 (0.618) Remain 19:30:50 loss: 0.7904 Lr: 0.00171
[2025-05-11 13:53:09,155 INFO misc.py line 117 288342] Train: [2/50][1111/2344] Data 0.002 (0.003) Batch 0.563 (0.618) Remain 19:30:43 loss: 0.9872 Lr: 0.00171
[2025-05-11 13:53:09,843 INFO misc.py line 117 288342] Train: [2/50][1112/2344] Data 0.002 (0.003) Batch 0.687 (0.618) Remain 19:30:50 loss: 0.7042 Lr: 0.00171
[2025-05-11 13:53:10,489 INFO misc.py line 117 288342] Train: [2/50][1113/2344] Data 0.002 (0.003) Batch 0.646 (0.618) Remain 19:30:52 loss: 0.6421 Lr: 0.00171
[2025-05-11 13:53:10,979 INFO misc.py line 117 288342] Train: [2/50][1114/2344] Data 0.002 (0.003) Batch 0.490 (0.618) Remain 19:30:38 loss: 0.7889 Lr: 0.00171
[2025-05-11 13:53:11,536 INFO misc.py line 117 288342] Train: [2/50][1115/2344] Data 0.003 (0.003) Batch 0.557 (0.617) Remain 19:30:32 loss: 0.8627 Lr: 0.00171
[2025-05-11 13:53:12,114 INFO misc.py line 117 288342] Train: [2/50][1116/2344] Data 0.003 (0.003) Batch 0.577 (0.617) Remain 19:30:27 loss: 0.7272 Lr: 0.00171
[2025-05-11 13:53:12,719 INFO misc.py line 117 288342] Train: [2/50][1117/2344] Data 0.003 (0.003) Batch 0.606 (0.617) Remain 19:30:25 loss: 0.7191 Lr: 0.00171
[2025-05-11 13:53:13,262 INFO misc.py line 117 288342] Train: [2/50][1118/2344] Data 0.003 (0.003) Batch 0.542 (0.617) Remain 19:30:17 loss: 0.9214 Lr: 0.00171
[2025-05-11 13:53:13,780 INFO misc.py line 117 288342] Train: [2/50][1119/2344] Data 0.003 (0.003) Batch 0.518 (0.617) Remain 19:30:06 loss: 0.8806 Lr: 0.00171
[2025-05-11 13:53:14,385 INFO misc.py line 117 288342] Train: [2/50][1120/2344] Data 0.002 (0.003) Batch 0.605 (0.617) Remain 19:30:04 loss: 0.5958 Lr: 0.00171
[2025-05-11 13:53:14,940 INFO misc.py line 117 288342] Train: [2/50][1121/2344] Data 0.003 (0.003) Batch 0.556 (0.617) Remain 19:29:57 loss: 0.5995 Lr: 0.00171
[2025-05-11 13:53:15,605 INFO misc.py line 117 288342] Train: [2/50][1122/2344] Data 0.002 (0.003) Batch 0.665 (0.617) Remain 19:30:02 loss: 0.8342 Lr: 0.00171
[2025-05-11 13:53:16,215 INFO misc.py line 117 288342] Train: [2/50][1123/2344] Data 0.003 (0.003) Batch 0.610 (0.617) Remain 19:30:00 loss: 0.8478 Lr: 0.00171
[2025-05-11 13:53:16,871 INFO misc.py line 117 288342] Train: [2/50][1124/2344] Data 0.002 (0.003) Batch 0.656 (0.617) Remain 19:30:04 loss: 0.7576 Lr: 0.00172
[2025-05-11 13:53:17,554 INFO misc.py line 117 288342] Train: [2/50][1125/2344] Data 0.002 (0.003) Batch 0.683 (0.617) Remain 19:30:10 loss: 0.6917 Lr: 0.00172
[2025-05-11 13:53:18,245 INFO misc.py line 117 288342] Train: [2/50][1126/2344] Data 0.002 (0.003) Batch 0.691 (0.617) Remain 19:30:16 loss: 0.7713 Lr: 0.00172
[2025-05-11 13:53:18,760 INFO misc.py line 117 288342] Train: [2/50][1127/2344] Data 0.003 (0.003) Batch 0.515 (0.617) Remain 19:30:05 loss: 0.7289 Lr: 0.00172
[2025-05-11 13:53:19,304 INFO misc.py line 117 288342] Train: [2/50][1128/2344] Data 0.003 (0.003) Batch 0.543 (0.617) Remain 19:29:57 loss: 1.0980 Lr: 0.00172
[2025-05-11 13:53:20,035 INFO misc.py line 117 288342] Train: [2/50][1129/2344] Data 0.003 (0.003) Batch 0.732 (0.617) Remain 19:30:08 loss: 0.8198 Lr: 0.00172
[2025-05-11 13:53:20,674 INFO misc.py line 117 288342] Train: [2/50][1130/2344] Data 0.003 (0.003) Batch 0.639 (0.617) Remain 19:30:10 loss: 0.6773 Lr: 0.00172
[2025-05-11 13:53:21,274 INFO misc.py line 117 288342] Train: [2/50][1131/2344] Data 0.003 (0.003) Batch 0.600 (0.617) Remain 19:30:08 loss: 0.8294 Lr: 0.00172
[2025-05-11 13:53:21,920 INFO misc.py line 117 288342] Train: [2/50][1132/2344] Data 0.003 (0.003) Batch 0.646 (0.617) Remain 19:30:10 loss: 0.9581 Lr: 0.00172
[2025-05-11 13:53:22,453 INFO misc.py line 117 288342] Train: [2/50][1133/2344] Data 0.003 (0.003) Batch 0.533 (0.617) Remain 19:30:01 loss: 0.8438 Lr: 0.00172
[2025-05-11 13:53:23,098 INFO misc.py line 117 288342] Train: [2/50][1134/2344] Data 0.003 (0.003) Batch 0.646 (0.617) Remain 19:30:03 loss: 0.8831 Lr: 0.00172
[2025-05-11 13:53:23,670 INFO misc.py line 117 288342] Train: [2/50][1135/2344] Data 0.003 (0.003) Batch 0.572 (0.617) Remain 19:29:58 loss: 0.6794 Lr: 0.00172
[2025-05-11 13:53:24,285 INFO misc.py line 117 288342] Train: [2/50][1136/2344] Data 0.003 (0.003) Batch 0.615 (0.617) Remain 19:29:57 loss: 1.0206 Lr: 0.00172
[2025-05-11 13:53:24,836 INFO misc.py line 117 288342] Train: [2/50][1137/2344] Data 0.003 (0.003) Batch 0.551 (0.617) Remain 19:29:50 loss: 0.7139 Lr: 0.00172
[2025-05-11 13:53:25,548 INFO misc.py line 117 288342] Train: [2/50][1138/2344] Data 0.003 (0.003) Batch 0.712 (0.617) Remain 19:29:58 loss: 0.7705 Lr: 0.00172
[2025-05-11 13:53:26,240 INFO misc.py line 117 288342] Train: [2/50][1139/2344] Data 0.003 (0.003) Batch 0.692 (0.617) Remain 19:30:05 loss: 0.7802 Lr: 0.00172
[2025-05-11 13:53:26,860 INFO misc.py line 117 288342] Train: [2/50][1140/2344] Data 0.003 (0.003) Batch 0.621 (0.617) Remain 19:30:05 loss: 0.8422 Lr: 0.00172
[2025-05-11 13:53:27,480 INFO misc.py line 117 288342] Train: [2/50][1141/2344] Data 0.003 (0.003) Batch 0.620 (0.617) Remain 19:30:05 loss: 0.8510 Lr: 0.00172
[2025-05-11 13:53:28,156 INFO misc.py line 117 288342] Train: [2/50][1142/2344] Data 0.003 (0.003) Batch 0.676 (0.617) Remain 19:30:10 loss: 0.8089 Lr: 0.00172
[2025-05-11 13:53:28,837 INFO misc.py line 117 288342] Train: [2/50][1143/2344] Data 0.003 (0.003) Batch 0.681 (0.617) Remain 19:30:16 loss: 0.8807 Lr: 0.00172
[2025-05-11 13:53:29,378 INFO misc.py line 117 288342] Train: [2/50][1144/2344] Data 0.003 (0.003) Batch 0.541 (0.617) Remain 19:30:07 loss: 0.9671 Lr: 0.00172
[2025-05-11 13:53:29,880 INFO misc.py line 117 288342] Train: [2/50][1145/2344] Data 0.003 (0.003) Batch 0.502 (0.617) Remain 19:29:55 loss: 0.9291 Lr: 0.00172
[2025-05-11 13:53:30,529 INFO misc.py line 117 288342] Train: [2/50][1146/2344] Data 0.002 (0.003) Batch 0.649 (0.617) Remain 19:29:58 loss: 0.7422 Lr: 0.00172
[2025-05-11 13:53:31,239 INFO misc.py line 117 288342] Train: [2/50][1147/2344] Data 0.002 (0.003) Batch 0.710 (0.617) Remain 19:30:06 loss: 0.7010 Lr: 0.00173
[2025-05-11 13:53:31,876 INFO misc.py line 117 288342] Train: [2/50][1148/2344] Data 0.003 (0.003) Batch 0.638 (0.617) Remain 19:30:08 loss: 0.6970 Lr: 0.00173
[2025-05-11 13:53:32,574 INFO misc.py line 117 288342] Train: [2/50][1149/2344] Data 0.003 (0.003) Batch 0.697 (0.618) Remain 19:30:15 loss: 0.8051 Lr: 0.00173
[2025-05-11 13:53:33,247 INFO misc.py line 117 288342] Train: [2/50][1150/2344] Data 0.003 (0.003) Batch 0.673 (0.618) Remain 19:30:20 loss: 0.7561 Lr: 0.00173
[2025-05-11 13:53:33,894 INFO misc.py line 117 288342] Train: [2/50][1151/2344] Data 0.002 (0.003) Batch 0.647 (0.618) Remain 19:30:22 loss: 0.6260 Lr: 0.00173
[2025-05-11 13:53:34,552 INFO misc.py line 117 288342] Train: [2/50][1152/2344] Data 0.003 (0.003) Batch 0.659 (0.618) Remain 19:30:26 loss: 0.9969 Lr: 0.00173
[2025-05-11 13:53:35,103 INFO misc.py line 117 288342] Train: [2/50][1153/2344] Data 0.003 (0.003) Batch 0.551 (0.618) Remain 19:30:18 loss: 0.7326 Lr: 0.00173
[2025-05-11 13:53:35,816 INFO misc.py line 117 288342] Train: [2/50][1154/2344] Data 0.002 (0.003) Batch 0.713 (0.618) Remain 19:30:27 loss: 0.9527 Lr: 0.00173
[2025-05-11 13:53:36,392 INFO misc.py line 117 288342] Train: [2/50][1155/2344] Data 0.002 (0.003) Batch 0.575 (0.618) Remain 19:30:22 loss: 0.7531 Lr: 0.00173
[2025-05-11 13:53:37,056 INFO misc.py line 117 288342] Train: [2/50][1156/2344] Data 0.002 (0.003) Batch 0.664 (0.618) Remain 19:30:26 loss: 0.5952 Lr: 0.00173
[2025-05-11 13:53:37,598 INFO misc.py line 117 288342] Train: [2/50][1157/2344] Data 0.003 (0.003) Batch 0.542 (0.618) Remain 19:30:18 loss: 1.1537 Lr: 0.00173
[2025-05-11 13:53:38,314 INFO misc.py line 117 288342] Train: [2/50][1158/2344] Data 0.002 (0.003) Batch 0.716 (0.618) Remain 19:30:27 loss: 1.0517 Lr: 0.00173
[2025-05-11 13:53:39,100 INFO misc.py line 117 288342] Train: [2/50][1159/2344] Data 0.002 (0.003) Batch 0.786 (0.618) Remain 19:30:43 loss: 0.8284 Lr: 0.00173
[2025-05-11 13:53:39,675 INFO misc.py line 117 288342] Train: [2/50][1160/2344] Data 0.003 (0.003) Batch 0.575 (0.618) Remain 19:30:39 loss: 0.7673 Lr: 0.00173
[2025-05-11 13:53:40,244 INFO misc.py line 117 288342] Train: [2/50][1161/2344] Data 0.003 (0.003) Batch 0.569 (0.618) Remain 19:30:33 loss: 1.0317 Lr: 0.00173
[2025-05-11 13:53:40,774 INFO misc.py line 117 288342] Train: [2/50][1162/2344] Data 0.003 (0.003) Batch 0.531 (0.618) Remain 19:30:24 loss: 0.6806 Lr: 0.00173
[2025-05-11 13:53:41,400 INFO misc.py line 117 288342] Train: [2/50][1163/2344] Data 0.003 (0.003) Batch 0.625 (0.618) Remain 19:30:24 loss: 0.9668 Lr: 0.00173
[2025-05-11 13:53:42,032 INFO misc.py line 117 288342] Train: [2/50][1164/2344] Data 0.002 (0.003) Batch 0.632 (0.618) Remain 19:30:25 loss: 0.9134 Lr: 0.00173
[2025-05-11 13:53:42,611 INFO misc.py line 117 288342] Train: [2/50][1165/2344] Data 0.003 (0.003) Batch 0.580 (0.618) Remain 19:30:20 loss: 0.6633 Lr: 0.00173
[2025-05-11 13:53:43,295 INFO misc.py line 117 288342] Train: [2/50][1166/2344] Data 0.002 (0.003) Batch 0.684 (0.618) Remain 19:30:26 loss: 0.8491 Lr: 0.00173
[2025-05-11 13:53:43,808 INFO misc.py line 117 288342] Train: [2/50][1167/2344] Data 0.002 (0.003) Batch 0.513 (0.618) Remain 19:30:16 loss: 0.5574 Lr: 0.00173
[2025-05-11 13:53:44,385 INFO misc.py line 117 288342] Train: [2/50][1168/2344] Data 0.003 (0.003) Batch 0.576 (0.618) Remain 19:30:11 loss: 0.7903 Lr: 0.00173
[2025-05-11 13:53:44,936 INFO misc.py line 117 288342] Train: [2/50][1169/2344] Data 0.003 (0.003) Batch 0.552 (0.618) Remain 19:30:04 loss: 0.7528 Lr: 0.00173
[2025-05-11 13:53:45,450 INFO misc.py line 117 288342] Train: [2/50][1170/2344] Data 0.003 (0.003) Batch 0.514 (0.617) Remain 19:29:53 loss: 0.8343 Lr: 0.00174
[2025-05-11 13:53:46,145 INFO misc.py line 117 288342] Train: [2/50][1171/2344] Data 0.003 (0.003) Batch 0.695 (0.618) Remain 19:30:00 loss: 0.7779 Lr: 0.00174
[2025-05-11 13:53:46,922 INFO misc.py line 117 288342] Train: [2/50][1172/2344] Data 0.003 (0.003) Batch 0.777 (0.618) Remain 19:30:15 loss: 0.7360 Lr: 0.00174
[2025-05-11 13:53:47,491 INFO misc.py line 117 288342] Train: [2/50][1173/2344] Data 0.003 (0.003) Batch 0.569 (0.618) Remain 19:30:10 loss: 0.7277 Lr: 0.00174
[2025-05-11 13:53:48,027 INFO misc.py line 117 288342] Train: [2/50][1174/2344] Data 0.003 (0.003) Batch 0.536 (0.618) Remain 19:30:01 loss: 0.6153 Lr: 0.00174
[2025-05-11 13:53:48,650 INFO misc.py line 117 288342] Train: [2/50][1175/2344] Data 0.003 (0.003) Batch 0.623 (0.618) Remain 19:30:01 loss: 1.0126 Lr: 0.00174
[2025-05-11 13:53:49,222 INFO misc.py line 117 288342] Train: [2/50][1176/2344] Data 0.003 (0.003) Batch 0.572 (0.617) Remain 19:29:56 loss: 0.6931 Lr: 0.00174
[2025-05-11 13:53:49,756 INFO misc.py line 117 288342] Train: [2/50][1177/2344] Data 0.003 (0.003) Batch 0.534 (0.617) Remain 19:29:47 loss: 0.7357 Lr: 0.00174
[2025-05-11 13:53:50,417 INFO misc.py line 117 288342] Train: [2/50][1178/2344] Data 0.003 (0.003) Batch 0.661 (0.617) Remain 19:29:51 loss: 0.8522 Lr: 0.00174
[2025-05-11 13:53:51,189 INFO misc.py line 117 288342] Train: [2/50][1179/2344] Data 0.003 (0.003) Batch 0.772 (0.618) Remain 19:30:05 loss: 0.7033 Lr: 0.00174
[2025-05-11 13:53:51,825 INFO misc.py line 117 288342] Train: [2/50][1180/2344] Data 0.003 (0.003) Batch 0.636 (0.618) Remain 19:30:06 loss: 0.7473 Lr: 0.00174
[2025-05-11 13:53:52,457 INFO misc.py line 117 288342] Train: [2/50][1181/2344] Data 0.003 (0.003) Batch 0.632 (0.618) Remain 19:30:07 loss: 0.7052 Lr: 0.00174
[2025-05-11 13:53:52,932 INFO misc.py line 117 288342] Train: [2/50][1182/2344] Data 0.003 (0.003) Batch 0.476 (0.617) Remain 19:29:53 loss: 0.6974 Lr: 0.00174
[2025-05-11 13:53:53,559 INFO misc.py line 117 288342] Train: [2/50][1183/2344] Data 0.003 (0.003) Batch 0.626 (0.618) Remain 19:29:53 loss: 0.7715 Lr: 0.00174
[2025-05-11 13:53:54,136 INFO misc.py line 117 288342] Train: [2/50][1184/2344] Data 0.003 (0.003) Batch 0.578 (0.617) Remain 19:29:49 loss: 0.7669 Lr: 0.00174
[2025-05-11 13:53:54,719 INFO misc.py line 117 288342] Train: [2/50][1185/2344] Data 0.002 (0.003) Batch 0.583 (0.617) Remain 19:29:45 loss: 0.6915 Lr: 0.00174
[2025-05-11 13:53:55,369 INFO misc.py line 117 288342] Train: [2/50][1186/2344] Data 0.002 (0.003) Batch 0.650 (0.617) Remain 19:29:47 loss: 0.6999 Lr: 0.00174
[2025-05-11 13:53:56,070 INFO misc.py line 117 288342] Train: [2/50][1187/2344] Data 0.002 (0.003) Batch 0.701 (0.618) Remain 19:29:54 loss: 0.7291 Lr: 0.00174
[2025-05-11 13:53:56,761 INFO misc.py line 117 288342] Train: [2/50][1188/2344] Data 0.002 (0.003) Batch 0.691 (0.618) Remain 19:30:01 loss: 0.7346 Lr: 0.00174
[2025-05-11 13:53:57,428 INFO misc.py line 117 288342] Train: [2/50][1189/2344] Data 0.003 (0.003) Batch 0.667 (0.618) Remain 19:30:05 loss: 0.7557 Lr: 0.00174
[2025-05-11 13:53:58,191 INFO misc.py line 117 288342] Train: [2/50][1190/2344] Data 0.002 (0.003) Batch 0.762 (0.618) Remain 19:30:18 loss: 0.8484 Lr: 0.00174
[2025-05-11 13:53:58,724 INFO misc.py line 117 288342] Train: [2/50][1191/2344] Data 0.003 (0.003) Batch 0.534 (0.618) Remain 19:30:10 loss: 0.6602 Lr: 0.00174
[2025-05-11 13:53:59,223 INFO misc.py line 117 288342] Train: [2/50][1192/2344] Data 0.002 (0.003) Batch 0.498 (0.618) Remain 19:29:58 loss: 0.8317 Lr: 0.00174
[2025-05-11 13:53:59,739 INFO misc.py line 117 288342] Train: [2/50][1193/2344] Data 0.003 (0.003) Batch 0.516 (0.618) Remain 19:29:47 loss: 0.8282 Lr: 0.00174
[2025-05-11 13:54:00,420 INFO misc.py line 117 288342] Train: [2/50][1194/2344] Data 0.003 (0.003) Batch 0.681 (0.618) Remain 19:29:53 loss: 0.8011 Lr: 0.00175
[2025-05-11 13:54:01,017 INFO misc.py line 117 288342] Train: [2/50][1195/2344] Data 0.003 (0.003) Batch 0.597 (0.618) Remain 19:29:50 loss: 1.1367 Lr: 0.00175
[2025-05-11 13:54:01,759 INFO misc.py line 117 288342] Train: [2/50][1196/2344] Data 0.003 (0.003) Batch 0.742 (0.618) Remain 19:30:01 loss: 0.7484 Lr: 0.00175
[2025-05-11 13:54:02,482 INFO misc.py line 117 288342] Train: [2/50][1197/2344] Data 0.003 (0.003) Batch 0.723 (0.618) Remain 19:30:11 loss: 0.7860 Lr: 0.00175
[2025-05-11 13:54:03,019 INFO misc.py line 117 288342] Train: [2/50][1198/2344] Data 0.002 (0.003) Batch 0.537 (0.618) Remain 19:30:03 loss: 0.8849 Lr: 0.00175
[2025-05-11 13:54:03,528 INFO misc.py line 117 288342] Train: [2/50][1199/2344] Data 0.002 (0.003) Batch 0.509 (0.618) Remain 19:29:52 loss: 0.9142 Lr: 0.00175
[2025-05-11 13:54:04,071 INFO misc.py line 117 288342] Train: [2/50][1200/2344] Data 0.003 (0.003) Batch 0.544 (0.618) Remain 19:29:44 loss: 0.6573 Lr: 0.00175
[2025-05-11 13:54:04,648 INFO misc.py line 117 288342] Train: [2/50][1201/2344] Data 0.003 (0.003) Batch 0.576 (0.617) Remain 19:29:39 loss: 0.7521 Lr: 0.00175
[2025-05-11 13:54:05,366 INFO misc.py line 117 288342] Train: [2/50][1202/2344] Data 0.003 (0.003) Batch 0.718 (0.618) Remain 19:29:48 loss: 0.8188 Lr: 0.00175
[2025-05-11 13:54:05,917 INFO misc.py line 117 288342] Train: [2/50][1203/2344] Data 0.003 (0.003) Batch 0.551 (0.618) Remain 19:29:41 loss: 0.6879 Lr: 0.00175
[2025-05-11 13:54:06,581 INFO misc.py line 117 288342] Train: [2/50][1204/2344] Data 0.003 (0.003) Batch 0.665 (0.618) Remain 19:29:45 loss: 0.7477 Lr: 0.00175
[2025-05-11 13:54:07,137 INFO misc.py line 117 288342] Train: [2/50][1205/2344] Data 0.003 (0.003) Batch 0.556 (0.617) Remain 19:29:39 loss: 0.7386 Lr: 0.00175
[2025-05-11 13:54:07,726 INFO misc.py line 117 288342] Train: [2/50][1206/2344] Data 0.003 (0.003) Batch 0.590 (0.617) Remain 19:29:36 loss: 0.6596 Lr: 0.00175
[2025-05-11 13:54:08,299 INFO misc.py line 117 288342] Train: [2/50][1207/2344] Data 0.003 (0.003) Batch 0.573 (0.617) Remain 19:29:31 loss: 0.9504 Lr: 0.00175
[2025-05-11 13:54:08,877 INFO misc.py line 117 288342] Train: [2/50][1208/2344] Data 0.002 (0.003) Batch 0.578 (0.617) Remain 19:29:26 loss: 0.6323 Lr: 0.00175
[2025-05-11 13:54:09,508 INFO misc.py line 117 288342] Train: [2/50][1209/2344] Data 0.002 (0.003) Batch 0.631 (0.617) Remain 19:29:27 loss: 0.7387 Lr: 0.00175
[2025-05-11 13:54:10,190 INFO misc.py line 117 288342] Train: [2/50][1210/2344] Data 0.002 (0.003) Batch 0.682 (0.617) Remain 19:29:32 loss: 0.6372 Lr: 0.00175
[2025-05-11 13:54:10,887 INFO misc.py line 117 288342] Train: [2/50][1211/2344] Data 0.003 (0.003) Batch 0.697 (0.618) Remain 19:29:39 loss: 0.5845 Lr: 0.00175
[2025-05-11 13:54:11,547 INFO misc.py line 117 288342] Train: [2/50][1212/2344] Data 0.002 (0.003) Batch 0.660 (0.618) Remain 19:29:43 loss: 0.7508 Lr: 0.00175
[2025-05-11 13:54:12,138 INFO misc.py line 117 288342] Train: [2/50][1213/2344] Data 0.002 (0.003) Batch 0.590 (0.618) Remain 19:29:40 loss: 0.6615 Lr: 0.00175
[2025-05-11 13:54:12,769 INFO misc.py line 117 288342] Train: [2/50][1214/2344] Data 0.003 (0.003) Batch 0.631 (0.618) Remain 19:29:40 loss: 0.9588 Lr: 0.00175
[2025-05-11 13:54:13,522 INFO misc.py line 117 288342] Train: [2/50][1215/2344] Data 0.030 (0.003) Batch 0.753 (0.618) Remain 19:29:52 loss: 0.5183 Lr: 0.00175
[2025-05-11 13:54:14,378 INFO misc.py line 117 288342] Train: [2/50][1216/2344] Data 0.003 (0.003) Batch 0.856 (0.618) Remain 19:30:14 loss: 0.5838 Lr: 0.00175
[2025-05-11 13:54:14,933 INFO misc.py line 117 288342] Train: [2/50][1217/2344] Data 0.003 (0.003) Batch 0.555 (0.618) Remain 19:30:08 loss: 0.9194 Lr: 0.00175
[2025-05-11 13:54:15,557 INFO misc.py line 117 288342] Train: [2/50][1218/2344] Data 0.003 (0.003) Batch 0.624 (0.618) Remain 19:30:07 loss: 1.2092 Lr: 0.00176
[2025-05-11 13:54:16,227 INFO misc.py line 117 288342] Train: [2/50][1219/2344] Data 0.003 (0.003) Batch 0.669 (0.618) Remain 19:30:12 loss: 0.6809 Lr: 0.00176
[2025-05-11 13:54:16,911 INFO misc.py line 117 288342] Train: [2/50][1220/2344] Data 0.003 (0.003) Batch 0.684 (0.618) Remain 19:30:17 loss: 0.7260 Lr: 0.00176
[2025-05-11 13:54:17,590 INFO misc.py line 117 288342] Train: [2/50][1221/2344] Data 0.003 (0.003) Batch 0.679 (0.618) Remain 19:30:22 loss: 0.8572 Lr: 0.00176
[2025-05-11 13:54:18,362 INFO misc.py line 117 288342] Train: [2/50][1222/2344] Data 0.003 (0.003) Batch 0.772 (0.618) Remain 19:30:36 loss: 0.8241 Lr: 0.00176
[2025-05-11 13:54:18,992 INFO misc.py line 117 288342] Train: [2/50][1223/2344] Data 0.003 (0.003) Batch 0.630 (0.618) Remain 19:30:37 loss: 0.8256 Lr: 0.00176
[2025-05-11 13:54:19,624 INFO misc.py line 117 288342] Train: [2/50][1224/2344] Data 0.003 (0.003) Batch 0.632 (0.618) Remain 19:30:37 loss: 0.9082 Lr: 0.00176
[2025-05-11 13:54:20,049 INFO misc.py line 117 288342] Train: [2/50][1225/2344] Data 0.003 (0.003) Batch 0.425 (0.618) Remain 19:30:19 loss: 0.8235 Lr: 0.00176
[2025-05-11 13:54:20,745 INFO misc.py line 117 288342] Train: [2/50][1226/2344] Data 0.003 (0.003) Batch 0.696 (0.618) Remain 19:30:25 loss: 0.6804 Lr: 0.00176
[2025-05-11 13:54:21,224 INFO misc.py line 117 288342] Train: [2/50][1227/2344] Data 0.024 (0.003) Batch 0.480 (0.618) Remain 19:30:12 loss: 0.6501 Lr: 0.00176
[2025-05-11 13:54:21,874 INFO misc.py line 117 288342] Train: [2/50][1228/2344] Data 0.003 (0.003) Batch 0.650 (0.618) Remain 19:30:14 loss: 0.7176 Lr: 0.00176
[2025-05-11 13:54:22,544 INFO misc.py line 117 288342] Train: [2/50][1229/2344] Data 0.003 (0.003) Batch 0.670 (0.618) Remain 19:30:18 loss: 0.8643 Lr: 0.00176
[2025-05-11 13:54:23,015 INFO misc.py line 117 288342] Train: [2/50][1230/2344] Data 0.002 (0.003) Batch 0.470 (0.618) Remain 19:30:04 loss: 0.7531 Lr: 0.00176
[2025-05-11 13:54:23,660 INFO misc.py line 117 288342] Train: [2/50][1231/2344] Data 0.003 (0.003) Batch 0.646 (0.618) Remain 19:30:06 loss: 0.9441 Lr: 0.00176
[2025-05-11 13:54:24,164 INFO misc.py line 117 288342] Train: [2/50][1232/2344] Data 0.003 (0.003) Batch 0.504 (0.618) Remain 19:29:55 loss: 0.7791 Lr: 0.00176
[2025-05-11 13:54:24,747 INFO misc.py line 117 288342] Train: [2/50][1233/2344] Data 0.003 (0.003) Batch 0.582 (0.618) Remain 19:29:51 loss: 0.6009 Lr: 0.00176
[2025-05-11 13:54:25,392 INFO misc.py line 117 288342] Train: [2/50][1234/2344] Data 0.003 (0.003) Batch 0.646 (0.618) Remain 19:29:53 loss: 0.7184 Lr: 0.00176
[2025-05-11 13:54:25,928 INFO misc.py line 117 288342] Train: [2/50][1235/2344] Data 0.002 (0.003) Batch 0.536 (0.618) Remain 19:29:45 loss: 0.7366 Lr: 0.00176
[2025-05-11 13:54:26,536 INFO misc.py line 117 288342] Train: [2/50][1236/2344] Data 0.003 (0.003) Batch 0.608 (0.618) Remain 19:29:43 loss: 0.9063 Lr: 0.00176
[2025-05-11 13:54:27,273 INFO misc.py line 117 288342] Train: [2/50][1237/2344] Data 0.002 (0.003) Batch 0.737 (0.618) Remain 19:29:54 loss: 0.7858 Lr: 0.00176
[2025-05-11 13:54:27,845 INFO misc.py line 117 288342] Train: [2/50][1238/2344] Data 0.003 (0.003) Batch 0.573 (0.618) Remain 19:29:49 loss: 0.9398 Lr: 0.00176
[2025-05-11 13:54:28,467 INFO misc.py line 117 288342] Train: [2/50][1239/2344] Data 0.003 (0.003) Batch 0.622 (0.618) Remain 19:29:49 loss: 0.6098 Lr: 0.00176
[2025-05-11 13:54:29,115 INFO misc.py line 117 288342] Train: [2/50][1240/2344] Data 0.002 (0.003) Batch 0.648 (0.618) Remain 19:29:51 loss: 0.8013 Lr: 0.00176
[2025-05-11 13:54:29,655 INFO misc.py line 117 288342] Train: [2/50][1241/2344] Data 0.003 (0.003) Batch 0.540 (0.618) Remain 19:29:43 loss: 0.7535 Lr: 0.00176
[2025-05-11 13:54:30,335 INFO misc.py line 117 288342] Train: [2/50][1242/2344] Data 0.003 (0.003) Batch 0.680 (0.618) Remain 19:29:48 loss: 0.9178 Lr: 0.00177
[2025-05-11 13:54:31,033 INFO misc.py line 117 288342] Train: [2/50][1243/2344] Data 0.003 (0.003) Batch 0.699 (0.618) Remain 19:29:55 loss: 0.7283 Lr: 0.00177
[2025-05-11 13:54:31,687 INFO misc.py line 117 288342] Train: [2/50][1244/2344] Data 0.003 (0.003) Batch 0.653 (0.618) Remain 19:29:57 loss: 0.8876 Lr: 0.00177
[2025-05-11 13:54:32,250 INFO misc.py line 117 288342] Train: [2/50][1245/2344] Data 0.003 (0.003) Batch 0.564 (0.618) Remain 19:29:52 loss: 0.9317 Lr: 0.00177
[2025-05-11 13:54:33,021 INFO misc.py line 117 288342] Train: [2/50][1246/2344] Data 0.003 (0.003) Batch 0.771 (0.618) Remain 19:30:05 loss: 0.9397 Lr: 0.00177
[2025-05-11 13:54:33,653 INFO misc.py line 117 288342] Train: [2/50][1247/2344] Data 0.003 (0.003) Batch 0.632 (0.618) Remain 19:30:06 loss: 0.8722 Lr: 0.00177
[2025-05-11 13:54:34,146 INFO misc.py line 117 288342] Train: [2/50][1248/2344] Data 0.003 (0.003) Batch 0.493 (0.618) Remain 19:29:54 loss: 0.7298 Lr: 0.00177
[2025-05-11 13:54:34,676 INFO misc.py line 117 288342] Train: [2/50][1249/2344] Data 0.003 (0.003) Batch 0.530 (0.618) Remain 19:29:45 loss: 0.9494 Lr: 0.00177
[2025-05-11 13:54:35,284 INFO misc.py line 117 288342] Train: [2/50][1250/2344] Data 0.003 (0.003) Batch 0.609 (0.618) Remain 19:29:44 loss: 0.7688 Lr: 0.00177
[2025-05-11 13:54:35,996 INFO misc.py line 117 288342] Train: [2/50][1251/2344] Data 0.003 (0.003) Batch 0.712 (0.618) Remain 19:29:52 loss: 0.6631 Lr: 0.00177
[2025-05-11 13:54:36,588 INFO misc.py line 117 288342] Train: [2/50][1252/2344] Data 0.003 (0.003) Batch 0.593 (0.618) Remain 19:29:49 loss: 0.8284 Lr: 0.00177
[2025-05-11 13:54:37,160 INFO misc.py line 117 288342] Train: [2/50][1253/2344] Data 0.002 (0.003) Batch 0.572 (0.618) Remain 19:29:44 loss: 0.7330 Lr: 0.00177
[2025-05-11 13:54:37,922 INFO misc.py line 117 288342] Train: [2/50][1254/2344] Data 0.003 (0.003) Batch 0.761 (0.618) Remain 19:29:56 loss: 1.0512 Lr: 0.00177
[2025-05-11 13:54:38,571 INFO misc.py line 117 288342] Train: [2/50][1255/2344] Data 0.003 (0.003) Batch 0.650 (0.618) Remain 19:29:59 loss: 0.5635 Lr: 0.00177
[2025-05-11 13:54:39,026 INFO misc.py line 117 288342] Train: [2/50][1256/2344] Data 0.003 (0.003) Batch 0.455 (0.618) Remain 19:29:43 loss: 0.7236 Lr: 0.00177
[2025-05-11 13:54:39,663 INFO misc.py line 117 288342] Train: [2/50][1257/2344] Data 0.003 (0.003) Batch 0.637 (0.618) Remain 19:29:44 loss: 0.7460 Lr: 0.00177
[2025-05-11 13:54:40,277 INFO misc.py line 117 288342] Train: [2/50][1258/2344] Data 0.002 (0.003) Batch 0.613 (0.618) Remain 19:29:43 loss: 0.5224 Lr: 0.00177
[2025-05-11 13:54:40,814 INFO misc.py line 117 288342] Train: [2/50][1259/2344] Data 0.003 (0.003) Batch 0.537 (0.618) Remain 19:29:35 loss: 0.8643 Lr: 0.00177
[2025-05-11 13:54:41,386 INFO misc.py line 117 288342] Train: [2/50][1260/2344] Data 0.002 (0.003) Batch 0.572 (0.618) Remain 19:29:31 loss: 0.6506 Lr: 0.00177
[2025-05-11 13:54:41,997 INFO misc.py line 117 288342] Train: [2/50][1261/2344] Data 0.003 (0.003) Batch 0.612 (0.618) Remain 19:29:30 loss: 0.9346 Lr: 0.00177
[2025-05-11 13:54:42,662 INFO misc.py line 117 288342] Train: [2/50][1262/2344] Data 0.003 (0.003) Batch 0.664 (0.618) Remain 19:29:33 loss: 0.7788 Lr: 0.00177
[2025-05-11 13:54:43,499 INFO misc.py line 117 288342] Train: [2/50][1263/2344] Data 0.003 (0.003) Batch 0.837 (0.618) Remain 19:29:52 loss: 0.8063 Lr: 0.00177
[2025-05-11 13:54:44,049 INFO misc.py line 117 288342] Train: [2/50][1264/2344] Data 0.002 (0.003) Batch 0.551 (0.618) Remain 19:29:46 loss: 0.6851 Lr: 0.00177
[2025-05-11 13:54:44,680 INFO misc.py line 117 288342] Train: [2/50][1265/2344] Data 0.003 (0.003) Batch 0.631 (0.618) Remain 19:29:46 loss: 0.8832 Lr: 0.00177
[2025-05-11 13:54:45,266 INFO misc.py line 117 288342] Train: [2/50][1266/2344] Data 0.003 (0.003) Batch 0.586 (0.618) Remain 19:29:43 loss: 1.0463 Lr: 0.00177
[2025-05-11 13:54:45,822 INFO misc.py line 117 288342] Train: [2/50][1267/2344] Data 0.003 (0.003) Batch 0.556 (0.618) Remain 19:29:36 loss: 0.7457 Lr: 0.00178
[2025-05-11 13:54:46,445 INFO misc.py line 117 288342] Train: [2/50][1268/2344] Data 0.003 (0.003) Batch 0.622 (0.618) Remain 19:29:36 loss: 0.7819 Lr: 0.00178
[2025-05-11 13:54:47,048 INFO misc.py line 117 288342] Train: [2/50][1269/2344] Data 0.003 (0.003) Batch 0.604 (0.618) Remain 19:29:34 loss: 0.8992 Lr: 0.00178
[2025-05-11 13:54:47,692 INFO misc.py line 117 288342] Train: [2/50][1270/2344] Data 0.002 (0.003) Batch 0.643 (0.618) Remain 19:29:36 loss: 0.7178 Lr: 0.00178
[2025-05-11 13:54:48,409 INFO misc.py line 117 288342] Train: [2/50][1271/2344] Data 0.003 (0.003) Batch 0.718 (0.618) Remain 19:29:44 loss: 0.6459 Lr: 0.00178
[2025-05-11 13:54:48,961 INFO misc.py line 117 288342] Train: [2/50][1272/2344] Data 0.003 (0.003) Batch 0.551 (0.618) Remain 19:29:38 loss: 0.7083 Lr: 0.00178
[2025-05-11 13:54:49,657 INFO misc.py line 117 288342] Train: [2/50][1273/2344] Data 0.004 (0.003) Batch 0.697 (0.618) Remain 19:29:44 loss: 0.8712 Lr: 0.00178
[2025-05-11 13:54:50,286 INFO misc.py line 117 288342] Train: [2/50][1274/2344] Data 0.003 (0.003) Batch 0.629 (0.618) Remain 19:29:45 loss: 0.8879 Lr: 0.00178
[2025-05-11 13:54:50,822 INFO misc.py line 117 288342] Train: [2/50][1275/2344] Data 0.003 (0.003) Batch 0.537 (0.618) Remain 19:29:37 loss: 0.6260 Lr: 0.00178
[2025-05-11 13:54:51,570 INFO misc.py line 117 288342] Train: [2/50][1276/2344] Data 0.003 (0.003) Batch 0.747 (0.618) Remain 19:29:48 loss: 0.7541 Lr: 0.00178
[2025-05-11 13:54:52,250 INFO misc.py line 117 288342] Train: [2/50][1277/2344] Data 0.003 (0.003) Batch 0.680 (0.618) Remain 19:29:53 loss: 0.6146 Lr: 0.00178
[2025-05-11 13:54:52,961 INFO misc.py line 117 288342] Train: [2/50][1278/2344] Data 0.003 (0.003) Batch 0.711 (0.618) Remain 19:30:00 loss: 0.8851 Lr: 0.00178
[2025-05-11 13:54:53,569 INFO misc.py line 117 288342] Train: [2/50][1279/2344] Data 0.003 (0.003) Batch 0.608 (0.618) Remain 19:29:59 loss: 0.6674 Lr: 0.00178
[2025-05-11 13:54:54,231 INFO misc.py line 117 288342] Train: [2/50][1280/2344] Data 0.003 (0.003) Batch 0.662 (0.618) Remain 19:30:02 loss: 0.9276 Lr: 0.00178
[2025-05-11 13:54:54,921 INFO misc.py line 117 288342] Train: [2/50][1281/2344] Data 0.003 (0.003) Batch 0.690 (0.618) Remain 19:30:08 loss: 0.7682 Lr: 0.00178
[2025-05-11 13:54:55,470 INFO misc.py line 117 288342] Train: [2/50][1282/2344] Data 0.003 (0.003) Batch 0.550 (0.618) Remain 19:30:01 loss: 0.7933 Lr: 0.00178
[2025-05-11 13:54:57,812 INFO misc.py line 117 288342] Train: [2/50][1283/2344] Data 0.003 (0.003) Batch 2.341 (0.619) Remain 19:32:33 loss: 0.8997 Lr: 0.00178
[2025-05-11 13:54:58,235 INFO misc.py line 117 288342] Train: [2/50][1284/2344] Data 0.003 (0.003) Batch 0.423 (0.619) Remain 19:32:15 loss: 0.8393 Lr: 0.00178
[2025-05-11 13:54:58,842 INFO misc.py line 117 288342] Train: [2/50][1285/2344] Data 0.003 (0.003) Batch 0.607 (0.619) Remain 19:32:14 loss: 0.7264 Lr: 0.00178
[2025-05-11 13:54:59,558 INFO misc.py line 117 288342] Train: [2/50][1286/2344] Data 0.002 (0.003) Batch 0.717 (0.619) Remain 19:32:22 loss: 0.7491 Lr: 0.00178
[2025-05-11 13:55:00,269 INFO misc.py line 117 288342] Train: [2/50][1287/2344] Data 0.002 (0.003) Batch 0.711 (0.619) Remain 19:32:29 loss: 0.5971 Lr: 0.00178
[2025-05-11 13:55:00,859 INFO misc.py line 117 288342] Train: [2/50][1288/2344] Data 0.002 (0.003) Batch 0.591 (0.619) Remain 19:32:26 loss: 0.8318 Lr: 0.00178
[2025-05-11 13:55:01,332 INFO misc.py line 117 288342] Train: [2/50][1289/2344] Data 0.002 (0.003) Batch 0.473 (0.619) Remain 19:32:12 loss: 0.5342 Lr: 0.00178
[2025-05-11 13:55:02,043 INFO misc.py line 117 288342] Train: [2/50][1290/2344] Data 0.003 (0.003) Batch 0.711 (0.619) Remain 19:32:20 loss: 0.6731 Lr: 0.00178
[2025-05-11 13:55:02,609 INFO misc.py line 117 288342] Train: [2/50][1291/2344] Data 0.003 (0.003) Batch 0.566 (0.619) Remain 19:32:14 loss: 0.7899 Lr: 0.00178
[2025-05-11 13:55:03,120 INFO misc.py line 117 288342] Train: [2/50][1292/2344] Data 0.003 (0.003) Batch 0.511 (0.619) Remain 19:32:04 loss: 0.6397 Lr: 0.00178
[2025-05-11 13:55:03,740 INFO misc.py line 117 288342] Train: [2/50][1293/2344] Data 0.003 (0.003) Batch 0.620 (0.619) Remain 19:32:04 loss: 0.7875 Lr: 0.00179
[2025-05-11 13:55:04,330 INFO misc.py line 117 288342] Train: [2/50][1294/2344] Data 0.003 (0.003) Batch 0.590 (0.619) Remain 19:32:00 loss: 0.7749 Lr: 0.00179
[2025-05-11 13:55:04,988 INFO misc.py line 117 288342] Train: [2/50][1295/2344] Data 0.003 (0.003) Batch 0.658 (0.619) Remain 19:32:03 loss: 0.6922 Lr: 0.00179
[2025-05-11 13:55:05,596 INFO misc.py line 117 288342] Train: [2/50][1296/2344] Data 0.003 (0.003) Batch 0.608 (0.619) Remain 19:32:02 loss: 0.8357 Lr: 0.00179
[2025-05-11 13:55:06,244 INFO misc.py line 117 288342] Train: [2/50][1297/2344] Data 0.003 (0.003) Batch 0.648 (0.619) Remain 19:32:04 loss: 1.0734 Lr: 0.00179
[2025-05-11 13:55:06,878 INFO misc.py line 117 288342] Train: [2/50][1298/2344] Data 0.003 (0.003) Batch 0.634 (0.619) Remain 19:32:04 loss: 0.9035 Lr: 0.00179
[2025-05-11 13:55:07,550 INFO misc.py line 117 288342] Train: [2/50][1299/2344] Data 0.003 (0.003) Batch 0.671 (0.619) Remain 19:32:08 loss: 0.8052 Lr: 0.00179
[2025-05-11 13:55:08,140 INFO misc.py line 117 288342] Train: [2/50][1300/2344] Data 0.003 (0.003) Batch 0.590 (0.619) Remain 19:32:05 loss: 0.9129 Lr: 0.00179
[2025-05-11 13:55:08,730 INFO misc.py line 117 288342] Train: [2/50][1301/2344] Data 0.003 (0.003) Batch 0.590 (0.619) Remain 19:32:02 loss: 0.7318 Lr: 0.00179
[2025-05-11 13:55:09,306 INFO misc.py line 117 288342] Train: [2/50][1302/2344] Data 0.002 (0.003) Batch 0.576 (0.619) Remain 19:31:57 loss: 1.0405 Lr: 0.00179
[2025-05-11 13:55:09,969 INFO misc.py line 117 288342] Train: [2/50][1303/2344] Data 0.003 (0.003) Batch 0.663 (0.619) Remain 19:32:01 loss: 0.8886 Lr: 0.00179
[2025-05-11 13:55:10,617 INFO misc.py line 117 288342] Train: [2/50][1304/2344] Data 0.003 (0.003) Batch 0.648 (0.619) Remain 19:32:03 loss: 0.5848 Lr: 0.00179
[2025-05-11 13:55:11,324 INFO misc.py line 117 288342] Train: [2/50][1305/2344] Data 0.003 (0.003) Batch 0.707 (0.619) Remain 19:32:10 loss: 0.8934 Lr: 0.00179
[2025-05-11 13:55:11,793 INFO misc.py line 117 288342] Train: [2/50][1306/2344] Data 0.003 (0.003) Batch 0.469 (0.619) Remain 19:31:56 loss: 0.5872 Lr: 0.00179
[2025-05-11 13:55:12,444 INFO misc.py line 117 288342] Train: [2/50][1307/2344] Data 0.004 (0.003) Batch 0.651 (0.619) Remain 19:31:58 loss: 0.6880 Lr: 0.00179
[2025-05-11 13:55:13,112 INFO misc.py line 117 288342] Train: [2/50][1308/2344] Data 0.003 (0.003) Batch 0.669 (0.619) Remain 19:32:02 loss: 0.7679 Lr: 0.00179
[2025-05-11 13:55:13,684 INFO misc.py line 117 288342] Train: [2/50][1309/2344] Data 0.003 (0.003) Batch 0.571 (0.619) Remain 19:31:57 loss: 0.8820 Lr: 0.00179
[2025-05-11 13:55:14,241 INFO misc.py line 117 288342] Train: [2/50][1310/2344] Data 0.003 (0.003) Batch 0.557 (0.619) Remain 19:31:51 loss: 0.7963 Lr: 0.00179
[2025-05-11 13:55:14,962 INFO misc.py line 117 288342] Train: [2/50][1311/2344] Data 0.003 (0.003) Batch 0.721 (0.619) Remain 19:31:59 loss: 0.6670 Lr: 0.00179
[2025-05-11 13:55:15,640 INFO misc.py line 117 288342] Train: [2/50][1312/2344] Data 0.003 (0.003) Batch 0.678 (0.619) Remain 19:32:04 loss: 0.7570 Lr: 0.00179
[2025-05-11 13:55:16,283 INFO misc.py line 117 288342] Train: [2/50][1313/2344] Data 0.002 (0.003) Batch 0.643 (0.619) Remain 19:32:05 loss: 0.8913 Lr: 0.00179
[2025-05-11 13:55:16,833 INFO misc.py line 117 288342] Train: [2/50][1314/2344] Data 0.002 (0.003) Batch 0.550 (0.619) Remain 19:31:58 loss: 0.8059 Lr: 0.00179
[2025-05-11 13:55:17,343 INFO misc.py line 117 288342] Train: [2/50][1315/2344] Data 0.003 (0.003) Batch 0.510 (0.619) Remain 19:31:48 loss: 0.7661 Lr: 0.00179
[2025-05-11 13:55:17,911 INFO misc.py line 117 288342] Train: [2/50][1316/2344] Data 0.003 (0.003) Batch 0.567 (0.619) Remain 19:31:43 loss: 0.8007 Lr: 0.00179
[2025-05-11 13:55:18,569 INFO misc.py line 117 288342] Train: [2/50][1317/2344] Data 0.003 (0.003) Batch 0.659 (0.619) Remain 19:31:46 loss: 0.8912 Lr: 0.00179
[2025-05-11 13:55:19,252 INFO misc.py line 117 288342] Train: [2/50][1318/2344] Data 0.003 (0.003) Batch 0.683 (0.619) Remain 19:31:51 loss: 0.8324 Lr: 0.00180
[2025-05-11 13:55:19,909 INFO misc.py line 117 288342] Train: [2/50][1319/2344] Data 0.003 (0.003) Batch 0.657 (0.619) Remain 19:31:53 loss: 0.8239 Lr: 0.00180
[2025-05-11 13:55:20,628 INFO misc.py line 117 288342] Train: [2/50][1320/2344] Data 0.002 (0.003) Batch 0.718 (0.619) Remain 19:32:01 loss: 0.8076 Lr: 0.00180
[2025-05-11 13:55:21,282 INFO misc.py line 117 288342] Train: [2/50][1321/2344] Data 0.003 (0.003) Batch 0.654 (0.619) Remain 19:32:04 loss: 0.7983 Lr: 0.00180
[2025-05-11 13:55:21,848 INFO misc.py line 117 288342] Train: [2/50][1322/2344] Data 0.003 (0.003) Batch 0.566 (0.619) Remain 19:31:59 loss: 0.7391 Lr: 0.00180
[2025-05-11 13:55:22,492 INFO misc.py line 117 288342] Train: [2/50][1323/2344] Data 0.003 (0.003) Batch 0.645 (0.619) Remain 19:32:00 loss: 0.7152 Lr: 0.00180
[2025-05-11 13:55:23,249 INFO misc.py line 117 288342] Train: [2/50][1324/2344] Data 0.003 (0.003) Batch 0.757 (0.619) Remain 19:32:11 loss: 0.6696 Lr: 0.00180
[2025-05-11 13:55:23,920 INFO misc.py line 117 288342] Train: [2/50][1325/2344] Data 0.003 (0.003) Batch 0.670 (0.620) Remain 19:32:15 loss: 0.8795 Lr: 0.00180
[2025-05-11 13:55:24,618 INFO misc.py line 117 288342] Train: [2/50][1326/2344] Data 0.002 (0.003) Batch 0.698 (0.620) Remain 19:32:21 loss: 0.9029 Lr: 0.00180
[2025-05-11 13:55:25,270 INFO misc.py line 117 288342] Train: [2/50][1327/2344] Data 0.002 (0.003) Batch 0.653 (0.620) Remain 19:32:23 loss: 0.7159 Lr: 0.00180
[2025-05-11 13:55:25,827 INFO misc.py line 117 288342] Train: [2/50][1328/2344] Data 0.002 (0.003) Batch 0.557 (0.620) Remain 19:32:17 loss: 0.7062 Lr: 0.00180
[2025-05-11 13:55:26,538 INFO misc.py line 117 288342] Train: [2/50][1329/2344] Data 0.003 (0.003) Batch 0.710 (0.620) Remain 19:32:25 loss: 0.7697 Lr: 0.00180
[2025-05-11 13:55:27,126 INFO misc.py line 117 288342] Train: [2/50][1330/2344] Data 0.002 (0.003) Batch 0.588 (0.620) Remain 19:32:21 loss: 0.6445 Lr: 0.00180
[2025-05-11 13:55:27,816 INFO misc.py line 117 288342] Train: [2/50][1331/2344] Data 0.004 (0.003) Batch 0.689 (0.620) Remain 19:32:27 loss: 0.8193 Lr: 0.00180
[2025-05-11 13:55:28,391 INFO misc.py line 117 288342] Train: [2/50][1332/2344] Data 0.002 (0.003) Batch 0.575 (0.620) Remain 19:32:22 loss: 0.7511 Lr: 0.00180
[2025-05-11 13:55:28,887 INFO misc.py line 117 288342] Train: [2/50][1333/2344] Data 0.002 (0.003) Batch 0.496 (0.620) Remain 19:32:11 loss: 0.6464 Lr: 0.00180
[2025-05-11 13:55:29,407 INFO misc.py line 117 288342] Train: [2/50][1334/2344] Data 0.003 (0.003) Batch 0.520 (0.619) Remain 19:32:02 loss: 0.6903 Lr: 0.00180
[2025-05-11 13:55:30,030 INFO misc.py line 117 288342] Train: [2/50][1335/2344] Data 0.003 (0.003) Batch 0.624 (0.619) Remain 19:32:02 loss: 1.0315 Lr: 0.00180
[2025-05-11 13:55:30,607 INFO misc.py line 117 288342] Train: [2/50][1336/2344] Data 0.003 (0.003) Batch 0.577 (0.619) Remain 19:31:57 loss: 0.7811 Lr: 0.00180
[2025-05-11 13:55:31,103 INFO misc.py line 117 288342] Train: [2/50][1337/2344] Data 0.002 (0.003) Batch 0.496 (0.619) Remain 19:31:46 loss: 0.7329 Lr: 0.00180
[2025-05-11 13:55:31,581 INFO misc.py line 117 288342] Train: [2/50][1338/2344] Data 0.002 (0.003) Batch 0.478 (0.619) Remain 19:31:34 loss: 0.6718 Lr: 0.00180
[2025-05-11 13:55:32,180 INFO misc.py line 117 288342] Train: [2/50][1339/2344] Data 0.003 (0.003) Batch 0.599 (0.619) Remain 19:31:31 loss: 0.8095 Lr: 0.00180
[2025-05-11 13:55:32,712 INFO misc.py line 117 288342] Train: [2/50][1340/2344] Data 0.003 (0.003) Batch 0.531 (0.619) Remain 19:31:23 loss: 0.6667 Lr: 0.00180
[2025-05-11 13:55:33,376 INFO misc.py line 117 288342] Train: [2/50][1341/2344] Data 0.003 (0.003) Batch 0.665 (0.619) Remain 19:31:26 loss: 0.7120 Lr: 0.00180
[2025-05-11 13:55:33,920 INFO misc.py line 117 288342] Train: [2/50][1342/2344] Data 0.003 (0.003) Batch 0.544 (0.619) Remain 19:31:19 loss: 0.8437 Lr: 0.00180
[2025-05-11 13:55:34,541 INFO misc.py line 117 288342] Train: [2/50][1343/2344] Data 0.003 (0.003) Batch 0.621 (0.619) Remain 19:31:19 loss: 0.6239 Lr: 0.00180
[2025-05-11 13:55:35,072 INFO misc.py line 117 288342] Train: [2/50][1344/2344] Data 0.003 (0.003) Batch 0.531 (0.619) Remain 19:31:11 loss: 0.7657 Lr: 0.00180
[2025-05-11 13:55:35,732 INFO misc.py line 117 288342] Train: [2/50][1345/2344] Data 0.003 (0.003) Batch 0.660 (0.619) Remain 19:31:14 loss: 0.7762 Lr: 0.00181
[2025-05-11 13:55:36,349 INFO misc.py line 117 288342] Train: [2/50][1346/2344] Data 0.003 (0.003) Batch 0.617 (0.619) Remain 19:31:13 loss: 0.7152 Lr: 0.00181
[2025-05-11 13:55:37,031 INFO misc.py line 117 288342] Train: [2/50][1347/2344] Data 0.003 (0.003) Batch 0.681 (0.619) Remain 19:31:18 loss: 0.7646 Lr: 0.00181
[2025-05-11 13:55:37,640 INFO misc.py line 117 288342] Train: [2/50][1348/2344] Data 0.002 (0.003) Batch 0.609 (0.619) Remain 19:31:16 loss: 0.9191 Lr: 0.00181
[2025-05-11 13:55:38,322 INFO misc.py line 117 288342] Train: [2/50][1349/2344] Data 0.003 (0.003) Batch 0.682 (0.619) Remain 19:31:21 loss: 0.7916 Lr: 0.00181
[2025-05-11 13:55:38,822 INFO misc.py line 117 288342] Train: [2/50][1350/2344] Data 0.002 (0.003) Batch 0.501 (0.619) Remain 19:31:10 loss: 0.7489 Lr: 0.00181
[2025-05-11 13:55:39,424 INFO misc.py line 117 288342] Train: [2/50][1351/2344] Data 0.002 (0.003) Batch 0.602 (0.619) Remain 19:31:08 loss: 1.0046 Lr: 0.00181
[2025-05-11 13:55:39,923 INFO misc.py line 117 288342] Train: [2/50][1352/2344] Data 0.003 (0.003) Batch 0.498 (0.619) Remain 19:30:57 loss: 0.7951 Lr: 0.00181
[2025-05-11 13:55:40,477 INFO misc.py line 117 288342] Train: [2/50][1353/2344] Data 0.003 (0.003) Batch 0.554 (0.619) Remain 19:30:51 loss: 1.0422 Lr: 0.00181
[2025-05-11 13:55:41,151 INFO misc.py line 117 288342] Train: [2/50][1354/2344] Data 0.003 (0.003) Batch 0.675 (0.619) Remain 19:30:55 loss: 0.7751 Lr: 0.00181
[2025-05-11 13:55:41,636 INFO misc.py line 117 288342] Train: [2/50][1355/2344] Data 0.003 (0.003) Batch 0.485 (0.619) Remain 19:30:43 loss: 0.7377 Lr: 0.00181
[2025-05-11 13:55:42,174 INFO misc.py line 117 288342] Train: [2/50][1356/2344] Data 0.003 (0.003) Batch 0.539 (0.619) Remain 19:30:36 loss: 0.8994 Lr: 0.00181
[2025-05-11 13:55:42,963 INFO misc.py line 117 288342] Train: [2/50][1357/2344] Data 0.003 (0.003) Batch 0.788 (0.619) Remain 19:30:50 loss: 0.6497 Lr: 0.00181
[2025-05-11 13:55:43,465 INFO misc.py line 117 288342] Train: [2/50][1358/2344] Data 0.003 (0.003) Batch 0.503 (0.619) Remain 19:30:39 loss: 0.7699 Lr: 0.00181
[2025-05-11 13:55:44,115 INFO misc.py line 117 288342] Train: [2/50][1359/2344] Data 0.003 (0.003) Batch 0.650 (0.619) Remain 19:30:41 loss: 0.7251 Lr: 0.00181
[2025-05-11 13:55:44,673 INFO misc.py line 117 288342] Train: [2/50][1360/2344] Data 0.002 (0.003) Batch 0.557 (0.619) Remain 19:30:36 loss: 0.7080 Lr: 0.00181
[2025-05-11 13:55:45,248 INFO misc.py line 117 288342] Train: [2/50][1361/2344] Data 0.003 (0.003) Batch 0.576 (0.619) Remain 19:30:31 loss: 0.7467 Lr: 0.00181
[2025-05-11 13:55:45,800 INFO misc.py line 117 288342] Train: [2/50][1362/2344] Data 0.003 (0.003) Batch 0.552 (0.619) Remain 19:30:25 loss: 0.5205 Lr: 0.00181
[2025-05-11 13:55:46,470 INFO misc.py line 117 288342] Train: [2/50][1363/2344] Data 0.003 (0.003) Batch 0.670 (0.619) Remain 19:30:29 loss: 0.8149 Lr: 0.00181
[2025-05-11 13:55:47,207 INFO misc.py line 117 288342] Train: [2/50][1364/2344] Data 0.005 (0.003) Batch 0.737 (0.619) Remain 19:30:38 loss: 0.7537 Lr: 0.00181
[2025-05-11 13:55:47,742 INFO misc.py line 117 288342] Train: [2/50][1365/2344] Data 0.003 (0.003) Batch 0.535 (0.619) Remain 19:30:30 loss: 0.6963 Lr: 0.00181
[2025-05-11 13:55:48,324 INFO misc.py line 117 288342] Train: [2/50][1366/2344] Data 0.003 (0.003) Batch 0.582 (0.619) Remain 19:30:27 loss: 0.7477 Lr: 0.00181
[2025-05-11 13:55:48,995 INFO misc.py line 117 288342] Train: [2/50][1367/2344] Data 0.003 (0.003) Batch 0.671 (0.619) Remain 19:30:30 loss: 0.7622 Lr: 0.00181
[2025-05-11 13:55:49,494 INFO misc.py line 117 288342] Train: [2/50][1368/2344] Data 0.002 (0.003) Batch 0.499 (0.619) Remain 19:30:20 loss: 0.6854 Lr: 0.00181
[2025-05-11 13:55:50,064 INFO misc.py line 117 288342] Train: [2/50][1369/2344] Data 0.003 (0.003) Batch 0.570 (0.619) Remain 19:30:15 loss: 1.1468 Lr: 0.00181
[2025-05-11 13:55:50,658 INFO misc.py line 117 288342] Train: [2/50][1370/2344] Data 0.003 (0.003) Batch 0.594 (0.619) Remain 19:30:13 loss: 0.7097 Lr: 0.00181
[2025-05-11 13:55:51,289 INFO misc.py line 117 288342] Train: [2/50][1371/2344] Data 0.003 (0.003) Batch 0.631 (0.619) Remain 19:30:13 loss: 0.7089 Lr: 0.00181
[2025-05-11 13:55:51,783 INFO misc.py line 117 288342] Train: [2/50][1372/2344] Data 0.003 (0.003) Batch 0.494 (0.619) Remain 19:30:02 loss: 0.8007 Lr: 0.00182
[2025-05-11 13:55:52,373 INFO misc.py line 117 288342] Train: [2/50][1373/2344] Data 0.003 (0.003) Batch 0.590 (0.619) Remain 19:29:59 loss: 0.7022 Lr: 0.00182
[2025-05-11 13:55:53,042 INFO misc.py line 117 288342] Train: [2/50][1374/2344] Data 0.003 (0.003) Batch 0.670 (0.619) Remain 19:30:03 loss: 0.7309 Lr: 0.00182
[2025-05-11 13:55:53,756 INFO misc.py line 117 288342] Train: [2/50][1375/2344] Data 0.003 (0.003) Batch 0.713 (0.619) Remain 19:30:10 loss: 1.0162 Lr: 0.00182
[2025-05-11 13:55:54,402 INFO misc.py line 117 288342] Train: [2/50][1376/2344] Data 0.002 (0.003) Batch 0.647 (0.619) Remain 19:30:11 loss: 0.9266 Lr: 0.00182
[2025-05-11 13:55:55,040 INFO misc.py line 117 288342] Train: [2/50][1377/2344] Data 0.002 (0.003) Batch 0.638 (0.619) Remain 19:30:12 loss: 0.7061 Lr: 0.00182
[2025-05-11 13:55:56,449 INFO misc.py line 117 288342] Train: [2/50][1378/2344] Data 0.002 (0.003) Batch 1.409 (0.619) Remain 19:31:17 loss: 0.7678 Lr: 0.00182
[2025-05-11 13:55:57,044 INFO misc.py line 117 288342] Train: [2/50][1379/2344] Data 0.003 (0.003) Batch 0.594 (0.619) Remain 19:31:14 loss: 0.6472 Lr: 0.00182
[2025-05-11 13:55:57,816 INFO misc.py line 117 288342] Train: [2/50][1380/2344] Data 0.003 (0.003) Batch 0.772 (0.619) Remain 19:31:26 loss: 0.6851 Lr: 0.00182
[2025-05-11 13:55:58,597 INFO misc.py line 117 288342] Train: [2/50][1381/2344] Data 0.003 (0.003) Batch 0.781 (0.620) Remain 19:31:39 loss: 0.6907 Lr: 0.00182
[2025-05-11 13:55:59,260 INFO misc.py line 117 288342] Train: [2/50][1382/2344] Data 0.003 (0.003) Batch 0.663 (0.620) Remain 19:31:42 loss: 0.7886 Lr: 0.00182
[2025-05-11 13:55:59,829 INFO misc.py line 117 288342] Train: [2/50][1383/2344] Data 0.003 (0.003) Batch 0.569 (0.620) Remain 19:31:37 loss: 0.6798 Lr: 0.00182
[2025-05-11 13:56:00,447 INFO misc.py line 117 288342] Train: [2/50][1384/2344] Data 0.003 (0.003) Batch 0.619 (0.620) Remain 19:31:36 loss: 0.7878 Lr: 0.00182
[2025-05-11 13:56:01,075 INFO misc.py line 117 288342] Train: [2/50][1385/2344] Data 0.003 (0.003) Batch 0.628 (0.620) Remain 19:31:37 loss: 0.8249 Lr: 0.00182
[2025-05-11 13:56:01,902 INFO misc.py line 117 288342] Train: [2/50][1386/2344] Data 0.003 (0.003) Batch 0.826 (0.620) Remain 19:31:53 loss: 0.6390 Lr: 0.00182
[2025-05-11 13:56:02,461 INFO misc.py line 117 288342] Train: [2/50][1387/2344] Data 0.002 (0.003) Batch 0.559 (0.620) Remain 19:31:47 loss: 0.6747 Lr: 0.00182
[2025-05-11 13:56:03,064 INFO misc.py line 117 288342] Train: [2/50][1388/2344] Data 0.003 (0.003) Batch 0.603 (0.620) Remain 19:31:45 loss: 0.7404 Lr: 0.00182
[2025-05-11 13:56:03,690 INFO misc.py line 117 288342] Train: [2/50][1389/2344] Data 0.003 (0.003) Batch 0.626 (0.620) Remain 19:31:45 loss: 0.6479 Lr: 0.00182
[2025-05-11 13:56:04,469 INFO misc.py line 117 288342] Train: [2/50][1390/2344] Data 0.003 (0.003) Batch 0.780 (0.620) Remain 19:31:58 loss: 0.8698 Lr: 0.00182
[2025-05-11 13:56:05,087 INFO misc.py line 117 288342] Train: [2/50][1391/2344] Data 0.003 (0.003) Batch 0.618 (0.620) Remain 19:31:57 loss: 0.6734 Lr: 0.00182
[2025-05-11 13:56:05,596 INFO misc.py line 117 288342] Train: [2/50][1392/2344] Data 0.003 (0.003) Batch 0.509 (0.620) Remain 19:31:47 loss: 0.6496 Lr: 0.00182
[2025-05-11 13:56:06,349 INFO misc.py line 117 288342] Train: [2/50][1393/2344] Data 0.003 (0.003) Batch 0.753 (0.620) Remain 19:31:58 loss: 0.8508 Lr: 0.00182
[2025-05-11 13:56:06,955 INFO misc.py line 117 288342] Train: [2/50][1394/2344] Data 0.003 (0.003) Batch 0.606 (0.620) Remain 19:31:56 loss: 0.8940 Lr: 0.00182
[2025-05-11 13:56:07,517 INFO misc.py line 117 288342] Train: [2/50][1395/2344] Data 0.003 (0.003) Batch 0.562 (0.620) Remain 19:31:50 loss: 0.7118 Lr: 0.00182
[2025-05-11 13:56:08,218 INFO misc.py line 117 288342] Train: [2/50][1396/2344] Data 0.003 (0.003) Batch 0.701 (0.620) Remain 19:31:56 loss: 0.8107 Lr: 0.00182
[2025-05-11 13:56:08,873 INFO misc.py line 117 288342] Train: [2/50][1397/2344] Data 0.003 (0.003) Batch 0.654 (0.620) Remain 19:31:59 loss: 0.7734 Lr: 0.00182
[2025-05-11 13:56:09,568 INFO misc.py line 117 288342] Train: [2/50][1398/2344] Data 0.003 (0.003) Batch 0.696 (0.620) Remain 19:32:04 loss: 0.9588 Lr: 0.00182
[2025-05-11 13:56:10,235 INFO misc.py line 117 288342] Train: [2/50][1399/2344] Data 0.002 (0.003) Batch 0.667 (0.620) Remain 19:32:07 loss: 0.9747 Lr: 0.00183
[2025-05-11 13:56:10,970 INFO misc.py line 117 288342] Train: [2/50][1400/2344] Data 0.003 (0.003) Batch 0.735 (0.620) Remain 19:32:16 loss: 0.8456 Lr: 0.00183
[2025-05-11 13:56:11,558 INFO misc.py line 117 288342] Train: [2/50][1401/2344] Data 0.003 (0.003) Batch 0.587 (0.620) Remain 19:32:13 loss: 0.8606 Lr: 0.00183
[2025-05-11 13:56:12,245 INFO misc.py line 117 288342] Train: [2/50][1402/2344] Data 0.002 (0.003) Batch 0.688 (0.620) Remain 19:32:18 loss: 0.8804 Lr: 0.00183
[2025-05-11 13:56:12,826 INFO misc.py line 117 288342] Train: [2/50][1403/2344] Data 0.003 (0.003) Batch 0.580 (0.620) Remain 19:32:14 loss: 0.7112 Lr: 0.00183
[2025-05-11 13:56:13,480 INFO misc.py line 117 288342] Train: [2/50][1404/2344] Data 0.002 (0.003) Batch 0.655 (0.620) Remain 19:32:16 loss: 0.8776 Lr: 0.00183
[2025-05-11 13:56:14,176 INFO misc.py line 117 288342] Train: [2/50][1405/2344] Data 0.003 (0.003) Batch 0.695 (0.620) Remain 19:32:22 loss: 0.9827 Lr: 0.00183
[2025-05-11 13:56:15,518 INFO misc.py line 117 288342] Train: [2/50][1406/2344] Data 0.003 (0.003) Batch 1.343 (0.621) Remain 19:33:19 loss: 1.1353 Lr: 0.00183
[2025-05-11 13:56:16,136 INFO misc.py line 117 288342] Train: [2/50][1407/2344] Data 0.003 (0.003) Batch 0.618 (0.621) Remain 19:33:19 loss: 0.8101 Lr: 0.00183
[2025-05-11 13:56:16,628 INFO misc.py line 117 288342] Train: [2/50][1408/2344] Data 0.002 (0.003) Batch 0.492 (0.620) Remain 19:33:08 loss: 0.7886 Lr: 0.00183
[2025-05-11 13:56:17,370 INFO misc.py line 117 288342] Train: [2/50][1409/2344] Data 0.003 (0.003) Batch 0.742 (0.621) Remain 19:33:17 loss: 0.8748 Lr: 0.00183
[2025-05-11 13:56:18,130 INFO misc.py line 117 288342] Train: [2/50][1410/2344] Data 0.002 (0.003) Batch 0.761 (0.621) Remain 19:33:27 loss: 0.6353 Lr: 0.00183
[2025-05-11 13:56:18,745 INFO misc.py line 117 288342] Train: [2/50][1411/2344] Data 0.002 (0.003) Batch 0.615 (0.621) Remain 19:33:26 loss: 0.6832 Lr: 0.00183
[2025-05-11 13:56:19,321 INFO misc.py line 117 288342] Train: [2/50][1412/2344] Data 0.003 (0.003) Batch 0.576 (0.621) Remain 19:33:22 loss: 0.7413 Lr: 0.00183
[2025-05-11 13:56:19,939 INFO misc.py line 117 288342] Train: [2/50][1413/2344] Data 0.002 (0.003) Batch 0.618 (0.621) Remain 19:33:21 loss: 0.9926 Lr: 0.00183
[2025-05-11 13:56:20,627 INFO misc.py line 117 288342] Train: [2/50][1414/2344] Data 0.002 (0.003) Batch 0.688 (0.621) Remain 19:33:26 loss: 0.5747 Lr: 0.00183
[2025-05-11 13:56:21,160 INFO misc.py line 117 288342] Train: [2/50][1415/2344] Data 0.002 (0.003) Batch 0.533 (0.621) Remain 19:33:18 loss: 1.0331 Lr: 0.00183
[2025-05-11 13:56:21,689 INFO misc.py line 117 288342] Train: [2/50][1416/2344] Data 0.003 (0.003) Batch 0.529 (0.621) Remain 19:33:10 loss: 0.6689 Lr: 0.00183
[2025-05-11 13:56:22,309 INFO misc.py line 117 288342] Train: [2/50][1417/2344] Data 0.003 (0.003) Batch 0.619 (0.621) Remain 19:33:10 loss: 0.6986 Lr: 0.00183
[2025-05-11 13:56:22,923 INFO misc.py line 117 288342] Train: [2/50][1418/2344] Data 0.003 (0.003) Batch 0.615 (0.621) Remain 19:33:09 loss: 0.5524 Lr: 0.00183
[2025-05-11 13:56:23,488 INFO misc.py line 117 288342] Train: [2/50][1419/2344] Data 0.003 (0.003) Batch 0.565 (0.620) Remain 19:33:04 loss: 0.8178 Lr: 0.00183
[2025-05-11 13:56:24,055 INFO misc.py line 117 288342] Train: [2/50][1420/2344] Data 0.003 (0.003) Batch 0.567 (0.620) Remain 19:32:59 loss: 0.6705 Lr: 0.00183
[2025-05-11 13:56:24,547 INFO misc.py line 117 288342] Train: [2/50][1421/2344] Data 0.003 (0.003) Batch 0.492 (0.620) Remain 19:32:48 loss: 0.7444 Lr: 0.00183
[2025-05-11 13:56:25,194 INFO misc.py line 117 288342] Train: [2/50][1422/2344] Data 0.003 (0.003) Batch 0.647 (0.620) Remain 19:32:49 loss: 0.7523 Lr: 0.00183
[2025-05-11 13:56:25,762 INFO misc.py line 117 288342] Train: [2/50][1423/2344] Data 0.002 (0.003) Batch 0.568 (0.620) Remain 19:32:44 loss: 0.5959 Lr: 0.00183
[2025-05-11 13:56:26,383 INFO misc.py line 117 288342] Train: [2/50][1424/2344] Data 0.003 (0.003) Batch 0.621 (0.620) Remain 19:32:44 loss: 0.7520 Lr: 0.00183
[2025-05-11 13:56:27,003 INFO misc.py line 117 288342] Train: [2/50][1425/2344] Data 0.002 (0.003) Batch 0.620 (0.620) Remain 19:32:43 loss: 0.9825 Lr: 0.00183
[2025-05-11 13:56:27,546 INFO misc.py line 117 288342] Train: [2/50][1426/2344] Data 0.002 (0.003) Batch 0.542 (0.620) Remain 19:32:36 loss: 0.8168 Lr: 0.00183
[2025-05-11 13:56:28,133 INFO misc.py line 117 288342] Train: [2/50][1427/2344] Data 0.003 (0.003) Batch 0.587 (0.620) Remain 19:32:33 loss: 1.0326 Lr: 0.00183
[2025-05-11 13:56:28,841 INFO misc.py line 117 288342] Train: [2/50][1428/2344] Data 0.002 (0.003) Batch 0.708 (0.620) Remain 19:32:40 loss: 0.8071 Lr: 0.00184
[2025-05-11 13:56:30,286 INFO misc.py line 117 288342] Train: [2/50][1429/2344] Data 0.002 (0.003) Batch 1.445 (0.621) Remain 19:33:45 loss: 0.6860 Lr: 0.00184
[2025-05-11 13:56:30,825 INFO misc.py line 117 288342] Train: [2/50][1430/2344] Data 0.003 (0.003) Batch 0.539 (0.621) Remain 19:33:37 loss: 0.9269 Lr: 0.00184
[2025-05-11 13:56:31,407 INFO misc.py line 117 288342] Train: [2/50][1431/2344] Data 0.003 (0.003) Batch 0.582 (0.621) Remain 19:33:34 loss: 0.6351 Lr: 0.00184
[2025-05-11 13:56:32,063 INFO misc.py line 117 288342] Train: [2/50][1432/2344] Data 0.003 (0.003) Batch 0.655 (0.621) Remain 19:33:36 loss: 0.6572 Lr: 0.00184
[2025-05-11 13:56:32,698 INFO misc.py line 117 288342] Train: [2/50][1433/2344] Data 0.003 (0.003) Batch 0.635 (0.621) Remain 19:33:36 loss: 0.7968 Lr: 0.00184
[2025-05-11 13:56:33,266 INFO misc.py line 117 288342] Train: [2/50][1434/2344] Data 0.002 (0.003) Batch 0.568 (0.621) Remain 19:33:32 loss: 0.9241 Lr: 0.00184
[2025-05-11 13:56:33,898 INFO misc.py line 117 288342] Train: [2/50][1435/2344] Data 0.003 (0.003) Batch 0.632 (0.621) Remain 19:33:32 loss: 0.8057 Lr: 0.00184
[2025-05-11 13:56:34,631 INFO misc.py line 117 288342] Train: [2/50][1436/2344] Data 0.003 (0.003) Batch 0.733 (0.621) Remain 19:33:40 loss: 0.6855 Lr: 0.00184
[2025-05-11 13:56:35,131 INFO misc.py line 117 288342] Train: [2/50][1437/2344] Data 0.003 (0.003) Batch 0.499 (0.621) Remain 19:33:30 loss: 1.0209 Lr: 0.00184
[2025-05-11 13:56:35,586 INFO misc.py line 117 288342] Train: [2/50][1438/2344] Data 0.003 (0.003) Batch 0.455 (0.621) Remain 19:33:16 loss: 0.6697 Lr: 0.00184
[2025-05-11 13:56:36,216 INFO misc.py line 117 288342] Train: [2/50][1439/2344] Data 0.003 (0.003) Batch 0.631 (0.621) Remain 19:33:16 loss: 0.8910 Lr: 0.00184
[2025-05-11 13:56:36,867 INFO misc.py line 117 288342] Train: [2/50][1440/2344] Data 0.003 (0.003) Batch 0.651 (0.621) Remain 19:33:18 loss: 0.8052 Lr: 0.00184
[2025-05-11 13:56:37,629 INFO misc.py line 117 288342] Train: [2/50][1441/2344] Data 0.003 (0.003) Batch 0.762 (0.621) Remain 19:33:29 loss: 0.6025 Lr: 0.00184
[2025-05-11 13:56:38,135 INFO misc.py line 117 288342] Train: [2/50][1442/2344] Data 0.003 (0.003) Batch 0.506 (0.621) Remain 19:33:19 loss: 0.6632 Lr: 0.00184
[2025-05-11 13:56:38,885 INFO misc.py line 117 288342] Train: [2/50][1443/2344] Data 0.003 (0.003) Batch 0.749 (0.621) Remain 19:33:28 loss: 0.8919 Lr: 0.00184
[2025-05-11 13:56:39,616 INFO misc.py line 117 288342] Train: [2/50][1444/2344] Data 0.003 (0.003) Batch 0.731 (0.621) Remain 19:33:37 loss: 0.8780 Lr: 0.00184
[2025-05-11 13:56:40,314 INFO misc.py line 117 288342] Train: [2/50][1445/2344] Data 0.003 (0.003) Batch 0.698 (0.621) Remain 19:33:42 loss: 0.6976 Lr: 0.00184
[2025-05-11 13:56:40,951 INFO misc.py line 117 288342] Train: [2/50][1446/2344] Data 0.003 (0.003) Batch 0.637 (0.621) Remain 19:33:43 loss: 0.8437 Lr: 0.00184
[2025-05-11 13:56:41,589 INFO misc.py line 117 288342] Train: [2/50][1447/2344] Data 0.003 (0.003) Batch 0.638 (0.621) Remain 19:33:43 loss: 0.6572 Lr: 0.00184
[2025-05-11 13:56:42,130 INFO misc.py line 117 288342] Train: [2/50][1448/2344] Data 0.003 (0.003) Batch 0.541 (0.621) Remain 19:33:36 loss: 0.8755 Lr: 0.00184
[2025-05-11 13:56:42,691 INFO misc.py line 117 288342] Train: [2/50][1449/2344] Data 0.003 (0.003) Batch 0.560 (0.621) Remain 19:33:31 loss: 0.7379 Lr: 0.00184
[2025-05-11 13:56:43,193 INFO misc.py line 117 288342] Train: [2/50][1450/2344] Data 0.003 (0.003) Batch 0.502 (0.621) Remain 19:33:21 loss: 0.6849 Lr: 0.00184
[2025-05-11 13:56:43,646 INFO misc.py line 117 288342] Train: [2/50][1451/2344] Data 0.003 (0.003) Batch 0.452 (0.621) Remain 19:33:07 loss: 0.9647 Lr: 0.00184
[2025-05-11 13:56:44,333 INFO misc.py line 117 288342] Train: [2/50][1452/2344] Data 0.003 (0.003) Batch 0.688 (0.621) Remain 19:33:12 loss: 0.7700 Lr: 0.00184
[2025-05-11 13:56:45,046 INFO misc.py line 117 288342] Train: [2/50][1453/2344] Data 0.003 (0.003) Batch 0.713 (0.621) Remain 19:33:19 loss: 1.0594 Lr: 0.00184
[2025-05-11 13:56:45,648 INFO misc.py line 117 288342] Train: [2/50][1454/2344] Data 0.003 (0.003) Batch 0.602 (0.621) Remain 19:33:17 loss: 0.9076 Lr: 0.00184
[2025-05-11 13:56:46,169 INFO misc.py line 117 288342] Train: [2/50][1455/2344] Data 0.002 (0.003) Batch 0.521 (0.621) Remain 19:33:08 loss: 0.6479 Lr: 0.00184
[2025-05-11 13:56:46,853 INFO misc.py line 117 288342] Train: [2/50][1456/2344] Data 0.003 (0.003) Batch 0.685 (0.621) Remain 19:33:12 loss: 0.8595 Lr: 0.00184
[2025-05-11 13:56:47,372 INFO misc.py line 117 288342] Train: [2/50][1457/2344] Data 0.002 (0.003) Batch 0.518 (0.621) Remain 19:33:04 loss: 0.7359 Lr: 0.00185
[2025-05-11 13:56:48,046 INFO misc.py line 117 288342] Train: [2/50][1458/2344] Data 0.003 (0.003) Batch 0.675 (0.621) Remain 19:33:07 loss: 0.7281 Lr: 0.00185
[2025-05-11 13:56:48,657 INFO misc.py line 117 288342] Train: [2/50][1459/2344] Data 0.003 (0.003) Batch 0.611 (0.621) Remain 19:33:06 loss: 0.7989 Lr: 0.00185
[2025-05-11 13:56:49,227 INFO misc.py line 117 288342] Train: [2/50][1460/2344] Data 0.003 (0.003) Batch 0.569 (0.621) Remain 19:33:01 loss: 0.8131 Lr: 0.00185
[2025-05-11 13:56:49,801 INFO misc.py line 117 288342] Train: [2/50][1461/2344] Data 0.003 (0.003) Batch 0.574 (0.621) Remain 19:32:57 loss: 0.7143 Lr: 0.00185
[2025-05-11 13:56:50,471 INFO misc.py line 117 288342] Train: [2/50][1462/2344] Data 0.002 (0.003) Batch 0.670 (0.621) Remain 19:33:00 loss: 0.7154 Lr: 0.00185
[2025-05-11 13:56:51,255 INFO misc.py line 117 288342] Train: [2/50][1463/2344] Data 0.003 (0.003) Batch 0.783 (0.621) Remain 19:33:12 loss: 0.7388 Lr: 0.00185
[2025-05-11 13:56:51,807 INFO misc.py line 117 288342] Train: [2/50][1464/2344] Data 0.003 (0.003) Batch 0.552 (0.621) Remain 19:33:07 loss: 0.7656 Lr: 0.00185
[2025-05-11 13:56:52,358 INFO misc.py line 117 288342] Train: [2/50][1465/2344] Data 0.003 (0.003) Batch 0.551 (0.621) Remain 19:33:01 loss: 0.7088 Lr: 0.00185
[2025-05-11 13:56:52,861 INFO misc.py line 117 288342] Train: [2/50][1466/2344] Data 0.003 (0.003) Batch 0.502 (0.621) Remain 19:32:51 loss: 0.8363 Lr: 0.00185
[2025-05-11 13:56:53,502 INFO misc.py line 117 288342] Train: [2/50][1467/2344] Data 0.003 (0.003) Batch 0.641 (0.621) Remain 19:32:52 loss: 0.7521 Lr: 0.00185
[2025-05-11 13:56:54,098 INFO misc.py line 117 288342] Train: [2/50][1468/2344] Data 0.003 (0.003) Batch 0.596 (0.621) Remain 19:32:49 loss: 0.9184 Lr: 0.00185
[2025-05-11 13:56:54,711 INFO misc.py line 117 288342] Train: [2/50][1469/2344] Data 0.003 (0.003) Batch 0.613 (0.621) Remain 19:32:48 loss: 0.8390 Lr: 0.00185
[2025-05-11 13:56:55,269 INFO misc.py line 117 288342] Train: [2/50][1470/2344] Data 0.002 (0.003) Batch 0.557 (0.621) Remain 19:32:43 loss: 0.8439 Lr: 0.00185
[2025-05-11 13:56:55,926 INFO misc.py line 117 288342] Train: [2/50][1471/2344] Data 0.003 (0.003) Batch 0.657 (0.621) Remain 19:32:45 loss: 0.6379 Lr: 0.00185
[2025-05-11 13:56:56,553 INFO misc.py line 117 288342] Train: [2/50][1472/2344] Data 0.002 (0.003) Batch 0.627 (0.621) Remain 19:32:45 loss: 0.6208 Lr: 0.00185
[2025-05-11 13:56:57,292 INFO misc.py line 117 288342] Train: [2/50][1473/2344] Data 0.002 (0.003) Batch 0.739 (0.621) Remain 19:32:53 loss: 0.6473 Lr: 0.00185
[2025-05-11 13:56:57,903 INFO misc.py line 117 288342] Train: [2/50][1474/2344] Data 0.003 (0.003) Batch 0.612 (0.621) Remain 19:32:52 loss: 0.7420 Lr: 0.00185
[2025-05-11 13:56:58,489 INFO misc.py line 117 288342] Train: [2/50][1475/2344] Data 0.002 (0.003) Batch 0.585 (0.621) Remain 19:32:48 loss: 0.7564 Lr: 0.00185
[2025-05-11 13:56:59,309 INFO misc.py line 117 288342] Train: [2/50][1476/2344] Data 0.003 (0.003) Batch 0.820 (0.621) Remain 19:33:03 loss: 0.6222 Lr: 0.00185
[2025-05-11 13:56:59,821 INFO misc.py line 117 288342] Train: [2/50][1477/2344] Data 0.003 (0.003) Batch 0.512 (0.621) Remain 19:32:54 loss: 0.6189 Lr: 0.00185
[2025-05-11 13:57:00,424 INFO misc.py line 117 288342] Train: [2/50][1478/2344] Data 0.003 (0.003) Batch 0.603 (0.621) Remain 19:32:52 loss: 0.7489 Lr: 0.00185
[2025-05-11 13:57:01,107 INFO misc.py line 117 288342] Train: [2/50][1479/2344] Data 0.002 (0.003) Batch 0.683 (0.621) Remain 19:32:56 loss: 0.8444 Lr: 0.00185
[2025-05-11 13:57:01,723 INFO misc.py line 117 288342] Train: [2/50][1480/2344] Data 0.002 (0.003) Batch 0.616 (0.621) Remain 19:32:55 loss: 0.7726 Lr: 0.00185
[2025-05-11 13:57:02,457 INFO misc.py line 117 288342] Train: [2/50][1481/2344] Data 0.003 (0.003) Batch 0.734 (0.621) Remain 19:33:03 loss: 0.7180 Lr: 0.00185
[2025-05-11 13:57:03,051 INFO misc.py line 117 288342] Train: [2/50][1482/2344] Data 0.003 (0.003) Batch 0.594 (0.621) Remain 19:33:01 loss: 0.8621 Lr: 0.00185
[2025-05-11 13:57:03,639 INFO misc.py line 117 288342] Train: [2/50][1483/2344] Data 0.003 (0.003) Batch 0.588 (0.621) Remain 19:32:58 loss: 0.8364 Lr: 0.00185
[2025-05-11 13:57:04,256 INFO misc.py line 117 288342] Train: [2/50][1484/2344] Data 0.002 (0.003) Batch 0.616 (0.621) Remain 19:32:57 loss: 0.8302 Lr: 0.00185
[2025-05-11 13:57:04,881 INFO misc.py line 117 288342] Train: [2/50][1485/2344] Data 0.003 (0.003) Batch 0.625 (0.621) Remain 19:32:56 loss: 0.7607 Lr: 0.00185
[2025-05-11 13:57:05,396 INFO misc.py line 117 288342] Train: [2/50][1486/2344] Data 0.002 (0.003) Batch 0.515 (0.621) Remain 19:32:48 loss: 0.9524 Lr: 0.00185
[2025-05-11 13:57:05,917 INFO misc.py line 117 288342] Train: [2/50][1487/2344] Data 0.003 (0.003) Batch 0.521 (0.621) Remain 19:32:39 loss: 0.7936 Lr: 0.00186
[2025-05-11 13:57:06,626 INFO misc.py line 117 288342] Train: [2/50][1488/2344] Data 0.003 (0.003) Batch 0.709 (0.621) Remain 19:32:46 loss: 0.7523 Lr: 0.00186
[2025-05-11 13:57:07,335 INFO misc.py line 117 288342] Train: [2/50][1489/2344] Data 0.003 (0.003) Batch 0.710 (0.621) Remain 19:32:52 loss: 0.8654 Lr: 0.00186
[2025-05-11 13:57:07,901 INFO misc.py line 117 288342] Train: [2/50][1490/2344] Data 0.002 (0.003) Batch 0.565 (0.621) Remain 19:32:47 loss: 0.7860 Lr: 0.00186
[2025-05-11 13:57:08,603 INFO misc.py line 117 288342] Train: [2/50][1491/2344] Data 0.003 (0.003) Batch 0.702 (0.621) Remain 19:32:53 loss: 0.8547 Lr: 0.00186
[2025-05-11 13:57:09,293 INFO misc.py line 117 288342] Train: [2/50][1492/2344] Data 0.003 (0.003) Batch 0.690 (0.621) Remain 19:32:57 loss: 0.8096 Lr: 0.00186
[2025-05-11 13:57:09,929 INFO misc.py line 117 288342] Train: [2/50][1493/2344] Data 0.003 (0.003) Batch 0.636 (0.621) Remain 19:32:58 loss: 0.6374 Lr: 0.00186
[2025-05-11 13:57:10,542 INFO misc.py line 117 288342] Train: [2/50][1494/2344] Data 0.002 (0.003) Batch 0.613 (0.621) Remain 19:32:57 loss: 1.0312 Lr: 0.00186
[2025-05-11 13:57:11,097 INFO misc.py line 117 288342] Train: [2/50][1495/2344] Data 0.002 (0.003) Batch 0.555 (0.621) Remain 19:32:51 loss: 0.7922 Lr: 0.00186
[2025-05-11 13:57:11,675 INFO misc.py line 117 288342] Train: [2/50][1496/2344] Data 0.003 (0.003) Batch 0.578 (0.621) Remain 19:32:47 loss: 0.6015 Lr: 0.00186
[2025-05-11 13:57:12,301 INFO misc.py line 117 288342] Train: [2/50][1497/2344] Data 0.003 (0.003) Batch 0.625 (0.621) Remain 19:32:47 loss: 0.7481 Lr: 0.00186
[2025-05-11 13:57:12,983 INFO misc.py line 117 288342] Train: [2/50][1498/2344] Data 0.003 (0.003) Batch 0.683 (0.621) Remain 19:32:51 loss: 0.7742 Lr: 0.00186
[2025-05-11 13:57:13,745 INFO misc.py line 117 288342] Train: [2/50][1499/2344] Data 0.003 (0.003) Batch 0.762 (0.621) Remain 19:33:01 loss: 0.8378 Lr: 0.00186
[2025-05-11 13:57:14,357 INFO misc.py line 117 288342] Train: [2/50][1500/2344] Data 0.003 (0.003) Batch 0.611 (0.621) Remain 19:33:00 loss: 0.8953 Lr: 0.00186
[2025-05-11 13:57:14,986 INFO misc.py line 117 288342] Train: [2/50][1501/2344] Data 0.003 (0.003) Batch 0.629 (0.621) Remain 19:33:00 loss: 0.8170 Lr: 0.00186
[2025-05-11 13:57:15,405 INFO misc.py line 117 288342] Train: [2/50][1502/2344] Data 0.002 (0.003) Batch 0.419 (0.621) Remain 19:32:44 loss: 0.4331 Lr: 0.00186
[2025-05-11 13:57:16,095 INFO misc.py line 117 288342] Train: [2/50][1503/2344] Data 0.003 (0.003) Batch 0.690 (0.621) Remain 19:32:48 loss: 0.9746 Lr: 0.00186
[2025-05-11 13:57:16,805 INFO misc.py line 117 288342] Train: [2/50][1504/2344] Data 0.003 (0.003) Batch 0.710 (0.621) Remain 19:32:54 loss: 0.7511 Lr: 0.00186
[2025-05-11 13:57:17,457 INFO misc.py line 117 288342] Train: [2/50][1505/2344] Data 0.003 (0.003) Batch 0.652 (0.621) Remain 19:32:56 loss: 0.5466 Lr: 0.00186
[2025-05-11 13:57:18,180 INFO misc.py line 117 288342] Train: [2/50][1506/2344] Data 0.003 (0.003) Batch 0.723 (0.621) Remain 19:33:03 loss: 0.8244 Lr: 0.00186
[2025-05-11 13:57:18,675 INFO misc.py line 117 288342] Train: [2/50][1507/2344] Data 0.003 (0.003) Batch 0.495 (0.621) Remain 19:32:53 loss: 0.7481 Lr: 0.00186
[2025-05-11 13:57:19,272 INFO misc.py line 117 288342] Train: [2/50][1508/2344] Data 0.003 (0.003) Batch 0.597 (0.621) Remain 19:32:51 loss: 0.7232 Lr: 0.00186
[2025-05-11 13:57:19,845 INFO misc.py line 117 288342] Train: [2/50][1509/2344] Data 0.003 (0.003) Batch 0.573 (0.621) Remain 19:32:46 loss: 0.8016 Lr: 0.00186
[2025-05-11 13:57:20,474 INFO misc.py line 117 288342] Train: [2/50][1510/2344] Data 0.003 (0.003) Batch 0.630 (0.621) Remain 19:32:46 loss: 0.8725 Lr: 0.00186
[2025-05-11 13:57:21,060 INFO misc.py line 117 288342] Train: [2/50][1511/2344] Data 0.002 (0.003) Batch 0.586 (0.621) Remain 19:32:43 loss: 0.6546 Lr: 0.00186
[2025-05-11 13:57:21,544 INFO misc.py line 117 288342] Train: [2/50][1512/2344] Data 0.028 (0.003) Batch 0.484 (0.621) Remain 19:32:32 loss: 0.8668 Lr: 0.00186
[2025-05-11 13:57:22,139 INFO misc.py line 117 288342] Train: [2/50][1513/2344] Data 0.003 (0.003) Batch 0.595 (0.621) Remain 19:32:30 loss: 0.6695 Lr: 0.00186
[2025-05-11 13:57:22,878 INFO misc.py line 117 288342] Train: [2/50][1514/2344] Data 0.003 (0.003) Batch 0.739 (0.621) Remain 19:32:38 loss: 0.7810 Lr: 0.00186
[2025-05-11 13:57:23,558 INFO misc.py line 117 288342] Train: [2/50][1515/2344] Data 0.002 (0.003) Batch 0.680 (0.621) Remain 19:32:42 loss: 0.6703 Lr: 0.00186
[2025-05-11 13:57:24,042 INFO misc.py line 117 288342] Train: [2/50][1516/2344] Data 0.003 (0.003) Batch 0.484 (0.621) Remain 19:32:31 loss: 0.8941 Lr: 0.00186
[2025-05-11 13:57:24,627 INFO misc.py line 117 288342] Train: [2/50][1517/2344] Data 0.003 (0.003) Batch 0.585 (0.621) Remain 19:32:28 loss: 0.6089 Lr: 0.00186
[2025-05-11 13:57:25,343 INFO misc.py line 117 288342] Train: [2/50][1518/2344] Data 0.003 (0.003) Batch 0.716 (0.621) Remain 19:32:34 loss: 0.6627 Lr: 0.00187
[2025-05-11 13:57:26,065 INFO misc.py line 117 288342] Train: [2/50][1519/2344] Data 0.002 (0.003) Batch 0.722 (0.621) Remain 19:32:41 loss: 0.8294 Lr: 0.00187
[2025-05-11 13:57:26,670 INFO misc.py line 117 288342] Train: [2/50][1520/2344] Data 0.002 (0.003) Batch 0.605 (0.621) Remain 19:32:39 loss: 0.8174 Lr: 0.00187
[2025-05-11 13:57:27,275 INFO misc.py line 117 288342] Train: [2/50][1521/2344] Data 0.002 (0.003) Batch 0.605 (0.621) Remain 19:32:38 loss: 0.9320 Lr: 0.00187
[2025-05-11 13:57:27,710 INFO misc.py line 117 288342] Train: [2/50][1522/2344] Data 0.002 (0.003) Batch 0.435 (0.621) Remain 19:32:23 loss: 0.6115 Lr: 0.00187
[2025-05-11 13:57:28,240 INFO misc.py line 117 288342] Train: [2/50][1523/2344] Data 0.003 (0.003) Batch 0.530 (0.621) Remain 19:32:16 loss: 0.6712 Lr: 0.00187
[2025-05-11 13:57:28,916 INFO misc.py line 117 288342] Train: [2/50][1524/2344] Data 0.003 (0.003) Batch 0.676 (0.621) Remain 19:32:19 loss: 0.8420 Lr: 0.00187
[2025-05-11 13:57:29,653 INFO misc.py line 117 288342] Train: [2/50][1525/2344] Data 0.003 (0.003) Batch 0.737 (0.621) Remain 19:32:27 loss: 0.6705 Lr: 0.00187
[2025-05-11 13:57:30,441 INFO misc.py line 117 288342] Train: [2/50][1526/2344] Data 0.003 (0.003) Batch 0.788 (0.621) Remain 19:32:39 loss: 0.5434 Lr: 0.00187
[2025-05-11 13:57:30,961 INFO misc.py line 117 288342] Train: [2/50][1527/2344] Data 0.002 (0.003) Batch 0.520 (0.621) Remain 19:32:31 loss: 0.8059 Lr: 0.00187
[2025-05-11 13:57:31,488 INFO misc.py line 117 288342] Train: [2/50][1528/2344] Data 0.003 (0.003) Batch 0.527 (0.621) Remain 19:32:23 loss: 1.0186 Lr: 0.00187
[2025-05-11 13:57:32,176 INFO misc.py line 117 288342] Train: [2/50][1529/2344] Data 0.003 (0.003) Batch 0.688 (0.621) Remain 19:32:28 loss: 0.6072 Lr: 0.00187
[2025-05-11 13:57:32,787 INFO misc.py line 117 288342] Train: [2/50][1530/2344] Data 0.003 (0.003) Batch 0.611 (0.621) Remain 19:32:26 loss: 0.7073 Lr: 0.00187
[2025-05-11 13:57:33,508 INFO misc.py line 117 288342] Train: [2/50][1531/2344] Data 0.003 (0.003) Batch 0.721 (0.621) Remain 19:32:33 loss: 0.7569 Lr: 0.00187
[2025-05-11 13:57:34,261 INFO misc.py line 117 288342] Train: [2/50][1532/2344] Data 0.003 (0.003) Batch 0.753 (0.621) Remain 19:32:42 loss: 1.0138 Lr: 0.00187
[2025-05-11 13:57:34,777 INFO misc.py line 117 288342] Train: [2/50][1533/2344] Data 0.003 (0.003) Batch 0.516 (0.621) Remain 19:32:34 loss: 0.7281 Lr: 0.00187
[2025-05-11 13:57:35,385 INFO misc.py line 117 288342] Train: [2/50][1534/2344] Data 0.003 (0.003) Batch 0.609 (0.621) Remain 19:32:32 loss: 0.6637 Lr: 0.00187
[2025-05-11 13:57:35,977 INFO misc.py line 117 288342] Train: [2/50][1535/2344] Data 0.003 (0.003) Batch 0.592 (0.621) Remain 19:32:30 loss: 0.8211 Lr: 0.00187
[2025-05-11 13:57:36,589 INFO misc.py line 117 288342] Train: [2/50][1536/2344] Data 0.003 (0.003) Batch 0.611 (0.621) Remain 19:32:28 loss: 0.6011 Lr: 0.00187
[2025-05-11 13:57:37,146 INFO misc.py line 117 288342] Train: [2/50][1537/2344] Data 0.003 (0.003) Batch 0.558 (0.621) Remain 19:32:23 loss: 0.7740 Lr: 0.00187
[2025-05-11 13:57:37,798 INFO misc.py line 117 288342] Train: [2/50][1538/2344] Data 0.003 (0.003) Batch 0.651 (0.621) Remain 19:32:25 loss: 0.8134 Lr: 0.00187
[2025-05-11 13:57:38,341 INFO misc.py line 117 288342] Train: [2/50][1539/2344] Data 0.003 (0.003) Batch 0.544 (0.621) Remain 19:32:18 loss: 0.7098 Lr: 0.00187
[2025-05-11 13:57:39,139 INFO misc.py line 117 288342] Train: [2/50][1540/2344] Data 0.002 (0.003) Batch 0.798 (0.621) Remain 19:32:31 loss: 0.8334 Lr: 0.00187
[2025-05-11 13:57:39,729 INFO misc.py line 117 288342] Train: [2/50][1541/2344] Data 0.003 (0.003) Batch 0.590 (0.621) Remain 19:32:28 loss: 0.8621 Lr: 0.00187
[2025-05-11 13:57:40,331 INFO misc.py line 117 288342] Train: [2/50][1542/2344] Data 0.003 (0.003) Batch 0.602 (0.621) Remain 19:32:26 loss: 0.6398 Lr: 0.00187
[2025-05-11 13:57:40,980 INFO misc.py line 117 288342] Train: [2/50][1543/2344] Data 0.003 (0.003) Batch 0.649 (0.621) Remain 19:32:27 loss: 0.8713 Lr: 0.00187
[2025-05-11 13:57:41,527 INFO misc.py line 117 288342] Train: [2/50][1544/2344] Data 0.002 (0.003) Batch 0.547 (0.621) Remain 19:32:21 loss: 0.8239 Lr: 0.00187
[2025-05-11 13:57:42,200 INFO misc.py line 117 288342] Train: [2/50][1545/2344] Data 0.002 (0.003) Batch 0.673 (0.621) Remain 19:32:25 loss: 0.7634 Lr: 0.00187
[2025-05-11 13:57:42,786 INFO misc.py line 117 288342] Train: [2/50][1546/2344] Data 0.002 (0.003) Batch 0.586 (0.621) Remain 19:32:21 loss: 0.6262 Lr: 0.00187
[2025-05-11 13:57:43,315 INFO misc.py line 117 288342] Train: [2/50][1547/2344] Data 0.003 (0.003) Batch 0.529 (0.621) Remain 19:32:14 loss: 0.7682 Lr: 0.00187
[2025-05-11 13:57:44,022 INFO misc.py line 117 288342] Train: [2/50][1548/2344] Data 0.003 (0.003) Batch 0.707 (0.621) Remain 19:32:20 loss: 0.7051 Lr: 0.00187
[2025-05-11 13:57:44,567 INFO misc.py line 117 288342] Train: [2/50][1549/2344] Data 0.003 (0.003) Batch 0.545 (0.621) Remain 19:32:14 loss: 0.5577 Lr: 0.00187
[2025-05-11 13:57:45,061 INFO misc.py line 117 288342] Train: [2/50][1550/2344] Data 0.002 (0.003) Batch 0.494 (0.621) Remain 19:32:04 loss: 0.5529 Lr: 0.00188
[2025-05-11 13:57:45,557 INFO misc.py line 117 288342] Train: [2/50][1551/2344] Data 0.003 (0.003) Batch 0.496 (0.621) Remain 19:31:54 loss: 0.7990 Lr: 0.00188
[2025-05-11 13:57:46,139 INFO misc.py line 117 288342] Train: [2/50][1552/2344] Data 0.004 (0.003) Batch 0.582 (0.621) Remain 19:31:50 loss: 0.8242 Lr: 0.00188
[2025-05-11 13:57:46,664 INFO misc.py line 117 288342] Train: [2/50][1553/2344] Data 0.003 (0.003) Batch 0.525 (0.620) Remain 19:31:43 loss: 0.9243 Lr: 0.00188
[2025-05-11 13:57:47,373 INFO misc.py line 117 288342] Train: [2/50][1554/2344] Data 0.003 (0.003) Batch 0.709 (0.621) Remain 19:31:49 loss: 0.7126 Lr: 0.00188
[2025-05-11 13:57:48,025 INFO misc.py line 117 288342] Train: [2/50][1555/2344] Data 0.003 (0.003) Batch 0.652 (0.621) Remain 19:31:50 loss: 0.8248 Lr: 0.00188
[2025-05-11 13:57:48,589 INFO misc.py line 117 288342] Train: [2/50][1556/2344] Data 0.002 (0.003) Batch 0.564 (0.621) Remain 19:31:46 loss: 0.7612 Lr: 0.00188
[2025-05-11 13:57:49,168 INFO misc.py line 117 288342] Train: [2/50][1557/2344] Data 0.002 (0.003) Batch 0.579 (0.621) Remain 19:31:42 loss: 0.6777 Lr: 0.00188
[2025-05-11 13:57:49,750 INFO misc.py line 117 288342] Train: [2/50][1558/2344] Data 0.002 (0.003) Batch 0.582 (0.620) Remain 19:31:39 loss: 0.6649 Lr: 0.00188
[2025-05-11 13:57:50,330 INFO misc.py line 117 288342] Train: [2/50][1559/2344] Data 0.002 (0.003) Batch 0.580 (0.620) Remain 19:31:35 loss: 0.7370 Lr: 0.00188
[2025-05-11 13:57:50,942 INFO misc.py line 117 288342] Train: [2/50][1560/2344] Data 0.002 (0.003) Batch 0.613 (0.620) Remain 19:31:34 loss: 1.1347 Lr: 0.00188
[2025-05-11 13:57:51,623 INFO misc.py line 117 288342] Train: [2/50][1561/2344] Data 0.002 (0.003) Batch 0.680 (0.620) Remain 19:31:38 loss: 1.2837 Lr: 0.00188
[2025-05-11 13:57:52,306 INFO misc.py line 117 288342] Train: [2/50][1562/2344] Data 0.002 (0.003) Batch 0.683 (0.621) Remain 19:31:41 loss: 0.7058 Lr: 0.00188
[2025-05-11 13:57:52,936 INFO misc.py line 117 288342] Train: [2/50][1563/2344] Data 0.002 (0.003) Batch 0.631 (0.621) Remain 19:31:42 loss: 0.8471 Lr: 0.00188
[2025-05-11 13:57:53,432 INFO misc.py line 117 288342] Train: [2/50][1564/2344] Data 0.002 (0.003) Batch 0.496 (0.620) Remain 19:31:32 loss: 0.8531 Lr: 0.00188
[2025-05-11 13:57:53,959 INFO misc.py line 117 288342] Train: [2/50][1565/2344] Data 0.003 (0.003) Batch 0.526 (0.620) Remain 19:31:24 loss: 0.8555 Lr: 0.00188
[2025-05-11 13:57:54,517 INFO misc.py line 117 288342] Train: [2/50][1566/2344] Data 0.003 (0.003) Batch 0.558 (0.620) Remain 19:31:19 loss: 0.8161 Lr: 0.00188
[2025-05-11 13:57:55,361 INFO misc.py line 117 288342] Train: [2/50][1567/2344] Data 0.003 (0.003) Batch 0.845 (0.620) Remain 19:31:35 loss: 0.8332 Lr: 0.00188
[2025-05-11 13:57:55,883 INFO misc.py line 117 288342] Train: [2/50][1568/2344] Data 0.002 (0.003) Batch 0.522 (0.620) Remain 19:31:27 loss: 0.8042 Lr: 0.00188
[2025-05-11 13:57:56,519 INFO misc.py line 117 288342] Train: [2/50][1569/2344] Data 0.003 (0.003) Batch 0.636 (0.620) Remain 19:31:28 loss: 0.7319 Lr: 0.00188
[2025-05-11 13:57:57,045 INFO misc.py line 117 288342] Train: [2/50][1570/2344] Data 0.003 (0.003) Batch 0.526 (0.620) Remain 19:31:20 loss: 0.8840 Lr: 0.00188
[2025-05-11 13:57:57,674 INFO misc.py line 117 288342] Train: [2/50][1571/2344] Data 0.003 (0.003) Batch 0.628 (0.620) Remain 19:31:20 loss: 0.8610 Lr: 0.00188
[2025-05-11 13:57:58,404 INFO misc.py line 117 288342] Train: [2/50][1572/2344] Data 0.003 (0.003) Batch 0.731 (0.620) Remain 19:31:28 loss: 0.7361 Lr: 0.00188
[2025-05-11 13:57:59,030 INFO misc.py line 117 288342] Train: [2/50][1573/2344] Data 0.003 (0.003) Batch 0.625 (0.620) Remain 19:31:27 loss: 0.6602 Lr: 0.00188
[2025-05-11 13:57:59,737 INFO misc.py line 117 288342] Train: [2/50][1574/2344] Data 0.003 (0.003) Batch 0.707 (0.621) Remain 19:31:33 loss: 0.8169 Lr: 0.00188
[2025-05-11 13:58:00,375 INFO misc.py line 117 288342] Train: [2/50][1575/2344] Data 0.006 (0.003) Batch 0.638 (0.621) Remain 19:31:34 loss: 0.6692 Lr: 0.00188
[2025-05-11 13:58:01,029 INFO misc.py line 117 288342] Train: [2/50][1576/2344] Data 0.003 (0.003) Batch 0.654 (0.621) Remain 19:31:35 loss: 0.9957 Lr: 0.00188
[2025-05-11 13:58:01,723 INFO misc.py line 117 288342] Train: [2/50][1577/2344] Data 0.003 (0.003) Batch 0.694 (0.621) Remain 19:31:40 loss: 0.9797 Lr: 0.00188
[2025-05-11 13:58:02,302 INFO misc.py line 117 288342] Train: [2/50][1578/2344] Data 0.003 (0.003) Batch 0.579 (0.621) Remain 19:31:36 loss: 0.6655 Lr: 0.00188
[2025-05-11 13:58:02,896 INFO misc.py line 117 288342] Train: [2/50][1579/2344] Data 0.003 (0.003) Batch 0.594 (0.621) Remain 19:31:34 loss: 0.7900 Lr: 0.00188
[2025-05-11 13:58:03,444 INFO misc.py line 117 288342] Train: [2/50][1580/2344] Data 0.003 (0.003) Batch 0.548 (0.621) Remain 19:31:28 loss: 0.6005 Lr: 0.00188
[2025-05-11 13:58:04,082 INFO misc.py line 117 288342] Train: [2/50][1581/2344] Data 0.018 (0.003) Batch 0.638 (0.621) Remain 19:31:29 loss: 0.8814 Lr: 0.00188
[2025-05-11 13:58:04,621 INFO misc.py line 117 288342] Train: [2/50][1582/2344] Data 0.003 (0.003) Batch 0.539 (0.620) Remain 19:31:22 loss: 0.7304 Lr: 0.00188
[2025-05-11 13:58:05,404 INFO misc.py line 117 288342] Train: [2/50][1583/2344] Data 0.002 (0.003) Batch 0.783 (0.621) Remain 19:31:33 loss: 0.6226 Lr: 0.00189
[2025-05-11 13:58:05,884 INFO misc.py line 117 288342] Train: [2/50][1584/2344] Data 0.003 (0.003) Batch 0.480 (0.620) Remain 19:31:23 loss: 0.8381 Lr: 0.00189
[2025-05-11 13:58:06,403 INFO misc.py line 117 288342] Train: [2/50][1585/2344] Data 0.002 (0.003) Batch 0.519 (0.620) Remain 19:31:15 loss: 0.8217 Lr: 0.00189
[2025-05-11 13:58:06,930 INFO misc.py line 117 288342] Train: [2/50][1586/2344] Data 0.003 (0.003) Batch 0.527 (0.620) Remain 19:31:07 loss: 1.0094 Lr: 0.00189
[2025-05-11 13:58:07,416 INFO misc.py line 117 288342] Train: [2/50][1587/2344] Data 0.003 (0.003) Batch 0.486 (0.620) Remain 19:30:57 loss: 0.5601 Lr: 0.00189
[2025-05-11 13:58:08,006 INFO misc.py line 117 288342] Train: [2/50][1588/2344] Data 0.003 (0.003) Batch 0.590 (0.620) Remain 19:30:54 loss: 0.6532 Lr: 0.00189
[2025-05-11 13:58:08,594 INFO misc.py line 117 288342] Train: [2/50][1589/2344] Data 0.003 (0.003) Batch 0.588 (0.620) Remain 19:30:51 loss: 0.6069 Lr: 0.00189
[2025-05-11 13:58:09,179 INFO misc.py line 117 288342] Train: [2/50][1590/2344] Data 0.002 (0.003) Batch 0.584 (0.620) Remain 19:30:48 loss: 0.7214 Lr: 0.00189
[2025-05-11 13:58:09,892 INFO misc.py line 117 288342] Train: [2/50][1591/2344] Data 0.002 (0.003) Batch 0.713 (0.620) Remain 19:30:54 loss: 0.7499 Lr: 0.00189
[2025-05-11 13:58:10,615 INFO misc.py line 117 288342] Train: [2/50][1592/2344] Data 0.003 (0.003) Batch 0.723 (0.620) Remain 19:31:01 loss: 1.2012 Lr: 0.00189
[2025-05-11 13:58:11,347 INFO misc.py line 117 288342] Train: [2/50][1593/2344] Data 0.003 (0.003) Batch 0.732 (0.620) Remain 19:31:08 loss: 0.7083 Lr: 0.00189
[2025-05-11 13:58:11,812 INFO misc.py line 117 288342] Train: [2/50][1594/2344] Data 0.003 (0.003) Batch 0.465 (0.620) Remain 19:30:57 loss: 0.8524 Lr: 0.00189
[2025-05-11 13:58:12,427 INFO misc.py line 117 288342] Train: [2/50][1595/2344] Data 0.003 (0.003) Batch 0.615 (0.620) Remain 19:30:56 loss: 0.5921 Lr: 0.00189
[2025-05-11 13:58:13,044 INFO misc.py line 117 288342] Train: [2/50][1596/2344] Data 0.005 (0.003) Batch 0.618 (0.620) Remain 19:30:55 loss: 0.7812 Lr: 0.00189
[2025-05-11 13:58:13,703 INFO misc.py line 117 288342] Train: [2/50][1597/2344] Data 0.003 (0.003) Batch 0.659 (0.620) Remain 19:30:57 loss: 0.7889 Lr: 0.00189
[2025-05-11 13:58:14,414 INFO misc.py line 117 288342] Train: [2/50][1598/2344] Data 0.003 (0.003) Batch 0.710 (0.620) Remain 19:31:03 loss: 0.6493 Lr: 0.00189
[2025-05-11 13:58:14,910 INFO misc.py line 117 288342] Train: [2/50][1599/2344] Data 0.003 (0.003) Batch 0.497 (0.620) Remain 19:30:53 loss: 0.6136 Lr: 0.00189
[2025-05-11 13:58:15,417 INFO misc.py line 117 288342] Train: [2/50][1600/2344] Data 0.002 (0.003) Batch 0.507 (0.620) Remain 19:30:45 loss: 0.8401 Lr: 0.00189
[2025-05-11 13:58:15,890 INFO misc.py line 117 288342] Train: [2/50][1601/2344] Data 0.002 (0.003) Batch 0.473 (0.620) Remain 19:30:34 loss: 0.6389 Lr: 0.00189
[2025-05-11 13:58:16,454 INFO misc.py line 117 288342] Train: [2/50][1602/2344] Data 0.003 (0.003) Batch 0.565 (0.620) Remain 19:30:29 loss: 0.5704 Lr: 0.00189
[2025-05-11 13:58:17,139 INFO misc.py line 117 288342] Train: [2/50][1603/2344] Data 0.003 (0.003) Batch 0.685 (0.620) Remain 19:30:33 loss: 0.7449 Lr: 0.00189
[2025-05-11 13:58:17,856 INFO misc.py line 117 288342] Train: [2/50][1604/2344] Data 0.004 (0.003) Batch 0.717 (0.620) Remain 19:30:39 loss: 1.0309 Lr: 0.00189
[2025-05-11 13:58:18,540 INFO misc.py line 117 288342] Train: [2/50][1605/2344] Data 0.003 (0.003) Batch 0.685 (0.620) Remain 19:30:43 loss: 0.8671 Lr: 0.00189
[2025-05-11 13:58:19,208 INFO misc.py line 117 288342] Train: [2/50][1606/2344] Data 0.002 (0.003) Batch 0.667 (0.620) Remain 19:30:46 loss: 0.5361 Lr: 0.00189
[2025-05-11 13:58:19,799 INFO misc.py line 117 288342] Train: [2/50][1607/2344] Data 0.003 (0.003) Batch 0.591 (0.620) Remain 19:30:43 loss: 0.5959 Lr: 0.00189
[2025-05-11 13:58:20,591 INFO misc.py line 117 288342] Train: [2/50][1608/2344] Data 0.003 (0.003) Batch 0.793 (0.620) Remain 19:30:55 loss: 0.7448 Lr: 0.00189
[2025-05-11 13:58:21,108 INFO misc.py line 117 288342] Train: [2/50][1609/2344] Data 0.003 (0.003) Batch 0.516 (0.620) Remain 19:30:47 loss: 0.6765 Lr: 0.00189
[2025-05-11 13:58:21,731 INFO misc.py line 117 288342] Train: [2/50][1610/2344] Data 0.003 (0.003) Batch 0.623 (0.620) Remain 19:30:46 loss: 0.6921 Lr: 0.00189
[2025-05-11 13:58:22,238 INFO misc.py line 117 288342] Train: [2/50][1611/2344] Data 0.003 (0.003) Batch 0.508 (0.620) Remain 19:30:38 loss: 0.7082 Lr: 0.00189
[2025-05-11 13:58:22,802 INFO misc.py line 117 288342] Train: [2/50][1612/2344] Data 0.003 (0.003) Batch 0.563 (0.620) Remain 19:30:33 loss: 0.5411 Lr: 0.00189
[2025-05-11 13:58:23,467 INFO misc.py line 117 288342] Train: [2/50][1613/2344] Data 0.003 (0.003) Batch 0.666 (0.620) Remain 19:30:36 loss: 0.8588 Lr: 0.00189
[2025-05-11 13:58:23,965 INFO misc.py line 117 288342] Train: [2/50][1614/2344] Data 0.003 (0.003) Batch 0.497 (0.620) Remain 19:30:26 loss: 0.7777 Lr: 0.00189
[2025-05-11 13:58:24,645 INFO misc.py line 117 288342] Train: [2/50][1615/2344] Data 0.003 (0.003) Batch 0.681 (0.620) Remain 19:30:30 loss: 0.8179 Lr: 0.00189
[2025-05-11 13:58:25,220 INFO misc.py line 117 288342] Train: [2/50][1616/2344] Data 0.003 (0.003) Batch 0.575 (0.620) Remain 19:30:26 loss: 0.6859 Lr: 0.00189
[2025-05-11 13:58:25,834 INFO misc.py line 117 288342] Train: [2/50][1617/2344] Data 0.003 (0.003) Batch 0.614 (0.620) Remain 19:30:25 loss: 0.7157 Lr: 0.00189
[2025-05-11 13:58:26,644 INFO misc.py line 117 288342] Train: [2/50][1618/2344] Data 0.003 (0.003) Batch 0.810 (0.620) Remain 19:30:38 loss: 0.7564 Lr: 0.00190
[2025-05-11 13:58:27,231 INFO misc.py line 117 288342] Train: [2/50][1619/2344] Data 0.003 (0.003) Batch 0.587 (0.620) Remain 19:30:35 loss: 0.6722 Lr: 0.00190
[2025-05-11 13:58:27,758 INFO misc.py line 117 288342] Train: [2/50][1620/2344] Data 0.003 (0.003) Batch 0.527 (0.620) Remain 19:30:28 loss: 0.7957 Lr: 0.00190
[2025-05-11 13:58:28,367 INFO misc.py line 117 288342] Train: [2/50][1621/2344] Data 0.003 (0.003) Batch 0.609 (0.620) Remain 19:30:26 loss: 1.0007 Lr: 0.00190
[2025-05-11 13:58:28,879 INFO misc.py line 117 288342] Train: [2/50][1622/2344] Data 0.003 (0.003) Batch 0.511 (0.620) Remain 19:30:18 loss: 0.5521 Lr: 0.00190
[2025-05-11 13:58:29,552 INFO misc.py line 117 288342] Train: [2/50][1623/2344] Data 0.003 (0.003) Batch 0.673 (0.620) Remain 19:30:21 loss: 0.6114 Lr: 0.00190
[2025-05-11 13:58:30,191 INFO misc.py line 117 288342] Train: [2/50][1624/2344] Data 0.002 (0.003) Batch 0.639 (0.620) Remain 19:30:22 loss: 0.6767 Lr: 0.00190
[2025-05-11 13:58:30,737 INFO misc.py line 117 288342] Train: [2/50][1625/2344] Data 0.003 (0.003) Batch 0.546 (0.620) Remain 19:30:16 loss: 0.6361 Lr: 0.00190
[2025-05-11 13:58:31,355 INFO misc.py line 117 288342] Train: [2/50][1626/2344] Data 0.002 (0.003) Batch 0.618 (0.620) Remain 19:30:15 loss: 0.6473 Lr: 0.00190
[2025-05-11 13:58:31,874 INFO misc.py line 117 288342] Train: [2/50][1627/2344] Data 0.002 (0.003) Batch 0.519 (0.620) Remain 19:30:08 loss: 0.8053 Lr: 0.00190
[2025-05-11 13:58:32,508 INFO misc.py line 117 288342] Train: [2/50][1628/2344] Data 0.003 (0.003) Batch 0.634 (0.620) Remain 19:30:08 loss: 0.9376 Lr: 0.00190
[2025-05-11 13:58:33,045 INFO misc.py line 117 288342] Train: [2/50][1629/2344] Data 0.003 (0.003) Batch 0.537 (0.620) Remain 19:30:02 loss: 0.7356 Lr: 0.00190
[2025-05-11 13:58:33,620 INFO misc.py line 117 288342] Train: [2/50][1630/2344] Data 0.003 (0.003) Batch 0.575 (0.620) Remain 19:29:58 loss: 0.7103 Lr: 0.00190
[2025-05-11 13:58:34,241 INFO misc.py line 117 288342] Train: [2/50][1631/2344] Data 0.003 (0.003) Batch 0.622 (0.620) Remain 19:29:57 loss: 0.8333 Lr: 0.00190
[2025-05-11 13:58:34,787 INFO misc.py line 117 288342] Train: [2/50][1632/2344] Data 0.003 (0.003) Batch 0.546 (0.620) Remain 19:29:52 loss: 0.8715 Lr: 0.00190
[2025-05-11 13:58:35,416 INFO misc.py line 117 288342] Train: [2/50][1633/2344] Data 0.003 (0.003) Batch 0.628 (0.620) Remain 19:29:52 loss: 0.8818 Lr: 0.00190
[2025-05-11 13:58:36,028 INFO misc.py line 117 288342] Train: [2/50][1634/2344] Data 0.003 (0.003) Batch 0.613 (0.620) Remain 19:29:50 loss: 0.7304 Lr: 0.00190
[2025-05-11 13:58:36,649 INFO misc.py line 117 288342] Train: [2/50][1635/2344] Data 0.003 (0.003) Batch 0.621 (0.620) Remain 19:29:50 loss: 0.9115 Lr: 0.00190
[2025-05-11 13:58:37,380 INFO misc.py line 117 288342] Train: [2/50][1636/2344] Data 0.003 (0.003) Batch 0.730 (0.620) Remain 19:29:57 loss: 0.9267 Lr: 0.00190
[2025-05-11 13:58:37,847 INFO misc.py line 117 288342] Train: [2/50][1637/2344] Data 0.003 (0.003) Batch 0.467 (0.620) Remain 19:29:46 loss: 0.8469 Lr: 0.00190
[2025-05-11 13:58:38,529 INFO misc.py line 117 288342] Train: [2/50][1638/2344] Data 0.003 (0.003) Batch 0.682 (0.620) Remain 19:29:49 loss: 0.7622 Lr: 0.00190
[2025-05-11 13:58:39,238 INFO misc.py line 117 288342] Train: [2/50][1639/2344] Data 0.003 (0.003) Batch 0.709 (0.620) Remain 19:29:55 loss: 0.7107 Lr: 0.00190
[2025-05-11 13:58:39,875 INFO misc.py line 117 288342] Train: [2/50][1640/2344] Data 0.002 (0.003) Batch 0.638 (0.620) Remain 19:29:56 loss: 0.6583 Lr: 0.00190
[2025-05-11 13:58:40,466 INFO misc.py line 117 288342] Train: [2/50][1641/2344] Data 0.002 (0.003) Batch 0.591 (0.620) Remain 19:29:53 loss: 1.0292 Lr: 0.00190
[2025-05-11 13:58:41,041 INFO misc.py line 117 288342] Train: [2/50][1642/2344] Data 0.002 (0.003) Batch 0.574 (0.620) Remain 19:29:49 loss: 0.5817 Lr: 0.00190
[2025-05-11 13:58:41,575 INFO misc.py line 117 288342] Train: [2/50][1643/2344] Data 0.003 (0.003) Batch 0.534 (0.620) Remain 19:29:43 loss: 0.6408 Lr: 0.00190
[2025-05-11 13:58:42,170 INFO misc.py line 117 288342] Train: [2/50][1644/2344] Data 0.002 (0.003) Batch 0.595 (0.620) Remain 19:29:40 loss: 0.6881 Lr: 0.00190
[2025-05-11 13:58:42,760 INFO misc.py line 117 288342] Train: [2/50][1645/2344] Data 0.002 (0.003) Batch 0.590 (0.620) Remain 19:29:38 loss: 0.6044 Lr: 0.00190
[2025-05-11 13:58:43,248 INFO misc.py line 117 288342] Train: [2/50][1646/2344] Data 0.003 (0.003) Batch 0.488 (0.620) Remain 19:29:28 loss: 0.6917 Lr: 0.00190
[2025-05-11 13:58:43,938 INFO misc.py line 117 288342] Train: [2/50][1647/2344] Data 0.003 (0.003) Batch 0.690 (0.620) Remain 19:29:32 loss: 0.7219 Lr: 0.00190
[2025-05-11 13:58:44,549 INFO misc.py line 117 288342] Train: [2/50][1648/2344] Data 0.004 (0.003) Batch 0.611 (0.620) Remain 19:29:31 loss: 0.7713 Lr: 0.00190
[2025-05-11 13:58:45,163 INFO misc.py line 117 288342] Train: [2/50][1649/2344] Data 0.003 (0.003) Batch 0.614 (0.620) Remain 19:29:30 loss: 0.6470 Lr: 0.00190
[2025-05-11 13:58:45,753 INFO misc.py line 117 288342] Train: [2/50][1650/2344] Data 0.003 (0.003) Batch 0.590 (0.620) Remain 19:29:27 loss: 0.7132 Lr: 0.00190
[2025-05-11 13:58:46,326 INFO misc.py line 117 288342] Train: [2/50][1651/2344] Data 0.003 (0.003) Batch 0.573 (0.620) Remain 19:29:23 loss: 0.9284 Lr: 0.00190
[2025-05-11 13:58:46,942 INFO misc.py line 117 288342] Train: [2/50][1652/2344] Data 0.003 (0.003) Batch 0.615 (0.620) Remain 19:29:22 loss: 0.8182 Lr: 0.00190
[2025-05-11 13:58:47,590 INFO misc.py line 117 288342] Train: [2/50][1653/2344] Data 0.003 (0.003) Batch 0.648 (0.620) Remain 19:29:24 loss: 0.7304 Lr: 0.00190
[2025-05-11 13:58:48,206 INFO misc.py line 117 288342] Train: [2/50][1654/2344] Data 0.003 (0.003) Batch 0.616 (0.620) Remain 19:29:23 loss: 0.8714 Lr: 0.00191
[2025-05-11 13:58:48,844 INFO misc.py line 117 288342] Train: [2/50][1655/2344] Data 0.003 (0.003) Batch 0.639 (0.620) Remain 19:29:24 loss: 1.0837 Lr: 0.00191
[2025-05-11 13:58:49,470 INFO misc.py line 117 288342] Train: [2/50][1656/2344] Data 0.002 (0.003) Batch 0.626 (0.620) Remain 19:29:23 loss: 0.7158 Lr: 0.00191
[2025-05-11 13:58:50,076 INFO misc.py line 117 288342] Train: [2/50][1657/2344] Data 0.002 (0.003) Batch 0.606 (0.620) Remain 19:29:22 loss: 0.9523 Lr: 0.00191
[2025-05-11 13:58:50,597 INFO misc.py line 117 288342] Train: [2/50][1658/2344] Data 0.005 (0.003) Batch 0.520 (0.620) Remain 19:29:14 loss: 0.9423 Lr: 0.00191
[2025-05-11 13:58:51,093 INFO misc.py line 117 288342] Train: [2/50][1659/2344] Data 0.003 (0.003) Batch 0.496 (0.620) Remain 19:29:05 loss: 0.9222 Lr: 0.00191
[2025-05-11 13:58:51,705 INFO misc.py line 117 288342] Train: [2/50][1660/2344] Data 0.003 (0.003) Batch 0.612 (0.620) Remain 19:29:04 loss: 0.9091 Lr: 0.00191
[2025-05-11 13:58:52,325 INFO misc.py line 117 288342] Train: [2/50][1661/2344] Data 0.003 (0.003) Batch 0.620 (0.620) Remain 19:29:04 loss: 0.6818 Lr: 0.00191
[2025-05-11 13:58:52,936 INFO misc.py line 117 288342] Train: [2/50][1662/2344] Data 0.003 (0.003) Batch 0.611 (0.620) Remain 19:29:02 loss: 0.7185 Lr: 0.00191
[2025-05-11 13:58:53,646 INFO misc.py line 117 288342] Train: [2/50][1663/2344] Data 0.003 (0.003) Batch 0.710 (0.620) Remain 19:29:08 loss: 0.8061 Lr: 0.00191
[2025-05-11 13:58:54,371 INFO misc.py line 117 288342] Train: [2/50][1664/2344] Data 0.003 (0.003) Batch 0.725 (0.620) Remain 19:29:14 loss: 0.9000 Lr: 0.00191
[2025-05-11 13:58:54,906 INFO misc.py line 117 288342] Train: [2/50][1665/2344] Data 0.003 (0.003) Batch 0.535 (0.620) Remain 19:29:08 loss: 0.8798 Lr: 0.00191
[2025-05-11 13:58:55,562 INFO misc.py line 117 288342] Train: [2/50][1666/2344] Data 0.003 (0.003) Batch 0.657 (0.620) Remain 19:29:10 loss: 0.6544 Lr: 0.00191
[2025-05-11 13:58:56,159 INFO misc.py line 117 288342] Train: [2/50][1667/2344] Data 0.003 (0.003) Batch 0.596 (0.620) Remain 19:29:08 loss: 0.8181 Lr: 0.00191
[2025-05-11 13:58:56,799 INFO misc.py line 117 288342] Train: [2/50][1668/2344] Data 0.003 (0.003) Batch 0.641 (0.620) Remain 19:29:08 loss: 0.6267 Lr: 0.00191
[2025-05-11 13:58:57,496 INFO misc.py line 117 288342] Train: [2/50][1669/2344] Data 0.003 (0.003) Batch 0.696 (0.620) Remain 19:29:13 loss: 0.9389 Lr: 0.00191
[2025-05-11 13:58:58,105 INFO misc.py line 117 288342] Train: [2/50][1670/2344] Data 0.003 (0.003) Batch 0.610 (0.620) Remain 19:29:12 loss: 0.6658 Lr: 0.00191
[2025-05-11 13:58:58,661 INFO misc.py line 117 288342] Train: [2/50][1671/2344] Data 0.003 (0.003) Batch 0.555 (0.620) Remain 19:29:07 loss: 0.7935 Lr: 0.00191
[2025-05-11 13:58:59,124 INFO misc.py line 117 288342] Train: [2/50][1672/2344] Data 0.003 (0.003) Batch 0.463 (0.620) Remain 19:28:56 loss: 0.9515 Lr: 0.00191
[2025-05-11 13:58:59,717 INFO misc.py line 117 288342] Train: [2/50][1673/2344] Data 0.003 (0.003) Batch 0.593 (0.620) Remain 19:28:53 loss: 0.8113 Lr: 0.00191
[2025-05-11 13:59:00,258 INFO misc.py line 117 288342] Train: [2/50][1674/2344] Data 0.003 (0.003) Batch 0.541 (0.620) Remain 19:28:47 loss: 0.8491 Lr: 0.00191
[2025-05-11 13:59:00,842 INFO misc.py line 117 288342] Train: [2/50][1675/2344] Data 0.005 (0.003) Batch 0.584 (0.620) Remain 19:28:44 loss: 0.6849 Lr: 0.00191
[2025-05-11 13:59:01,592 INFO misc.py line 117 288342] Train: [2/50][1676/2344] Data 0.002 (0.003) Batch 0.750 (0.620) Remain 19:28:52 loss: 0.7523 Lr: 0.00191
[2025-05-11 13:59:02,234 INFO misc.py line 117 288342] Train: [2/50][1677/2344] Data 0.002 (0.003) Batch 0.643 (0.620) Remain 19:28:53 loss: 0.9157 Lr: 0.00191
[2025-05-11 13:59:02,823 INFO misc.py line 117 288342] Train: [2/50][1678/2344] Data 0.002 (0.003) Batch 0.589 (0.620) Remain 19:28:51 loss: 0.5607 Lr: 0.00191
[2025-05-11 13:59:03,554 INFO misc.py line 117 288342] Train: [2/50][1679/2344] Data 0.002 (0.003) Batch 0.731 (0.620) Remain 19:28:57 loss: 0.6741 Lr: 0.00191
[2025-05-11 13:59:04,062 INFO misc.py line 117 288342] Train: [2/50][1680/2344] Data 0.003 (0.003) Batch 0.508 (0.620) Remain 19:28:49 loss: 0.7056 Lr: 0.00191
[2025-05-11 13:59:04,843 INFO misc.py line 117 288342] Train: [2/50][1681/2344] Data 0.003 (0.003) Batch 0.781 (0.620) Remain 19:29:00 loss: 0.8424 Lr: 0.00191
[2025-05-11 13:59:05,398 INFO misc.py line 117 288342] Train: [2/50][1682/2344] Data 0.002 (0.003) Batch 0.555 (0.620) Remain 19:28:55 loss: 0.6702 Lr: 0.00191
[2025-05-11 13:59:05,897 INFO misc.py line 117 288342] Train: [2/50][1683/2344] Data 0.002 (0.003) Batch 0.499 (0.620) Remain 19:28:46 loss: 0.8434 Lr: 0.00191
[2025-05-11 13:59:06,508 INFO misc.py line 117 288342] Train: [2/50][1684/2344] Data 0.004 (0.003) Batch 0.610 (0.620) Remain 19:28:45 loss: 0.8481 Lr: 0.00191
[2025-05-11 13:59:07,210 INFO misc.py line 117 288342] Train: [2/50][1685/2344] Data 0.003 (0.003) Batch 0.702 (0.620) Remain 19:28:50 loss: 0.7467 Lr: 0.00191
[2025-05-11 13:59:07,854 INFO misc.py line 117 288342] Train: [2/50][1686/2344] Data 0.003 (0.003) Batch 0.644 (0.620) Remain 19:28:51 loss: 0.6910 Lr: 0.00191
[2025-05-11 13:59:08,474 INFO misc.py line 117 288342] Train: [2/50][1687/2344] Data 0.003 (0.003) Batch 0.620 (0.620) Remain 19:28:50 loss: 0.7521 Lr: 0.00191
[2025-05-11 13:59:09,127 INFO misc.py line 117 288342] Train: [2/50][1688/2344] Data 0.003 (0.003) Batch 0.653 (0.620) Remain 19:28:52 loss: 0.8180 Lr: 0.00191
[2025-05-11 13:59:09,793 INFO misc.py line 117 288342] Train: [2/50][1689/2344] Data 0.003 (0.003) Batch 0.665 (0.620) Remain 19:28:54 loss: 0.7047 Lr: 0.00191
